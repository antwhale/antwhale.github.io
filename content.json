{"pages":[{"title":"","date":"2021-02-20T15:30:20.361Z","path":"404.html","text":"layout: false 404"},{"title":"404 Page Not Found","date":"2017-08-04T15:36:59.000Z","path":"404.html","text":""},{"title":"文章标签","date":"2021-02-20T15:30:20.546Z","path":"tags/index.html","text":""},{"title":"文章分类","date":"2021-02-20T15:30:20.536Z","path":"categories/index.html","text":""},{"title":"About","date":"2021-02-25T15:52:24.077Z","path":"about/index.html","text":"about this blog转载一些好文章； 做一些读书笔记； 写一些技术博客； 记录一些雕虫小技； about me我是🐳Ant丶，Java程序猿一枚； 有时候很懒； 有时候很勤奋； 喜欢自由，爱好和平； 希望有一天可以赚很多很多的钱，然后去赚更多的钱； contract 小飞机：https://telegram.me/cayzlh 引导页：https://www.cayzlh.com 碎碎念：https://wwwcayzlh.com/diary Email：chenanyu@cayzlh.com GitHub：https://github.com/cayzlh GitHub Chart note本站内容用于记录生活与笔记，也会有转载或摘录的内容。 转载内容都会在文章末尾标出来源，如有侵犯，请联系我删除。"},{"title":"Tools","date":"2021-02-19T14:13:05.000Z","path":"tools/index.html","text":"实用的在线工具 Json在线工具 Markdown在线转换工具 在线HASH工具"},{"title":"Search","date":"2021-02-19T10:27:47.000Z","path":"search/index.html","text":""},{"title":"Links","date":"2020-05-26T15:04:29.000Z","path":"links/index.html","text":"STUDY justdopython - python技术 justdojava - Java极客技术 relatos - 一个分享故事的地方 tooool - 程序猿导航网站 GitHub-Chinese-Top-Charts - GitHub中文排行榜，帮助你发现高分优秀中文项目 Spring Cloud - Spring Cloud中文索引 Spring Boot - Spring Boot中文索引 MDN - Web开发技术 死磕Spring - 学习Spring源码 死磕Java并发 - 死磕Java并发精品合集 死磕Tomcat - 死磕Tomcat学习资料 advanced-java - 互联网 Java 工程师进阶知识完全扫盲 JavaGuide - Java学习 FRIENDS v2fy - 猫爪导航 Web橙 - 一颗爱分享技术橙纸 Kaciras’ Blog - 编程 • 生活 • 梦想 MINE GITHUB - 我的GitHub CAYZLH - 我的主页 DIARY - 碎碎念"}],"posts":[{"title":"SpringBoot文件上传异常处理","date":"2021-02-23T02:38:43.000Z","path":"2021/02/23/ab909668.html","text":"SpringBoot搭建的应用，一直工作得好好的，突然发现上传文件失败，提示org.springframework.web.multipart.MultipartException: Failed to parse multipart servlet request; nested exception is java.io.IOException: The temporary upload location [/tmp/tomcat.6239989728636105816.19530/work/Tomcat/localhost/ROOT] is not valid目录非法，实际查看目录，结果还真没有，下面就这个问题的表现，分析下SpringBoot针对文件上传的处理过程 问题分析堆栈分析问题定位，最佳的辅助手段就是堆栈分析，首先捞出核心的堆栈信息 org.springframework.web.multipart.MultipartException: Failed to parse multipart servlet request; nested exception is java.io.IOException: The temporary upload location [/tmp/tomcat.6239989728636105816.19530/work/Tomcat/localhost/ROOT] is not valid at org.springframework.web.multipart.support.StandardMultipartHttpServletRequest.handleParseFailure(StandardMultipartHttpServletRequest.java:122) at org.springframework.web.multipart.support.StandardMultipartHttpServletRequest.parseRequest(StandardMultipartHttpServletRequest.java:113) at org.springframework.web.multipart.support.StandardMultipartHttpServletRequest.&lt;init>(StandardMultipartHttpServletRequest.java:86) at org.springframework.web.multipart.support.StandardServletMultipartResolver.resolveMultipart(StandardServletMultipartResolver.java:93) at org.springframework.web.servlet.DispatcherServlet.checkMultipart(DispatcherServlet.java:1128) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:960) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:974) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:877) at javax.servlet.http.HttpServlet.service(HttpServlet.java:661) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:851) at javax.servlet.http.HttpServlet.service(HttpServlet.java:742) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) 从堆栈内容来看，问题比较清晰，目录非法，根据path路径，进入目录，结果发现，没有这个目录，那么问题的关键就是没有目录为什么会导致异常了，这个目录到底有啥用 先简单描述下上面的原因，上传的文件会缓存到本地磁盘，而缓存的路径就是上面的/tmp/tomcat.6239989728636105816.19530/work/Tomcat/localhost/ROOT，接着引入的疑问就是： 为什么上传的文件要缓存到本地 为什么临时目录会不存在 什么地方实现文件缓存 场景模拟要确认上面的问题，最直观的方法就是撸源码，直接看代码就有点蛋疼了，接下来采用debug方式来层层剥离，看下根源再哪里。 首先是搭建一个简单的测试项目，进行场景复现, 首先创建一个接收文件上传的Controller，如下 @RestController @RequestMapping(path = \"/file\") public class FileUploadRest { /** * 保存上传的文件 * * @param file * @return */ private String saveFileToLocal(MultipartFile file) { try { String name = \"/tmp/out_\" + System.currentTimeMillis() + file.getName(); FileOutputStream writer = new FileOutputStream(new File(name)); writer.write(file.getBytes()); writer.flush(); writer.close(); return name; } catch (Exception e) { e.printStackTrace(); return e.getMessage(); } } @PostMapping(path = \"upload\") public String upload(@RequestParam(\"file\") MultipartFile file) { String ans = saveFileToLocal(file); return ans; } } 其次就是使用curl来上传文件 curl http://127.0.0.1:8080/file/upload -F \"file=@/Users/user/Desktop/demo.jpg\" -v 然后在接收文件上传的方法中开启断点，注意下面红框中的 location, 就是文件上传的临时目录 源码定位上面的截图可以确认确实将上传的文件保存到了临时目录，验证方式就是进入那个目录进行查看，会看到一个tmp文件，接下来我们需要确定的是在什么地方，实现将数据缓存到本地的。 注意下图，左边红框是这次请求的完整链路，我们可以通过逆推链路，去定位可能实现文件缓存的地方 如果对spring和tomcat的源码不熟的话，也没什么特别的好办法，从上面的链路中，多打一些断点，采用传说中的二分定位方法来缩小范围。 通过最开始的request对象和后面的request对象分析，发现一个可以作为参考标准的就是上图中右边红框的request#parts属性；开始是null，文件保存之后则会有数据，下面给一个最终定位的动图 所以关键就是org.springframework.web.filter.HiddenHttpMethodFilter#doFilterInternal 中的 String paramValue = request.getParameter(this.methodParam); 这一行代码 到这里在单步进去，主要的焦点将集中在 org.apache.catalina.connector.Request#parseParts 进入上面方法的逻辑，很容易找到具体的实现位置 org.apache.tomcat.util.http.fileupload.FileUploadBase#parseRequest，这个方法的实现比较有意思，有必要贴出来看一下 public List&lt;FileItem> parseRequest(RequestContext ctx) throws FileUploadException { List&lt;FileItem> items = new ArrayList&lt;>(); boolean successful = false; try { FileItemIterator iter = getItemIterator(ctx); // 注意这里，文件工厂类，里面保存了临时目录的地址 // 这个对象首次是在 org.apache.catalina.connector.Request#parseParts 方法的 FileItemFactory fac = getFileItemFactory(); if (fac == null) { throw new NullPointerException(\"No FileItemFactory has been set.\"); } while (iter.hasNext()) { final FileItemStream item = iter.next(); // Don't use getName() here to prevent an InvalidFileNameException. final String fileName = ((FileItemIteratorImpl.FileItemStreamImpl) item).name; // 创建一个临时文件对象 FileItem fileItem = fac.createItem(item.getFieldName(), item.getContentType(), item.isFormField(), fileName); items.add(fileItem); try { // 流的拷贝，这块代码也挺有意思，将输入流数据写入输出流 // 后面会贴出源码，看下开源大佬们的玩法，和我们自己写的有啥区别 Streams.copy(item.openStream(), fileItem.getOutputStream(), true); } catch (FileUploadIOException e) { throw (FileUploadException) e.getCause(); } catch (IOException e) { throw new IOFileUploadException(String.format(\"Processing of %s request failed. %s\", MULTIPART_FORM_DATA, e.getMessage()), e); } final FileItemHeaders fih = item.getHeaders(); fileItem.setHeaders(fih); } successful = true; return items; } catch (FileUploadIOException e) { throw (FileUploadException) e.getCause(); } catch (IOException e) { throw new FileUploadException(e.getMessage(), e); } finally { if (!successful) { for (FileItem fileItem : items) { try { fileItem.delete(); } catch (Exception ignored) { // ignored TODO perhaps add to tracker delete failure list somehow? } } } } } 核心代码就两点，一个是文件工厂类，一个是流的拷贝；前者定义了我们的临时文件目录，也是我们解决前面问题的关键，换一个我自定义的目录永不删除，不就可以避免上面的问题了么；后面一个则是数据复用方面的 首先看下FileItemFactory的实例化位置，在org.apache.catalina.connector.Request#parseParts中，代码如下 具体的location实例化代码为 // TEMPDIR = \"javax.servlet.context.tempdir\"; location = ((File) context.getServletContext().getAttribute(ServletContext.TEMPDIR)); ##问题review ###解决问题 到上面，基本上就捞到了最终的问题，先看如何解决这个问题 方法1 应用重启 方法2 增加服务配置，自定义baseDir server.tomcat.basedir=/tmp/tomcat 方法3 注入bean，手动配置临时目录 @Bean MultipartConfigElement multipartConfigElement() { MultipartConfigFactory factory = new MultipartConfigFactory(); factory.setLocation(\"/tmp/tomcat\"); return factory.createMultipartConfig(); } 方法4 配置不删除tmp目录下的tomcat vim /usr/lib/tmpfiles.d/tmp.conf # 添加一行 x /tmp/tomcat.* 流拷贝tomcat中实现流的拷贝代码如下，org.apache.tomcat.util.http.fileupload.util.Streams#copy(java.io.InputStream, java.io.OutputStream, boolean, byte[]) , 看下面的实现，直观影响就是写得真特么严谨 public static long copy(InputStream inputStream, OutputStream outputStream, boolean closeOutputStream, byte[] buffer) throws IOException { OutputStream out = outputStream; InputStream in = inputStream; try { long total = 0; for (;;) { int res = in.read(buffer); if (res == -1) { break; } if (res > 0) { total += res; if (out != null) { out.write(buffer, 0, res); } } } if (out != null) { if (closeOutputStream) { out.close(); } else { out.flush(); } out = null; } in.close(); in = null; return total; } finally { IOUtils.closeQuietly(in); if (closeOutputStream) { IOUtils.closeQuietly(out); } } } ###自问自答 什么地方缓存文件 上面的定位过程给出答案，具体实现逻辑在 org.apache.tomcat.util.http.fileupload.FileUploadBase#parseRequest ####为什么目录会不存在 springboot启动时会创建一个/tmp/tomcat.*/work/Tomcat/localhost/ROOT的临时目录作为文件上传的临时目录，但是该目录会在n天之后被系统自动清理掉，这个清理是由linux操作系统完成的，具体的配置如下 vim /usr/lib/tmpfiles.d/tmp.conf # This file is part of systemd. # # systemd is free software; you can redistribute it and/or modify it # under the terms of the GNU Lesser General Public License as published by # the Free Software Foundation; either version 2.1 of the License, or # (at your option) any later version. # See tmpfiles.d(5) for details # Clear tmp directories separately, to make them easier to override v /tmp 1777 root root 10d v /var/tmp 1777 root root 30d # Exclude namespace mountpoints created with PrivateTmp=yes x /tmp/systemd-private-%b-* X /tmp/systemd-private-%b-*/tmp x /var/tmp/systemd-private-%b-* X /var/tmp/systemd-private-%b-*/tmp ####为什么要缓存文件 因为流取一次消费之后，后面无法再从流中获取数据，所以缓存方便后续复用；","tags":[{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cayzlh.com/tags/SpringBoot/"}],"categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cayzlh.com/categories/SpringBoot/"}]},{"title":"《Elasticsearch权威指南》-基础入门","date":"2021-01-05T07:40:41.000Z","path":"2021/01/05/d2d07489.html","text":"Elasticsearch 是一个实时的分布式搜索分析引擎，它能让你以前所未有的速度和规模，去探索你的数据。 它被用作全文检索、结构化搜索、分析以及这三个功能的组合。 Elasticsearch 中没有一个单独的组件是全新的或者是革命性的。全文搜索很久之前就已经可以做到了， 就像很早之前出现的分析系统和分布式数据库。 革命性的成果在于将这些单独的，有用的组件融合到一个单一的、一致的、实时的应用中。 Elasticsearch是什么Elasticsearch 是一个开源的搜索引擎，建立在一个全文搜索引擎库 Apache Lucene™ 基础之上。 Lucene 可以说是当下最先进、高性能、全功能的搜索引擎库—无论是开源还是私有。 但是 Lucene 仅仅只是一个库。为了充分发挥其功能，你需要使用 Java 并将 Lucene 直接集成到应用程序中。 更糟糕的是，您可能需要获得信息检索学位才能了解其工作原理。Lucene 非常 复杂。 Elasticsearch 也是使用 Java 编写的，它的内部使用 Lucene 做索引与搜索，但是它的目的是使全文检索变得简单， 通过隐藏 Lucene 的复杂性，取而代之的提供一套简单一致的 RESTful API。 然而，Elasticsearch 不仅仅是 Lucene，并且也不仅仅只是一个全文搜索引擎。 它可以被下面这样准确的形容： 一个分布式的实时文档存储，每个字段 可以被索引与搜索 一个分布式实时分析搜索引擎 能胜任上百个服务节点的扩展，并支持 PB 级别的结构化或者非结构化数据 Elasticsearch 将所有的功能打包成一个单独的服务，这样你可以通过程序与它提供的简单的 RESTful API 进行通信， 可以使用自己喜欢的编程语言充当 web 客户端，甚至可以使用命令行（去充当这个客户端）。 安装并运行Elasticsearch1、安装步骤参考Docker部署elasticsearch。 2、验证是否运行成功，在终端执行以下命令： curl 'http://localhost:9200/?pretty' 得到下面类似的响应则成功： { \"name\" : \"72Hw8Z7\", \"cluster_name\" : \"elasticsearch\", \"cluster_uuid\" : \"qjNWdKc2TtePsX9apDnatw\", \"version\" : { \"number\" : \"5.6.12\", \"build_hash\" : \"cfe3d9f\", \"build_date\" : \"2018-09-10T20:12:43.732Z\", \"build_snapshot\" : false, \"lucene_version\" : \"6.6.1\" }, \"tagline\" : \"You Know, for Search\" } 这就意味着你现在已经启动并运行一个 Elasticsearch 节点了，你可以用它做实验了。 单个 节点 可以作为一个运行中的 Elasticsearch 的实例。 而一个 集群 是一组拥有相同 cluster.name 的节点， 他们能一起工作并共享数据，还提供容错与可伸缩性。(当然，一个单独的节点也可以组成一个集群) 你可以在 elasticsearch.yml 配置文件中 修改 cluster.name ，该文件会在节点启动时加载 (译者注：这个重启服务后才会生效)。 与Elasticsearch交互集群内的原理数据输入和输出分布式文档存储搜索——最基本的工具映射与分析请求体查询排序与相关性执行分布式检索索引管理分片内部管理","tags":[],"categories":[{"name":"书籍","slug":"书籍","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/"},{"name":"《Elasticsearch权威指南》","slug":"书籍/《Elasticsearch权威指南》","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/%E3%80%8AElasticsearch%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E3%80%8B/"}]},{"title":"Docker部署elasticsearch","date":"2021-01-05T03:19:48.000Z","path":"2021/01/05/93edb835.html","text":"dockerhub找到elasticsearch镜像文档正常来说，按照elasticsearch上的文档提示，一步步操作即可。 1、拉取镜像 docker pull elasticsearch 2、创建用户定义的网络（可用于连接到连接到同一网络的其他服务（例如Kibana）） docker network create somenetwork 3、运行elasticsearch容器 docker run -d --name elasticsearch --net somenetwork -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" elasticsearch:tag 本地机器环境为 macOS ，在运行之后发现容器直接挂了，通过查看日志发现： 由于elasticsearch默认分配jvm空间大小为2g，内存不足以分配导致。 解决报错问题在启动命令中指定jvm大小来启动容器，添加-e ES_JAVA_OPTS=&quot;-Xms256m -Xmx256m&quot;参数。完整命令如下： docker run -d --name std-es --net esnetwork -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -e ES_JAVA_OPTS=\"-Xms256m -Xmx256m\" elasticsearch … 后续关于elasticsearch使用的问题也会维护在这篇文章之中","tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cayzlh.com/tags/Docker/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://www.cayzlh.com/tags/elasticsearch/"}],"categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Docker","slug":"微服务/Docker","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/Docker/"}]},{"title":"记关于Consul的一点使用笔记","date":"2020-10-30T16:07:20.000Z","path":"2020/10/31/51a1d996.html","text":"由于开发需要，需要在本地运行一个Consul环境，由于电脑上已经有Docker环境了，于是就直接在Docker里面搭一套Consul集群。 Docker搭建Consul集群 集群要求要有3个Server，将容器8500端口映射到主机8900端口，同时开启管理界面 搭建集群1. 启动第1个Server节点 docker run -d --name=consul1 -p 8500:8500 -e CONSUL_BIND_INTERFACE=eth0 consul:1.6.2 agent --server=true --bootstrap-expect=3 --client=0.0.0.0 -ui 2. 获取consul1的ip地址 JOIN_IP=\"$(docker inspect -f '{{.NetworkSettings.IPAddress}}' do1_consul1)\"; 3. 启动第2个Server节点，并加入集群 docker run -d --name=consul2 -e CONSUL_BIND_INTERFACE=eth0 consul:1.6.2 agent --server=true --client=0.0.0.0 --join $JOIN_IP 4. 启动第3个Server节点，并加入集群 docker run -d --name=consul3 -e CONSUL_BIND_INTERFACE=eth0 consul:1.6.2 agent --server=true --client=0.0.0.0 --join $JOIN_IP 5. 启动第4个Client节点，并加入集群 docker run -d --name=consul4 -e CONSUL_BIND_INTERFACE=eth0 consul:1.6.2 agent --server=false --client=0.0.0.0 --join $JOIN_IP 浏览器访问 http://localhost:8500验证是否部署成功。 导入kv1. 将kv.json复制到容器内 docker cp ~/Desktop/consul_kv.json consul1:/tmp 2. 导入kv.json docker exec consul1 consul kv import @/tmp/consul_kv.json IDEA跑服务注册到Consul遇到的坑consul集群跑起来之后，于是在IDEA跑SpringCloud项目注册到部署好的Consul服务，当服务注册好之后，检查其健康状态，发现服务一直提示All node checks passing报了个小红叉❌。 解决通过各种尝试都发解决之后，发现是因为在容器内部调用容器外（宿主机）的相应服务的时候网络不通，导致健康检查一直处于失败的状态，于是，修改SpringCloud工程的配置文件，新增配置： spring.cloud.consul.discovery.preferIpAddress=true spring.cloud.consul.discovery.ipAddress=docker.for.mac.host.internal 重新启动服务，各项检查都正常了。 以上操作环境是macOS，未在别的环境重现和解决这个问题。 容器内可以通过docker.for.mac.host.internal访问宿主机网络和端口。","tags":[{"name":"Consul","slug":"Consul","permalink":"https://www.cayzlh.com/tags/Consul/"}],"categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}]},{"title":"API签名验证方案","date":"2020-09-29T08:45:11.000Z","path":"2020/09/29/138fc827.html","text":"接口安全问题 请求身份是否合法？ 请求参数是否被篡改？ 请求是否唯一？ AccessKey&amp;SecretKey （开放平台）请求身份为开发者分配AccessKey（开发者标识，确保唯一）和SecretKey（用于接口加密，确保不易被穷举，生成算法不易被猜测）。 防止篡改参数签名 按照请求参数名的字母升序排列非空请求参数（包含AccessKey），使用URL键值对的格式（即key1=value1&amp;key2=value2…）拼接成字符串stringA； 在stringA最后拼接上Secretkey得到字符串stringSignTemp； 对stringSignTemp进行MD5运算，并将得到的字符串所有字符转换为大写，得到sign值。 请求携带参数AccessKey和Sign，只有拥有合法的身份AccessKey和正确的签名Sign才能放行。这样就解决了身份验证和参数篡改问题，即使请求参数被劫持，由于获取不到SecretKey（仅作本地加密使用，不参与网络传输），无法伪造合法的请求。 重放攻击虽然解决了请求参数被篡改的隐患，但是还存在着重复使用请求参数伪造二次请求的隐患。 timestamp+nonce方案 nonce指唯一的随机字符串，用来标识每个被签名的请求。通过为每个请求提供一个唯一的标识符，服务器能够防止请求被多次使用（记录所有用过的nonce以阻止它们被二次使用）。 然而，对服务器来说永久存储所有接收到的nonce的代价是非常大的。可以使用timestamp来优化nonce的存储。 假设允许客户端和服务端最多能存在15分钟的时间差，同时追踪记录在服务端的nonce集合。当有新的请求进入时，首先检查携带的timestamp是否在15分钟内，如超出时间范围，则拒绝，然后查询携带的nonce，如存在已有集合，则拒绝。否则，记录该nonce，并删除集合内时间戳大于15分钟的nonce（可以使用redis的expire，新增nonce的同时设置它的超时失效时间为15分钟）。 实现请求接口：http://api.test.com/test?name=hello&home=world&work=java 客户端 生成当前时间戳timestamp=now和唯一随机字符串nonce=random 按照请求参数名的字母升序排列非空请求参数（包含AccessKey)： stringA=&quot;AccessKey=access&amp;home=world&amp;name=hello&amp;work=java&amp;timestamp=now&amp;nonce=random&quot;; 拼接密钥SecretKey： stringSignTemp=&quot;AccessKey=access&amp;home=world&amp;name=hello&amp;work=java&amp;timestamp=now&amp;nonce=random&amp;SecretKey=secret&quot;; MD5并转换为大写： sign=MD5(stringSignTemp).toUpperCase(); 最终请求： http://api.test.com/test?name=hello&amp;home=world&amp;work=java&amp;timestamp=now&amp;nonce=nonce&amp;sign=sign; 服务端 Token&amp;AppKey（APP）在APP开放API接口的设计中，由于大多数接口涉及到用户的个人信息以及产品的敏感数据，所以要对这些接口进行身份验证，为了安全起见让用户暴露的明文密码次数越少越好，然而客户端与服务器的交互在请求之间是无状态的，也就是说，当涉及到用户状态时，每次请求都要带上身份验证信息。 Token身份验证 用户登录向服务器提供认证信息（如账号和密码），服务器验证成功后返回Token给客户端； 客户端将Token保存在本地，后续发起请求时，携带此Token； 服务器检查Token的有效性，有效则放行，无效（Token错误或过期）则拒绝。 安全隐患：Token被劫持，伪造请求和篡改参数。 Token+AppKey签名验证与上面开发平台的验证方式类似，为客户端分配AppKey（密钥，用于接口加密，不参与传输），将AppKey和所有请求参数组合成源串，根据签名算法生成签名值，发送请求时将签名值一起发送给服务器验证。这样，即使Token被劫持，对方不知道AppKey和签名算法，就无法伪造请求和篡改参数。再结合上述的重发攻击解决方案，即使请求参数被劫持也无法伪造二次重复请求。 实现登录和退出请求 后续请求 客户端 和上述开放平台的客户端行为类似，把AccessKey改为token即可。 服务端","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"}]},{"title":"核心处理层-SqlNode&SqlSource","date":"2020-08-21T08:43:42.000Z","path":"2020/08/21/bebe404d.html","text":"核心处理层以基础支持层为基础，实现了MyBatis的核心功能。这个部分将从MyBatis的初始化、动态SQL语句的解析、结果集的映射、参数解析以及SQL语句的执行等几个方面分析MyBatis的核心处理层，了解MyBatis的核心原理。 本篇介绍SqINode&amp;SqISource 映射配置文件中定义的SQL节点会被解析成MappedStatement对象，其中的SQL语句会被解析成SqlSource对象，SQL语句中定义的动态SQL节点、文本节点等，则由SqlNode接口的相应实现表示。 SqlSource接口的定义： public interface SqlSource { BoundSql getBoundSql(Object parameterObject); } SqlSource接口的实现类图： DynamicSqlSource负责处理动态SQL语句，RawSqlSource负责处理静态语句，两者最终都会将处理后的SQL语句封装成StaticSqlSource返回。 DynamicSqlSource与StaticSqlSource的主要区别： StaticSqlSource中记录的SQL语句中可能含有?占位符，但是可以直接提交给数据库执行 DynamicSqlSource中封装的SQL语句还需要进行一系列解析，才会最终形成数据库可执行的SQL语句 组合模式组合模式是将对象组合成树形结构，以表示部分-整体的层次结构(一般是树形结构)，用户可以像处理一个简单对象一样来处理一个复杂对象，从而使得调用者无须了解复杂元素的内部结构。 组合模式中的各模式如下： 抽象组件(Component) Component接口定义了树形结构中所有类的公共行为，例如这里的operation()方法。 一般情况下，其中还会定义一些用于管理子组件的方法，例如这里的add()、remove()、getChild()方法。 树叶(Leaf) Leaf在树形结构中表示叶节点对象，叶节点没有子节点。 树枝(Composite) 定义有子组件的那些组件的行为。该角色用于管理子组件，并通过operation()方法调用其管理的子组件的相关操作。 调用者(Client) 通过Component接口操纵整个树形结构。 组合模式主要有两点好处，首先组合模式可以帮助调用者屏蔽对象的复杂性。 对于调用者来说，使用整个树形结构与使用单个Component对象没有任何区别，也就是说，调用者并不必关心自己处理的是单个Component对象还是整个树形结构，这样就可以将调用者与复杂对象进行解耦。 另外，使用了组合模式之后，我们可以通过增加树中节点的方式，添加新的Component对象，从而实现功能上的扩展，这符合开放-封闭原则，也可以简化日后的维护工作。 组合模式在带来上述好处的同时，也会引入一些问题。 例如，有些场景下程序希望一个组合结构中只能有某些特定的组件，此时就很难直接通过组件类型进行限制(因为都是Component接口的实现类)，这就必须在运行时进行类型检测。而且，在递归程序中定位问题也是一件比较复杂的事情。 MyBatis在处理动态SQL节点时，应用到了组合设计模式。MyBatis会将动态SQL节点解析成对应的SqlNode实现，并形成树形结构。 OGNL表达式OGNL(Object Graphic Navigation Language，对象图导航语言)表达式在Struts、MyBatis等开源项目中有广泛的应用，其中Struts框架更是将OGNL作为默认的表达式语言。 在MyBatis中涉及的OGNL表达式的功能主要是：存取Java对象树中的属性、调用Java对象树中的方法等。 OGNL中的几个概念： 表达式 OGNL表达式执行的所有操作都是根据表达式解析得到的。 例如： 对象名.方法名表示调用指定对象的指定方法 @[类的完全限定名]@[静态方法或静态字段]表示调用指定类的静态方法或访问静态字段 OGNL表达式还可以完成变量赋值、操作集合等操作。 root对象 OGNL表达式指定了具体的操作，而root对象指定了需要操作的对象。 OgnlContext（上下文对象） OgnlContext类继承了Map接口，OgnlContext对象说白了也就是一个Map对象。 既然如此，OgnIContext对象中就可以存放除root对象之外的其他对象。 在使用OGNL表达式操作非root对象时，需要使用#前缀，而操作root对象则不需要使用#前缀。 在MyBatis中，使用OgnlCache对原生的OGNL进行了封装。OGNL表达式的解析过程是比较耗时的，为了提高效率，OgnlCache中使用expressionCache字段(静态成员，ConcurrentHashMap&lt;String,Object&gt;类型)对解析后的OGNL表达式进行缓存。 private static final Map&lt;String, Object> expressionCache = new ConcurrentHashMap&lt;String, Object>(); public static Object getValue(String expression, Object root) { try { Map&lt;Object, OgnlClassResolver> context = Ognl.createDefaultContext(root, new OgnlClassResolver()); return Ognl.getValue(parseExpression(expression), context, root); } catch (OgnlException e) { throw new BuilderException(\"Error evaluating expression '\" + expression + \"'. Cause: \" + e, e); } } private static Object parseExpression(String expression) throws OgnlException { Object node = expressionCache.get(expression); if (node == null) { node = Ognl.parseExpression(expression); expressionCache.put(expression, node); } return node; } DynamicContextDynamicContext主要用于记录解析动态SQL语句之后产生的SQL语句片段，可以认为它是一个用于记录动态SQL语句解析结果的容器。 其中有两个核心字段： // 参数上下文 private final ContextMap bindings; // 在SqlNode解析动态sql的时候，会将解析后的sql语句片段添加到该属性中保存，最终拼凑出一条完整的sql语句 private final StringBuilder sqlBuilder = new StringBuilder(); ContextMap是DynamicContext中定义的内部类，它实现了HashMap并重写了get()方法。 static class ContextMap extends HashMap&lt;String, Object> { private static final long serialVersionUID = 2977601501966151582L; // 将用户传的参数封装成MetaObject对象 private MetaObject parameterMetaObject; public ContextMap(MetaObject parameterMetaObject) { this.parameterMetaObject = parameterMetaObject; } @Override public Object get(Object key) { String strKey = (String) key; if (super.containsKey(strKey)) { return super.get(strKey); } if (parameterMetaObject != null) { // issue #61 do not modify the context when reading return parameterMetaObject.getValue(strKey); } return null; } } DynamicContext的构造方法会初始化bindings集合，注意构造方法的第二个参数pammeterObject，它是运行时用户传入的参数，其中包含了后续用于替换#{}占位符的实参。 public DynamicContext(Configuration configuration, Object parameterObject) { if (parameterObject != null &amp;&amp; !(parameterObject instanceof Map)) { // 对于不是Map类型的参数，会创装MetaObject对象，并封装成ContextMap对象 MetaObject metaObject = configuration.newMetaObject(parameterObject); bindings = new ContextMap(metaObject); } else { bindings = new ContextMap(null); } bindings.put(PARAMETER_OBJECT_KEY, parameterObject); bindings.put(DATABASE_ID_KEY, configuration.getDatabaseId()); } SqlNode接下来看看SqlNode的实现类是如何解析其对应的SQL节点。 public interface SqlNode { // apply()是SqlNode接口中定义的唯一方法，该方法会根据用户传入的实参，参数解析该SqlNode所 // 记录的动态SQL节点，并调用DynamicContext.appendSql()方法将解析后的SQL片段追加到 // DynamicContext.sqlBuilder中保存 // 当SQL节点下的所有SqlNode完成解析后，我们就可以从DynamicContext中获取一条动态生成的、 // 完整的SQL语句 boolean apply(DynamicContext context); } SqlNode接口有多个实现类，每个实现类对应一个动态SQL节点。按照组合模式的角色来划分，SqlNode扮演了抽象组件的角色，MixedSqlNode扮演了树枝节点的角色，TextSqlNode节点扮演了树叶节点的角色等等。 1、StaticTextSqINode&amp;MixedSqINode StaticTextSqINode中使用text字段(String类型)记录了对应的非动态SQL语句节点，其apply()方法直接将text字段追加到DynamicContext.sqlBuilder字段中。 MixedSqINode中使用contents字段(List&lt;SqlNode&gt;类型)记录其子节点对应的SqlNode对象集合，其apply()方法会循环调用contents集合中所有SqlNode对象的apply()方法。 2、TextSqlNode TextSqlNode表示的是包含占位符的动态SQL节点。TextSqlNode.apply()方法会使用GenericTokenParser解析${}占位符，并直接替换成用户给定的实际参数值。 @Override public boolean apply(DynamicContext context) { // 创建GenericTokenParser解析器， GenericTokenParser parser = createParser(new BindingTokenParser(context, injectionFilter)); // 将解析后的SQL片段添加到DynamicContext中 context.appendSql(parser.parse(text)); return true; } private GenericTokenParser createParser(TokenHandler handler) { return new GenericTokenParser(\"${\", \"}\", handler); } BindingTokenParser是TextSqlNode中定义的内部类，继承了TokenHandler接口，它的主要功能是根据DynamicContext.bindings集合中的信息解析SQL语句节点中的${}占位符。BindingTokenParser.context字段指向了对应的DynamicContext对象。 private static class BindingTokenParser implements TokenHandler { private DynamicContext context; private Pattern injectionFilter; public BindingTokenParser(DynamicContext context, Pattern injectionFilter) { this.context = context; this.injectionFilter = injectionFilter; } @Override public String handleToken(String content) { Object parameter = context.getBindings().get(\"_parameter\"); if (parameter == null) { context.getBindings().put(\"value\", null); } else if (SimpleTypeRegistry.isSimpleType(parameter.getClass())) { context.getBindings().put(\"value\", parameter); } Object value = OgnlCache.getValue(content, context.getBindings()); String srtValue = (value == null ? \"\" : String.valueOf(value)); // issue #274 return \"\" instead of \"null\" checkInjection(srtValue); return srtValue; } private void checkInjection(String value) { if (injectionFilter != null &amp;&amp; !injectionFilter.matcher(value).matches()) { throw new ScriptingException(\"Invalid input. Please conform to regex\" + injectionFilter.pattern()); } } } 3、IfSqlNode IfSqlNode对应的动态SQL节点是&lt;if&gt;节点，以下是几个核心字段。 // 用于解析if节点的test表达式的值 private final ExpressionEvaluator evaluator; // 记录了test表达式 private final String test; // 记录子节点 private final SqlNode contents; IfSqlNode.apply()方法首先会通过ExpressionEvaluator.evaluateBoolean()方法检测其test表达式是否为true，然后根据test表达式的结果，决定是否执行其子节点的apply()方法。 @Override public boolean apply(DynamicContext context) { if (evaluator.evaluateBoolean(test, context.getBindings())) { contents.apply(context); return true; } return false; } public boolean evaluateBoolean(String expression, Object parameterObject) { Object value = OgnlCache.getValue(expression, parameterObject); if (value instanceof Boolean) { return (Boolean) value; } if (value instanceof Number) { return new BigDecimal(String.valueOf(value)).compareTo(BigDecimal.ZERO) != 0; } return value != null; } 4、TrimSqINode&amp;WhereSqINode&amp;SetSqINode TrimSqlNode会根据子节点的解析结果，添加或删除相应的前缀或后缀。其中几个字段如下： // 记录子节点 private final SqlNode contents; // SQL语句添加的前缀 private final String prefix; // SQL语句添加的后缀 private final String suffix; // private final List&lt;String> prefixesToOverride; private final List&lt;String> suffixesToOverride; 在TrimSqlNode的构造函数中，会调用parseOverrides()方法对参数prefixesToOverride(对应&lt;trim&gt;节点的prefixOverrides属性)和参数suffixesToOverride(对应&lt;trim&gt;节点的suffixOverrides属性)进行解析，并初始化prefixesToOverride和sufflxesToOverride。 private static List&lt;String> parseOverrides(String overrides) { if (overrides != null) { final StringTokenizer parser = new StringTokenizer(overrides, \"|\", false); final List&lt;String> list = new ArrayList&lt;String>(parser.countTokens()); while (parser.hasMoreTokens()) { list.add(parser.nextToken().toUpperCase(Locale.ENGLISH)); } return list; } return Collections.emptyList(); } TrimSqlNode.apply()方法首先解析子节点，然后根据子节点的解析结果处理前缀和后缀。 public boolean apply(DynamicContext context) { // 创建FilteredDynamicContext对象，其中封装了DynamicContext FilteredDynamicContext filteredDynamicContext = new FilteredDynamicContext(context); // 调用子节点的apply方法进行解析 boolean result = contents.apply(filteredDynamicContext); // 处理前缀和后缀 filteredDynamicContext.applyAll(); return result; } 处理前缀和后缀的主要逻辑是在FilteredDynamicContext中实现的，它继承了DynamicContext，同时也是DynamicContext的代理类。 FilteredDynamicContext除了将对应方法调用委托给其中封装的DynamicContext对象，还提供了处理前缀和后缀的applyAll()方法。 private class FilteredDynamicContext extends DynamicContext { // 底层封装的DynamicContext对象 private DynamicContext delegate; // 是否已经处理过前缀和后缀 private boolean prefixApplied; private boolean suffixApplied; // 记录子节点解析过后的结果 private StringBuilder sqlBuffer; // ... // ... public void applyAll() { // 获取子节点解析过后的结果，并全部转换为大写 sqlBuffer = new StringBuilder(sqlBuffer.toString().trim()); String trimmedUppercaseSql = sqlBuffer.toString().toUpperCase(Locale.ENGLISH); if (trimmedUppercaseSql.length() > 0) { applyPrefix(sqlBuffer, trimmedUppercaseSql);// 处理前缀 applySuffix(sqlBuffer, trimmedUppercaseSql);// 处理后缀 } delegate.appendSql(sqlBuffer.toString()); } // ... // ... // 处理前缀 private void applyPrefix(StringBuilder sql, String trimmedUppercaseSql) { if (!prefixApplied) { prefixApplied = true; if (prefixesToOverride != null) { for (String toRemove : prefixesToOverride) { if (trimmedUppercaseSql.startsWith(toRemove)) { sql.delete(0, toRemove.trim().length()); break; } } } if (prefix != null) { sql.insert(0, \" \"); sql.insert(0, prefix); } } } // 处理后缀 private void applySuffix(StringBuilder sql, String trimmedUppercaseSql) { if (!suffixApplied) { suffixApplied = true; if (suffixesToOverride != null) { for (String toRemove : suffixesToOverride) { if (trimmedUppercaseSql.endsWith(toRemove) || trimmedUppercaseSql.endsWith(toRemove.trim())) { int start = sql.length() - toRemove.trim().length(); int end = sql.length(); sql.delete(start, end); break; } } } if (suffix != null) { sql.append(\" \"); sql.append(suffix); } } } } WhereSqlNode和SetSqlNode都继承了TrimSqlNode。 其中WhereSqlNode指定了prefix字段为WHERE，prefixesToOverride集合中的项为AND和OR，suffix字段和suffixesToOverride集合为null。也就是说，&lt;where&gt;节点解析后的SQL语句片段如果以AND或OR开头，则将开头处的AND或OR删除，之后再将WHERE关键字添加到SQL片段开始位置，从而得到该&lt;where&gt;节点最终生成的SQL片段。 SetSqlNode指定了prefix字段为SET，suffixesToOverride集合中的项只有suffix字段和prefixesToOverride集合为null。也就是说，&lt;set&gt;节点解析后的SQL语句片段如果以,结尾，则将结尾处的删除掉，之后再将SET关键字添加到SQL片段的开始位置，从而得到该&lt;set&gt;节点最终生成的SQL片段。 5、ForeachSqINode 在动态SQL语句中构建IN条件语句的时候，通常需要对一个集合进行迭代，MyBatis提供了&lt;foreach&gt;标签实现该功能。在使用&lt;foreach&gt;标签迭代集合时，不仅可以使用集合的元素和索引值，还可以在循环开始之前或结束之后添加指定的字符串，也允许在迭代过程中添加指定的分隔符。 解析&lt;foreach&gt;节点对应的sqlnode实现类是ForeachSqlNode，以下是其中定义的字段： // 用于判断循环的终止条件，ForeachSqlNode构造方法中会创建该对象 private final ExpressionEvaluator evaluator; // 迭代的集合表达式 private final String collectionExpression; // 子节点 private final SqlNode contents; // 循环开始前要添加的字符串 private final String open; // 循环结束时要添加的字符串 private final String close; // 分隔符 private final String separator; // 本次迭代的元素 private final String item; // 当前迭代的次数 private final String index; // 配置 private final Configuration configuration; ForeachSqINode中有两个内部类，分别是PrefixedContext和FilteredDynamicContext，它们都继承了DynamicContext，同时也都是DynamicContext的代理类。 PreFixedContext private class PrefixedContext extends DynamicContext { private final DynamicContext delegate; private final String prefix; // 是否已经处理过前缀 private boolean prefixApplied; // ... @Override public void appendSql(String sql) { if (!prefixApplied &amp;&amp; sql != null &amp;&amp; sql.trim().length() > 0) { // 是否需要追加前缀 delegate.appendSql(prefix); // 追加前缀 prefixApplied = true; } delegate.appendSql(sql); // 追加sql } } FilteredDynamicContext FilteredDynamicContext负责处理#{}占位符，但它并未完全解析#{}占位符。 private static class FilteredDynamicContext extends DynamicContext { // DynamicContext对象 private final DynamicContext delegate; // 索引位置 private final int index; // 对应集合项的index private final String itemIndex; private final String item; // ... @Override public void appendSql(String sql) { GenericTokenParser parser = new GenericTokenParser(\"#{\", \"}\", new TokenHandler() { @Override public String handleToken(String content) { String newContent = content.replaceFirst(\"^\\\\s*\" + item + \"(?![^.,:\\\\s])\", itemizeItem(item, index)); if (itemIndex != null &amp;&amp; newContent.equals(content)) { newContent = content.replaceFirst(\"^\\\\s*\" + itemIndex + \"(?![^.,:\\\\s])\", itemizeItem(itemIndex, index)); } return new StringBuilder(\"#{\").append(newContent).append(\"}\").toString(); } }); delegate.appendSql(parser.parse(sql)); } @Override public int getUniqueNumber() { return delegate.getUniqueNumber(); } } 6、ChooseSqlNode 如果在编写动态SQL语句时需要类似Java中的switch语句的功能，可以考虑使用&lt;choose&gt;、&lt;when&gt;和&lt;otherwise&gt;三个标签的组合。MyBatis会将&lt;choose&gt;标签解析成ChooseSqlNode，将&lt;when&gt;标签解析成IfSqlNode，将&lt;otherwise&gt;标签解析成MixedSqlNode。 ChooseSqlNode.apply()方法的逻辑比较简单，首先遍历ifSqlNodes集合并调用其中SqlNode对象的apply()方法，然后根据前面的处理结果决定是否调用defaultSqlNode的apply()方法。 7、VarDecISqINode VarDeclSqlNode表示的是动态SQL语句中的&lt;bind&gt;节点,该节点可以从OGNL表达式中创建一个变量并将其记录到上下文中。 在VarDecISqINode中通过name字段记录&lt;bind&gt;节点的name属性值，expression字段记录&lt;bind&gt;节点的value属性值。 SqlSourceBuilder在经过SqlNode.apply()方法的解析之后，SQL语句会被传递到SqlSourceBuilder中进行进一步的解析。 SqISourceBuilder主要完成了两方面的操作，一方面是解析SQL语句中的#{}占位符中定义的属性，格式类似于#{__frc_item_0,javaType=int,jdbcType=NUMERIC,typeHandler=MyTypeHandler}，另一方面是将SQL语句中的#{}占位符替换成?占位符。 SqlSourceBuilder也是BaseBuilder的子类之一，其核心逻辑位于parse()方法中。 public SqlSource parse( String originalSql, Class&lt;?> parameterType, Map&lt;String, Object> additionalParameters) { // 第一个参数是经过SqlNode.apply()方法处理之后的sql语句 // 第二个参数是用户传入的实参类型 // 第三个参数记录了形参与实参的对应关系，其实就是经过SqlNode.apply()方法处理后的DynamicContext.bindings集合 // 创建ParameterMappingTokenHandler对象， 它是解析#{}占位符中的参数属性以及替换占位符的核心 ParameterMappingTokenHandler handler = new ParameterMappingTokenHandler(configuration, parameterType, additionalParameters); // 配合ParameterMappingTokenHandler解析占位符 GenericTokenParser parser = new GenericTokenParser(\"#{\", \"}\", handler); String sql = parser.parse(originalSql); return new StaticSqlSource(configuration, sql, handler.getParameterMappings()); } DynamicSqlSourceDynamicSqlSource负责解析动态SQL语句，也是最常用的Sqlource实现之一。SqlNode中使用了组合模式，形成了一个树状结构，DynamicSqlSource中使用rootSqlNode字段(SqlNode类型)记录了待解析的SqlNode树的根节点。 DynamicSqlSource.getBoundSql()方法： public BoundSql getBoundSql(Object parameterObject) { // 创建DynamicContext对象 DynamicContext context = new DynamicContext(configuration, parameterObject); // 通过调用rootSqlNode.apply()方法调用整个树形结构中全部SqlNode.apply()方法。 // 每个SqlNode的apply()方法都将解析得到的SQL语句片段追加到context中， // 最终通过context.getSql()得到完整的SQL语句 rootSqlNode.apply(context); SqlSourceBuilder sqlSourceParser = new SqlSourceBuilder(configuration); Class&lt;?> parameterType = parameterObject == null ? Object.class : parameterObject.getClass(); SqlSource sqlSource = sqlSourceParser.parse(context.getSql(), parameterType, context.getBindings()); // 创建BoundSql对象，并将DynamicContext.bindings中的参数信息复制到其 BoundSql boundSql = sqlSource.getBoundSql(parameterObject); for (Map.Entry&lt;String, Object> entry : context.getBindings().entrySet()) { boundSql.setAdditionalParameter(entry.getKey(), entry.getValue()); } return boundSql; } RawSqISourceRawSqISource是SqlSource的另一个实现，其逻辑与DynamicSqlSource类似，但是执行时机不一样，处理的SQL语句类型也不一样。 前面介绍XMLScriptBuilder.parseDynamicTags()方法时提到过，如果节点只包含#{}占位符，而不包含动态SQL节点或未解析的${}占位符的话，则不是动态SQL语句，会创建相应的StaticTextSqlNode对象。 在XMLScriptBuilder.parseScriptNode()方法中会判断整个SQL节点是否为动态的，如果不是动态的SQL节点，则创建相应的RawSqlSource对象。 RawSqlSource在构造方法中首先会调用getSql()方法，其中通过调用SqlNode.apply()方法完成SQL语句的拼装和初步处理；之后会使用SqlSourceBuilder完成占位符的替换和ParameterMapping集合的创建，并返回StaticSqlSource对象。 public class RawSqlSource implements SqlSource { private final SqlSource sqlSource; public RawSqlSource(Configuration configuration, SqlNode rootSqlNode, Class&lt;?> parameterType) { // 调用getsql()方法，完成SQL语句的拼装和初步解析 this(configuration, getSql(configuration, rootSqlNode), parameterType); } public RawSqlSource(Configuration configuration, String sql, Class&lt;?> parameterType) { SqlSourceBuilder sqlSourceParser = new SqlSourceBuilder(configuration); Class&lt;?> clazz = parameterType == null ? Object.class : parameterType; sqlSource = sqlSourceParser.parse(sql, clazz, new HashMap&lt;String, Object>()); } private static String getSql(Configuration configuration, SqlNode rootSqlNode) { DynamicContext context = new DynamicContext(configuration, null); rootSqlNode.apply(context); return context.getSql(); } @Override public BoundSql getBoundSql(Object parameterObject) { return sqlSource.getBoundSql(parameterObject); } } 无论是StaticSqlSource、DynamicSqlSource还是RawSqlSource，最终都会统一生成BoundSql对象，其中封装了完整的SQL语句(可能包含?占位符)、参数映射关系(parameterMappings集合)以及用户传入的参数(additionalParameters集合)。 另外，DynamicSqlSource负责处理动态SQL语句，RawSqlSource负责处理静态SQL语句，除此之外，两者解析SQL语句的时机也不一样，前者的解析时机是在实际执行SQL语句之前，而后者则是在MyBatis初始化时完成SQL语句的解析。 参考 《MyBatis技术内幕》 部分图片来源——《MyBatis技术内幕》","tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://www.cayzlh.com/tags/MyBatis/"},{"name":"《MyBatis技术内幕》","slug":"《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/tags/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"},{"name":"核心处理层","slug":"核心处理层","permalink":"https://www.cayzlh.com/tags/%E6%A0%B8%E5%BF%83%E5%A4%84%E7%90%86%E5%B1%82/"}],"categories":[{"name":"书籍","slug":"书籍","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/"},{"name":"《MyBatis技术内幕》","slug":"书籍/《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"}]},{"title":"Spring Boot 2.3.3 稳定版发布！","date":"2020-08-15T08:40:38.000Z","path":"2020/08/15/c4d21d93.html","text":"Spring Boot 2.3.3 稳定版已发布，可从 repo.spring.io 和 Maven Central 获取。 &lt;parent> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-parent&lt;/artifactId> &lt;version>2.3.3.RELEASE&lt;/version> &lt;relativePath/> &lt;/parent> 此版本包括总计 67 处 bugfix、功能增强、文档改进和依赖升级。 新特性 在 Spring Boot 中应用 HTTP/2 不再要求强制 Jetty 和 Conscrypt 绑定使用 #22188 Bugfix 修复外部化配置会忽略 SPRING_APPLICATION_JSON 中的 null 值的问题 #22895 修复带’-‘的遗留端点 ID 无法完全迁移的问题 #22849 当 Reactor 的调试代理未能初始化时，失败的原因将被丢弃 #22847 修复当环境存在空属性时，OCI 镜像构建失败的问题 #22703 修复 LiquibaseEndpoint 没有报告来自父级上下文(ancestor contexts)的变化集 #22686 修复应由其他 DispatcherServlet 处理的请求导致出现 404 响应的问题 #22682 修复使用 war 部署的页面无法处理异步异常的问题 #22672 修复 XADataSourceAutoConfiguration 很难与 DB2XADataSource 搭配使用的问题，因为它没有 URL 属性 #22641 在配置等待终止期时，TaskExecutorBuilder 只使用秒级精度 #22611 修复在 @ConfigurationProperties 上设置 ignoreInvalidFields=true 会导致未知字段也被忽略的问题 #22585 Spring Boot 2.3.2: 如果使用 SpyBean，将为每个 IT class 创建新的上下文 #22583 修复后台预初始化可能会导致 Jackson2ObjectMapperBuilder 的 Kotlin 检测警告被静默移除的问题 #22580 修复 UndertowWebServerFactoryCustomizer 不支持 Options，只支持 UndertowOptions 的问题 #22578 修复 WebMvcTest 和 WebFluxTest 不引入 Jackson Module bean 的问题 #22576 CouchbaseCacheManager 不能再使用 CacheManagerCustomizer 进行定制 #22573 修复 Kubernetes readiness 探测端点返回 404 的问题 #22562 修复 CouchbaseCacheConfiguration 排序不正确的问题 #22542 修复在 2.3.1 中，使用 nullValue 编译器选项的 MustacheEnvironmentCollector 不再运行的问题 #22039 除此之外还升级了多项依赖，详情查看文档。","tags":[{"name":"Spring, SpringBoot","slug":"Spring-SpringBoot","permalink":"https://www.cayzlh.com/tags/Spring-SpringBoot/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"}]},{"title":"核心处理层-MyBatis初始化","date":"2020-06-22T01:09:42.000Z","path":"2020/06/22/c499e157.html","text":"核心处理层以基础支持层为基础，实现了MyBatis的核心功能。这个部分将从MyBatis的初始化、动态SQL语句的解析、结果集的映射、参数解析以及SQL语句的执行等几个方面分析MyBatis的核心处理层，了解MyBatis的核心原理。 本篇介绍MyBatis的初始化 在MyBatis初始化的过程中，除了会读取mybatis-config.xml配置文件以及映射配置文件，还会加载配置文件指定的类，处理类中的注解，创建一些配置对象，最终完成框架中各个模块的初始化。 另外，也可以使用JavaAPI的方式对MyBatis进行配置，这种硬编码的配置方式主要用在配置量比较少且配置信息不常变化的场景下。 建造者模式在MyBatis处理mybatis-config.xml以及映射配置文件时，会在内存中创建相应的配置对象，该过程的设计使用到建造者模式的相关知识。 建造者模式中的主要角色如下： 建造者(Builder)接口 Builder接口用于定义建造者构建产品对象的各部分的行为。 具体建造者(ConcreteBuilder)角色 在建造者模式中，直接创建产品对象的是具体建造者。具体建造者类必须实现建造者接口所要求的两类方法： 一类是建造方法，如上图中的buildPart1()、buildPart2()等方法。 另一类是获取构建好的产品对象的方法，如上图中的getProduct()方法。 导演(Director)角色 该角色会通过调用具体建造者， 创建需要的产品对象 产品(Product)角色 产品对象就是用户需要使用的复杂对象 建造者模式的优点： 建造者模式中的导演角色并不需要知晓产品类的内部细节，它只提供需要的信息给建造者，由具体建造者处理这些信息(这个处理过程可能会比较复杂)并完成产品构造。这就使产品对象的上层代码与产品对象的创建过程解耦。 建造者模式将复杂产品的创建过程分散到了不同的构造步骤中，这样可以对产品创建过程实现更加精细的控制，也会使创建过程更加清晰。 每个具体建造者都可以创建出完整的产品对象，而且具体建造者之间是相互独立的，因此系统就可以通过不同的具体建造者，得到不同的产品对象。当有新产品出现时，无须修改原有的代码，只需要添加新的具体建造者即可完成扩展，这符合开放-封闭原则。 建造者模式也有一些缺点，它所创建的产品一般具有较多的共同点，其组成部分相似，如果产品之间的差异性很大，则不适合使用建造者模式。 如果产品种类较多，且内部变化复杂，就需要定义多个具体建造者类来实现这种变化，导致整个系统变得很复杂，不易于理解。 BaseBuilderMyBatis初始化的主要工作是加载并解析mybatis-config.xml配置文件、映射配置文件以及相关的注解信息。MyBatis的初始化入口是SqlSessionFactoryBuilder.build()方法，其具体实现如下: public SqlSessionFactory build(Reader reader, String environment, Properties properties) { try { // 读取配置文件 XMLConfigBuilder parser = new XMLConfigBuilder(reader, environment, properties); // 解析配置文件得到Configuration对象，创建DefaultSqlSessionFactory对象 return build(parser.parse()); } catch (Exception e) { throw ExceptionFactory.wrapException(\"Error building SqlSession.\", e); } finally { ErrorContext.instance().reset(); try { reader.close(); } catch (IOException e) { // Intentionally ignore. Prefer previous error. } } } SqlSessionFactoryBuilder.build()方法会创建XMLConfigBuilder对象来解析mybatis-config.xml配置文件，而XMLConfigBuilder继承自BaseBuilder抽象类。 MyBatis的初始化过程使用了建造者模式，这里的BaseBuilder抽象类就扮演着建造者接口的角色。BaseBuilder中核心字段的含义如下： // Configuration是MyBatis初始化过程的核心对象，MyBatis中几乎全部的配置信息都会保存到Configuration中 // Configuration对象是在MyBatis初始化过程中创建且是全局唯一的（all-in-one配置对象）。 protected final Configuration configuration; // 在mybatis-config.xml配置文件中可以使用&lt;typeAliases>标签定义别名，这些定义的别名都会记录在 // TypeAliasRegistry对象中 protected final TypeAliasRegistry typeAliasRegistry; // 在mybatis-config.xml配置文件中可以使用&lt;typeHandlers>标签添加自定义TypeHandler器， // 完成指定数据库类型与Java类型的转换，这些TypeHandler都会记录在TypeHandlerRegistry中 protected final TypeHandlerRegistry typeHandlerRegistry; BaseBuilder中记录的TypeAliasRegistry对象和TypeHandlerRegistry对象，其实是全局唯一的，它们都是在Configuration对象初始化时创建的。 Configuration类中定义了这两个字段： protected final TypeHandlerRegistry typeHandlerRegistry = new TypeHandlerRegistry(); protected final TypeAliasRegistry typeAliasRegistry = new TypeAliasRegistry(); 在BaseBuilder构造函数中，通过相应的Configuration.get*()方法得到TypeAliasRegistry对象和TypeHandlerRegistry对象，并赋值给BaseBuilder相应字段。 BaseBuilder.resolveAlias()方法依赖TypeAliasRegistry解析别名，BaseBuilder.resolveTypeHandler()方法依赖TypeHandlerRegistry查找指定的TypeHandler对象。 MyBatis使用JdbcType枚举类型表示JDBC类型。MyBatis中常用的枚举类型还有ResultSetType和ParameterMode:ResultSetType枚举类型表示结果集类型，使用ParameterMode枚举类型表示存储过程中的参数类型。 在BaseBuilder中提供了相应的resolveJdbcType()、resolveResultSetType()、resolveParameterMode()方法，将String转换成对应的枚举对象。 XMLConfigBuilderXMLConfigBuilder是BaseBuilder的众多子类之一，它扮演的是具体建造者的角色。XMLConfigBuilder主要负责解析mybatis-config.xml配置。 核心字段： // 标识是否已经解析过mybatis-config.xml文件 private boolean parsed; // 用于解析mybatis-config.xml配置文件的XpathParser对象 private final XPathParser parser; // 标识 &lt;environment> 配置的名称， 默认读取&lt;environment>标签的默认值 private String environment; // 负责创建和缓存Reflector对象 private final ReflectorFactory localReflectorFactory = new DefaultReflectorFactory(); XMLConfigBuilder.parse()方法是解析mybatis-config.xml配置文件的入口，它通过调用XMLConfigBuilder.parseConfiguration()方法实现整个解析过程。 public Configuration parse() { if (parsed) { // 根据parsed变量的值判断是否已经完成了对mybatis-config.xml配置文件的解析 throw new BuilderException(\"Each XMLConfigBuilder can only be used once.\"); } parsed = true; // 找到 configuration 节点，开始解析 parseConfiguration(parser.evalNode(\"/configuration\")); return configuration; } private void parseConfiguration(XNode root) { try { // 解析properties节点 propertiesElement(root.evalNode(\"properties\")); // 解析settings节点 Properties settings = settingsAsProperties(root.evalNode(\"settings\")); loadCustomVfs(settings); typeAliasesElement(root.evalNode(\"typeAliases\")); pluginElement(root.evalNode(\"plugins\")); objectFactoryElement(root.evalNode(\"objectFactory\")); objectWrapperFactoryElement(root.evalNode(\"objectWrapperFactory\")); reflectorFactoryElement(root.evalNode(\"reflectorFactory\")); settingsElement(settings); // read it after objectFactory and objectWrapperFactory issue #631 environmentsElement(root.evalNode(\"environments\")); databaseIdProviderElement(root.evalNode(\"databaseIdProvider\")); typeHandlerElement(root.evalNode(\"typeHandlers\")); mapperElement(root.evalNode(\"mappers\")); } catch (Exception e) { throw new BuilderException(\"Error parsing SQL Mapper Configuration. Cause: \" + e, e); } } 解析&lt;properties&gt;节点 XMLConfigBuilder.propertiesElement()方法会解析mybatis-config.xml配置文件中的properties节点并形成java.util.Properties对象，之后将该Properties对象设置到XPathParser和Configuration的variables字段中。在后面的解析过程中，会使用该Properties对象中的信息替换占位符。 private void propertiesElement(XNode context) throws Exception { if (context != null) { // 解析&lt;properties>的子节点（&lt;property>标签）的name和value属性， 并记录到Properties中 Properties defaults = context.getChildrenAsProperties(); // 解析&lt;properties>的resource和url属性，这两个属性用于确定properties配置文件的位置 String resource = context.getStringAttribute(\"resource\"); String url = context.getStringAttribute(\"url\"); // resource和url属性不能同时存在，否则抛出异常 if (resource != null &amp;&amp; url != null) { throw new BuilderException(\"...\"); } if (resource != null) { defaults.putAll(Resources.getResourceAsProperties(resource)); } else if (url != null) { defaults.putAll(Resources.getUrlAsProperties(url)); } Properties vars = configuration.getVariables(); if (vars != null) { defaults.putAll(vars); } // 更新XPathParser和Configuration的variables字段 parser.setVariables(defaults); configuration.setVariables(defaults); } } 解析&lt;settings&gt;节点 XMLConfigBuilder.settingsAsProperties()方法负责解析settings节点，在settings点下的配置是MyBatis全局性的配置，它们会改变MyBatis的运行时行为，需要注意的是，在MyBatis初始化时，这些全局配置信息都会被记录到Configuration对象的对应属性中。 例如：开发人员可以通过配置autoMappingBehavior修改MyBatis是否开启自动映射的功能，具体配置如下 &lt;settings> &lt;!- autoMappingBehavior配置项 是决 定MyBatis是否幵 启 自动 映射功能的条 件之一 --> &lt;setting name=\"autoMappingBehavior\" value=\"PARTIAL\" /> &lt;/settings> 在Configuration中存在一个同名的相应字段： protected AutoMappingBehavior autoMappingBehavior = AutoMappingBehavior.PARTIAL; settingsAsProperties()方法的解析方式与propertiesElement()方法类似，但是多了使用MetaClass检测key指定的属性在Configuration类中是否有对应setter方法的步骤。 private Properties settingsAsProperties(XNode context) { if (context == null) { return new Properties(); } Properties props = context.getChildrenAsProperties(); // Check that all settings are known to the configuration class // 创建 Configuration 对应的MetaClass对象 MetaClass metaConfig = MetaClass.forClass(Configuration.class, localReflectorFactory); // 检测Configuration中是否定义了key指定属性相应的setter方法 for (Object key : props.keySet()) { if (!metaConfig.hasSetter(String.valueOf(key))) { throw new BuilderException(\"...\"); } } return props; } 解析&lt;typeAliases&gt;、&lt;typeHandlers&gt;节点 XMLConfigBuilder.typeAliasesElement()方法负责解析typeAliases节点点及其子节点，并通过TypeAliasRegistry完成别名的注册。 private void typeAliasesElement(XNode parent) { if (parent != null) { for (XNode child : parent.getChildren()) { // 处理全部子节点 if (\"package\".equals(child.getName())) { // 处理package节点 // 获取指定包名 String typeAliasPackage = child.getStringAttribute(\"name\"); // 通过TypeAliasRegistry扫描指定包中所有的类，并解析@Alias注解，完成别名注册 configuration.getTypeAliasRegistry().registerAliases(typeAliasPackage); } else { // 处理typeAlias节点 String alias = child.getStringAttribute(\"alias\"); // 获取指定别名 String type = child.getStringAttribute(\"type\"); // 获取别名对应的类型 try { Class&lt;?> clazz = Resources.classForName(type); if (alias == null) { typeAliasRegistry.registerAlias(clazz); // 扫描@Alias注解，完成注册 } else { typeAliasRegistry.registerAlias(alias, clazz); // 注册别名 } } catch (ClassNotFoundException e) { throw new BuilderException(\"...\"); } } } } } XMLConfigBuilder.typeHandlerElement()方法负责解析typeHandlers节点，并通过TypeHandlerRegistry对象完成TypeHandler的注册，该方法的实现与typeAliasesElement()方法类似。 解析&lt;plugins&gt;节点 插件是MyBatis提供的扩展机制之一，用户可以通过添加自定义插件在SQL语句执行过程中的某一点进行拦截。 MyBatis中的自定义插件只需实现Interceptor接口，并通过注解指定想要拦截的方法签名即可。这里分析MyBatis中如何加载和管理插件。XMLConfigBuilder.pluginElement()方法负责解析plugins节点中定义的插件，并完成实例化和配置操作。 private void pluginElement(XNode parent) throws Exception { if (parent != null) { for (XNode child : parent.getChildren()) { // 获取plugin节点的interceptor属性 String interceptor = child.getStringAttribute(\"interceptor\"); // 获取plugin节点下的properties配置的信息，并形成Properties对象 Properties properties = child.getChildrenAsProperties(); // 通过TypeAliasRegistry解析别名之后，实例化Interceptor对象 Interceptor interceptorInstance = (Interceptor) resolveClass(interceptor).newInstance(); // 设置Interceptor的属性 interceptorInstance.setProperties(properties); // 记录Interceptor对象 configuration.addInterceptor(interceptorInstance); } } } 所有配置的Interceptor对象都是通过Configuration.interceptorChain字段(InterceptorChain类型)管理的，InterceptorChain底层使用ArrayList&lt;Interceptor&gt;实现。 public class InterceptorChain { private final List&lt;Interceptor> interceptors = new ArrayList&lt;Interceptor>(); public Object pluginAll(Object target) { for (Interceptor interceptor : interceptors) { target = interceptor.plugin(target); } return target; } public void addInterceptor(Interceptor interceptor) { interceptors.add(interceptor); } public List&lt;Interceptor> getInterceptors() { return Collections.unmodifiableList(interceptors); } } 解析&lt;objectFactory&gt;节点 我们可以通过添加自定义Objectory实现类、ObjectWrapperFactory实现类以及ReflectorFactory实现类对MyBatis进行扩展。XMLConfigBuilder.objectFactoryElement()方法负责解析并实例化&lt;objectFactory&gt;节点指定的ObjectFactory实现类，之后将自定义的ObjectFactory对象记录到Configuration.objectFactory字段中。 private void objectFactoryElement(XNode context) throws Exception { if (context != null) { // 获取&lt;objectFactory>节点的type属性 String type = context.getStringAttribute(\"type\"); // 获取&lt;ObjectFactory>节点下配置的信息，并形成Properties对象 Properties properties = context.getChildrenAsProperties(); // 进行别名解析后，实例化自定义ObjectFactory实现 ObjectFactory factory = (ObjectFactory) resolveClass(type).newInstance(); // 设置自定义ObjectFactory属性， 完成初始化相关操作 factory.setProperties(properties); // 将自定义ObjectFactory对象记录到Configuration对象的ObjectFactory字段中，待后续使用 configuration.setObjectFactory(factory); } } XMLConfigBuilder对&lt;objectWrapperFactory&gt;节点、&lt;reflectorFactory&gt;节点的解析与上述过程类似，最终会将解析得到的自定义对象记录到Configuration的相应字段中。 解析&lt;environments&gt;节点 在实际生产中，同一项目可能分为开发、测试和生产多个不同的环境，每个环境的配置可能也不尽相同。 MyBatis可以配置多个&lt;environment&gt;节点，每个&lt;environment&gt;节点对应一种环境的配置。但需要注意的是，尽管可以配置多个环境，每个SqlSessionFactory实例只能选择其一。 XMLConfigBuilder.environmentsElement()方法负责解析&lt;environments&gt;的相关配置，它会根据XMLConfigBuilder.environment字段值确定要使用的&lt;environment&gt;配置，之后创建对应的TransactionFactory和DataSource对象，并封装进Environment对象中。 private void environmentsElement(XNode context) throws Exception { if (context != null) { // 未指定 XMLConfigBuilder.environment 字段，则使用default属性指定的&lt;environment> if (environment == null) { environment = context.getStringAttribute(\"default\"); } for (XNode child : context.getChildren()) { String id = child.getStringAttribute(\"id\"); if (isSpecifiedEnvironment(id)) { TransactionFactory txFactory = transactionManagerElement(child.evalNode(\"transactionManager\")); DataSourceFactory dsFactory = dataSourceElement(child.evalNode(\"dataSource\")); DataSource dataSource = dsFactory.getDataSource(); Environment.Builder environmentBuilder = new Environment.Builder(id) .transactionFactory(txFactory) .dataSource(dataSource); configuration.setEnvironment(environmentBuilder.build()); } } } } 解析&lt;databaseldProvider&gt;节点 MyBatis不能像Hibernate那样，直接帮助开发人员屏蔽多种数据库产品在SQL语言支持方面的差异。 但是在mybatis-config.xml配置文件中，通过&lt;databaseIdProvider&gt;定义所有支持的数据库产品的databaseld,然后在映射配置文件中定义SQL语句节点时，通过databaseld指定该SQL语句应用的数据库产品，这样也可以实现类似的功能。 在MyBatis初始化时，会根据前面确定的DataSource确定当前使用的数据库产品，然后在解析映射配置文件时，加载不带databaseld属性和带有匹配当前数据库databaseld属性的所有SQL语句。如果同时找到带有databaseld和不带databaseld的相同语句，则后者会被舍弃，使用前者。 XMLConfigBuilder.databaseIdProviderElement()方法负责解析&lt;databaseIdProvider&gt;节点，并创建指定的DatabaseldProvider对象。DatabaseldProvider会返回databaseld值，MyBatis会根据databaseld选择合适的SQL进行执行。 private void databaseIdProviderElement(XNode context) throws Exception { DatabaseIdProvider databaseIdProvider = null; if (context != null) { String type = context.getStringAttribute(\"type\"); // awful patch to keep backward compatibility if (\"VENDOR\".equals(type)) { type = \"DB_VENDOR\"; } Properties properties = context.getChildrenAsProperties(); // 创建DatabaseIdProvider对象 databaseIdProvider = (DatabaseIdProvider) resolveClass(type).newInstance(); // 配置DatabaseIdProvider，完成初始化 databaseIdProvider.setProperties(properties); } Environment environment = configuration.getEnvironment(); if (environment != null &amp;&amp; databaseIdProvider != null) { // 通过前面确定的DataSource获取databaseld，并记录到Configuration.databaseld字段中 String databaseId = databaseIdProvider.getDatabaseId(environment.getDataSource()); configuration.setDatabaseId(databaseId); } } MyBatis提供的DatabaseldProvider接口及其实现比较简单。 DatabaseldProvider接口的核心方法是getDatabaseId()方法，它主要负责通过给定的DataSource来查找对应的databaseld。 MyBatis提供了VendorDatabaseldProvider和DefaukDatabaseldProvider两个实现，其中DefaultDatabaseldProvider己过时。 VendorDatabaseIdProvider.getDatabaseId()方法在接收到DataSource对象时，会先解析DataSource所连接的数据库产品名称，之后根据&lt;databaseIdProvider&gt;节点配置的数据库产品名称与databaseld的对应关系确定最终的databaseld。 private String getDatabaseName(DataSource dataSource) throws SQLException { // 解析DataSource连接的数据库产品的名称 String productName = getDatabaseProductName(dataSource); if (this.properties != null) { for (Map.Entry&lt;Object, Object> property : properties.entrySet()) { if (productName.contains((String) property.getKey())) { return (String) property.getValue(); } } // no match, return null return null; } return productName; } private String getDatabaseProductName(DataSource dataSource) throws SQLException { Connection con = null; try { con = dataSource.getConnection(); DatabaseMetaData metaData = con.getMetaData(); return metaData.getDatabaseProductName(); } finally { if (con != null) { try { con.close(); } catch (SQLException e) { // ignored } } } } 解析&lt;mappers&gt;节点 在MyBatis初始化时，除了加载mybatis-config.xml配置文件，还会加载全部的映射配置文件，mybatis-config.xml配置文件中的&lt;mappers&gt;节点会告诉MyBatis去哪些位置查找映射配置文件以及使用了配置注解标识的接口。XMLConfigBuilder.mapperElement()方法负责解析&lt;mappers&gt;节点，它会创建XMLMapperBuilder对象加载映射文件，如果映射配置文件存在相应的Mapper接口，也会加载相应的Mapper接口，解析其中的注解并完成向MapperRegistry的注册。 private void mapperElement(XNode parent) throws Exception { if (parent != null) { for (XNode child : parent.getChildren()) { // 处理&lt;mappers>的子节点 if (\"package\".equals(child.getName())) { // &lt;package>子节点 String mapperPackage = child.getStringAttribute(\"name\"); // 扫描指定的包，并向MapperRegistry注册Mapper接口 configuration.addMappers(mapperPackage); } else { // 获 取&lt;mapper>节点的resource、url、class属性，这三个属性互斥 String resource = child.getStringAttribute(\"resource\"); String url = child.getStringAttribute(\"url\"); String mapperClass = child.getStringAttribute(\"class\"); // 如果&lt;mapper>节点指定了resource或是url属性，则创建XMLMapperBuilder对象， // 并通过该对象解析resource或是url属性指定的Mapper配置文件 if (resource != null &amp;&amp; url == null &amp;&amp; mapperClass == null) { ErrorContext.instance().resource(resource); InputStream inputStream = Resources.getResourceAsStream(resource); // 创建XMLMapperBuilder对象，解析映射配置文件 XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, resource, configuration.getSqlFragments()); mapperParser.parse(); } else if (resource == null &amp;&amp; url != null &amp;&amp; mapperClass == null) { ErrorContext.instance().resource(url); InputStream inputStream = Resources.getUrlAsStream(url); // 创建XMLMapperBuilder对象，解析映射配置文件 XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, url, configuration.getSqlFragments()); mapperParser.parse(); } else if (resource == null &amp;&amp; url == null &amp;&amp; mapperClass != null) { // 如果&lt;mapper>节点指定了class属性，则向MapperRegistry注册该Mapper接口 Class&lt;?> mapperInterface = Resources.classForName(mapperClass); configuration.addMapper(mapperInterface); } else { throw new BuilderException(\"...\"); } } } } } XMLMapperBuilder通过对XMLConfigBuilder.mapperElement()方法的介绍我们知道，XMLMapperBuilder负责解析映射配置文件，它继承了BaseBuilder抽象类，也是具体建造者的角色。XMLMapperBuilder.parse()方法是解析映射文件的入口。 public void parse() { // 判断是否已加载过该映射文件 if (!configuration.isResourceLoaded(resource)) { configurationElement(parser.evalNode(\"/mapper\")); // 将resource添加到Configuration•loadedResources集合中保存，它是HashSet&lt;String> // 类型的集合，其中记录了已经加栽过的映射文件。 configuration.addLoadedResource(resource); bindMapperForNamespace(); } // 处理configurationElement()方法中解析失败的&lt;resultMap>节点 parsePendingResultMaps(); // 处理configurationElement()方法中解析失败的&lt;cache-ref>节点 parsePendingCacheRefs(); // 处理configurationElement()方法中解析失败的SQL语句节点 parsePendingStatements(); } XMLMapperBuilder也是将每个节点的解析过程封装成了一个方法，而这些方法由XMLMapperBuilder.configurationElement()方法调用。 private void configurationElement(XNode context) { try { String namespace = context.getStringAttribute(\"namespace\"); if (namespace == null || namespace.equals(\"\")) { throw new BuilderException(\"Mapper's namespace cannot be empty\"); } builderAssistant.setCurrentNamespace(namespace); cacheRefElement(context.evalNode(\"cache-ref\")); cacheElement(context.evalNode(\"cache\")); parameterMapElement(context.evalNodes(\"/mapper/parameterMap\")); resultMapElements(context.evalNodes(\"/mapper/resultMap\")); sqlElement(context.evalNodes(\"/mapper/sql\")); buildStatementFromContext(context.evalNodes(\"select|insert|update|delete\")); } catch (Exception e) { throw new BuilderException(\"...\"); } } 1. 解析&lt;cache&gt;节点 MyBatis拥有非常强大的二级缓存功能，该功能可以非常方便地进行配置，MyBatis默认情况下没有开启二级缓存，如果要为某命名空间开启二级缓存功能，则需要在相应映射配置文件中添加&lt;cache&gt;节点，还可以通过配置&lt;cache&gt;节点的相关属性，为二级缓存配置相应的特性(本质上就是添加相应的装饰器)。 XMLMapperBuilder.cacheElement()方法主要负责解析&lt;cache&gt;节点： private void cacheElement(XNode context) throws Exception { if (context != null) { String type = context.getStringAttribute(\"type\", \"PERPETUAL\"); Class&lt;? extends Cache> typeClass = typeAliasRegistry.resolveAlias(type); String eviction = context.getStringAttribute(\"eviction\", \"LRU\"); Class&lt;? extends Cache> evictionClass = typeAliasRegistry.resolveAlias(eviction); Long flushInterval = context.getLongAttribute(\"flushInterval\"); Integer size = context.getIntAttribute(\"size\"); boolean readWrite = !context.getBooleanAttribute(\"readOnly\", false); boolean blocking = context.getBooleanAttribute(\"blocking\", false); Properties props = context.getChildrenAsProperties(); builderAssistant.useNewCache( typeClass, evictionClass, flushInterval, size, readWrite, blocking, props); } } MapperBuilderAssistant是一个辅助类，其useNewCache()方法负责创建Cache对象，并将其添加到Configuration.caches集合中保存。 Configuration中的caches字段是StrictMap&lt;Cache&gt;类型的字段，它记录Cache的id(默认是映射文件的namespace)与Cache对象(二级缓存)之间的对应关系。 StrictMap继承了HashMap,并在其基础上进行了少许修改，这里重点关注StrictMap.put()方法，如果检测到重复的key则抛出异常，如果没有重复的key则添加key以及value，同时会根据key产生shortKey。 public V put(String key, V value) { if (containsKey(key)) { // 如果已经包含了该key，则直接返回异常 throw new IllegalArgumentException(name + \" already contains value for \" + key); } if (key.contains(\".\")) { // 按照将key切分成数组，并将数组的最后一项作为shortKey final String shortKey = getShortName(key); if (super.get(shortKey) == null) { // 如果不包含指定的sortKey，则添加键值对 super.put(shortKey, value); } else { // 如果shortKey已存在，则将value修改成Ambiguity对象 super.put(shortKey, (V) new Ambiguity(shortKey)); } } return super.put(key, value); // 如果不包含该key，则添加键值对 } Ambiguity是StrictMap中定义的静态内部类，它表示的是存在二义性的键值对。Ambiguity中使用subject字段记录了存在二义性的key，并提供了相应的getter方法。 StrictMap.get()方法会检测value是否存在以及value是否为Ambiguity类型对象，如果满足这两个条件中的任意一个，则抛出异常。 public V get(Object key) { V value = super.get(key); if (value == null) { // 如果key没有对应的value，就报错 throw new IllegalArgumentException(\"...\"); } if (value instanceof Ambiguity) { throw new IllegalArgumentException(\"...\"); } return value; } MapperBuilderAssistant. useNewCache()方法的实现如下： public Cache useNewCache(Class&lt;? extends Cache> typeClass, Class&lt;? extends Cache> evictionClass, Long flushInterval, Integer size, boolean readWrite, boolean blocking, Properties props) { Cache cache = new CacheBuilder(currentNamespace) .implementation(valueOrDefault(typeClass, PerpetualCache.class)) .addDecorator(valueOrDefault(evictionClass, LruCache.class)) .clearInterval(flushInterval) .size(size) .readWrite(readWrite) .blocking(blocking) .properties(props) .build(); configuration.addCache(cache); currentCache = cache; return cache; } CacheBuilder是Cache的建造者，其字段如下： // 唯一标识，一般情况下对应的是映射文件中配置的namespace private final String id; // Cache对象的真正实现类 private Class&lt;? extends Cache> implementation; // 装饰器集合 private final List&lt;Class&lt;? extends Cache>> decorators; // 缓存大小 private Integer size; // 清理时间周期 private Long clearInterval; // 是否可读写 private boolean readWrite; // 其他配置信息 private Properties properties; // 是否阻塞 private boolean blocking; CacheBuilder.build()方法，根据CacheBuilder中上述字段的值创建Cache对象并添加合适的装饰器。 public Cache build() { setDefaultImplementations(); Cache cache = newBaseCacheInstance(implementation, id); setCacheProperties(cache); // issue #352, do not apply decorators to custom caches if (PerpetualCache.class.equals(cache.getClass())) { for (Class&lt;? extends Cache> decorator : decorators) { cache = newCacheDecoratorInstance(decorator, cache); setCacheProperties(cache); } cache = setStandardDecorators(cache); } else if (!LoggingCache.class.isAssignableFrom(cache.getClass())) { cache = new LoggingCache(cache); } return cache; } CacheBuilder.setCacheProperties()方法会根据&lt;cache&gt;节点下配置的&lt;property&gt;信息，初始化Cache对象。 private void setCacheProperties(Cache cache) { if (properties != null) { MetaObject metaCache = SystemMetaObject.forObject(cache); for (Map.Entry&lt;Object, Object> entry : properties.entrySet()) { String name = (String) entry.getKey(); String value = (String) entry.getValue(); if (metaCache.hasSetter(name)) { Class&lt;?> type = metaCache.getSetterType(name); if (String.class == type) { metaCache.setValue(name, value); } else if (int.class == type || Integer.class == type) { metaCache.setValue(name, Integer.valueOf(value)); } else if (long.class == type || Long.class == type) { metaCache.setValue(name, Long.valueOf(value)); } else if (short.class == type || Short.class == type) { metaCache.setValue(name, Short.valueOf(value)); } else if (byte.class == type || Byte.class == type) { metaCache.setValue(name, Byte.valueOf(value)); } else if (float.class == type || Float.class == type) { metaCache.setValue(name, Float.valueOf(value)); } else if (boolean.class == type || Boolean.class == type) { metaCache.setValue(name, Boolean.valueOf(value)); } else if (double.class == type || Double.class == type) { metaCache.setValue(name, Double.valueOf(value)); } else { throw new CacheException(\"...\"); } } } } if (InitializingObject.class.isAssignableFrom(cache.getClass())){ try { ((InitializingObject) cache).initialize(); } catch (Exception e) { throw new CacheException(\"...\", e); } } } CacheBuilder.setStandardDecorators()方法会根据CacheBuilder中各个字段的值，为cache对象添加对应的装饰器。 private Cache setStandardDecorators(Cache cache) { try { MetaObject metaCache = SystemMetaObject.forObject(cache); if (size != null &amp;&amp; metaCache.hasSetter(\"size\")) { metaCache.setValue(\"size\", size); } if (clearInterval != null) { cache = new ScheduledCache(cache); ((ScheduledCache) cache).setClearInterval(clearInterval); } if (readWrite) { cache = new SerializedCache(cache); } cache = new LoggingCache(cache); cache = new SynchronizedCache(cache); if (blocking) { cache = new BlockingCache(cache); } return cache; } catch (Exception e) { throw new CacheException(\"...\", e); } } 2. 解析&lt;cache-ref&gt;节点 XMLMapperBuilder.cacheElement()方法会为每个namespace创建一个对应的Cache对象，并在Configuration.caches集合中记录namespace与Cache对象之间的对应关系。 如果希望多个namespace共用同一个二级缓存，即同一个Cache对象，则可以使用&lt;cache-ref&gt;点进行配置。 XMLMapperBuilder.cacheReffilement()方法负责解析&lt;cache-ref&gt;节点。 这里首先需要了解的是Configuration.cacheRefMap集合，该集合是HashMap&lt;String，String&gt;类型，其中key是&lt;cache-ref&gt;节点所在的namespace，value是&lt;cache-ref&gt;节点的namespace属性所指定的namespace。 也就是说，前者共用后者的Cache对象，如下图，namespace2共用了namespace1的Cache对象。 XMLMapperBuilder.cacheReffilement()： private void cacheRefElement(XNode context) { if (context != null) { configuration.addCacheRef( builderAssistant.getCurrentNamespace(), context.getStringAttribute(\"namespace\")); CacheRefResolver cacheRefResolver = new CacheRefResolver( builderAssistant, context.getStringAttribute(\"namespace\")); try { cacheRefResolver.resolveCacheRef(); } catch (IncompleteElementException e) { //如果解析过程出现异常，则添加到Configuration.incompleteCacheRefs集合，稍后再解析 configuration.addIncompleteCacheRef(cacheRefResolver); } } } CacheRefResolver是一个简单的Cache引用解析器，其中封装了被引用的namespace以及当前XMLMapperBuilder对应的MapperBuilderAssistant对象。 CacheRefResolver.resolveCacheRef()方法会调用MapperBuilderAssistant.useCacheRef()方法。在MapperBuilderAssistant.useCacheRef()方法中会通过namespace查找被引用的Cache对象。 public Cache useCacheRef(String namespace) { if (namespace == null) { throw new BuilderException(\"...\"); } try { unresolvedCacheRef = true; Cache cache = configuration.getCache(namespace); if (cache == null) { throw new IncompleteElementException(\"...\"); } currentCache = cache; unresolvedCacheRef = false; return cache; } catch (IllegalArgumentException e) { throw new IncompleteElementException(\"...\", e); } } 另一个需要了解的Configuration字段是incompleteCacheRefs集合，它是LinkedList&lt;CacheRefResolver&gt;类型，其中记录了当前解析出现异常的CacheRefResolver对象。 3. 解析&lt;resultMap&gt;节点 select语句查询得到的结果集是一张二维表，水平方向上看是一个个字段，垂直方向上看是一条条记录。 而Java是面向对象的程序设计语言，对象是根据类定义创建的，类之间的引用关系可以认为是嵌套的结构。 在JDBC编程中，为了将结果集中的数据映射成对象，我们需要自己写代码从结果集中获取数据，然后封装成对应的对象并设置对象之间的关系，而这些都是大量的重复性代码。 为了减少这些重复的代码，MyBatis使用&lt;resultMap&gt;节点定义了结果集与结果对象(JavaBean对象)之间的映射规则，&lt;resultMap&gt;节点可以满足绝大部分的映射需求，从而减少开发人员的重复性劳动，提高开发效率。 每个ResultMapping对象记录了结果集中的一列与JavaBean中一个属性之间的映射关系。&lt;resultMap&gt;节点下除了&lt;discriminator&gt;子节点的其他子节点，都会被解析成对应的ResultMapping对象。核心字段如下： // Configuration对象 private Configuration configuration; // 应 节 点的property属 性，表示的是与 该 列进 行映射的属 性 private String property; // 数据库获取的列名或别名 private String column; // 对应的java类型，JavaBean的完全限定名 private Class&lt;?> javaType; // JDBC类型 private JdbcType jdbcType; // 对应节点的typeHandler属性，表示的是类型处理器，它会覆盖默认的类型处理器，后面会介绍该字段的作用 private TypeHandler&lt;?> typeHandler; // 对应节点的resultMap属性，该属性通过id引用了另一个&lt;resultMap>节点定义，它负责将结果集中的一部 // 分列映射成其他关联的结果对象。这样我们就可以通过join方式进行关联查询，然后直接映射成多个对象， // 并同时设置这些对象之间的组合关系 private String nestedResultMapId; // 对应节点的select属性，该属性通过id引用了另一个&lt;select>节点定义，它会把指定的列的值传入 // select属性指定的select语句中作为参数进行查询。使用select属性可能会导致N+1问题 private String nestedQueryId; // 非空字段集合 private Set&lt;String> notNullColumns; // private String columnPrefix; // private List&lt;ResultFlag> flags; // private List&lt;ResultMapping> composites; // private String resultSet; // private String foreignColumn; // 是否延迟加载 private boolean lazy; ResultMapping中定义了一个内部Builder类，也应用了建造者模式，该Builder类主要用于数据整理和数据校验校验。 另一个比较重要的类是ResultMap，每个&lt;resultMap&gt;节点都会被解析成一个ResultMap对象，其中每个节点所定义的映射关系，则使用ResultMapping对象表示。 ResultMap字段定义： // Configuration对象 private Configuration configuration; // 对应节点的id属性 private String id; // 对应节点的type属性 private Class&lt;?> type; // ResultMapping对象集合 private List&lt;ResultMapping> resultMappings; // 记录了映射关系中带有ID标志的映射关系，例如&lt;id>节点和&lt;constructor>节点的&lt;idArg>子节点 private List&lt;ResultMapping> idResultMappings; // 记录了映射关系中带有Constructor标志的映射关系，例如&lt;constructor>所有子元素 private List&lt;ResultMapping> constructorResultMappings; // 记录了映射关系中不带有Constructor标志的映射关系 private List&lt;ResultMapping> propertyResultMappings; // 记录所有映射关系中涉及的column属性的集合 private Set&lt;String> mappedColumns; // private Set&lt;String> mappedProperties; // 鉴别器 private Discriminator discriminator; // 是否含有嵌套的结果映射，如果某个映射关系中存在resultMap属性，且不存在resultSet属性，则为true private boolean hasNestedResultMaps; // 是否含有嵌套查询，如果某个属性映射存在select属性，则为true private boolean hasNestedQueries; // 是否开启自动映射 private Boolean autoMapping; 在XMLMapperBuilder中通过resultMapElements()方法解析映射配置文件中的全部&lt;resultMap&gt;节点，该方法会循环调用resultMapElement()方法处理每个&lt;resultMap&gt;节点。 private ResultMap resultMapElement(XNode resultMapNode, List&lt;ResultMapping> additionalResultMappings) throws Exception { ErrorContext.instance().activity(\"processing \" + resultMapNode.getValueBasedIdentifier()); String id = resultMapNode.getStringAttribute( \"id\", resultMapNode.getValueBasedIdentifier()); String type = resultMapNode.getStringAttribute( \"type\",resultMapNode.getStringAttribute( \"ofType\",resultMapNode.getStringAttribute(\"resultType\", resultMapNode.getStringAttribute(\"javaType\")))); String extend = resultMapNode.getStringAttribute(\"extends\"); Boolean autoMapping = resultMapNode.getBooleanAttribute(\"autoMapping\"); Class&lt;?> typeClass = resolveClass(type); Discriminator discriminator = null; List&lt;ResultMapping> resultMappings = new ArrayList&lt;ResultMapping>(); resultMappings.addAll(additionalResultMappings); List&lt;XNode> resultChildren = resultMapNode.getChildren(); for (XNode resultChild : resultChildren) { if (\"constructor\".equals(resultChild.getName())) { processConstructorElement(resultChild, typeClass, resultMappings); } else if (\"discriminator\".equals(resultChild.getName())) { discriminator = processDiscriminatorElement(resultChild, typeClass, resultMappings); } else { List&lt;ResultFlag> flags = new ArrayList&lt;ResultFlag>(); if (\"id\".equals(resultChild.getName())) { flags.add(ResultFlag.ID); } resultMappings.add(buildResultMappingFromContext(resultChild, typeClass, flags)); } } ResultMapResolver resultMapResolver = new ResultMapResolver(builderAssistant, id, typeClass, extend, discriminator, resultMappings, autoMapping); try { return resultMapResolver.resolve(); } catch (IncompleteElementException e) { configuration.addIncompleteResultMap(resultMapResolver); throw e; } } 在处理&lt;resultMap&gt;节点的过程中，该过程在执行获取到id属性和type属性之后，就会通过XMLMapperBuilder.buildResultMappingFromContext()方法为&lt;result&gt;节点创建对应的ResultMapping对象。 private ResultMapping buildResultMappingFromContext(XNode context, Class&lt;?> resultType, List&lt;ResultFlag> flags) throws Exception { String property; // 获取property的属性值 if (flags.contains(ResultFlag.CONSTRUCTOR)) { property = context.getStringAttribute(\"name\"); } else { property = context.getStringAttribute(\"property\"); } String column = context.getStringAttribute(\"column\"); String javaType = context.getStringAttribute(\"javaType\"); String jdbcType = context.getStringAttribute(\"jdbcType\"); String nestedSelect = context.getStringAttribute(\"select\"); String nestedResultMap = context.getStringAttribute( \"resultMap\",processNestedResultMappings(context, Collections.&lt;ResultMapping>emptyList())); String notNullColumn = context.getStringAttribute(\"notNullColumn\"); String columnPrefix = context.getStringAttribute(\"columnPrefix\"); String typeHandler = context.getStringAttribute(\"typeHandler\"); String resultSet = context.getStringAttribute(\"resultSet\"); String foreignColumn = context.getStringAttribute(\"foreignColumn\"); boolean lazy = \"lazy\".equals( context.getStringAttribute(\"fetchType\", configuration.isLazyLoadingEnabled() ? \"lazy\" : \"eager\")); Class&lt;?> javaTypeClass = resolveClass(javaType); @SuppressWarnings(\"unchecked\") Class&lt;? extends TypeHandler&lt;?>> typeHandlerClass = (Class&lt;? extends TypeHandler&lt;?>>) resolveClass(typeHandler); JdbcType jdbcTypeEnum = resolveJdbcType(jdbcType); return builderAssistant.buildResultMapping( resultType, property, column, javaTypeClass, jdbcTypeEnum, nestedSelect, nestedResultMap, notNullColumn, columnPrefix, typeHandlerClass, flags, resultSet, foreignColumn, lazy); } MapperBuilderAssistant.buildResultMapping()的具体实现： public ResultMapping buildResultMapping( Class&lt;?> resultType, String property, String column, Class&lt;?> javaType, JdbcType jdbcType, String nestedSelect, String nestedResultMap, String notNullColumn, String columnPrefix, Class&lt;? extends TypeHandler&lt;?>> typeHandler, List&lt;ResultFlag> flags, String resultSet, String foreignColumn, boolean lazy) { Class&lt;?> javaTypeClass = resolveResultJavaType(resultType, property, javaType); TypeHandler&lt;?> typeHandlerInstance = resolveTypeHandler(javaTypeClass, typeHandler); List&lt;ResultMapping> composites = parseCompositeColumnName(column); return new ResultMapping.Builder(configuration, property, column, javaTypeClass) .jdbcType(jdbcType) .nestedQueryId(applyCurrentNamespace(nestedSelect, true)) .nestedResultMapId(applyCurrentNamespace(nestedResultMap, true)) .resultSet(resultSet) .typeHandler(typeHandlerInstance) .flags(flags == null ? new ArrayList&lt;ResultFlag>() : flags) .composites(composites) .notNullColumns(parseMultipleColumnNames(notNullColumn)) .columnPrefix(columnPrefix) .foreignColumn(foreignColumn) .lazy(lazy) .build(); } 得到ResultMapping对象集合之后，会调用ResultMapResolver.resolve()方法，该方法会调用MapperBuilderAssistant.addResultMap()方法创建ResultMap对象，并将ResultMap对象添加到Configuration.resultMaps集合中保存。 public ResultMap addResultMap( String id, Class&lt;?> type, String extend, Discriminator discriminator, List&lt;ResultMapping> resultMappings, Boolean autoMapping) { id = applyCurrentNamespace(id, false); extend = applyCurrentNamespace(extend, true); if (extend != null) { if (!configuration.hasResultMap(extend)) { throw new IncompleteElementException(\"...\"); } ResultMap resultMap = configuration.getResultMap(extend); List&lt;ResultMapping> extendedResultMappings = new ArrayList&lt;ResultMapping>(resultMap.getResultMappings()); extendedResultMappings.removeAll(resultMappings); // Remove parent constructor if this resultMap declares a constructor. boolean declaresConstructor = false; for (ResultMapping resultMapping : resultMappings) { if (resultMapping.getFlags().contains(ResultFlag.CONSTRUCTOR)) { declaresConstructor = true; break; } } if (declaresConstructor) { Iterator&lt;ResultMapping> extendedResultMappingsIter = extendedResultMappings.iterator(); while (extendedResultMappingsIter.hasNext()) { if (extendedResultMappingsIter.next().getFlags().contains(ResultFlag.CONSTRUCTOR)) { extendedResultMappingsIter.remove(); } } } resultMappings.addAll(extendedResultMappings); } ResultMap resultMap = new ResultMap.Builder(configuration, id, type, resultMappings, autoMapping) .discriminator(discriminator) .build(); configuration.addResultMap(resultMap); return resultMap; } &lt;constructor&gt;节点的解析，由XMLMapperBuilder.processConstructorElement()方法完成。 private void processConstructorElement(XNode resultChild, Class&lt;?> resultType, List&lt;ResultMapping> resultMappings) throws Exception { List&lt;XNode> argChildren = resultChild.getChildren(); for (XNode argChild : argChildren) { List&lt;ResultFlag> flags = new ArrayList&lt;ResultFlag>(); flags.add(ResultFlag.CONSTRUCTOR); if (\"idArg\".equals(argChild.getName())) { flags.add(ResultFlag.ID); } resultMappings.add(buildResultMappingFromContext(argChild, resultType, flags)); } } 之后会解析&lt;association&gt;节点，正如前面对XMLMapperBuilder.resultMapElement()方法的介绍，&lt;association&gt;节点也是在XMLMapperBuilder.buildResultMappingFromContext()方法中完成解析的。 &lt;discriminator&gt;节点的解析，该解析过程由XMLMapperBuilder.processDiscriminatorElement()方法完成。 private Discriminator processDiscriminatorElement(XNode context, Class&lt;?> resultType, List&lt;ResultMapping> resultMappings) throws Exception { String column = context.getStringAttribute(\"column\"); String javaType = context.getStringAttribute(\"javaType\"); String jdbcType = context.getStringAttribute(\"jdbcType\"); String typeHandler = context.getStringAttribute(\"typeHandler\"); Class&lt;?> javaTypeClass = resolveClass(javaType); @SuppressWarnings(\"unchecked\") Class&lt;? extends TypeHandler&lt;?>> typeHandlerClass = (Class&lt;? extends TypeHandler&lt;?>>) resolveClass(typeHandler); JdbcType jdbcTypeEnum = resolveJdbcType(jdbcType); Map&lt;String, String> discriminatorMap = new HashMap&lt;String, String>(); for (XNode caseChild : context.getChildren()) { String value = caseChild.getStringAttribute(\"value\"); String resultMap = caseChild.getStringAttribute(\"resultMap\", processNestedResultMappings(caseChild, resultMappings)); discriminatorMap.put(value, resultMap); } return builderAssistant.buildDiscriminator(resultType, column, javaTypeClass, jdbcTypeEnum, typeHandlerClass, discriminatorMap); } 4. 解析&lt;sql&gt;节点 XMLMapperBuilder.sqlElement()方法负责解析映射配置文件中定义的全部&lt;sql&gt;节点。 private void sqlElement(List&lt;XNode> list) throws Exception { if (configuration.getDatabaseId() != null) { sqlElement(list, configuration.getDatabaseId()); } sqlElement(list, null); } private void sqlElement(List&lt;XNode> list, String requiredDatabaseId) throws Exception { for (XNode context : list) { String databaseId = context.getStringAttribute(\"databaseId\"); String id = context.getStringAttribute(\"id\"); id = builderAssistant.applyCurrentNamespace(id, false); if (databaseIdMatchesCurrent(id, databaseId, requiredDatabaseId)) { sqlFragments.put(id, context); } } } XMLStatementBuilder除了节点解析，映射文件中还有一类比较重要的节点需要解析，也就是SQL节点。SQL节点主要用于定义SQL语句，SQL节点由XMLStatementBuilder负责解析。 MyBatis使用SqlSource接口表示映射文件或注解中定义的SQL语句，但它表示的SQL语句是不能直接被数据库执行的，因为其中可能含有动态SQL语句相关的节点或是占位符等需要解析的元素。 public interface SqlSource { // getBoundSql()方法会根据映射文件或注解描述的SQL语句，以及传入的参数，返回可执行的SQL BoundSql getBoundSql(Object parameterObject); } MyBatis使用MappedStatement表示映射配置文件中定义的SQL节点，MappedStatement包含了这些节点的很多属性。 // id属性 private String resource; private Configuration configuration; private String id; private Integer fetchSize; private Integer timeout; private StatementType statementType; private ResultSetType resultSetType; // 对应一条sql语句 private SqlSource sqlSource; private Cache cache; private ParameterMap parameterMap; private List&lt;ResultMap> resultMaps; private boolean flushCacheRequired; private boolean useCache; private boolean resultOrdered; // sql类型 private SqlCommandType sqlCommandType; private KeyGenerator keyGenerator; private String[] keyProperties; private String[] keyColumns; private boolean hasNestedResultMaps; private String databaseId; private Log statementLog; private LanguageDriver lang; private String[] resultSets; XMLStatementBuilder.parseStatementNode()方法是解析SQL节点的入口函数。 public void parseStatementNode() { String id = context.getStringAttribute(\"id\"); String databaseId = context.getStringAttribute(\"databaseId\"); if (!databaseIdMatchesCurrent(id, databaseId, this.requiredDatabaseId)) { return; } Integer fetchSize = context.getIntAttribute(\"fetchSize\"); Integer timeout = context.getIntAttribute(\"timeout\"); String parameterMap = context.getStringAttribute(\"parameterMap\"); String parameterType = context.getStringAttribute(\"parameterType\"); Class&lt;?> parameterTypeClass = resolveClass(parameterType); String resultMap = context.getStringAttribute(\"resultMap\"); String resultType = context.getStringAttribute(\"resultType\"); String lang = context.getStringAttribute(\"lang\"); LanguageDriver langDriver = getLanguageDriver(lang); Class&lt;?> resultTypeClass = resolveClass(resultType); String resultSetType = context.getStringAttribute(\"resultSetType\"); StatementType statementType = StatementType.valueOf( context.getStringAttribute(\"statementType\", StatementType.PREPARED.toString())); ResultSetType resultSetTypeEnum = resolveResultSetType(resultSetType); // 根据节点名称决定SqlCommandType String nodeName = context.getNode().getNodeName(); SqlCommandType sqlCommandType = SqlCommandType.valueOf(nodeName.toUpperCase(Locale.ENGLISH)); boolean isSelect = sqlCommandType == SqlCommandType.SELECT; boolean flushCache = context.getBooleanAttribute(\"flushCache\", !isSelect); boolean useCache = context.getBooleanAttribute(\"useCache\", isSelect); boolean resultOrdered = context.getBooleanAttribute(\"resultOrdered\", false); // Include Fragments before parsing XMLIncludeTransformer includeParser = new XMLIncludeTransformer(configuration, builderAssistant); includeParser.applyIncludes(context.getNode()); // Parse selectKey after includes and remove them. processSelectKeyNodes(id, parameterTypeClass, langDriver); // Parse the SQL (pre: &lt;selectKey> and &lt;include> were parsed and removed) SqlSource sqlSource = langDriver.createSqlSource(configuration, context, parameterTypeClass); String resultSets = context.getStringAttribute(\"resultSets\"); String keyProperty = context.getStringAttribute(\"keyProperty\"); String keyColumn = context.getStringAttribute(\"keyColumn\"); KeyGenerator keyGenerator; String keyStatementId = id + SelectKeyGenerator.SELECT_KEY_SUFFIX; keyStatementId = builderAssistant.applyCurrentNamespace(keyStatementId, true); if (configuration.hasKeyGenerator(keyStatementId)) { keyGenerator = configuration.getKeyGenerator(keyStatementId); } else { keyGenerator = context.getBooleanAttribute(\"useGeneratedKeys\", configuration.isUseGeneratedKeys() &amp;&amp; SqlCommandType.INSERT.equals(sqlCommandType)) ? Jdbc3KeyGenerator.INSTANCE : NoKeyGenerator.INSTANCE; } builderAssistant.addMappedStatement( id, sqlSource, statementType, sqlCommandType, fetchSize, timeout, parameterMap, parameterTypeClass, resultMap, resultTypeClass,resultSetTypeEnum, flushCache, useCache, resultOrdered, keyGenerator, keyProperty, keyColumn, databaseId, langDriver, resultSets); } 1. 解析&lt;include&gt;节点 在解析SQL节点之前，首先通过XMLIncludeTransformer解析SQL语句中的&lt;include&gt;节点，该过程会将&lt;include&gt;节点替换成&lt;sql&gt;节点中定义的SQL片段，并将其中的${xxx}占位符替换成真实的参数，该解析过程在XMLIncludeTransformer.applyIncludes()方法中实现。 public void applyIncludes(Node source) { // 获取mybatis-config.xml中&lt;properties>节点下定义的变量集合 Properties variablesContext = new Properties(); Properties configurationVariables = configuration.getVariables(); if (configurationVariables != null) { variablesContext.putAll(configurationVariables); } applyIncludes(source, variablesContext, false); } // 处理&lt;include>节点的重载方法 private void applyIncludes(Node source, final Properties variablesContext, boolean included) { if (source.getNodeName().equals(\"include\")) { Node toInclude = findSqlFragment(getStringAttribute(source, \"refid\"), variablesContext); Properties toIncludeContext = getVariablesContext(source, variablesContext); applyIncludes(toInclude, toIncludeContext, true); if (toInclude.getOwnerDocument() != source.getOwnerDocument()) { toInclude = source.getOwnerDocument().importNode(toInclude, true); } source.getParentNode().replaceChild(toInclude, source); while (toInclude.hasChildNodes()) { toInclude.getParentNode().insertBefore(toInclude.getFirstChild(), toInclude); } toInclude.getParentNode().removeChild(toInclude); } else if (source.getNodeType() == Node.ELEMENT_NODE) { if (included &amp;&amp; !variablesContext.isEmpty()) { // replace variables in attribute values NamedNodeMap attributes = source.getAttributes(); for (int i = 0; i &lt; attributes.getLength(); i++) { Node attr = attributes.item(i); attr.setNodeValue(PropertyParser.parse(attr.getNodeValue(), variablesContext)); } } NodeList children = source.getChildNodes(); for (int i = 0; i &lt; children.getLength(); i++) { applyIncludes(children.item(i), variablesContext, included); } } else if (included &amp;&amp; source.getNodeType() == Node.TEXT_NODE &amp;&amp; !variablesContext.isEmpty()) { // replace variables in text node source.setNodeValue(PropertyParser.parse(source.getNodeValue(), variablesContext)); } } &lt;inClude&gt;节点和&lt;sql&gt;节点可以配合使用、多层嵌套，实现更加复杂的sql片段的重用，这样的话，解析过程就会递归更多层，流程变得更加复杂。 2. 解析&lt;selectKey&gt;节点 在&lt;insert&gt;、&lt;update&gt;节点中可以定义&lt;selectKey&gt;节点来解决主键自增问题，&lt;selectKey&gt;节点对应的KeyGenerator接口在后面会详细介绍，现在重点关节点的解析。 XMLStatementBuilder.processSelectKeyNodes()方法负责解析SQL节点中子节点。 private void processSelectKeyNodes(String id, Class&lt;?> parameterTypeClass, LanguageDriver langDriver) { // 获取全部selectKey节点 List&lt;XNode> selectKeyNodes = context.evalNodes(\"selectKey\"); // 解析selectKey节点 if (configuration.getDatabaseId() != null) { parseSelectKeyNodes(id, selectKeyNodes, parameterTypeClass, langDriver, configuration.getDatabaseId()); } parseSelectKeyNodes(id, selectKeyNodes, parameterTypeClass, langDriver, null); removeSelectKeyNodes(selectKeyNodes); } 在parseSelectKeyNodes()方法中会为&lt;selectKey&gt;节点生成id，检测databaseld是否匹配以及是否己经加载过相同id且databaseld不为空的&lt;selectKey&gt;节点，并调用parseSelectKeyNode()方法处理每个&lt;selectKey&gt;节点。在parseSelectKeyNode()方法中，首先读取&lt;selectKey&gt;节点的一系列属性，然后调用LanguageDriver.createSqlSource()方法创建对应的SqlSource对象，最后创建MappedStatement对象，并添加到Configuration.mappedStatements集合中保存。 private void parseSelectKeyNode(String id, XNode nodeToHandle, Class&lt;?> parameterTypeClass, LanguageDriver langDriver, String databaseId) { String resultType = nodeToHandle.getStringAttribute(\"resultType\"); Class&lt;?> resultTypeClass = resolveClass(resultType); StatementType statementType = StatementType.valueOf( nodeToHandle.getStringAttribute(\"statementType\", StatementType.PREPARED.toString())); String keyProperty = nodeToHandle.getStringAttribute(\"keyProperty\"); String keyColumn = nodeToHandle.getStringAttribute(\"keyColumn\"); boolean executeBefore = \"BEFORE\".equals(nodeToHandle.getStringAttribute(\"order\", \"AFTER\")); //defaults boolean useCache = false; boolean resultOrdered = false; KeyGenerator keyGenerator = NoKeyGenerator.INSTANCE; Integer fetchSize = null; Integer timeout = null; boolean flushCache = false; String parameterMap = null; String resultMap = null; ResultSetType resultSetTypeEnum = null; SqlSource sqlSource = langDriver.createSqlSource(configuration, nodeToHandle, parameterTypeClass); SqlCommandType sqlCommandType = SqlCommandType.SELECT; builderAssistant.addMappedStatement( id, sqlSource, statementType, sqlCommandType, fetchSize, timeout, parameterMap, parameterTypeClass, resultMap, resultTypeClass, resultSetTypeEnum, flushCache, useCache, resultOrdered, keyGenerator, keyProperty, keyColumn, databaseId, langDriver, null); id = builderAssistant.applyCurrentNamespace(id, false); MappedStatement keyStatement = configuration.getMappedStatement(id, false); configuration.addKeyGenerator(id, new SelectKeyGenerator(keyStatement, executeBefore)); } LanguageDriver接口有两个实现类。 在Configuration的构造方法中，可以看到如下代码片段，我们由此可以判断默认使用的XMLLanguageDriver实现类。 languageRegistry.setDefaultDriverClass(XMLLanguageDriver.class); 也可以提供自定义的LanguageDriver实现，并在mybatis-config.xml中通过defaultScriptingLanguage配置指定使用该自定义实现。在XMLLanguageDriver.createSqlSource()方法中会创建XMLScriptBuilder对象并XMLScriptBuilder.parseScriptNode()方法创建SqlSource对象。 public SqlSource parseScriptNode() { MixedSqlNode rootSqlNode = parseDynamicTags(context); SqlSource sqlSource = null; if (isDynamic) { sqlSource = new DynamicSqlSource(configuration, rootSqlNode); } else { sqlSource = new RawSqlSource(configuration, rootSqlNode, parameterType); } return sqlSource; } 在XMLScriptBuilder.parseDynamicTags()方法中，会遍历&lt;selectKey&gt;下的每个节点，如果包含任何标签节点，则认为是动态SQL语句；如果文本节点中含有${}占位符，也认为其为动态SQL语句。 protected MixedSqlNode parseDynamicTags(XNode node) { List&lt;SqlNode> contents = new ArrayList&lt;SqlNode>(); NodeList children = node.getNode().getChildNodes(); for (int i = 0; i &lt; children.getLength(); i++) { XNode child = node.newXNode(children.item(i)); if (child.getNode().getNodeType() == Node.CDATA_SECTION_NODE || child.getNode().getNodeType() == Node.TEXT_NODE) { String data = child.getStringBody(\"\"); TextSqlNode textSqlNode = new TextSqlNode(data); if (textSqlNode.isDynamic()) { contents.add(textSqlNode); isDynamic = true; } else { contents.add(new StaticTextSqlNode(data)); } } else if (child.getNode().getNodeType() == Node.ELEMENT_NODE) { // issue #628 String nodeName = child.getNode().getNodeName(); NodeHandler handler = nodeHandlerMap.get(nodeName); if (handler == null) { throw new BuilderException(\"Unknown element &lt;\" + nodeName + \"> in SQL statement.\"); } handler.handleNode(child, contents); isDynamic = true; } } return new MixedSqlNode(contents); } 上面遇到的TextSqlNode、StaticTextSqlNode等都是SqlNode接口的实现，SqlNode接口的每个实现都对应于不同的动态SQL节点类型，每个实现的具体代码后面遇到了再详细分析。 TextSqlNode.isDynamic()方法中会通过GenericTokenParser和DynamicCheckerTokenParser配合解析文本节点，并判断它是否为动态SQL。 public boolean isDynamic() { DynamicCheckerTokenParser checker = new DynamicCheckerTokenParser(); GenericTokenParser parser = createParser(checker); parser.parse(text); return checker.isDynamic(); } @Override public String handleToken(String content) { this.isDynamic = true; return null; } 3. 解析SQL节点 经过上述两个解析过程之后，&lt;include&gt;节点和&lt;selectKey&gt;节点己经被解析并删除掉了。XMLStatementBuilder.parseStatementNode()方法剩余的操作就是解析SQL节点。 public void parseStatementNode() { String id = context.getStringAttribute(\"id\"); String databaseId = context.getStringAttribute(\"databaseId\"); if (!databaseIdMatchesCurrent(id, databaseId, this.requiredDatabaseId)) { return; } Integer fetchSize = context.getIntAttribute(\"fetchSize\"); Integer timeout = context.getIntAttribute(\"timeout\"); String parameterMap = context.getStringAttribute(\"parameterMap\"); String parameterType = context.getStringAttribute(\"parameterType\"); Class&lt;?> parameterTypeClass = resolveClass(parameterType); String resultMap = context.getStringAttribute(\"resultMap\"); String resultType = context.getStringAttribute(\"resultType\"); String lang = context.getStringAttribute(\"lang\"); LanguageDriver langDriver = getLanguageDriver(lang); Class&lt;?> resultTypeClass = resolveClass(resultType); String resultSetType = context.getStringAttribute(\"resultSetType\"); StatementType statementType = StatementType.valueOf(context.getStringAttribute(\"statementType\", StatementType.PREPARED.toString())); ResultSetType resultSetTypeEnum = resolveResultSetType(resultSetType); String nodeName = context.getNode().getNodeName(); SqlCommandType sqlCommandType = SqlCommandType.valueOf(nodeName.toUpperCase(Locale.ENGLISH)); boolean isSelect = sqlCommandType == SqlCommandType.SELECT; boolean flushCache = context.getBooleanAttribute(\"flushCache\", !isSelect); boolean useCache = context.getBooleanAttribute(\"useCache\", isSelect); boolean resultOrdered = context.getBooleanAttribute(\"resultOrdered\", false); // Include Fragments before parsing XMLIncludeTransformer includeParser = new XMLIncludeTransformer(configuration, builderAssistant); includeParser.applyIncludes(context.getNode()); // Parse selectKey after includes and remove them. processSelectKeyNodes(id, parameterTypeClass, langDriver); // Parse the SQL (pre: &lt;selectKey> and &lt;include> were parsed and removed) SqlSource sqlSource = langDriver.createSqlSource(configuration, context, parameterTypeClass); String resultSets = context.getStringAttribute(\"resultSets\"); String keyProperty = context.getStringAttribute(\"keyProperty\"); String keyColumn = context.getStringAttribute(\"keyColumn\"); KeyGenerator keyGenerator; String keyStatementId = id + SelectKeyGenerator.SELECT_KEY_SUFFIX; keyStatementId = builderAssistant.applyCurrentNamespace(keyStatementId, true); if (configuration.hasKeyGenerator(keyStatementId)) { keyGenerator = configuration.getKeyGenerator(keyStatementId); } else { keyGenerator = context.getBooleanAttribute(\"useGeneratedKeys\", configuration.isUseGeneratedKeys() &amp;&amp; SqlCommandType.INSERT.equals(sqlCommandType)) ? Jdbc3KeyGenerator.INSTANCE : NoKeyGenerator.INSTANCE; } builderAssistant.addMappedStatement(id, sqlSource, statementType, sqlCommandType, fetchSize, timeout, parameterMap, parameterTypeClass, resultMap, resultTypeClass, resultSetTypeEnum, flushCache, useCache, resultOrdered, keyGenerator, keyProperty, keyColumn, databaseId, langDriver, resultSets); } 绑定Mapper接口每个映射配置文件的命名空间可以绑定一个Mapper接口，并注册到MapperRegistry中。 在XMLMapperBuilder.bindMapperForNamespace()方法中，完成了映射配置文件与对应Mapper接口的绑定。 private void bindMapperForNamespace() { String namespace = builderAssistant.getCurrentNamespace(); if (namespace != null) { Class&lt;?> boundType = null; try { boundType = Resources.classForName(namespace); } catch (ClassNotFoundException e) { //ignore, bound type is not required } if (boundType != null) { if (!configuration.hasMapper(boundType)) { // Spring may not know the real resource name so we set a flag // to prevent loading again this resource from the mapper interface // look at MapperAnnotationBuilder#loadXmlResource configuration.addLoadedResource(\"namespace:\" + namespace); configuration.addMapper(boundType); } } } } 在介绍MapperRegistry.addMapper()方法时，只提到了该方法会向MapperRegistry.knownMappers集合注册指定的Mapper接口，其实该方法还会创建MapperAnnotationBuilder，并调用MapperAnnotationBuilder.parse()方法解析Mapper接口中的注解信息。 public void parse() { String resource = type.toString(); if (!configuration.isResourceLoaded(resource)) { loadXmlResource(); configuration.addLoadedResource(resource); assistant.setCurrentNamespace(type.getName()); parseCache(); parseCacheRef(); Method[] methods = type.getMethods(); for (Method method : methods) { try { // issue #237 if (!method.isBridge()) { parseStatement(method); } } catch (IncompleteElementException e) { configuration.addIncompleteMethod(new MethodResolver(this, method)); } } } parsePendingMethods(); } 处理incomplete*集合XMLMapperBuilder.configurationElement()方法解析映射配置文件时，是按照从文件头到文件尾的顺序解析的，但是有时候在解析一个节点时，会引用定义在该节点之后的、还未解析的节点，这就会导致解析失败并抛出IncompleteElementException。 根据抛出异常的节点不同，MyBatis会创建不同的*Resolver对象，并添加到Configuration的不同incomplete*集合中。 例如， 解析Mapper接口中的方法出现异常时，会创建MethodResolver对象，并将其追加到Configuration.incompleteMethods集合(LinkedList&lt;MethodResolver&gt;类型)中暂存; 解析&lt;resultMap&gt;节点时出现异常，则会将对应的ResultMapResolver对象追加到incompleteResultMaps(LinkedList&lt;ResultMapResolver&gt;类型)集合中暂存; 解析&lt;cache-ref&gt;节点时出现异常，则会将对应的CacheRefResolver对象追加到incompleteCacheRefs(LinkedList&lt;CacheRefResolver&gt;类型)集合中暂存; 解析SQL语句节点时出现异常，则会将对应的XMLStatementBuilder对象追加到incompleteStatements(LinkedList&lt;XMLStatementBuilder&gt;类型)集合中暂存。 在XMLMapperBuilder.parse()方法中可以看到，通过configurationElement()方法完了一次映射配置文件的解析后，还会调用parsePendingResultMaps()方法、parsePendingChacheRefs()方法、parsePendingStatements()方法三个parsePending*()方法处理Configuration中对应的三个incomplete*集合。所有parsePending*()方法的逻辑都是基本类似的，这里以parsePendingStatements()方法为例进行分析 private void parsePendingStatements() { Collection&lt;XMLStatementBuilder> incompleteStatements = configuration.getIncompleteStatements(); synchronized (incompleteStatements) { Iterator&lt;XMLStatementBuilder> iter = incompleteStatements.iterator(); while (iter.hasNext()) { try { iter.next().parseStatementNode(); iter.remove(); } catch (IncompleteElementException e) { // Statement is still missing a resource... } } } } 到此为止，MyBatis的初始化过程就全部介绍完了，其中分析了mybatis-config.xml配置文件的解析过程、映射配置文件的解析过程以及Mapper接口中相关注解的解析过程。 参考 《MyBatis技术内幕》 部分图片来源——《MyBatis技术内幕》","tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://www.cayzlh.com/tags/MyBatis/"},{"name":"《MyBatis技术内幕》","slug":"《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/tags/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"},{"name":"核心处理层","slug":"核心处理层","permalink":"https://www.cayzlh.com/tags/%E6%A0%B8%E5%BF%83%E5%A4%84%E7%90%86%E5%B1%82/"}],"categories":[{"name":"书籍","slug":"书籍","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/"},{"name":"《MyBatis技术内幕》","slug":"书籍/《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"}]},{"title":"Java中的引用类型","date":"2020-06-18T07:33:38.000Z","path":"2020/06/18/ae9388fa.html","text":"Java提供的4种引用类型，它们分别是强引用(StrongReference)、软引用(SoftReference)、弱引用(WeakReference)和幽灵引用(PhantomReference)。 强引用(StrongReference)强引用是Java编程中最普遍的引用，例如Objectobj=newObject()中，新建的Object对象就是被强引用的。 如果一个对象被强引用，即使是Java虚拟机内存空间不足时，GC(垃圾收集器)也绝不会回收该对象。 当Java虚拟机内存不足时，就可能会导致内存溢出，我们常见的就是OutOfMemoryError异常。 软引用(SoftReference)软引用是引用强度仅弱于强引用的一种引用，它使用类SoftReference来表示。 当Java虚拟机内存不足时，GC会回收那些只被软引用指向的对象，从而避免内存溢出。 在GC释放了那些只被软引用指向的对象之后，虚拟机内存依然不足，才会抛出OutOfMemoryError异常。 软引用适合引用那些可以通过其他方式恢复的对象，例如，数据库缓存中的对象就可以从数据库中恢复，所以软引用可以用来实现缓存。另外，由于在程序使用软引用之前的某个时刻，其所指向的对象可能已经被G·C回收掉了，所以通过Reference.get()方法来获取软引用所指向的对象时，总是要通过检查该方法返回值是否为null,来判断被软引用的对象是否还存活。 引用队列 (ReferenceQueue )在很多场景下，我们的程序需要在一个对象的可达性(是否己经被GC回收)发生变化时得到通知，引用队列就是用于收集这些信息的队列。 在创建SoftReference对象时，可以为其关联一个引用队列，当SoftReference所引用的对象被GC回收时，Java虚拟机就会将该SoftReference对象添加到与之关联的引用队列中。 当需要检测这些通知信息时，就可以从引用队列中获取这些SoftReference对象。不仅是SoftReference，下面介绍的弱引用和幽灵引用都可以关联相应的队列。 弱引用(WeakReference)弱引用的强度比软引用的强度还要弱。弱引用使用WeakReference来表示，它可以引用一个对象，但并不阻止被引用的对象被GC回收。在JVM虚拟机进行垃圾回收时，如果指向一个对象的所有引用都是弱引用，那么该对象会被回收。 由此可见，只被弱引用所指向的对象的生存周期是两次GC之间的这段时间，而只被软引用所指向的对象可以经历多次GC，直到出现内存紧张的情况才被回收。弱引用典型的应用情景是就是JDK提供的java.util.WeakHashMap。WeakHashMap.Entry实现继承了WeakReference，Entry弱引用key，强引用value。 当不再由强引用指向key时，则key可以被垃圾回收，当key被垃圾回收之后，对应的Entry对象会被Java虚拟机加入到其关联的队列中。 当应用程序下次操作WeakHashMap时，例如对WeakHashMap的扩容操作，就会遍历关联的引用队列，将其中的Entry对象从WeakHashMap中删除。 幽灵引用(PhantomReference)在介绍幽灵引用之前，要先了解一下Java提供的对象终止化机制。 在Object类里面有个finalize()方法，设计该方法的初衷是在一个对象被真正回收之前，执行一些清理工作，但由于GC的运行时间是不固定的，所以这些清理工作的实际运行时间也是无法预知的，而且JVM虚拟机不能保证finalize()方法一定会被调用。 每个对象的finalize()方法至多由GC执行一次，对于再生对象GC不会再次调用其finalize()方法。另外，使用finalize()方法还会导致严重的内存消耗和性能损失。 由于finalize()方法存在的种种问题，该方法现在已经被废弃，而我们可以使用幽灵引用实现其替代方案。 幽灵引用，又叫“虚引用”，它是最弱的一种引用类型，由类PhantomReference表示。在引用的对象未被GC回收时，调用前面介绍的SoftReference以及WeakReference的get()方法，得到的是其引用的对象；当引用的对象已经被GC回收时，则得到null。但是PhantomReference.get()方法始终返回null。 在创建幽灵引用的时候必须要指定一个引用队列。当GC准备回收一个对象时，如果发现它还有幽灵引用，就会在回收对象的内存之前，把该虚引用加入到与之关联的引用队列中。 程序可以通过检查该引用队列里面的内容，跟踪对象是否己经被回收并进行一些清理工作。幽灵引用还可以用来实现比较精细的内存使用控制，例如应用程序可以在确定一个对象要被回收之后，再申请内存创建新对象，但这种需求并不多见。","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"}]},{"title":"批量修改maven多模块版本号","date":"2020-04-25T06:22:59.000Z","path":"2020/04/25/8802fffc.html","text":"前置最近在开发starter的时候发现，当进行版本升级的时候需要对每个子模块项目手动修改版本号，由于子模块较多，一个个修改的体验是极差的，而且还很容易出错。作为一个程序猿，当然要去寻找一个更好的姿势来完成这件事。 代码经过长期修改后，版本号却从没有推进，导致个别release稳定版的模块更新代码之后，其他开发机器并不会自动更新本地依赖包。并使主干针对某分支的修改也同步到其他分支。所以，此文档描述如何使用versions maven plugin插件，批量修改项目各模块的版本号，灵活推进或回退版本，避免主干每次更新代码，立即对所有分支产生影响。 versions-maven-plugin在问过搜索引擎之后，一款maven插件进入了我的视线。。。 &lt;dependency> &lt;groupId>org.codehaus.mojo&lt;/groupId> &lt;artifactId>versions-maven-plugin&lt;/artifactId> &lt;version>2.3&lt;/version> &lt;/dependency> 这是一个能够批量修改版本号的插件，话不多说，在项目中引入。。 修改pom.xml，在plugins节点下添加如下代码： &lt;plugin> &lt;groupId>org.codehaus.mojo&lt;/groupId> &lt;artifactId>versions-maven-plugin&lt;/artifactId> &lt;version>2.3&lt;/version> &lt;configuration> &lt;generateBackupPoms>false&lt;/generateBackupPoms> &lt;/configuration> &lt;/plugin> 同步好插件之后，在IDEA右侧maven窗口可以看到该插件已经启用了。 展开插件，可以看到它有N个功能，我目前只用到了version:set这个功能： 使用双击version:set运行插件，之后在控制台输入你想修改的版本号回车，等运行完毕之后就完成了所有模块的版本号修改。 查看git修改记录，所有模块的pom文件都被修改过来了。 。 比之前的手动修改升了不知道多少时间。。。 毕竟这年头，时间管理还是很重要的。 。 。","tags":[{"name":"Maven","slug":"Maven","permalink":"https://www.cayzlh.com/tags/Maven/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"},{"name":"Maven","slug":"Java/Maven","permalink":"https://www.cayzlh.com/categories/Java/Maven/"}]},{"title":"Spring面向切面编程（知识梳理）","date":"2020-03-31T03:03:22.000Z","path":"2020/03/31/741621cd.html","text":"Aspect Oriented Programming with Spring 面向切面的编程（AOP）通过提供另一种思考程序结构的方式来补充面向对象的编程（OOP）。 OOP中模块化的关键单元是类，而在AOP中模块化是方面。切面使关注点（例如事务管理）的模块化跨越了多个类型和对象。 （这种关注在AOP文献中通常被称为“跨领域”关注。） Spring的关键组件之一是AOP框架。尽管Spring IoC容器不依赖于AOP，但AOP是对Spring IoC的补充，可以提供功能强大的中间件解决方案。 Spring AOP with AspectJ pointcuts Spring provides simple and powerful ways of writing custom aspects by using either a schema-based approach or the @AspectJ annotation style. Both of these styles offer fully typed advice and use of the AspectJ pointcut language while still using Spring AOP for weaving. 具有AspectJ切入点的Spring AOP通过使用基于模式的方法或@AspectJ注解样式，Spring提供了编写自定义切面的简单而强大的方法。这两种样式都提供了完全类型化的建议，并使用了AspectJ切入点语言，同时仍然使用Spring AOP进行编程。 Spring AOP概念一些重要的AOP概念和术语。这些术语不是特定于Spring的。 切面（Aspect） 类是对物体特征的抽象，切面就是对横切关注点的抽象。 在Spring AOP中，切面是通过使用常规类（基于架构的方法）或使用@Aspect注释（@AspectJ样式）注释的常规类来实现的。 aspect 由 pointcount 和 advice 组成, 它既包含了横切逻辑的定义, 也包括了连接点的定义. Spring AOP就是负责实施切面的框架, 它将切面所定义的横切逻辑织入到切面所指定的连接点中.AOP的工作重心在于如何将增强织入目标对象的连接点上, 这里包含两个工作: 如何通过 pointcut 和 advice 定位到特定的 joinpoint 上 如何在 advice 中编写切面代码. 连接点（Join point） A point during the execution of a program, such as the execution of a method or the handling of an exception. In Spring AOP, a join point always represents a method execution. 程序运行中的一些时间点，例如一个方法的执行，或者是一个异常的处理。在 Spring AOP 中, join point 总是方法的执行点, 即只有方法连接点. 增强（Advice） Action taken by an aspect at a particular join point. Different types of advice include “around”, “before” and “after” advice. (Advice types are discussed later.) Many AOP frameworks, including Spring, model an advice as an interceptor and maintain a chain of interceptors around the join point. 切面在特定的连接点处采取的操作。不同类型的建议包括around，before和after通知。 包括Spring在内的许多AOP框架都将通知建模为拦截器，并在连接点周围维护一系列拦截器。 由 aspect 添加到特定的 join point(即满足 point cut 规则的 join point) 的一段代码.许多 AOP框架, 包括 Spring AOP, 会将 advice 模拟为一个拦截器(interceptor), 并且在 join point 上维护多个 advice, 进行层层拦截.例如 HTTP 鉴权的实现, 我们可以为每个使用 RequestMapping 标注的方法织入 advice, 当 HTTP 请求到来时, 首先进入到 advice 代码中, 在这里我们可以分析这个 HTTP 请求是否有相应的权限, 如果有, 则执行 Controller, 如果没有, 则抛出异常. 这里的 advice 就扮演着鉴权拦截器的角色了. 切入点（Pointcut） A predicate that matches join points. Advice is associated with a pointcut expression and runs at any join point matched by the pointcut (for example, the execution of a method with a certain name). The concept of join points as matched by pointcut expressions is central to AOP, and Spring uses the AspectJ pointcut expression language by default. 匹配连接点的谓词。通知与切入点表达式关联，并在与该切入点匹配的任何连接点处运行（例如，执行具有特定名称的方法）。使用切入点表达式来匹配连接点是AOP的核心，并且Spring默认使用AspectJ切入点表达语言。 在 Spring 中, 所有的方法都可以认为是 joinpoint, 但是我们并不希望在所有的方法上都添加 Advice, 而 pointcut 的作用就是提供一组规则(使用 AspectJ pointcut expression language 来描述) 来匹配joinpoint, 给满足规则的 joinpoint 添加 Advice. 引入（Introduction） Declaring additional methods or fields on behalf of a type. Spring AOP lets you introduce new interfaces (and a corresponding implementation) to any advised object. For example, you could use an introduction to make a bean implement an IsModified interface, to simplify caching. (An introduction is known as an inter-type declaration in the AspectJ community.) 代表类型声明其他方法或字段。 Spring AOP允许您向任何建议的对象引入新的接口（和相应的实现）。例如，您可以使用引入使Bean实现IsModified接口，以简化缓存。 （在AspectJ社区中，引入被称为类型间声明。） 为一个类型添加额外的方法或字段. Spring AOP 允许我们为 目标对象 引入新的接口(和对应的实现). 例如我们可以使用 introduction 来为一个 bean 实现 IsModified 接口, 并以此来简化 caching 的实现. 目标对象（Target object） An object being advised by one or more aspects. Also referred to as the “advised object”. Since Spring AOP is implemented by using runtime proxies, this object is always a proxied object. 一个或多个切面通知的对象。也称为“目标对象”。由于Spring AOP是使用运行时代理实现的，因此该对象始终是代理对象。 因为 Spring AOP 使用运行时代理的方式来实现 aspect, 因此 adviced object 总是一个代理对象(proxied object)。 注意, adviced object 指的不是原来的类, 而是织入 advice 后所产生的代理类 代理（AOP proxy） An object created by the AOP framework in order to implement the aspect contracts (advise method executions and so on). In the Spring Framework, an AOP proxy is a JDK dynamic proxy or a CGLIB proxy. 一个类被 AOP 织入 advice， 就会产生一个结果类, 它是融合了原类和增强逻辑的代理类。在 Spring AOP 中, 一个 AOP 代理是一个 JDK 动态代理对象或 CGLIB 代理对象。 织入（Weaving） linking aspects with other application types or objects to create an advised object. This can be done at compile time (using the AspectJ compiler, for example), load time, or at runtime. Spring AOP, like other pure Java AOP frameworks, performs weaving at runtime. 将切面与其他应用程序类型或对象链接以创建建议的对象（将 aspect 和其他对象连接起来, 并创建 adviced object 的过程）。这可以在编译时（例如，使用AspectJ编译器），加载时或在运行时完成。像其他纯Java AOP框架一样，Spring AOP在运行时执行编织。根据不同的实现技术, AOP织入有三种方式: 编译器织入, 这要求有特殊的Java编译器. 类装载期织入, 这需要有特殊的类装载器. 动态代理织入, 在运行期为目标类添加增强(Advice)生成子类的方式.Spring 采用动态代理织入, 而AspectJ采用编译器织入和类装载期织入. advice的几种类型 前置通知（Before advice） 在连接点之前运行但无法阻止执行流前进到连接点的通知（除非它引发异常）。 后置通知（After returning advice） 连接点正常完成后要运行的通知（例如，如果方法返回而没有引发异常）。 抛出异常后通知（After throwing advice） 如果存在方法则通过抛出异常来执行的通知。 在finally执行后通知（After (finally) advice） 无论连接点退出的方式如何（正常或异常返回），都将执行通知。 环绕通知（Around advice） 围绕联接点的通知，例如方法调用。这是最有力的通知。环绕通知可以在方法调用之前和之后执行自定义行为。它还负责选择是返回连接点还是通过返回其自身的返回值或引发异常来进行通知的方法执行。 AOP代理Spring AOP默认将标准JDK动态代理用于AOP代理。这使得可以代理任何接口（或一组接口）。 Spring AOP也可以使用CGLIB代理。这对于代理类而不是接口是必需的。默认情况下，如果业务对象未实现接口，则使用CGLIB。由于对接口而不是对类进行编程是一种好习惯，因此业务类通常实现一个或多个业务接口。在那些需要建议在接口上未声明的方法或需要将代理对象作为具体类型传递给方法的情况下（在极少数情况下），可以强制使用CGLIB。 Spring Bean的生命周期 插播一下Spring Bean的生命周期 两个概念：Spring Bean 和 对象： spring bean——受spring容器管理的对象，可能经过了完整的spring bean生命周期（为什么是可能？难道还有bean是没有经过bean生命周期的？答案是有的，具体我们后面文章分析），最终存在spring容器当中；一个bean一定是个对象 对象——任何符合java语法规则实例化出来的对象，但是一个对象并不一定是spring bean； 所谓的bean的生命周期就是磁盘上的类通过Spring扫描，然后实例化，跟着初始化，继而放到容器当中的过程。下图展示Spring Bean的生命周期大概有哪些步骤： 其中AOP的代理也是在这个过程中完成的。 AOP的使用AspectJ与@AspectJ@AspectJ是一种将切面声明为带有注解的常规Java类的样式。 @AspectJ样式是AspectJ项目在AspectJ 5版本中引入的。 Spring使用AspectJ提供的用于切入点解析和匹配的库来解释与AspectJ 5相同的注解。但是，AOP运行时仍然是纯Spring AOP，并且不依赖于AspectJ编译器或编织器。 为了方便使用，Spring借鉴了AspectJ的语法。 使用AspectJ编译器和weaver可以使用完整的AspectJ语法。 AspectJ 是最早、功能比较强大的 AOP 实现之一，对整套 AOP 机制都有较好的实现，很多其他语言的 AOP 实现，也借鉴或采纳了 AspectJ 中很多设计。 启用@AspectJ支持 通过Java配置启用@AspectJ支持 在配置类加上@EnableAspectJAutoProxy注解以启用@AspectJ支持 @Configuration @EnableAspectJAutoProxy public class AppConfig { } 通过XML配置启用@AspectJ支持 &lt;aop:aspectj-autoproxy/> 声明一个切面启用@AspectJ支持后，Spring会自动检测在应用程序上下文中使用@AspectJ切面（具有@Aspect批注）的类定义的bean，并用于配置Spring AOP。 使用xml配置声明切面 &lt;bean id=\"myAspect\" class=\"org.xyz.NotVeryUsefulAspect\"> &lt;!-- configure properties of the aspect here --> &lt;/bean> 使用注解声明切面 package org.xyz; import org.aspectj.lang.annotation.Aspect; @Aspect public class NotVeryUsefulAspect { } 声明切入点切入点确定了关注的的连接点，从而使我们能够控制执行通知的时机。 Spring AOP仅支持Spring Bean的方法执行连接点，可以将切入点视为与Spring Bean上的方法执行匹配。 切入点声明由两部分组成：一个包含名称和任何参数的签名，以及一个切入点表达式，该切入点表达式精确地确定我们关注的方法执行。在AOP的@AspectJ批注样式中，常规方法定义提供了切入点签名。 并通过使用@Pointcut注解声明切入点表达式（用作切入点签名的方法必须具有void返回类型）。 一个例子： @Pointcut(\"execution(* transfer(..))\") // 切入点表达式 private void anyOldTransfer() {} // 切入点方法签名 支持的切入点指示符Spring AOP支持以下在切入点表达式中使用的AspectJ切入点指示符（PCD）： execution：匹配方法执行的连接点，这是你将会用到的Spring的最主要的切入点指定者。 描述的最小粒度精确到方法（甚至方法的参数） within：限定匹配特定类型的连接点（在使用SpringAOP的时候，在匹配的类型中定义的方法的执行）。 描述的最小粒度仅仅到一个类 this：限定匹配特定的连接点（使用Spring AOP的时候方法的执行），其中bean reference（Spring AOP 代理）是指定类型的实例。（代理的对象本身） target：限定匹配特定的连接点（使用SpringAOP的时候方法的执行），其中目标对象（被代理的appolication object）是指定类型的实例。（被代理的对象） args：限定匹配特定的连接点（使用Spring AOP的时候方法的执行），其中参数是指定类型的实例。 @target：限定匹配特定的连接点（使用SpringAOP的时候方法的执行），其中执行的对象的类已经有指定类型的注解。 @args：限定匹配特定的连接点（使用SpringAOP的时候方法的执行），其中实际传入参数的运行时类型有指定类型的注解。 @within：限定匹配特定的连接点，其中连接点所在类型已指定注解（在使用Spring AOP的时候，所执行的方法所在类型已指定注解）。 @annotation：限定匹配特定的连接点（使用SpringAOP的时候方法的执行），其中连接点的主题有某种给定的注解合并切入点表达式 组合切入点您可以使用&amp;&amp;，||组合切入点表达式和！您也可以按名称引用切入点表达式。以下示例显示了三个切入点表达式： @Pointcut(\"execution(public * *(..))\") private void anyPublicOperation() {} // 1⃣️ 匹配所有公共方法 @Pointcut(\"within(com.xyz.someapp.trading..*)\") private void inTrading() {} // 2⃣️ 匹配指定包里面的所有方法 @Pointcut(\"anyPublicOperation() &amp;&amp; inTrading()\") private void tradingOperation() {} // 3⃣️ 匹配指定包里面的所有公共方法 共享通用切入点定义在开发应用程序时，开发人员通常希望从多个方面引用应用程序的模块和特定的操作集。我们建议为此定义一个 SystemArchitecture切面，以捕获常见的切入点表达式。这样的方面通常类似于以下示例： package com.xyz.someapp; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Pointcut; @Aspect public class SystemArchitecture { /** * A join point is in the web layer if the method is defined * in a type in the com.xyz.someapp.web package or any sub-package * under that. */ @Pointcut(\"within(com.xyz.someapp.web..*)\") public void inWebLayer() {} /** * A join point is in the service layer if the method is defined * in a type in the com.xyz.someapp.service package or any sub-package * under that. */ @Pointcut(\"within(com.xyz.someapp.service..*)\") public void inServiceLayer() {} /** * A join point is in the data access layer if the method is defined * in a type in the com.xyz.someapp.dao package or any sub-package * under that. */ @Pointcut(\"within(com.xyz.someapp.dao..*)\") public void inDataAccessLayer() {} /** * A business service is the execution of any method defined on a service * interface. This definition assumes that interfaces are placed in the * \"service\" package, and that implementation types are in sub-packages. * * If you group service interfaces by functional area (for example, * in packages com.xyz.someapp.abc.service and com.xyz.someapp.def.service) then * the pointcut expression \"execution(* com.xyz.someapp..service.*.*(..))\" * could be used instead. * * Alternatively, you can write the expression using the 'bean' * PCD, like so \"bean(*Service)\". (This assumes that you have * named your Spring service beans in a consistent fashion.) */ @Pointcut(\"execution(* com.xyz.someapp..service.*.*(..))\") public void businessService() {} /** * A data access operation is the execution of any method defined on a * dao interface. This definition assumes that interfaces are placed in the * \"dao\" package, and that implementation types are in sub-packages. */ @Pointcut(\"execution(* com.xyz.someapp.dao.*.*(..))\") public void dataAccessOperation() {} } 可以在需要切入点表达式的任何地方引用切面中定义的切入点。例如，要使服务层具有事务性： &lt;aop:config> &lt;aop:advisor pointcut=\"com.xyz.someapp.SystemArchitecture.businessService()\" advice-ref=\"tx-advice\"/> &lt;/aop:config> &lt;tx:advice id=\"tx-advice\"> &lt;tx:attributes> &lt;tx:method name=\"*\" propagation=\"REQUIRED\"/> &lt;/tx:attributes> &lt;/tx:advice> Examples 语法： execution(modifiers-pattern? ret-type-pattern declaring-type-pattern?name-pattern(param-pattern) throws-pattern?) 问号表示当前项有也可以没有 其中各项语义如下： modifiers- pattern：方法的可见性，如 public, protected ret-type- pattern：方法的返回值类型，如 int, void 等 declaring-type- pattern：方法所在类的全路径名，如 com, spring, Aspect name- pattern：方法名，如 bui sinessservice () param- pattern：方法的参数类型，如 java. Lang String throws- pattern: 方法抛出的异常类型，如 java.Lang. Exception 一些常见的表达式： 匹配任意public方法 execution(public * *(..)) 匹配所有以set开头的方法 execution(* set*(..)) 匹配AccountService接口定义的任何方法 execution(* com.xyz.service.AccountService.*(..)) 匹配指定包下的方法 execution(* com.xyz.service.*.*(..)) 匹配指定包下面的一个或多个子包下的类方法 execution(* com.xyz.service..*.*(..)) 匹配service包中的所有连接点 within(com.xyz.service.*) 匹配service一个或多个子包中的所有连接点 within(com.xyz.service..*) 代理实现AccountService接口的任何连接点 this(com.xyz.service.AccountService) 目标对象实现AccountService接口的任何连接点 target(com.xyz.service.AccountService) 任何采用单个参数并且在运行时传递的参数为Serializable的连接点 args(java.io.Serializable) 目标对象具有@Transactional注解的任何连接点 @target(org.springframework.transaction.annotation.Transactional) 目标对象的声明类型具有@Transactional注解的任何连接点 @within(org.springframework.transaction.annotation.Transactional) 任何执行方法带有@Transactional批注的连接点 @annotation(org.springframework.transaction.annotation.Transactional) 任何采用单个参数的联接点，并且传递的参数的运行时类型具有Classified注解 @args(com.xyz.security.Classified) 名为tradeService的Spring bean上的任何连接点 bean(tradeService) Spring Bean上具有与通配符表达式* Service匹配的名称的任何连接点 bean(*Service) 声明通知通知用来声明方法在切入点表达式匹配的方法执行之前，之后或周围运行。切入点表达式可以是对命名切入点的简单引用，也可以是就地声明的切入点表达式。 Before Advice使用@Before注解在切面中声明通知。 import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; @Aspect public class BeforeExample { @Before(\"com.xyz.myapp.SystemArchitecture.dataAccessOperation()\") public void doAccessCheck() { // ... } } 声明通知的同时声明切入点： import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; @Aspect public class BeforeExample { @Before(\"execution(* com.xyz.myapp.dao.*.*(..))\") public void doAccessCheck() { // ... } } After Returning Adviceimport org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.AfterReturning; @Aspect public class AfterReturningExample { @AfterReturning(\"com.xyz.myapp.SystemArchitecture.dataAccessOperation()\") public void doAccessCheck() { // ... } } 有时，您需要在通知正文中访问返回的实际值。您可以使用@AfterReturning的形式绑定返回值以获取该访问权限，如以下示例所示： import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.AfterReturning; @Aspect public class AfterReturningExample { @AfterReturning( pointcut=\"com.xyz.myapp.SystemArchitecture.dataAccessOperation()\", returning=\"retVal\") public void doAccessCheck(Object retVal) { // ... } } After Throwing Adviceimport org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.AfterThrowing; @Aspect public class AfterThrowingExample { @AfterThrowing(\"com.xyz.myapp.SystemArchitecture.dataAccessOperation()\") public void doRecoveryActions() { // ... } } 指定异常类型： import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.AfterThrowing; @Aspect public class AfterThrowingExample { @AfterThrowing( pointcut=\"com.xyz.myapp.SystemArchitecture.dataAccessOperation()\", throwing=\"ex\") public void doRecoveryActions(DataAccessException ex) { // ... } } After (Finally) Adviceimport org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.After; @Aspect public class AfterFinallyExample { @After(\"com.xyz.myapp.SystemArchitecture.dataAccessOperation()\") public void doReleaseLock() { // ... } } Around Adviceimport org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Around; import org.aspectj.lang.ProceedingJoinPoint; @Aspect public class AroundExample { @Around(\"com.xyz.myapp.SystemArchitecture.businessService()\") public Object doBasicProfiling(ProceedingJoinPoint pjp) throws Throwable { // start stopwatch Object retVal = pjp.proceed(); // stop stopwatch return retVal; } } 引入引入（Introductions）（在AspectJ中称为类型间声明）使切面可以声明通知对象实现给定的接口，并代表那些对象提供该接口的实现。 您可以使用@DeclareParents批注进行介绍。此批注用于声明匹配类型具有新的父代（因此而得名）。例如，给定一个名为UsageTracked的接口和该接口名为DefaultUsageTracked的实现，以下方面声明服务接口的所有实现者也都实现了UsageTracked接口（例如，通过JMX公开统计信息）： @Aspect public class UsageTracking { @DeclareParents(value=\"com.xzy.myapp.service.*+\", defaultImpl=DefaultUsageTracked.class) public static UsageTracked mixin; @Before(\"com.xyz.myapp.SystemArchitecture.businessService() &amp;&amp; this(usageTracked)\") public void recordUsage(UsageTracked usageTracked) { usageTracked.incrementUseCount(); } } Spring AOP实例代码地址：https://github.com/cayzlh/cayzlh-demos 总结 Spring借鉴了AspectJ的语法 Spring通过动态代理来实现aop 对接口创建代理优于对类创建代理，因为会产生更加松耦合的系统，所以spring默认是使用JDK代理。对类代理是让遗留系统或无法实现接口的第三方类库同样可以得到通知，这种方式应该是备用方案 标记为final的方法不能够被通知。spring是为目标类产生子类。任何需要被通知的方法都被复写，将通知织入。final方法是不允许重写的 spring只支持方法连接点：不提供属性接入点，spring的观点是属性拦截破坏了封装。面向对象的概念是对象自己处理工作，其他对象只能通过方法调用的得到的结果 spring在运行期，生成动态代理对象，不需要特殊的编译器 Spring AOP 优先对接口进行代理 （使用Jdk动态代理）如果目标对象没有实现任何接口，才会对类进行代理 （使用cglib动态代理） 参考 Spring官网(aop) Spring AOP简介与底层实现机制——动态代理 spring源码系列（一）——spring循环引用 彻底征服 Spring AOP 之 理论篇","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"}]},{"title":"SpringBoot异步请求和异步调用","date":"2020-03-24T01:50:41.000Z","path":"2020/03/24/40c5d21f.html","text":"本文转载自：https://cnblogs.com/baixianlong/p/10661591.html 异步请求与同步请求同步请求%% 时序图例子,-> 直线，-->虚线，->>实线箭头 sequenceDiagram participant 浏览器/APP participant 请求处理线程 participant 处理线程 浏览器/APP->>请求处理线程: request loop 等待 浏览器/APP-->浏览器/APP: 等待Response end 请求处理线程->>处理线程: call loop 阻塞 请求处理线程->请求处理线程: 请求处理线程阻塞 end loop 处理中 处理线程->处理线程: 处理线程处理中 end 处理线程->>请求处理线程: return 请求处理线程 ->> 浏览器/APP: Response 异步请求sequenceDiagram participant 浏览器/APP participant 请求处理线程 participant 回调处理线程 participant 处理线程 浏览器/APP->>请求处理线程: request loop 等待 浏览器/APP->浏览器/APP: 等待Response end 请求处理线程->>处理线程: invoke loop 结束 请求处理线程-->>请求处理线程: 处理别的请求去了 end loop 处理中 处理线程->处理线程: 处理线程处理中 end 处理线程->>回调处理线程: callback 回调处理线程 ->> 浏览器/APP: Response 特点可以先释放容器分配给请求的线程与相关资源，减轻系统负担，释放了容器所分配线程的请求，其响应将被延后，可以在耗时处理完成（例如长时间的运算）时再对客户端进行响应。 一句话：增加了服务器对客户端请求的吞吐量（实际生产上我们用的比较少，如果并发请求量很大的情况下，我们会通过nginx把请求负载到集群服务的各个节点上来分摊请求压力，当然还可以通过消息队列来做请求的缓冲）。 异步请求的实现方式一Servlet方式实现异步请求 ： @RequestMapping(value = \"/email/servletReq\", method = GET) public void servletReq (HttpServletRequest request, HttpServletResponse response) { AsyncContext asyncContext = request.startAsync(); //设置监听器:可设置其开始、完成、异常、超时等事件的回调处理 asyncContext.addListener(new AsyncListener() { @Override public void onTimeout(AsyncEvent event) throws IOException { System.out.println(\"超时了...\"); //做一些超时后的相关操作... } @Override public void onStartAsync(AsyncEvent event) throws IOException { System.out.println(\"线程开始\"); } @Override public void onError(AsyncEvent event) throws IOException { System.out.println(\"发生错误：\"+event.getThrowable()); } @Override public void onComplete(AsyncEvent event) throws IOException { System.out.println(\"执行完成\"); //这里可以做一些清理资源的操作... } }); //设置超时时间 asyncContext.setTimeout(20000); asyncContext.start(new Runnable() { @Override public void run() { try { Thread.sleep(10000); System.out.println(\"内部线程：\" + Thread.currentThread().getName()); asyncContext.getResponse().setCharacterEncoding(\"utf-8\"); asyncContext.getResponse().setContentType(\"text/html;charset=UTF-8\"); asyncContext.getResponse().getWriter().println(\"这是异步的请求返回\"); } catch (Exception e) { System.out.println(\"异常：\"+e); } //异步请求完成通知 //此时整个请求才完成 asyncContext.complete(); } }); //此时之类 request的线程连接已经释放了 System.out.println(\"主线程：\" + Thread.currentThread().getName()); } 方式二使用很简单，直接返回的参数包裹一层callable即可，可以继承WebMvcConfigurerAdapter类来设置默认线程池和超时处理。 @RequestMapping(value = \"/email/callableReq\", method = GET) @ResponseBody public Callable&lt;String> callableReq () { System.out.println(\"外部线程：\" + Thread.currentThread().getName()); return new Callable&lt;String>() { @Override public String call() throws Exception { Thread.sleep(10000); System.out.println(\"内部线程：\" + Thread.currentThread().getName()); return \"callable!\"; } }; } @Configuration public class RequestAsyncPoolConfig extends WebMvcConfigurerAdapter { @Resource private ThreadPoolTaskExecutor myThreadPoolTaskExecutor; @Override public void configureAsyncSupport(final AsyncSupportConfigurer configurer) { //处理 callable超时 configurer.setDefaultTimeout(60*1000); configurer.setTaskExecutor(myThreadPoolTaskExecutor); configurer.registerCallableInterceptors(timeoutCallableProcessingInterceptor()); } @Bean public TimeoutCallableProcessingInterceptor timeoutCallableProcessingInterceptor() { return new TimeoutCallableProcessingInterceptor(); } } 方式三和方式二差不多，在Callable外包一层，给WebAsyncTask设置一个超时回调，即可实现超时处理。 @RequestMapping(value = \"/email/webAsyncReq\", method = GET) @ResponseBody public WebAsyncTask&lt;String> webAsyncReq () { System.out.println(\"外部线程：\" + Thread.currentThread().getName()); Callable&lt;String> result = () -> { System.out.println(\"内部线程开始：\" + Thread.currentThread().getName()); try { TimeUnit.SECONDS.sleep(4); } catch (Exception e) { // TODO: handle exception } logger.info(\"副线程返回\"); System.out.println(\"内部线程返回：\" + Thread.currentThread().getName()); return \"success\"; }; WebAsyncTask&lt;String> wat = new WebAsyncTask&lt;String>(3000L, result); wat.onTimeout(new Callable&lt;String>() { @Override public String call() throws Exception { // TODO Auto-generated method stub return \"超时\"; } }); return wat; } 方式四DeferredResult可以处理一些相对复杂一些的业务逻辑，最主要还是可以在另一个线程里面进行业务处理及返回，即可在两个完全不相干的线程间的通信。 @RequestMapping(value = \"/email/deferredResultReq\", method = GET) @ResponseBody public DeferredResult&lt;String> deferredResultReq () { System.out.println(\"外部线程：\" + Thread.currentThread().getName()); //设置超时时间 DeferredResult&lt;String> result = new DeferredResult&lt;String>(60*1000L); //处理超时事件 采用委托机制 result.onTimeout(new Runnable() { @Override public void run() { System.out.println(\"DeferredResult超时\"); result.setResult(\"超时了!\"); } }); result.onCompletion(new Runnable() { @Override public void run() { //完成后 System.out.println(\"调用完成\"); } }); myThreadPoolTaskExecutor.execute(new Runnable() { @Override public void run() { //处理业务逻辑 System.out.println(\"内部线程：\" + Thread.currentThread().getName()); //返回结果 result.setResult(\"DeferredResult!!\"); } }); return result; } SpringBoot中异步调用的使用介绍异步请求的处理。除了异步请求，一般上我们用的比较多的应该是异步调用。通常在开发过程中，会遇到一个方法是和实际业务无关的，没有紧密性的。比如记录日志信息等业务。这个时候正常就是启一个新线程去做一些业务处理，让主线程异步的执行其他业务。 使用方式（基于spring下）需要在启动类加入@EnableAsync使异步调用@Async注解生效 在需要异步执行的方法上加入此注解即可@Async(&quot;threadPool&quot;),threadPool为自定义线程池。 代码略。 注意事项在默认情况下，未设置TaskExecutor时，默认是使用SimpleAsyncTaskExecutor这个线程池，但此线程不是真正意义上的线程池，因为线程不重用，每次调用都会创建一个新的线程。可通过控制台日志输出可以看出，每次输出线程名都是递增的。所以最好我们来自定义一个线程池。 调用的异步方法，不能为同一个类的方法（包括同一个类的内部类），简单来说，因为Spring在启动扫描时会为其创建一个代理类，而同类调用时，还是调用本身的代理类的，所以和平常调用是一样的。 其他的注解如@Cache等也是一样的道理，说白了，就是Spring的代理机制造成的。所以在开发中，最好把异步服务单独抽出一个类来管理。下面会重点讲述。。 什么情况下会导致@Async异步方法会失效？ 调用同一个类下注有@Async异步方法： 在spring中像@Async和@Transactional、cache等注解本质使用的是动态代理，其实Spring容器在初始化的时候Spring容器会将含有AOP注解的类对象“替换”为代理对象（简单这么理解），那么注解失效的原因就很明显了，就是因为调用方法的是对象本身而不是代理对象，因为没有经过Spring容器，那么解决方法也会沿着这个思路来解决。 调用的是静态(static )方法 调用(private)私有化方法 解决4中问题1的方式将要异步执行的方法单独抽取成一个类，原理就是当你把执行异步的方法单独抽取成一个类的时候，这个类肯定是被Spring管理的，其他Spring组件需要调用的时候肯定会注入进去，这时候实际上注入进去的就是代理类了。 其实我们的注入对象都是从Spring容器中给当前Spring组件进行成员变量的赋值，由于某些类使用了AOP注解，那么实际上在Spring容器中实际存在的是它的代理对象。那么我们就可以通过上下文获取自己的代理对象调用异步方法。 @Controller @RequestMapping(\"/app\") public class EmailController { //获取ApplicationContext对象方式有多种,这种最简单,其它的大家自行了解一下 @Autowired private ApplicationContext applicationContext; @RequestMapping(value = \"/email/asyncCall\", method = GET) @ResponseBody public Map&lt;String, Object> asyncCall () { Map&lt;String, Object> resMap = new HashMap&lt;String, Object>(); try{ //这样调用同类下的异步方法是不起作用的 //this.testAsyncTask(); //通过上下文获取自己的代理对象调用异步方法 EmailController emailController = (EmailController)applicationContext.getBean(EmailController.class); emailController.testAsyncTask(); resMap.put(\"code\",200); }catch (Exception e) { resMap.put(\"code\",400); logger.error(\"error!\",e); } return resMap; } //注意一定是public,且是非static方法 @Async public void testAsyncTask() throws InterruptedException { Thread.sleep(10000); System.out.println(\"异步任务执行完成！\"); } } 开启cglib代理，手动获取Spring代理类,从而调用同类下的异步方法。首先，在启动类上加上@EnableAspectJAutoProxy(exposeProxy = true)注解。代码实现，如下： @Service @Transactional(value = \"transactionManager\", readOnly = false, propagation = Propagation.REQUIRED, rollbackFor = Throwable.class) public class EmailService { @Autowired private ApplicationContext applicationContext; @Async public void testSyncTask() throws InterruptedException { Thread.sleep(10000); System.out.println(\"异步任务执行完成！\"); } public void asyncCallTwo() throws InterruptedException { //this.testSyncTask(); // EmailService emailService = (EmailService)applicationContext.getBean(EmailService.class); // emailService.testSyncTask(); boolean isAop = AopUtils.isAopProxy(EmailController.class);//是否是代理对象； boolean isCglib = AopUtils.isCglibProxy(EmailController.class); //是否是CGLIB方式的代理对象； boolean isJdk = AopUtils.isJdkDynamicProxy(EmailController.class); //是否是JDK动态代理方式的代理对象； //以下才是重点!!! EmailService emailService = (EmailService)applicationContext.getBean(EmailService.class); EmailService proxy = (EmailService) AopContext.currentProxy(); System.out.println(emailService == proxy ? true : false); proxy.testSyncTask(); System.out.println(\"end!!!\"); } } 异步请求与异步调用的区别两者的使用场景不同，异步请求用来解决并发请求对服务器造成的压力，从而提高对请求的吞吐量；而异步调用是用来做一些非主线流程且不需要实时计算和响应的任务，比如同步日志到kafka中做日志分析等。 异步请求是会一直等待response相应的，需要返回结果给客户端的；而异步调用我们往往会马上返回给客户端响应，完成这次整个的请求，至于异步调用的任务后台自己慢慢跑就行，客户端不会关心。","tags":[{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cayzlh.com/tags/SpringBoot/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"https://www.cayzlh.com/categories/Spring/SpringBoot/"}]},{"title":"Mybatis中用到的几种设计模式","date":"2020-03-23T12:50:34.000Z","path":"2020/03/23/26b455b4.html","text":"本文转载自：http://www.crazyant.net/2022.html Mybatis至少遇到了以下的设计模式的使用： Builder模式，例如SqlSessionFactoryBuilder、XMLConfigBuilder、XMLMapperBuilder、XMLStatementBuilder、CacheBuilder； 工厂模式，例如SqlSessionFactory、ObjectFactory、MapperProxyFactory； 单例模式，例如ErrorContext和LogFactory； 代理模式，Mybatis实现的核心，比如MapperProxy、ConnectionLogger，用的jdk的动态代理；还有executor.loader包使用了cglib或者javassist达到延迟加载的效果； 组合模式，例如SqlNode和各个子类ChooseSqlNode等； 模板方法模式，例如BaseExecutor和SimpleExecutor，还有BaseTypeHandler和所有的子类例如IntegerTypeHandler； 适配器模式，例如Log的Mybatis接口和它对jdbc、log4j等各种日志框架的适配实现； 装饰者模式，例如Cache包中的cache.decorators子包中等各个装饰者的实现； 迭代器模式，例如迭代器模式PropertyTokenizer； 接下来挨个模式进行解读，先介绍模式自身的知识，然后解读在Mybatis中怎样应用了该模式。 Builder模式Builder模式的定义是“将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示”，它属于创建类模式，一般来说，如果一个对象的构建比较复杂，超出了构造函数所能包含的范围，就可以使用工厂模式和Builder模式，相对于工厂模式会产出一个完整的产品，Builder应用于更加复杂的对象的构建，甚至只会构建产品的一个部分。 在Mybatis环境的初始化过程中，SqlSessionFactoryBuilder会调用XMLConfigBuilder读取所有的MybatisMapConfig.xml和所有的*Mapper.xml文件，构建Mybatis运行的核心对象Configuration对象，然后将该Configuration对象作为参数构建一个SqlSessionFactory对象。 其中XMLConfigBuilder在构建Configuration对象时，也会调用XMLMapperBuilder用于读取*Mapper文件，而XMLMapperBuilder会使用XMLStatementBuilder来读取和build所有的SQL语句。 在这个过程中，有一个相似的特点，就是这些Builder会读取文件或者配置，然后做大量的XpathParser解析、配置或语法的解析、反射生成对象、存入结果缓存等步骤，这么多的工作都不是一个构造函数所能包括的，因此大量采用了Builder模式来解决。 对于builder的具体类，方法都大都用build*开头，比如SqlSessionFactoryBuilder为例，它包含以下方法： 即根据不同的输入参数来构建SqlSessionFactory这个工厂对象。 工厂模式在Mybatis中比如SqlSessionFactory使用的是工厂模式，该工厂没有那么复杂的逻辑，是一个简单工厂模式。 简单工厂模式(Simple Factory Pattern)：又称为静态工厂方法(Static Factory Method)模式，它属于类创建型模式。在简单工厂模式中，可以根据参数的不同返回不同类的实例。简单工厂模式专门定义一个类来负责创建其他类的实例，被创建的实例通常都具有共同的父类。 SqlSession可以认为是一个Mybatis工作的核心的接口，通过这个接口可以执行执行SQL语句、获取Mappers、管理事务。类似于连接MySQL的Connection对象。 可以看到，该Factory的openSession方法重载了很多个，分别支持autoCommit、Executor、Transaction等参数的输入，来构建核心的SqlSession对象。 在DefaultSqlSessionFactory的默认工厂实现里，有一个方法可以看出工厂怎么产出一个产品： private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) { Transaction tx = null; try { final Environment environment = configuration.getEnvironment(); final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); final Executor executor = configuration.newExecutor(tx, execType); return new DefaultSqlSession(configuration, executor, autoCommit); } catch (Exception e) { closeTransaction(tx); // may have fetched a connection so lets call // close() throw ExceptionFactory.wrapException(\"Error opening session. Cause: \" + e, e); } finally { ErrorContext.instance().reset(); } } 这是一个openSession调用的底层方法，该方法先从configuration读取对应的环境配置，然后初始化TransactionFactory获得一个Transaction对象，然后通过Transaction获取一个Executor对象，最后通过configuration、Executor、是否autoCommit三个参数构建了SqlSession。 在这里其实也可以看到端倪，SqlSession的执行，其实是委托给对应的Executor来进行的。 而对于LogFactory，它的实现代码： public final class LogFactory { private static Constructor&lt;? extends Log> logConstructor; private LogFactory() { // disable construction } public static Log getLog(Class&lt;?> aClass) { return getLog(aClass.getName()); } 这里有个特别的地方，是Log变量的的类型是Constructor，也就是说该工厂生产的不只是一个产品，而是具有Log公共接口的一系列产品，比如Log4jImpl、Slf4jImpl等很多具体的Log。 单例模式单例模式(Singleton Pattern)：单例模式确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例，这个类称为单例类，它提供全局访问的方法。 单例模式的要点有三个：一是某个类只能有一个实例；二是它必须自行创建这个实例；三是它必须自行向整个系统提供这个实例。单例模式是一种对象创建型模式。单例模式又名单件模式或单态模式。 在Mybatis中有两个地方用到单例模式，ErrorContext和LogFactory，其中ErrorContext是用在每个线程范围内的单例，用于记录该线程的执行环境错误信息，而LogFactory则是提供给整个Mybatis使用的日志工厂，用于获得针对项目配置好的日志对象。 ErrorContext的单例实现代码： public class ErrorContext { private static final ThreadLocal&lt;ErrorContext> LOCAL = new ThreadLocal&lt;ErrorContext>(); private ErrorContext() { } public static ErrorContext instance() { ErrorContext context = LOCAL.get(); if (context == null) { context = new ErrorContext(); LOCAL.set(context); } return context; } 构造函数是private修饰，具有一个static的局部instance变量和一个获取instance变量的方法，在获取实例的方法中，先判断是否为空如果是的话就先创建，然后返回构造好的对象。 只是这里有个有趣的地方是，LOCAL的静态实例变量使用了ThreadLocal修饰，也就是说它属于每个线程各自的数据，而在instance()方法中，先获取本线程的该实例，如果没有就创建该线程独有的ErrorContext。 代理模式代理模式可以认为是Mybatis的核心使用的模式，正是由于这个模式，我们只需要编写Mapper.java接口，不需要实现，由Mybatis后台帮我们完成具体SQL的执行。 代理模式(Proxy Pattern) ：给某一个对象提供一个代 理，并由代理对象控制对原对象的引用。代理模式的英 文叫做Proxy或Surrogate，它是一种对象结构型模式。 代理模式包含如下角色： Subject: 抽象主题角色 Proxy: 代理主题角色 RealSubject: 真实主题角色 这里有两个步骤，第一个是提前创建一个Proxy，第二个是使用的时候会自动请求Proxy，然后由Proxy来执行具体事务； 当我们使用Configuration的getMapper方法时，会调用mapperRegistry.getMapper方法，而该方法又会调用mapperProxyFactory.newInstance(sqlSession)来生成一个具体的代理： return mapperInterface; } public Map&lt;Method, MapperMethod> getMethodCache() { return methodCache; } @SuppressWarnings(\"unchecked\") protected T newInstance(MapperProxy&lt;T> mapperProxy) { return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] { mapperInterface }, mapperProxy); } public T newInstance(SqlSession sqlSession) { final MapperProxy&lt;T> mapperProxy = new MapperProxy&lt;T>(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy); } } 在这里，先通过T newInstance(SqlSession sqlSession)方法会得到一个MapperProxy对象，然后调用T newInstance(MapperProxy mapperProxy)生成代理对象然后返回。 而查看MapperProxy的代码，可以看到如下内容： public class MapperProxy&lt;T> implements InvocationHandler, Serializable { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { try { if (Object.class.equals(method.getDeclaringClass())) { return method.invoke(this, args); } else if (isDefaultMethod(method)) { return invokeDefaultMethod(proxy, method, args); } } catch (Throwable t) { throw ExceptionUtil.unwrapThrowable(t); } final MapperMethod mapperMethod = cachedMapperMethod(method); return mapperMethod.execute(sqlSession, args); } 非常典型的，该MapperProxy类实现了InvocationHandler接口，并且实现了该接口的invoke方法。 通过这种方式，我们只需要编写Mapper.java接口类，当真正执行一个Mapper接口的时候，就会转发给MapperProxy.invoke方法，而该方法则会调用后续的sqlSession.cud&gt;executor.execute&gt;prepareStatement等一系列方法，完成SQL的执行和返回。 组合模式组合模式组合多个对象形成树形结构以表示“整体-部分”的结构层次。 组合模式对单个对象(叶子对象)和组合对象(组合对象)具有一致性，它将对象组织到树结构中，可以用来描述整体与部分的关系。同时它也模糊了简单元素(叶子对象)和复杂元素(容器对象)的概念，使得客户能够像处理简单元素一样来处理复杂元素，从而使客户程序能够与复杂元素的内部结构解耦。 在使用组合模式中需要注意一点也是组合模式最关键的地方：叶子对象和组合对象实现相同的接口。这就是组合模式能够将叶子节点和对象节点进行一致处理的原因。 Mybatis支持动态SQL的强大功能，比如下面的这个SQL： &lt;update id=\"update\" parameterType=\"org.format.dynamicproxy.mybatis.bean.User\"> UPDATE users &lt;trim prefix=\"SET\" prefixOverrides=\",\"> &lt;if test=\"name != null and name != ''\"> name = #{name} &lt;/if> &lt;if test=\"age != null and age != ''\"> , age = #{age} &lt;/if> &lt;if test=\"birthday != null and birthday != ''\"> , birthday = #{birthday} &lt;/if> &lt;/trim> where id = ${id} &lt;/update> 在这里面使用到了trim、if等动态元素，可以根据条件来生成不同情况下的SQL； 在DynamicSqlSource.getBoundSql方法里，调用了rootSqlNode.apply(context)方法，apply方法是所有的动态节点都实现的接口： public interface SqlNode { boolean apply(DynamicContext context); } 对于实现该SqlSource接口的所有节点，就是整个组合模式树的各个节点： 组合模式的简单之处在于，所有的子节点都是同一类节点，可以递归的向下执行，比如对于TextSqlNode，因为它是最底层的叶子节点，所以直接将对应的内容append到SQL语句中： @Override public boolean apply(DynamicContext context) { GenericTokenParser parser = createParser(new BindingTokenParser(context, injectionFilter)); context.appendSql(parser.parse(text)); return true; } 但是对于IfSqlNode，就需要先做判断，如果判断通过，仍然会调用子元素的SqlNode，即contents.apply方法，实现递归的解析。 @Override public boolean apply(DynamicContext context) { if (evaluator.evaluateBoolean(test, context.getBindings())) { contents.apply(context); return true; } return false; } 模板方法模式模板方法模式是所有模式中最为常见的几个模式之一，是基于继承的代码复用的基本技术。 模板方法模式需要开发抽象类和具体子类的设计师之间的协作。一个设计师负责给出一个算法的轮廓和骨架，另一些设计师则负责给出这个算法的各个逻辑步骤。代表这些具体逻辑步骤的方法称做基本方法(primitive method)；而将这些基本方法汇总起来的方法叫做模板方法(template method)，这个设计模式的名字就是从此而来。 模板类定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。 在Mybatis中，sqlSession的SQL执行，都是委托给Executor实现的，Executor包含以下结构： 其中的BaseExecutor就采用了模板方法模式，它实现了大部分的SQL执行逻辑，然后把以下几个方法交给子类定制化完成： @Override public boolean apply(DynamicContext context) { if (evaluator.evaluateBoolean(test, context.getBindings())) { contents.apply(context); return true; } return false; } 该模板方法类有几个子类的具体实现，使用了不同的策略： 简单SimpleExecutor：每执行一次update或select，就开启一个Statement对象，用完立刻关闭Statement对象。（可以是Statement或PrepareStatement对象） 重用ReuseExecutor：执行update或select，以sql作为key查找Statement对象，存在就使用，不存在就创建，用完后，不关闭Statement对象，而是放置于Map内，供下一次使用。（可以是Statement或PrepareStatement对象） 批量BatchExecutor：执行update（没有select，JDBC批处理不支持select），将所有sql都添加到批处理中（addBatch()），等待统一执行（executeBatch()），它缓存了多个Statement对象，每个Statement对象都是addBatch()完毕后，等待逐一执行executeBatch()批处理的；BatchExecutor相当于维护了多个桶，每个桶里都装了很多属于自己的SQL，就像苹果蓝里装了很多苹果，番茄蓝里装了很多番茄，最后，再统一倒进仓库。（可以是Statement或PrepareStatement对象） 比如在SimpleExecutor中这样实现update方法： @Override public int doUpdate(MappedStatement ms, Object parameter) throws SQLException { Statement stmt = null; try { Configuration configuration = ms.getConfiguration(); StatementHandler handler = configuration.newStatementHandler(this, ms, parameter, RowBounds.DEFAULT, null, null); stmt = prepareStatement(handler, ms.getStatementLog()); return handler.update(stmt); } finally { closeStatement(stmt); } } 适配器模式适配器模式(Adapter Pattern) ：将一个接口转换成客户希望的另一个接口，适配器模式使接口不兼容的那些类可以一起工作，其别名为包装器(Wrapper)。适配器模式既可以作为类结构型模式，也可以作为对象结构型模式。 在Mybatsi的logging包中，有一个Log接口： public interface Log { boolean isDebugEnabled(); boolean isTraceEnabled(); void error(String s, Throwable e); void error(String s); void debug(String s); void trace(String s); void warn(String s); } 该接口定义了Mybatis直接使用的日志方法，而Log接口具体由谁来实现呢？Mybatis提供了多种日志框架的实现，这些实现都匹配这个Log接口所定义的接口方法，最终实现了所有外部日志框架到Mybatis日志包的适配： 比如对于Log4jImpl的实现来说，该实现持有了org.apache.log4j.Logger的实例，然后所有的日志方法，均委托该实例来实现。 public class Log4jImpl implements Log { private static final String FQCN = Log4jImpl.class.getName(); private Logger log; public Log4jImpl(String clazz) { log = Logger.getLogger(clazz); } @Override public boolean isDebugEnabled() { return log.isDebugEnabled(); } @Override public boolean isTraceEnabled() { return log.isTraceEnabled(); } @Override public void error(String s, Throwable e) { log.log(FQCN, Level.ERROR, s, e); } @Override public void error(String s) { log.log(FQCN, Level.ERROR, s, null); } @Override public void debug(String s) { log.log(FQCN, Level.DEBUG, s, null); } @Override public void trace(String s) { log.log(FQCN, Level.TRACE, s, null); } @Override public void warn(String s) { log.log(FQCN, Level.WARN, s, null); } } 装饰者模式装饰模式(Decorator Pattern) ：动态地给一个对象增加一些额外的职责(Responsibility)，就增加对象功能来说，装饰模式比生成子类实现更为灵活。其别名也可以称为包装器(Wrapper)，与适配器模式的别名相同，但它们适用于不同的场合。根据翻译的不同，装饰模式也有人称之为“油漆工模式”，它是一种对象结构型模式。 在mybatis中，缓存的功能由根接口Cache（org.apache.ibatis.cache.Cache）定义。整个体系采用装饰器设计模式，数据存储和缓存的基本功能由PerpetualCache（org.apache.ibatis.cache.impl.PerpetualCache）永久缓存实现，然后通过一系列的装饰器来对PerpetualCache永久缓存进行缓存策略等方便的控制。如下图： 用于装饰PerpetualCache的标准装饰器共有8个（全部在org.apache.ibatis.cache.decorators包中）： FifoCache：先进先出算法，缓存回收策略 LoggingCache：输出缓存命中的日志信息 LruCache：最近最少使用算法，缓存回收策略 ScheduledCache：调度缓存，负责定时清空缓存 SerializedCache：缓存序列化和反序列化存储 SoftCache：基于软引用实现的缓存管理策略 SynchronizedCache：同步的缓存装饰器，用于防止多线程并发访问 WeakCache：基于弱引用实现的缓存管理策略 另外，还有一个特殊的装饰器TransactionalCache：事务性的缓存正如大多数持久层框架一样，mybatis缓存同样分为一级缓存和二级缓存 一级缓存，又叫本地缓存，是PerpetualCache类型的永久缓存，保存在执行器中（BaseExecutor），而执行器又在SqlSession（DefaultSqlSession）中，所以一级缓存的生命周期与SqlSession是相同的。 二级缓存，又叫自定义缓存，实现了Cache接口的类都可以作为二级缓存，所以可配置如encache等的第三方缓存。二级缓存以namespace名称空间为其唯一标识，被保存在Configuration核心配置对象中。 二级缓存对象的默认类型为PerpetualCache，如果配置的缓存是默认类型，则mybatis会根据配置自动追加一系列装饰器。 Cache对象之间的引用顺序为： SynchronizedCache–&gt;LoggingCache–&gt;SerializedCache–&gt;ScheduledCache–&gt;LruCache–&gt;PerpetualCache 迭代器模式迭代器（Iterator）模式，又叫做游标（Cursor）模式。GOF给出的定义为：提供一种方法访问一个容器（container）对象中各个元素，而又不需暴露该对象的内部细节。 Java的Iterator就是迭代器模式的接口，只要实现了该接口，就相当于应用了迭代器模式： 比如Mybatis的PropertyTokenizer是property包中的重量级类，该类会被reflection包中其他的类频繁的引用到。这个类实现了Iterator接口，在使用时经常被用到的是Iterator接口中的hasNext这个函数。 public class PropertyTokenizer implements Iterator&lt;PropertyTokenizer> { private String name; private String indexedName; private String index; private String children; public PropertyTokenizer(String fullname) { int delim = fullname.indexOf('.'); if (delim > -1) { name = fullname.substring(0, delim); children = fullname.substring(delim + 1); } else { name = fullname; children = null; } indexedName = name; delim = name.indexOf('['); if (delim > -1) { index = name.substring(delim + 1, name.length() - 1); name = name.substring(0, delim); } } public String getName() { return name; } public String getIndex() { return index; } public String getIndexedName() { return indexedName; } public String getChildren() { return children; } @Override public boolean hasNext() { return children != null; } @Override public PropertyTokenizer next() { return new PropertyTokenizer(children); } @Override public void remove() { throw new UnsupportedOperationException( \"Remove is not supported, as it has no meaning in the context of properties.\"); } } 可以看到，这个类传入一个字符串到构造函数，然后提供了iterator方法对解析后的子串进行遍历，是一个很常用的方法类。 参考资料 图说设计模式 深入浅出Mybatis系列（十）—SQL执行流程分析（源码篇） 设计模式读书笔记—–组合模式 Mybatis3.3.x技术内幕（四）：五鼠闹东京之执行器Executor设计原本 mybatis缓存机制详解（一）——Cache","tags":[{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"设计模式","slug":"设计模式","permalink":"https://www.cayzlh.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"MyBatis","slug":"MyBatis","permalink":"https://www.cayzlh.com/tags/MyBatis/"}],"categories":[{"name":"框架","slug":"框架","permalink":"https://www.cayzlh.com/categories/%E6%A1%86%E6%9E%B6/"},{"name":"MyBatis","slug":"框架/MyBatis","permalink":"https://www.cayzlh.com/categories/%E6%A1%86%E6%9E%B6/MyBatis/"}]},{"title":"Java8 的日期处理实践","date":"2020-03-22T13:07:59.000Z","path":"2020/03/22/d856f34b.html","text":"出处：JavaSE基础:扩展Java 8 日期操作 示例1： 获取当天日期Java 8中获取今天的日期 Java 8中的 LocalDate 用于表示当天日期。和java.util.Date不同，它只有日期，不包含时间。当你仅需要表示日期时就用这个类。 public class Demo01 { public static void main(String[] args) { LocalDate today = LocalDate.now(); System.out.println(\"今天的日期:\" + today); } }/*运行结果:今天的日期:2018-02-05*/ 示例2：获取年、月、日Java 8中获取年、月、日信息 public class Demo02 { public static void main(String[] args) { LocalDate today = LocalDate.now(); int year = today.getYear(); int month = today.getMonthValue(); int day = today.getDayOfMonth(); System.out.println(\"year:\" + year); System.out.println(\"month:\" + month); System.out.println(\"day:\" + day); } } 示例3：创建任意日期Java 8中处理特定日期 我们通过静态工厂方法now()非常容易地创建了当天日期，你还可以调用另一个有用的工厂方法LocalDate.of()创建任意日期， 该方法需要传入年、月、日做参数，返回对应的LocalDate实例。这个方法的好处是没再犯老API的设计错误，比如年度起始于1900，月份是从0开 始等等。 public class Demo03 { public static void main(String[] args) { LocalDate date = LocalDate.of(2018, 2, 6); System.out.println(\"自定义日期:\" + date); } } 示例4：判断日期是否相等Java 8中判断两个日期是否相等 public class Demo04 { public static void main(String[] args) { LocalDate date1 = LocalDate.now(); LocalDate date2 = LocalDate.of(2018, 2, 5); if (date1.equals(date2)) { System.out.println(\"时间相等\"); } else { System.out.println(\"时间不等\"); } } } 示例5：周期性事件（生日）Java 8中检查像生日这种周期性事件 public class Demo05 { public static void main(String[] args) { LocalDate date1 = LocalDate.now(); LocalDate date2 = LocalDate.of(2018, 2, 6); MonthDay birthday = MonthDay.of(date2.getMonth(), date2.getDayOfMonth()); MonthDay currentMonthDay = MonthDay.from(date1); if (currentMonthDay.equals(birthday)) { System.out.println(\"是你的生日\"); } else { System.out.println(\"你的生日还没有到\"); } } } 只要当天的日期和生日匹配，无论是哪一年都会打印出祝贺信息。你可以把程序整合进系统时钟，看看生日时是否会受到提醒，或者写一个单元测试来检测代码是否运行正确。 示例6：获取当前时间Java 8中获取当前时间 public class Demo06 { public static void main(String[] args) { LocalTime time = LocalTime.now(); System.out.println(\"获取当前的时间,不含有日期:\" + time); } } 可以看到当前时间就只包含时间信息，没有日期 示例7：计算3小时以后的时间Java 8中获取当前时间 通过增加小时、分、秒来计算将来的时间很常见。Java 8除了不变类型和线程安全的好处之外，还提供了更好的plusHours()方法替换add()，并且是兼容的。注意，这些方法返回一个全新的LocalTime实例，由于其不可变性，返回后一定要用变量赋值。 public class Demo07 { public static void main(String[] args) { LocalTime time = LocalTime.now(); LocalTime newTime = time.plusHours(3); System.out.println(\"三个小时后的时间为:\" + newTime); } } 示例8：计算一周后的日期Java 8如何计算一周后的日期 和上个例子计算3小时以后的时间类似，这个例子会计算一周后的日期。LocalDate日期不包含时间信息，它的plus()方法用来增加天、周、月，ChronoUnit类声明了这些时间单位。由于LocalDate也是不变类型，返回后一定要用变量赋值。 public class Demo08 { public static void main(String[] args) { LocalDate today = LocalDate.now(); System.out.println(\"今天的日期为:\" + today); LocalDate nextWeek = today.plus(1, ChronoUnit.WEEKS); System.out.println(\"一周后的日期为:\" + nextWeek); } } 可以看到新日期离当天日期是7天，也就是一周。你可以用同样的方法增加1个月、1年、1小时、1分钟甚至一个世纪，更多选项可以查看Java 8 API中的ChronoUnit类 示例9：计算一年前的日期Java 8计算一年前或一年后的日期 利用minus()方法计算一年前的日期 public class Demo09 { public static void main(String[] args) { LocalDate today = LocalDate.now(); LocalDate previousYear = today.minus(1, ChronoUnit.YEARS); System.out.println(\"一年前的日期 : \" + previousYear); LocalDate nextYear = today.plus(1, ChronoUnit.YEARS); System.out.println(\"一年后的日期:\" + nextYear); } } 示例10：时间戳Java 8的Clock时钟类 Java 8增加了一个Clock时钟类用于获取当时的时间戳，或当前时区下的日期时间信息。以前用到System.currentTimeInMillis()和TimeZone.getDefault()的地方都可用Clock替换。 public class Demo10 { public static void main( String[] args) { // Returns the current time based on your system clock and set to UTC. Clock clock = Clock.systemUTC(); System.out.println(\"Clock : \" + clock.millis()); // Returns time based on system clock zone Clock defaultClock = Clock.systemDefaultZone(); System.out.println(\"Clock : \" + defaultClock.millis()); } } 示例11：判断日期的前后如何用Java判断日期是早于还是晚于另一个日期 另一个工作中常见的操作就是如何判断给定的一个日期是大于某天还是小于某天？在Java 8中，LocalDate类有两类方法isBefore()和isAfter()用于比较日期。调用isBefore()方法时，如果给定日期小于当前日期则返回true。 public class Demo11 { public static void main(String[] args) { LocalDate today = LocalDate.now(); LocalDate tomorrow = LocalDate.of(2018, 2, 6); if (tomorrow.isAfter(today)) { System.out.println(\"之后的日期:\" + tomorrow); } LocalDate yesterday = today.minus(1, ChronoUnit.DAYS); if (yesterday.isBefore(today)) { System.out.println(\"之前的日期:\" + yesterday); } } } 示例12：时区分离Java 8中处理时区 Java 8不仅分离了日期和时间，也把时区分离出来了。现在有一系列单独的类如ZoneId来处理特定时区，ZoneDateTime类来表示某时区下的时间。这在Java 8以前都是 GregorianCalendar类来做的。下面这个例子展示了如何把本时区的时间转换成另一个时区的时间。 public class Demo12 { public static void main(String[] args) { // Date and time with timezone in Java 8 ZoneId america = ZoneId.of(\"America/New_York\"); LocalDateTime localtDateAndTime = LocalDateTime.now(); ZonedDateTime dateAndTimeInNewYork = ZonedDateTime.of(localtDateAndTime, america ); System.out.println(\"Current date and time in a particular timezone : \" + dateAndTimeInNewYork); } } 示例13：固定日期如何表示信用卡到期这类固定日期，答案就在YearMonth 与 MonthDay检查重复事件的例子相似，YearMonth是另一个组合类，用于表示信用卡到期日、FD到期日、期货期权到期日等。还可以用这个类得到 当月共有多少天，YearMonth实例的lengthOfMonth()方法可以返回当月的天数，在判断2月有28天还是29天时非常有用。 public class Demo13 { public static void main(String[] args) { YearMonth currentYearMonth = YearMonth.now(); System.out.printf(\"Days in month year %s: %d%n\", currentYearMonth, currentYearMonth.lengthOfMonth()); YearMonth creditCardExpiry = YearMonth.of(2019, Month.FEBRUARY); System.out.printf(\"Your credit card expires on %s %n\", creditCardExpiry); } } 示例14：检查闰年如何在Java 8中检查闰年 public class Demo14 { public static void main(String[] args) { LocalDate today = LocalDate.now(); if (today.isLeapYear()) { System.out.println(\"This year is Leap year\"); } else { System.out.println(\"2018 is not a Leap year\"); } } } 示例15：计算日期之间的天数计算两个日期之间的天数和月数 有一个常见日期操作是计算两个日期之间的天数、周数或月数。在Java 8中可以用java.time.Period类来做计算。下面这个例子中，我们计算了当天和将来某一天之间的月数。 public class Demo15 { public static void main(String[] args) { LocalDate today = LocalDate.now(); LocalDate java8Release = LocalDate.of(2018, 12, 14); Period periodToNextJavaRelease = Period.between(today, java8Release); System.out.println( \"Months left between today and Java 8 release : \" + periodToNextJavaRelease.getMonths()); } } 示例16：获取时间戳在Java 8中获取当前的时间戳 Instant类有一个静态工厂方法now()会返回当前的时间戳，如下所示： public class Demo16 { public static void main(String[] args) { Instant timestamp = Instant.now(); System.out.println(\"What is value of this instant \" + timestamp.toEpochMilli()); } } 时间戳信息里同时包含了日期和时间，这和java.util.Date很像。实际上Instant类确实等同于 Java 8之前的Date类，你可以使用Date类和Instant类各自的转换方法互相转换，例如：Date.from(Instant) 将Instant转换成java.util.Date，Date.toInstant()则是将Date类转换成Instant类。 示例17：格式化工具:Java 8中如何使用预定义的格式化工具去解析或格式化日期 public class Demo17 { public static void main(String[] args) { String dayAfterTommorrow = \"20180205\"; LocalDate formatted = LocalDate .parse(dayAfterTommorrow, DateTimeFormatter.BASIC_ISO_DATE); System.out.println(dayAfterTommorrow + \" 格式化后的日期为: \" + formatted); } } 示例18：字符串互转字符串互转日期类型 public class Demo18 { public static void main(String[] args) { LocalDateTime date = LocalDateTime.now(); DateTimeFormatter format1 = DateTimeFormatter.ofPattern( \"yyyy/MM/dd HH:mm:ss\"); //日期转字符串 String str = date.format(format1); System.out.println(\"日期转换为字符串:\" + str); DateTimeFormatter format2 = DateTimeFormatter.ofPattern( \"yyyy/MM/dd HH:mm:ss\"); //字符串转日期 LocalDate date2 = LocalDate.parse(str,format2); System.out.println(\"日期类型:\"+date2); } }","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"}]},{"title":"Spring AOP和Spring Transaction源码资料整理","date":"2020-01-27T09:07:23.000Z","path":"2020/01/27/9cf21717.html","text":"前置前面学习了Spring AOP的源码，接下来准备看AOP相关源码。Spring AOP基于Spring IOC机制。 在学习完Spring AOP之后可以继续看看Spring Transaction源码。 调试Spring AOP通过调试 org.springframework.aop.aspectj.autoproxy.AspectJAutoProxyCreatorTests 这个单元测试里的方法，来跟源码。 Spring Transaction 调试 &lt;tx:advice /&gt; 标签的解析的流程 可调试 org.springframework.transaction.TxNamespaceHandlerTests 这个单元测试里的方法。 #invokeTransactional() 方法，提交事务。 #rollbackRules() 方法，回滚事务。 调试 @Transactional 注解的解析的流程 使用的还是 org.springframework.transaction.TxNamespaceHandlerTests 这个单元测试里的方法 资料整理Spring AOP Spring 源码深度解析(第2版) - AOP部分 《【Spring源码分析】AOP源码解析（上篇）》 ，对 Spring AOP XML 配置的方式进行源码解析。 《【Spring源码分析】AOP源码解析（下篇）》 ，和Spring 源码深度解析(第2版) 的内容相互补充 Spring Transaction Spring 源码深度解析(第2版) - 事务相关部分 《原创 Spring 源码解析之事务篇》 《Spring-事务的源码分析（七）》 《可能是最漂亮的 Spring 事务管理详解》 后置Spring MVC","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"源码学习","slug":"源码学习","permalink":"https://www.cayzlh.com/tags/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"4张图带你读懂Spring IOC的世界","date":"2020-01-26T07:08:04.000Z","path":"2020/01/26/101fc769.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=4045 在学习Spring源码的过程中发现的好站+好贴，原创不易感谢作者。 Spring版本：Spring 5.0.6.RELEASE bean 的转换过程下面这张图演示了一个可用的bean是如何从xml配置文件中演变过来的. ApplicationContext 的架构图 loadBean 的全流程 getBean 的全流程","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"深入分析ApplicationContext的refresh()","date":"2020-01-26T06:53:43.000Z","path":"2020/01/26/ea3a33da.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=4043 在学习Spring源码的过程中发现的好站+好贴，原创不易感谢作者。 Spring版本：Spring 5.0.6.RELEASE 上篇博客对 ApplicationContext 相关的接口做了一个简单的介绍，作为一个高富帅级别的 Spring 容器，它涉及的方法实在是太多了，全部介绍是不可能的，而且大部分功能都已经在前面系列博客中做了详细的介绍，所以这篇博问介绍 ApplicationContext 最重要的方法（小编认为的） ：refresh()。 refresh() 是定义在 ConfigurableApplicationContext 类中的，如下： /** * Load or refresh the persistent representation of the configuration, * which might an XML file, properties file, or relational database schema. * As this is a startup method, it should destroy already created singletons * if it fails, to avoid dangling resources. In other words, after invocation * of that method, either all or no singletons at all should be instantiated. * @throws BeansException if the bean factory could not be initialized * @throws IllegalStateException if already initialized and multiple refresh * attempts are not supported */ void refresh() throws BeansException, IllegalStateException; 作用就是：刷新 Spring 的应用上下文。其实现是在 AbstractApplicationContext 中实现。如下： @Override public void refresh() throws BeansException, IllegalStateException { synchronized (this.startupShutdownMonitor) { // 准备刷新上下文环境 prepareRefresh(); // 创建并初始化 BeanFactory ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 填充BeanFactory功能 prepareBeanFactory(beanFactory); try { // 提供子类覆盖的额外处理，即子类处理自定义的BeanFactoryPostProcess postProcessBeanFactory(beanFactory); // 激活各种BeanFactory处理器 invokeBeanFactoryPostProcessors(beanFactory); // 注册拦截Bean创建的Bean处理器，即注册 BeanPostProcessor registerBeanPostProcessors(beanFactory); // 初始化上下文中的资源文件，如国际化文件的处理等 initMessageSource(); // 初始化上下文事件广播器 initApplicationEventMulticaster(); // 给子类扩展初始化其他Bean onRefresh(); // 在所有bean中查找listener bean，然后注册到广播器中 registerListeners(); // 初始化剩下的单例Bean(非延迟加载的) finishBeanFactoryInitialization(beanFactory); // 完成刷新过程,通知生命周期处理器lifecycleProcessor刷新过程,同时发出ContextRefreshEvent通知别人 finishRefresh(); } catch (BeansException ex) { if (logger.isWarnEnabled()) { logger.warn(\"Exception encountered during context initialization - \" + \"cancelling refresh attempt: \" + ex); } // 销毁已经创建的Bean destroyBeans(); // 重置容器激活标签 cancelRefresh(ex); // 抛出异常 throw ex; } finally { // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); } } } 这里每一个方法都非常重要，需要一个一个地解释说明。 prepareRefresh() 初始化上下文环境，对系统的环境变量或者系统属性进行准备和校验,如环境变量中必须设置某个值才能运行，否则不能运行，这个时候可以在这里加这个校验，重写initPropertySources方法就好了 protected void prepareRefresh() { // 设置启动日期 this.startupDate = System.currentTimeMillis(); // 设置 context 当前状态 this.closed.set(false); this.active.set(true); if (logger.isInfoEnabled()) { logger.info(\"Refreshing \" + this); } // 初始化context environment（上下文环境）中的占位符属性来源 initPropertySources(); // 对属性进行必要的验证 getEnvironment().validateRequiredProperties(); this.earlyApplicationEvents = new LinkedHashSet&lt;>(); } 该方法主要是做一些准备工作，如： 设置 context 启动时间 设置 context 的当前状态 初始化 context environment 中占位符 对属性进行必要的验证 obtainFreshBeanFactory() 创建并初始化 BeanFactory protected ConfigurableListableBeanFactory obtainFreshBeanFactory() { // 刷新 BeanFactory refreshBeanFactory(); // 获取 BeanFactory ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (logger.isDebugEnabled()) { logger.debug(\"Bean factory for \" + getDisplayName() + \": \" + beanFactory); } return beanFactory; } 核心方法就在 refreshBeanFactory() ，该方法的核心任务就是创建 BeanFactory 并对其就行一番初始化。如下： protected final void refreshBeanFactory() throws BeansException { if (hasBeanFactory()) { destroyBeans(); closeBeanFactory(); } try { DefaultListableBeanFactory beanFactory = createBeanFactory(); beanFactory.setSerializationId(getId()); customizeBeanFactory(beanFactory); loadBeanDefinitions(beanFactory); synchronized (this.beanFactoryMonitor) { this.beanFactory = beanFactory; } } catch (IOException ex) { throw new ApplicationContextException(\"I/O error parsing bean definition source for \" + getDisplayName(), ex); } } 判断当前容器是否存在一个 BeanFactory，如果存在则对其进行销毁和关闭 调用 createBeanFactory() 创建一个 BeanFactory 实例，其实就是 DefaultListableBeanFactory 自定义 BeanFactory 加载 BeanDefinition 将创建好的 bean 工厂的引用交给的 context 来管理 上面 5 个步骤，都是比较简单的，但是有必要讲解下第 4 步：加载 BeanDefinition。如果各位看过 【死磕 Spring】系列的话，在刚刚开始分析源码的时候，小编就是以 loadBeanDefinitions() 为入口来分析的，如下： ClassPathResource resource = new ClassPathResource(\"bean.xml\"); DefaultListableBeanFactory factory = new DefaultListableBeanFactory(); XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(factory); reader.loadBeanDefinitions(resource); 只不过这段代码的 loadBeanDefinitions() 是定义在 BeanDefinitionReader 中，而此处的 loadBeanDefinitions() 则是定义在 AbstractRefreshableApplicationContext 中，如下： protected abstract void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException 由具体的子类实现，我们以 AbstractXmlApplicationContext 为例，实现如下： protected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException { // Create a new XmlBeanDefinitionReader for the given BeanFactory. XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); // Configure the bean definition reader with this context's // resource loading environment. beanDefinitionReader.setEnvironment(this.getEnvironment()); beanDefinitionReader.setResourceLoader(this); beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); // Allow a subclass to provide custom initialization of the reader, // then proceed with actually loading the bean definitions. initBeanDefinitionReader(beanDefinitionReader); loadBeanDefinitions(beanDefinitionReader); } 新建 XmlBeanDefinitionReader 实例对象 beanDefinitionReader，调用 initBeanDefinitionReader() 对其进行初始化，然后调用 loadBeanDefinitions() 加载 BeanDefinition。 protected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws BeansException, IOException { Resource[] configResources = getConfigResources(); if (configResources != null) { reader.loadBeanDefinitions(configResources); } String[] configLocations = getConfigLocations(); if (configLocations != null) { reader.loadBeanDefinitions(configLocations); } } 到这里我们发现，其实内部依然是调用 BeanDefinitionReader#loadBeanDefinitionn() 进行 BeanDefinition 的加载进程。 prepareBeanFactory(beanFactory) 填充 BeanFactory 功能 上面获取获取的 BeanFactory 除了加载了一些 BeanDefinition 就没有其他任何东西了，这个时候其实还不能投入生产，因为还少配置了一些东西，比如 context的 ClassLoader 和 后置处理器等等。 protected void prepareBeanFactory(ConfigurableListableBeanFactory beanFactory) { // 设置beanFactory的classLoader beanFactory.setBeanClassLoader(getClassLoader()); // 设置beanFactory的表达式语言处理器,Spring3开始增加了对语言表达式的支持,默认可以使用#{bean.xxx}的形式来调用相关属性值 beanFactory.setBeanExpressionResolver(new StandardBeanExpressionResolver(beanFactory.getBeanClassLoader())); // 为beanFactory增加一个默认的propertyEditor beanFactory.addPropertyEditorRegistrar(new ResourceEditorRegistrar(this, getEnvironment())); // 添加ApplicationContextAwareProcessor beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this)); // 设置忽略自动装配的接口 beanFactory.ignoreDependencyInterface(EnvironmentAware.class); beanFactory.ignoreDependencyInterface(EmbeddedValueResolverAware.class); beanFactory.ignoreDependencyInterface(ResourceLoaderAware.class); beanFactory.ignoreDependencyInterface(ApplicationEventPublisherAware.class); beanFactory.ignoreDependencyInterface(MessageSourceAware.class); beanFactory.ignoreDependencyInterface(ApplicationContextAware.class); // 设置几个自动装配的特殊规则 beanFactory.registerResolvableDependency(BeanFactory.class, beanFactory); beanFactory.registerResolvableDependency(ResourceLoader.class, this); beanFactory.registerResolvableDependency(ApplicationEventPublisher.class, this); beanFactory.registerResolvableDependency(ApplicationContext.class, this); // Register early post-processor for detecting inner beans as ApplicationListeners. beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(this)); // 增加对AspectJ的支持 if (beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) { beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory)); // Set a temporary ClassLoader for type matching. beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader())); } // 注册默认的系统环境bean if (!beanFactory.containsLocalBean(ENVIRONMENT_BEAN_NAME)) { beanFactory.registerSingleton(ENVIRONMENT_BEAN_NAME, getEnvironment()); } if (!beanFactory.containsLocalBean(SYSTEM_PROPERTIES_BEAN_NAME)) { beanFactory.registerSingleton(SYSTEM_PROPERTIES_BEAN_NAME, getEnvironment().getSystemProperties()); } if (!beanFactory.containsLocalBean(SYSTEM_ENVIRONMENT_BEAN_NAME)) { beanFactory.registerSingleton(SYSTEM_ENVIRONMENT_BEAN_NAME, getEnvironment().getSystemEnvironment()); } } 看上面的源码知道这个就是对 BeanFactory 设置各种各种的功能。 postProcessBeanFactory() 提供子类覆盖的额外处理，即子类处理自定义的BeanFactoryPostProcess protected void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) { beanFactory.addBeanPostProcessor(new ServletContextAwareProcessor(this.servletContext, this.servletConfig)); beanFactory.ignoreDependencyInterface(ServletContextAware.class); beanFactory.ignoreDependencyInterface(ServletConfigAware.class); WebApplicationContextUtils.registerWebApplicationScopes(beanFactory, this.servletContext); WebApplicationContextUtils.registerEnvironmentBeans(beanFactory, this.servletContext, this.servletConfig); } 添加 ServletContextAwareProcessor 到 BeanFactory 容器中，该 processor 实现 BeanPostProcessor 接口，主要用于将ServletContext 传递给实现了 ServletContextAware 接口的 bean 忽略 ServletContextAware、ServletConfigAware 注册 WEB 应用特定的域（scope）到 beanFactory 中，以便 WebApplicationContext 可以使用它们。比如 “request” , “session” , “globalSession” , “application” 注册 WEB 应用特定的 Environment bean 到 beanFactory 中，以便WebApplicationContext 可以使用它们。如：”contextParameters”, “contextAttributes” invokeBeanFactoryPostProcessors() 激活各种BeanFactory处理器 public static void invokeBeanFactoryPostProcessors( ConfigurableListableBeanFactory beanFactory, List&lt;BeanFactoryPostProcessor> beanFactoryPostProcessors) { // 定义一个 set 保存所有的 BeanFactoryPostProcessors Set&lt;String> processedBeans = new HashSet&lt;>(); // 如果当前 BeanFactory 为 BeanDefinitionRegistry if (beanFactory instanceof BeanDefinitionRegistry) { BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory; // BeanFactoryPostProcessor 集合 List&lt;BeanFactoryPostProcessor> regularPostProcessors = new ArrayList&lt;>(); // BeanDefinitionRegistryPostProcessor 集合 List&lt;BeanDefinitionRegistryPostProcessor> registryProcessors = new ArrayList&lt;>(); // 迭代注册的 beanFactoryPostProcessors for (BeanFactoryPostProcessor postProcessor : beanFactoryPostProcessors) { // 如果是 BeanDefinitionRegistryPostProcessor，则调用 postProcessBeanDefinitionRegistry 进行注册， // 同时加入到 registryProcessors 集合中 if (postProcessor instanceof BeanDefinitionRegistryPostProcessor) { BeanDefinitionRegistryPostProcessor registryProcessor = (BeanDefinitionRegistryPostProcessor) postProcessor; registryProcessor.postProcessBeanDefinitionRegistry(registry); registryProcessors.add(registryProcessor); } else { // 否则当做普通的 BeanFactoryPostProcessor 处理 // 添加到 regularPostProcessors 集合中即可，便于后面做后续处理 regularPostProcessors.add(postProcessor); } } // 用于保存当前处理的 BeanDefinitionRegistryPostProcessor List&lt;BeanDefinitionRegistryPostProcessor> currentRegistryProcessors = new ArrayList&lt;>(); // 首先处理实现了 PriorityOrdered (有限排序接口)的 BeanDefinitionRegistryPostProcessor String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) { if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) { currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); } } // 排序 sortPostProcessors(currentRegistryProcessors, beanFactory); // 加入registryProcessors集合 registryProcessors.addAll(currentRegistryProcessors); // 调用所有实现了 PriorityOrdered 的 BeanDefinitionRegistryPostProcessors 的 postProcessBeanDefinitionRegistry() invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); // 清空，以备下次使用 currentRegistryProcessors.clear(); // 其次，调用是实现了 Ordered（普通排序接口）的 BeanDefinitionRegistryPostProcessors // 逻辑和 上面一样 postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) { if (!processedBeans.contains(ppName) &amp;&amp; beanFactory.isTypeMatch(ppName, Ordered.class)) { currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); } } sortPostProcessors(currentRegistryProcessors, beanFactory); registryProcessors.addAll(currentRegistryProcessors); invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); currentRegistryProcessors.clear(); // 最后调用其他的 BeanDefinitionRegistryPostProcessors boolean reiterate = true; while (reiterate) { reiterate = false; // 获取 BeanDefinitionRegistryPostProcessor postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) { // 没有包含在 processedBeans 中的（因为包含了的都已经处理了） if (!processedBeans.contains(ppName)) { currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); reiterate = true; } } // 与上面处理逻辑一致 sortPostProcessors(currentRegistryProcessors, beanFactory); registryProcessors.addAll(currentRegistryProcessors); invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); currentRegistryProcessors.clear(); } // 调用所有 BeanDefinitionRegistryPostProcessor (包括手动注册和通过配置文件注册) // 和 BeanFactoryPostProcessor(只有手动注册)的回调函数(postProcessBeanFactory()) invokeBeanFactoryPostProcessors(registryProcessors, beanFactory); invokeBeanFactoryPostProcessors(regularPostProcessors, beanFactory); } else { // 如果不是 BeanDefinitionRegistry 只需要调用其回调函数（postProcessBeanFactory()）即可 invokeBeanFactoryPostProcessors(beanFactoryPostProcessors, beanFactory); } // String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanFactoryPostProcessor.class, true, false); // 这里同样需要区分 PriorityOrdered 、Ordered 和 no Ordered List&lt;BeanFactoryPostProcessor> priorityOrderedPostProcessors = new ArrayList&lt;>(); List&lt;String> orderedPostProcessorNames = new ArrayList&lt;>(); List&lt;String> nonOrderedPostProcessorNames = new ArrayList&lt;>(); for (String ppName : postProcessorNames) { // 已经处理过了的，跳过 if (processedBeans.contains(ppName)) { // skip - already processed in first phase above } // PriorityOrdered else if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) { priorityOrderedPostProcessors.add(beanFactory.getBean(ppName, BeanFactoryPostProcessor.class)); } // Ordered else if (beanFactory.isTypeMatch(ppName, Ordered.class)) { orderedPostProcessorNames.add(ppName); } // no Ordered else { nonOrderedPostProcessorNames.add(ppName); } } // First, PriorityOrdered 接口 sortPostProcessors(priorityOrderedPostProcessors, beanFactory); invokeBeanFactoryPostProcessors(priorityOrderedPostProcessors, beanFactory); // Next, Ordered 接口 List&lt;BeanFactoryPostProcessor> orderedPostProcessors = new ArrayList&lt;>(); for (String postProcessorName : orderedPostProcessorNames) { orderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class)); } sortPostProcessors(orderedPostProcessors, beanFactory); invokeBeanFactoryPostProcessors(orderedPostProcessors, beanFactory); // Finally, no ordered List&lt;BeanFactoryPostProcessor> nonOrderedPostProcessors = new ArrayList&lt;>(); for (String postProcessorName : nonOrderedPostProcessorNames) { nonOrderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class)); } invokeBeanFactoryPostProcessors(nonOrderedPostProcessors, beanFactory); // Clear cached merged bean definitions since the post-processors might have // modified the original metadata, e.g. replacing placeholders in values... beanFactory.clearMetadataCache(); } 上述代码较长，但是处理逻辑较为单一，就是对所有的 BeanDefinitionRegistryPostProcessors 、手动注册的 BeanFactoryPostProcessor 以及通过配置文件方式的 BeanFactoryPostProcessor 按照 PriorityOrdered 、 Ordered、no ordered 三种方式分开处理、调用。 registerBeanPostProcessors 注册拦截Bean创建的Bean处理器，即注册 BeanPostProcessor 与 BeanFactoryPostProcessor 一样，也是委托给 PostProcessorRegistrationDelegate 来实现的。 public static void registerBeanPostProcessors( ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) { // 所有的 BeanPostProcessors String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false); // 注册 BeanPostProcessorChecker // 主要用于记录一些 bean 的信息，这些 bean 不符合所有 BeanPostProcessors 处理的资格时 int beanProcessorTargetCount = beanFactory.getBeanPostProcessorCount() + 1 + postProcessorNames.length; beanFactory.addBeanPostProcessor(new BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount)); // 区分 PriorityOrdered、Ordered 、 no ordered List&lt;BeanPostProcessor> priorityOrderedPostProcessors = new ArrayList&lt;>(); List&lt;String> orderedPostProcessorNames = new ArrayList&lt;>(); List&lt;String> nonOrderedPostProcessorNames = new ArrayList&lt;>(); // MergedBeanDefinition List&lt;BeanPostProcessor> internalPostProcessors = new ArrayList&lt;>(); for (String ppName : postProcessorNames) { if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) { BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); priorityOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) { internalPostProcessors.add(pp); } } else if (beanFactory.isTypeMatch(ppName, Ordered.class)) { orderedPostProcessorNames.add(ppName); } else { nonOrderedPostProcessorNames.add(ppName); } } // First, PriorityOrdered sortPostProcessors(priorityOrderedPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors); // Next, Ordered List&lt;BeanPostProcessor> orderedPostProcessors = new ArrayList&lt;>(); for (String ppName : orderedPostProcessorNames) { BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); orderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) { internalPostProcessors.add(pp); } } sortPostProcessors(orderedPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, orderedPostProcessors); // onOrdered List&lt;BeanPostProcessor> nonOrderedPostProcessors = new ArrayList&lt;>(); for (String ppName : nonOrderedPostProcessorNames) { BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); nonOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) { internalPostProcessors.add(pp); } } registerBeanPostProcessors(beanFactory, nonOrderedPostProcessors); // Finally, all internal BeanPostProcessors. sortPostProcessors(internalPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, internalPostProcessors); // 重新注册用来自动探测内部ApplicationListener的post-processor，这样可以将他们移到处理器链条的末尾 beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(applicationContext)); } initMessageSource 初始化上下文中的资源文件，如国际化文件的处理等 其实该方法就是初始化一个 MessageSource 接口的实现类，主要用于国际化/i18n。 protected void initMessageSource() { ConfigurableListableBeanFactory beanFactory = getBeanFactory(); // 包含 “messageSource” bean if (beanFactory.containsLocalBean(MESSAGE_SOURCE_BEAN_NAME)) { this.messageSource = beanFactory.getBean(MESSAGE_SOURCE_BEAN_NAME, MessageSource.class); // 如果有父类 // HierarchicalMessageSource 分级处理的 MessageSource if (this.parent != null &amp;&amp; this.messageSource instanceof HierarchicalMessageSource) { HierarchicalMessageSource hms = (HierarchicalMessageSource) this.messageSource; if (hms.getParentMessageSource() == null) { // 如果没有注册父 MessageSource，则设置为父类上下文的的 MessageSource hms.setParentMessageSource(getInternalParentMessageSource()); } } if (logger.isDebugEnabled()) { logger.debug(\"Using MessageSource [\" + this.messageSource + \"]\"); } } else { // 使用 空 MessageSource DelegatingMessageSource dms = new DelegatingMessageSource(); dms.setParentMessageSource(getInternalParentMessageSource()); this.messageSource = dms; beanFactory.registerSingleton(MESSAGE_SOURCE_BEAN_NAME, this.messageSource); if (logger.isDebugEnabled()) { logger.debug(\"Unable to locate MessageSource with name '\" + MESSAGE_SOURCE_BEAN_NAME + \"': using default [\" + this.messageSource + \"]\"); } } } initApplicationEventMulticaster 初始化上下文事件广播器 protected void initApplicationEventMulticaster() { ConfigurableListableBeanFactory beanFactory = getBeanFactory(); // 如果存在 applicationEventMulticaster bean，则获取赋值 if (beanFactory.containsLocalBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME)) { this.applicationEventMulticaster = beanFactory.getBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, ApplicationEventMulticaster.class); if (logger.isDebugEnabled()) { logger.debug(\"Using ApplicationEventMulticaster [\" + this.applicationEventMulticaster + \"]\"); } } else { // 没有则新建 SimpleApplicationEventMulticaster，并完成 bean 的注册 this.applicationEventMulticaster = new SimpleApplicationEventMulticaster(beanFactory); beanFactory.registerSingleton(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, this.applicationEventMulticaster); if (logger.isDebugEnabled()) { logger.debug(\"Unable to locate ApplicationEventMulticaster with name '\" + APPLICATION_EVENT_MULTICASTER_BEAN_NAME + \"': using default [\" + this.applicationEventMulticaster + \"]\"); } } } 如果当前容器中存在 applicationEventMulticaster 的 bean，则对 applicationEventMulticaster 赋值，否则新建一个 SimpleApplicationEventMulticaster 的对象（默认的），并完成注册。 onRefresh 给子类扩展初始化其他Bean 预留给 AbstractApplicationContext 的子类用于初始化其他特殊的 bean，该方法需要在所有单例 bean 初始化之前调用。 registerListeners 在所有 bean 中查找 listener bean，然后注册到广播器中 protected void registerListeners() { // 注册静态 监听器 for (ApplicationListener&lt;?> listener : getApplicationListeners()) { getApplicationEventMulticaster().addApplicationListener(listener); } String[] listenerBeanNames = getBeanNamesForType(ApplicationListener.class, true, false); for (String listenerBeanName : listenerBeanNames) { getApplicationEventMulticaster().addApplicationListenerBean(listenerBeanName); } // 至此，已经完成将监听器注册到ApplicationEventMulticaster中，下面将发布前期的事件给监听器。 Set&lt;ApplicationEvent> earlyEventsToProcess = this.earlyApplicationEvents; this.earlyApplicationEvents = null; if (earlyEventsToProcess != null) { for (ApplicationEvent earlyEvent : earlyEventsToProcess) { getApplicationEventMulticaster().multicastEvent(earlyEvent); } } } finishBeanFactoryInitialization 初始化剩下的单例Bean(非延迟加载的) protected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) { // 初始化转换器 if (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME) &amp;&amp; beanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) { beanFactory.setConversionService( beanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)); } // 如果之前没有注册 bean 后置处理器（例如PropertyPlaceholderConfigurer），则注册默认的解析器 if (!beanFactory.hasEmbeddedValueResolver()) { beanFactory.addEmbeddedValueResolver(strVal -> getEnvironment().resolvePlaceholders(strVal)); } // 初始化 Initialize LoadTimeWeaverAware beans early to allow for registering their transformers early. String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false); for (String weaverAwareName : weaverAwareNames) { getBean(weaverAwareName); } // 停止使用临时的 ClassLoader beanFactory.setTempClassLoader(null); // beanFactory.freezeConfiguration(); // 初始化所有剩余的单例（非延迟初始化） beanFactory.preInstantiateSingletons(); } finishRefresh 完成刷新过程,通知生命周期处理器 lifecycleProcessor 刷新过程,同时发出 ContextRefreshEvent 通知别人 主要是调用 LifecycleProcessor#onRefresh() ，并且发布事件（ContextRefreshedEvent）。 protected void finishRefresh() { // Clear context-level resource caches (such as ASM metadata from scanning). clearResourceCaches(); // Initialize lifecycle processor for this context. initLifecycleProcessor(); // Propagate refresh to lifecycle processor first. getLifecycleProcessor().onRefresh(); // Publish the final event. publishEvent(new ContextRefreshedEvent(this)); // Participate in LiveBeansView MBean, if active. LiveBeansView.registerApplicationContext(this); }","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"ApplicationContext相关接口架构分析","date":"2020-01-26T06:31:24.000Z","path":"2020/01/26/1a84ff95.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=4036 在学习Spring源码的过程中发现的好站+好贴，原创不易感谢作者。 Spring版本：Spring 5.0.6.RELEASE 前面的文章都是基于 BeanFactory 这个容器来进行分析的，BeanFactory 容器有点儿简单，并不适用于我们生产环境，在生产环境我们通常会选择 ApplicationContext ，相对于大多数人而言，它才是正规军，相比于 BeanFactory 这个杂牌军而言，它由如下几个区别： 继承 MessageSource，提供国际化的标准访问策略。 继承 ApplicationEventPublisher ，提供强大的事件机制。 扩展 ResourceLoader，可以用来加载多个 Resource，可以灵活访问不同的资源。 对 Web 应用的支持。 ApplicationContext下图是 ApplicationContext 结构类图： BeanFactory：Spring 管理 Bean 的顶层接口，我们可以认为他是一个简易版的 Spring 容器。 ApplicationContext 继承 BeanFactory 的两个子类：HierarchicalBeanFactory 和 ListableBeanFactory。HierarchicalBeanFactory 是一个具有层级关系的 BeanFactory，拥有属性 parentBeanFactory。ListableBeanFactory 实现了枚举方法可以列举出当前 BeanFactory 中所有的 bean 对象而不必根据 name 一个一个的获取。 ApplicationEventPublisher：用于封装事件发布功能的接口，向事件监听器（Listener）发送事件消息。 ResourceLoader：Spring 加载资源的顶层接口，用于从一个源加载资源文件。 ApplicationContext 继承 ResourceLoader 的子类 ResourcePatternResolver，该接口是将 location 解析为 Resource 对象的策略接口。 MessageSource：解析 message 的策略接口，用不支撑国际化等功能。 EnvironmentCapable：用于获取 Environment 的接口。 ApplicationContext 的子接口ApplicationContext 有两个直接子类：WebApplicationContext 和 ConfigurableApplicationContext。 WebApplicationContextpublic interface WebApplicationContext extends ApplicationContext { ServletContext getServletContext(); } 该接口只有一个 getServletContext() ，用于给 servlet 提供上下文信息。 ConfigurableApplicationContextpublic interface ConfigurableApplicationContext extends ApplicationContext, Lifecycle, Closeable { // 为 ApplicationContext 设置唯一 ID void setId(String id); // 为 ApplicationContext 设置 parent // 父类不应该被修改：如果创建的对象不可用时，则应该在构造函数外部设置它 void setParent(@Nullable ApplicationContext parent); // 设置 Environment void setEnvironment(ConfigurableEnvironment environment); // 获取 Environment @Override ConfigurableEnvironment getEnvironment(); // 添加 BeanFactoryPostProcessor void addBeanFactoryPostProcessor(BeanFactoryPostProcessor postProcessor); // 添加 ApplicationListener void addApplicationListener(ApplicationListener&lt;?> listener); // 添加 ProtocolResolver void addProtocolResolver(ProtocolResolver resolver); // 加载或者刷新配置 // 这是一个非常重要的方法 void refresh() throws BeansException, IllegalStateException; // 注册 shutdown hook void registerShutdownHook(); // 关闭 ApplicationContext @Override void close(); // ApplicationContext 是否处于激活状态 boolean isActive(); // 获取当前上下文的 BeanFactory ConfigurableListableBeanFactory getBeanFactory() throws IllegalStateException; } 从上面代码可以看到 ConfigurableApplicationContext 接口提供的方法都是对 ApplicationContext 进行配置的，例如 setEnvironment()、addBeanFactoryPostProcessor，同时它还继承了如下两个接口： Lifecycle：对 context 生命周期的管理，它提供 start() 和 stop() 方法启动和暂停组件。 Closeable：标准 JDK 所提供的一个接口，用于最后关闭组件释放资源等。 WebApplicationContext 接口和 ConfigurableApplicationContext 接口有一个共同的子类接口 ConfigurableWebApplicationContext，该接口将这两个接口进行合并，提供了一个可配置、可管理、可关闭的WebApplicationContext，同时该接口还增加了 setServletContext()，setServletConfig()等方法，用于装配WebApplicationContext。 public interface ConfigurableWebApplicationContext extends WebApplicationContext, ConfigurableApplicationContext { void setServletContext(@Nullable ServletContext servletContext); void setServletConfig(@Nullable ServletConfig servletConfig); ServletConfig getServletConfig(); void setNamespace(@Nullable String namespace); String getNamespace(); void setConfigLocation(String configLocation); void setConfigLocations(String... configLocations); String[] getConfigLocations(); } 上面三个接口就可以构成一个比较完整的 Spring 容器，整个 Spring 容器体系涉及的接口较多，所以下面小编就一个具体的实现类来看看 ApplicationContext 的实现（其实在前面一系列的文章中，小编对涉及的大部分接口都已经分析了其原理），当然不可能每个方法都涉及到，但小编会把其中最为重要的实现方法贴出来分析。 ApplicationContext 的实现类较多，就以 ClassPathXmlApplicationContext 来分析 ApplicationContext。 ClassPathXmlApplicationContextClassPathXmlApplicationContext 是我们在学习 Spring 过程中用的非常多的一个类，很多人第一个接触的 Spring 容器就是它，包括小编自己，下面代码我想很多人依然还记得吧。 ApplicationContext ac = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); StudentService studentService = (StudentService)ac.getBean(\"studentService\"); 下图是 ClassPathXmlApplicationContext 的结构类图： 主要的的类层级关系如下： org.springframework.context.support.AbstractApplicationContext org.springframework.context.support.AbstractRefreshableApplicationContext org.springframework.context.support.AbstractRefreshableConfigApplicationContext org.springframework.context.support.AbstractXmlApplicationContext org.springframework.context.support.ClassPathXmlApplicationContext 这种设计是模板方法模式典型的应用，AbstractApplicationContext 实现了 ConfigurableApplicationContext 这个全家桶接口，其子类 AbstractRefreshableConfigApplicationContext 又实现了 BeanNameAware 和 InitializingBean 接口。所以 ClassPathXmlApplicationContext 设计的顶级接口有： BeanFactory：Spring 容器 Bean 的管理 MessageSource：管理 message ，实现国际化等功能 ApplicationEventPublisher：事件发布 ResourcePatternResolver：资源加载 EnvironmentCapable：系统 Environment（profile + Properties） 相关 Lifecycle：管理生命周期 Closeable：关闭，释放资源 InitializingBean：自定义初始化 BeanNameAware：设置 beanName 的 Aware 接口 下面就这些接口来一一分析。 MessageSourceMessageSource 定义了获取 message 的策略方法 getMessage()，在 ApplicationContext 体系中，该方法 AbstractApplicationContext 实现，在 AbstractApplicationContext 中，它持有一个 MessageSource 实例，将 getMessage() 的实现给该实例来实现，如下： private MessageSource messageSource; // 实现 getMessage() public String getMessage(String code, @Nullable Object[] args, @Nullable String defaultMessage, Locale locale) { // 委托给 messageSource 实现 return getMessageSource().getMessage(code, args, defaultMessage, locale); } private MessageSource getMessageSource() throws IllegalStateException { if (this.messageSource == null) { throw new IllegalStateException(\"MessageSource not initialized - \" + \"call 'refresh' before accessing messages via the context: \" + this); } return this.messageSource; } 真正实现 是在 AbstractMessageSource 中，如下： public final String getMessage(String code, @Nullable Object[] args, @Nullable String defaultMessage, Locale locale) { String msg = getMessageInternal(code, args, locale); if (msg != null) { return msg; } if (defaultMessage == null) { return getDefaultMessage(code); } return renderDefaultMessage(defaultMessage, args, locale); } 具体的实现这里就不分析了。 ApplicationEventPublisher用于封装事件发布功能的接口，向事件监听器（Listener）发送事件消息。 该接口提供了一个 publishEvent() 用于通知在此应用程序中注册的所有的监听器。 该方法在 AbstractApplicationContext 中实现。 @Override public void publishEvent(Object event) { publishEvent(event, null); } protected void publishEvent(Object event, @Nullable ResolvableType eventType) { Assert.notNull(event, \"Event must not be null\"); if (logger.isTraceEnabled()) { logger.trace(\"Publishing event in \" + getDisplayName() + \": \" + event); } ApplicationEvent applicationEvent; if (event instanceof ApplicationEvent) { applicationEvent = (ApplicationEvent) event; } else { applicationEvent = new PayloadApplicationEvent&lt;>(this, event); if (eventType == null) { eventType = ((PayloadApplicationEvent) applicationEvent).getResolvableType(); } } if (this.earlyApplicationEvents != null) { this.earlyApplicationEvents.add(applicationEvent); } else { getApplicationEventMulticaster().multicastEvent(applicationEvent, eventType); } if (this.parent != null) { if (this.parent instanceof AbstractApplicationContext) { ((AbstractApplicationContext) this.parent).publishEvent(event, eventType); } else { this.parent.publishEvent(event); } } } 如果指定的事件不是ApplicationEvent，则它将包装在PayloadApplicationEvent中。如果存在父级 ApplicationContext ，则同样要将 event 发布给父级 ApplicationContext。 ResourcePatternResolverResourcePatternResolver 接口继承 ResourceLoader 接口，为将 location 解析为 Resource 对象的策略接口。他提供的 getResources() 在 AbstractApplicationContext 中实现，在 AbstractApplicationContext 中他持有一个 ResourcePatternResolver 的实例对象。 如下： public Resource[] getResources(String locationPattern) throws IOException { return this.resourcePatternResolver.getResources(locationPattern); } 如果小伙伴对 Spring 的 ResourceLoader 比较熟悉的话，你会发现最终是在 PathMatchingResourcePatternResolver 中实现，该类是 ResourcePatternResolver 接口的实现者。 EnvironmentCapable提供当前系统环境 Environment 组件。提供了一个 getEnvironment() 用于返回 Environment 实例对象，该方法在 AbstractApplicationContext 实现。 public ConfigurableEnvironment getEnvironment() { if (this.environment == null) { this.environment = createEnvironment(); } return this.environment; } 如果持有的 environment 实例对象为空，则调用 createEnvironment() 创建一个。 protected ConfigurableEnvironment createEnvironment() { return new StandardEnvironment(); } StandardEnvironment 是一个适用于非 WEB 应用的 Environment。 Lifecycle一个用于管理声明周期的接口。 在 AbstractApplicationContext 中存在一个 LifecycleProcessor 类型的实例对象 lifecycleProcessor，AbstractApplicationContext 中关于 Lifecycle 接口的实现都是委托给 lifecycleProcessor 实现的。如下： @Override public void start() { getLifecycleProcessor().start(); publishEvent(new ContextStartedEvent(this)); } @Override public void stop() { getLifecycleProcessor().stop(); publishEvent(new ContextStoppedEvent(this)); } @Override public boolean isRunning() { return (this.lifecycleProcessor != null &amp;&amp; this.lifecycleProcessor.isRunning()); } 在启动、停止的时候会分别发布 ContextStartedEvent 和 ContextStoppedEvent 事件。 CloseableCloseable 接口用于关闭和释放资源，提供了 close() 以释放对象所持有的资源。在 ApplicationContext 体系中由AbstractApplicationContext 实现，用于关闭 ApplicationContext 销毁所有 bean ，此外如果注册有 JVM shutdown hook，同样要将其移除。如下： public void close() { synchronized (this.startupShutdownMonitor) { doClose(); // If we registered a JVM shutdown hook, we don't need it anymore now: // We've already explicitly closed the context. if (this.shutdownHook != null) { try { Runtime.getRuntime().removeShutdownHook(this.shutdownHook); } catch (IllegalStateException ex) { // ignore - VM is already shutting down } } } } 调用 doClose() 发布 ContextClosedEvent 事件，销毁所有 bean（单例），关闭 BeanFactory 。如下： protected void doClose() { // 省略部分代码 try { // Publish shutdown event. publishEvent(new ContextClosedEvent(this)); } catch (Throwable ex) { logger.warn(\"Exception thrown from ApplicationListener handling ContextClosedEvent\", ex); } // 省略部分代码 destroyBeans(); closeBeanFactory(); onClose(); this.active.set(false); } } InitializingBeanInitializingBean 为 bean 提供了初始化方法的方式，它提供的 afterPropertiesSet() 用于执行初始化动作。在 ApplicationContext 体系中，该方法由 AbstractRefreshableConfigApplicationContext 实现，如下： public void afterPropertiesSet() { if (!isActive()) { refresh(); } } 执行 refresh() ，该方法在 AbstractApplicationContext 中执行，执行整个 Spring 容器的初始化过程。该方法将在下篇文章进行详细分析说明。 BeanNameAware设置 bean name 的接口。接口在 AbstractRefreshableConfigApplicationContext 中实现。 public void setBeanName(String name) { if (!this.setIdCalled) { super.setId(name); setDisplayName(\"ApplicationContext '\" + name + \"'\"); } } 由于篇幅问题再加上大部分接口都已经在前面文章进行了详细的阐述，所以本文主要是以 Spring Framework 的 ApplicationContext 为中心，对其结构和功能的实现进行了简要的说明。 这里不得不说 Spring 真的是一个非常优秀的框架，具有良好的结构设计和接口抽象，它的每一个接口职能单一，且都是具体功能到各个模块的高度抽象，且几乎每套接口都提供了一个默认的实现（defaultXXX）。 对于 ApplicationContext 体系而言，他继承 Spring 中众多的核心接口，能够为客户端提供一个相对完整的 Spring 容器，接口 ConfigurableApplicationContext 对 ApplicationContext 接口再次进行扩展，提供了生命周期的管理功能。 抽象类 ApplicationContext 对整套接口提供了大部分的默认实现，将其中“不易变动”的部分进行了封装，通过“组合”的方式将“容易变动”的功能委托给其他类来实现，同时利用模板方法模式将一些方法的实现开放出去由子类实现，从而实现“对扩展开放，对修改封闭”的设计原则。 最后我们再来领略下图的风采：","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之分析bean的生命周期","date":"2020-01-26T01:21:09.000Z","path":"2020/01/26/90c034e1.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=4034 在学习Spring源码的过程中发现的好站+好贴，原创不易感谢作者。 Spring版本：Spring 5.0.6.RELEASE 在分析 Spring Bean 实例化过程中提到 Spring 并不是一启动容器就开启 bean 的实例化进程，只有当客户端通过显示或者隐式的方式调用 BeanFactory 的 getBean() 方法来请求某个实例对象的时候，它才会触发相应 bean 的实例化进程，当然也可以选择直接使用 ApplicationContext 容器，因为该容器启动的时候会立刻调用注册到该容器所有 bean 定义的实例化方法。当然对于 BeanFactory 容器而言并不是所有的 getBean() 方法都会触发实例化进程，比如 signleton 类型的 bean，该类型的 bean 只会在第一次调用 getBean() 的时候才会触发，而后续的调用则会直接返回容器缓存中的实例对象。 getBean() 只是 bean 实例化进程的入口，真正的实现逻辑其实是在 AbstractAutowireCapableBeanFactory 的 doCreateBean() 实现，实例化过程如下图： 原来我们采用 new 的方式创建一个对象，用完该对象在其脱离作用域后就会被回收，对于后续操作我们无权也没法干涉，但是采用 Spring 容器后，我们完全摆脱了这种命运，Spring 容器将会对其所有管理的 Bean 对象全部给予一个统一的生命周期管理，同时在这个阶段我们也可以对其进行干涉（比如对 bean 进行增强处理，对 bean 进行篡改），如上图。 bean 实例化在 doCreateBean() 中首先进行 bean 实例化工作，主要由 createBeanInstance() 实现，该方法返回一个 BeanWrapper 对象。BeanWrapper 对象是 Spring 的一个低级 Bean 基础结构的核心接口，为什么说是低级呢？因为这个时候的 Bean 还不能够被我们使用，连最基本的属性都没有设置。而且在我们实际开发过程中一般都不会直接使用该类，而是通过 BeanFactory 隐式使用。 BeanWrapper 接口有一个默认实现类 BeanWrapperImpl，其主要作用是对 Bean 进行“包裹”，然后对这个包裹的 bean 进行操作，比如后续注入 bean 属性。 在实例化 bean 过程中，Spring 采用“策略模式”来决定采用哪种方式来实例化 bean，一般有反射和 CGLIB 动态字节码两种方式。 InstantiationStrategy 定义了 Bean 实例化策略的抽象接口，其子类 SimpleInstantiationStrategy 提供了基于反射来实例化对象的功能，但是不支持方法注入方式的对象实例化。 CglibSubclassingInstantiationStrategy 继承 SimpleInstantiationStrategy，他除了拥有父类以反射实例化对象的功能外，还提供了通过 CGLIB 的动态字节码的功能进而支持方法注入所需的对象实例化需求。默认情况下，Spring 采用 CglibSubclassingInstantiationStrategy。 激活 Aware当 Spring 完成 bean 对象实例化并且设置完相关属性和依赖后，则会开始 bean 的初始化进程（initializeBean()），初始化第一个阶段是检查当前 bean 对象是否实现了一系列以 Aware 结尾的的接口。 Aware 接口为 Spring 容器的核心接口，是一个具有标识作用的超级接口，实现了该接口的 bean 是具有被 Spring 容器通知的能力，通知的方式是采用回调的方式。 在初始化阶段主要是感知 BeanNameAware、BeanClassLoaderAware、BeanFactoryAware ： private void invokeAwareMethods(final String beanName, final Object bean) { if (bean instanceof Aware) { if (bean instanceof BeanNameAware) { ((BeanNameAware) bean).setBeanName(beanName); } if (bean instanceof BeanClassLoaderAware) { ClassLoader bcl = getBeanClassLoader(); if (bcl != null) { ((BeanClassLoaderAware) bean).setBeanClassLoader(bcl); } } if (bean instanceof BeanFactoryAware) { ((BeanFactoryAware) bean).setBeanFactory(AbstractAutowireCapableBeanFactory.this); } } } BeanNameAware：对该 bean 对象定义的 beanName 设置到当前对象实例中 BeanClassLoaderAware：将当前 bean 对象相应的 ClassLoader 注入到当前对象实例中 BeanFactoryAware：BeanFactory 容器会将自身注入到当前对象实例中，这样当前对象就会拥有一个 BeanFactory 容器的引用。 当然，Spring 不仅仅只是提供了上面三个 Aware 接口，而是一系列： LoadTimeWeaverAware：加载Spring Bean时织入第三方模块，如AspectJ BootstrapContextAware：资源适配器BootstrapContext，如JCA,CCI ResourceLoaderAware：底层访问资源的加载器 PortletConfigAware：PortletConfig PortletContextAware：PortletContext ServletConfigAware：ServletConfig ServletContextAware：ServletContext MessageSourceAware：国际化 ApplicationEventPublisherAware：应用事件 NotificationPublisherAware：JMX通知 BeanPostProcessor初始化第二个阶段则是 BeanPostProcessor 增强处理，在该阶段 BeanPostProcessor 会处理当前容器内所有符合条件的实例化后的 bean 对象。 它主要是对 Spring 容器提供的 bean 实例对象进行有效的扩展，允许 Spring 在初始化 bean 阶段对其进行定制化修改，如处理标记接口或者为其提供代理实现。 BeanPostProcessor 接口提供了两个方法，在不同的时机执行，分别对应上图的前置处理和后置处理。 public interface BeanPostProcessor { @Nullable default Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { return bean; } @Nullable default Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { return bean; } } InitializingBean 和 init-methodInitializingBean 是一个接口，它为 Spring Bean 的初始化提供了一种方式，它有一个 afterPropertiesSet() 方法，在 bean 的初始化进程中会判断当前 bean 是否实现了 InitializingBean，如果实现了则调用 afterPropertiesSet() 进行初始化工作。然后再检查是否也指定了 init-method()，如果指定了则通过反射机制调用指定的 init-method()。 protected void invokeInitMethods(String beanName, final Object bean, @Nullable RootBeanDefinition mbd) throws Throwable { boolean isInitializingBean = (bean instanceof InitializingBean); if (isInitializingBean &amp;&amp; (mbd == null || !mbd.isExternallyManagedInitMethod(\"afterPropertiesSet\"))) { if (logger.isDebugEnabled()) { logger.debug(\"Invoking afterPropertiesSet() on bean with name '\" + beanName + \"'\"); } if (System.getSecurityManager() != null) { try { AccessController.doPrivileged((PrivilegedExceptionAction&lt;Object>) () -> { ((InitializingBean) bean).afterPropertiesSet(); return null; }, getAccessControlContext()); } catch (PrivilegedActionException pae) { throw pae.getException(); } } else { ((InitializingBean) bean).afterPropertiesSet(); } } if (mbd != null &amp;&amp; bean.getClass() != NullBean.class) { String initMethodName = mbd.getInitMethodName(); if (StringUtils.hasLength(initMethodName) &amp;&amp; !(isInitializingBean &amp;&amp; \"afterPropertiesSet\".equals(initMethodName)) &amp;&amp; !mbd.isExternallyManagedInitMethod(initMethodName)) { invokeCustomInitMethod(beanName, bean, mbd); } } } 对于 Spring 而言，虽然上面两种方式都可以实现初始化定制化，但是更加推崇 init-method 方式，因为对于 InitializingBean 接口而言，他需要 bean 去实现接口，这样就会污染我们的应用程序，显得 Spring 具有一定的侵入性。但是由于 init-method 是采用反射的方式，所以执行效率上相对于 InitializingBean 接口回调的方式可能会低一些。 DisposableBean 和 destroy-method与 InitializingBean 和 init-method 用于对象的自定义初始化工作相似，DisposableBean和 destroy-method 则用于对象的自定义销毁工作。 当一个 bean 对象经历了实例化、设置属性、初始化阶段,那么该 bean 对象就可以供容器使用了（调用的过程）。当完成调用后，如果是 singleton 类型的 bean ，则会看当前 bean 是否应实现了 DisposableBean 接口或者配置了 destroy-method 属性，如果是的话，则会为该实例注册一个用于对象销毁的回调方法，便于在这些 singleton 类型的 bean 对象销毁之前执行销毁逻辑。 但是，并不是对象完成调用后就会立刻执行销毁方法，因为这个时候 Spring 容器还处于运行阶段，只有当 Spring 容器关闭的时候才会去调用。但是， Spring 容器不会这么聪明会自动去调用这些销毁方法，而是需要我们主动去告知 Spring 容器。 对于 BeanFactory 容器而言，我们需要主动调用 destroySingletons() 通知 BeanFactory 容器去执行相应的销毁方法。 对于 ApplicationContext 容器而言调用 registerShutdownHook() 方法。 实践验证下面用一个实例来真实看看看上面执行的逻辑，毕竟理论是不能缺少实践的： public class lifeCycleBean implements BeanNameAware,BeanFactoryAware,BeanClassLoaderAware,BeanPostProcessor, InitializingBean,DisposableBean { private String test; public String getTest() { return test; } public void setTest(String test) { System.out.println(\"属性注入....\"); this.test = test; } public lifeCycleBean(){ System.out.println(\"构造函数调用...\"); } public void display(){ System.out.println(\"方法调用...\"); } @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException { System.out.println(\"BeanFactoryAware 被调用...\"); } @Override public void setBeanName(String name) { System.out.println(\"BeanNameAware 被调用...\"); } @Override public void setBeanClassLoader(ClassLoader classLoader) { System.out.println(\"BeanClassLoaderAware 被调用...\"); } @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { System.out.println(\"BeanPostProcessor postProcessBeforeInitialization 被调用...\"); return bean; } @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { System.out.println(\"BeanPostProcessor postProcessAfterInitialization 被调用...\"); return bean; } @Override public void destroy() throws Exception { System.out.println(\"DisposableBean destroy 被调动...\"); } @Override public void afterPropertiesSet() throws Exception { System.out.println(\"InitializingBean afterPropertiesSet 被调动...\"); } public void initMethod(){ System.out.println(\"init-method 被调用...\"); } public void destroyMethdo(){ System.out.println(\"destroy-method 被调用...\"); } } lifeCycleBean 继承了 BeanNameAware , BeanFactoryAware , BeanClassLoaderAware , BeanPostProcessor , InitializingBean , DisposableBean 六个接口，同时定义了一个 test 属性用于验证属性注入和提供一个 display() 用于模拟调用。 配置如下： &lt;bean id=\"lifeCycle\" class=\"org.springframework.core.test.lifeCycleBean\" init-method=\"initMethod\" destroy-method=\"destroyMethdo\"> &lt;property name=\"test\" value=\"test\"/> &lt;/bean> 配置 init-method 和 destroy-method。测试方法如下： // BeanFactory 容器一定要调用该方法进行 BeanPostProcessor 注册 factory.addBeanPostProcessor(new lifeCycleBean()); lifeCycleBean lifeCycleBean = (lifeCycleBean) factory.getBean(\"lifeCycle\"); lifeCycleBean.display(); System.out.println(\"方法调用完成，容器开始关闭....\"); // 关闭容器 factory.destroySingletons(); 运行结果： 构造函数调用... 构造函数调用... 属性注入.... BeanNameAware 被调用... BeanClassLoaderAware 被调用... BeanFactoryAware 被调用... BeanPostProcessor postProcessBeforeInitialization 被调用... InitializingBean afterPropertiesSet 被调动... init-method 被调用... BeanPostProcessor postProcessAfterInitialization 被调用... 方法调用... 方法调用完成，容器开始关闭.... DisposableBean destroy 被调动... destroy-method 被调用... 有两个构造函数调用是因为要注入一个 BeanPostProcessor（你也可以另外提供一个 BeanPostProcessor 实例）。 根据执行的结果已经上面的分析，我们就可以对 Spring Bean 的声明周期过程如下（方法级别）： Spring 容器根据实例化策略对 Bean 进行实例化。 实例化完成后，如果该 bean 设置了一些属性的话，则利用 set 方法设置一些属性。 如果该 Bean 实现了 BeanNameAware 接口，则调用 setBeanName() 方法。 如果该 bean 实现了 BeanClassLoaderAware 接口，则调用 setBeanClassLoader() 方法。 如果该 bean 实现了 BeanFactoryAware接口，则调用 setBeanFactory() 方法。 如果该容器注册了 BeanPostProcessor，则会调用postProcessBeforeInitialization() 方法完成 bean 前置处理 如果该 bean 实现了 InitializingBean 接口，则调用 。afterPropertiesSet() 方法。 如果该 bean 配置了 init-method 方法，则调用 init-method 指定的方法。 初始化完成后，如果该容器注册了 BeanPostProcessor 则会调用 postProcessAfterInitialization() 方法完成 bean 的后置处理。 对象完成初始化，开始方法调用。 在容器进行关闭之前，如果该 bean 实现了 DisposableBean 接口，则调用 destroy() 方法。 在容器进行关闭之前，如果该 bean 配置了 destroy-mehod，则调用其指定的方法。 到这里一个 bean 也就完成了它的一生。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"Spring的环境&属性：PropertySource、Environment、Profile","date":"2020-01-25T14:09:19.000Z","path":"2020/01/25/8ce6797f.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=4032 在学习Spring源码的过程中发现的好站+好贴，原创不易感谢作者。 Spring版本：Spring 5.0.6.RELEASE spring.profiles.active 和 @Profile 这两个我相信各位都熟悉吧，主要功能是可以实现不同环境下（开发、测试、生产）参数配置的切换。 其实关于环境的切换，在博客 IOC 之 PropertyPlaceholderConfigurer 的应用 已经介绍了利用 PropertyPlaceholderConfigurer 来实现动态切换配置环境，当然这种方法需要我们自己实现，有点儿麻烦。但是对于这种非常实际的需求，Spring 怎么可能没有提供呢？下面就这个问题来对 Spring 的环境 &amp; 属性来做一个分析说明。 概括Spring 环境 &amp; 属性由四个部分组成：PropertySource、PropertyResolver、Profile 和 Environment。 PropertySource：属性源，key-value 属性对抽象，用于配置数据。 PropertyResolver：属性解析器，用于解析属性配置 Profile：剖面，只有激活的剖面的组件/配置才会注册到 Spring 容器，类似于 Spring Boot 中的 profile Environment：环境，Profile 和 PropertyResolver 的组合。 下面是整个体系的结构图： 下面就针对上面结构图对 Spring 的 Properties &amp; Environment 做一个详细的分析。 PropertiesPropertyResolver 属性解析器，用于解析任何基础源的属性的接口 public interface PropertyResolver { // 是否包含某个属性 boolean containsProperty(String key); // 获取属性值 如果找不到返回null @Nullable String getProperty(String key); // 获取属性值，如果找不到返回默认值 String getProperty(String key, String defaultValue); // 获取指定类型的属性值，找不到返回null @Nullable &lt;T> T getProperty(String key, Class&lt;T> targetType); // 获取指定类型的属性值，找不到返回默认值 &lt;T> T getProperty(String key, Class&lt;T> targetType, T defaultValue); // 获取属性值，找不到抛出异常IllegalStateException String getRequiredProperty(String key) throws IllegalStateException; // 获取指定类型的属性值，找不到抛出异常IllegalStateException &lt;T> T getRequiredProperty(String key, Class&lt;T> targetType) throws IllegalStateException; // 替换文本中的占位符（${key}）到属性值，找不到不解析 String resolvePlaceholders(String text); // 替换文本中的占位符（${key}）到属性值，找不到抛出异常IllegalArgumentException String resolveRequiredPlaceholders(String text) throws IllegalArgumentException; } 从 API 上面我们就知道属性解析器 PropertyResolver 的作用了。下面是一个简单的运用。 PropertyResolver propertyResolver = new PropertySourcesPropertyResolver(propertySources); System.out.println(propertyResolver.getProperty(\"name\")); System.out.println(propertyResolver.getProperty(\"name\", \"chenssy\")); System.out.println(propertyResolver.resolvePlaceholders(\"my name is ${name}\")); 下图是 PropertyResolver 体系结构图： ConfigurablePropertyResolver：供属性类型转换的功能 AbstractPropertyResolver：解析属性文件的抽象基类 PropertySourcesPropertyResolver：PropertyResolver 的实现者，他对一组 PropertySources 提供属性解析服务 ConfigurablePropertyResolver 提供属性类型转换的功能 通俗点说就是 ConfigurablePropertyResolver 提供属性值类型转换所需要的 ConversionService。 public interface ConfigurablePropertyResolver extends PropertyResolver { // 返回执行类型转换时使用的 ConfigurableConversionService ConfigurableConversionService getConversionService(); // 设置 ConfigurableConversionService void setConversionService(ConfigurableConversionService conversionService); // 设置占位符前缀 void setPlaceholderPrefix(String placeholderPrefix); // 设置占位符后缀 void setPlaceholderSuffix(String placeholderSuffix); // 设置占位符与默认值之间的分隔符 void setValueSeparator(@Nullable String valueSeparator); // 设置当遇到嵌套在给定属性值内的不可解析的占位符时是否抛出异常 // 当属性值包含不可解析的占位符时，getProperty(String)及其变体的实现必须检查此处设置的值以确定正确的行为。 void setIgnoreUnresolvableNestedPlaceholders(boolean ignoreUnresolvableNestedPlaceholders); // 指定必须存在哪些属性，以便由validateRequiredProperties（）验证 void setRequiredProperties(String... requiredProperties); // 验证setRequiredProperties指定的每个属性是否存在并解析为非null值 void validateRequiredProperties() throws MissingRequiredPropertiesException; } 从 ConfigurablePropertyResolver 所提供的方法来看，除了访问和设置 ConversionService 外，主要还提供了一些解析规则之类的方法。 就 Properties 体系而言，PropertyResolver 定义了访问 Properties 属性值的方法，而 ConfigurablePropertyResolver 则定义了解析 Properties 一些相关的规则和值进行类型转换所需要的 Service。 该体系有两个实现者：AbstractPropertyResolver 和 PropertySourcesPropertyResolver，其中 AbstractPropertyResolver 为实现的抽象基类，PropertySourcesPropertyResolver 为真正的实现者。 AbstractPropertyResolver 解析属性文件的抽象基类 AbstractPropertyResolver 作为基类它仅仅只是设置了一些解析属性文件所需要配置或者转换器，如 setConversionService()、setPlaceholderPrefix()、setValueSeparator()，其实这些方法的实现都比较简单都是设置或者获取 AbstractPropertyResolver 所提供的属性，如下： // 类型转换去 private volatile ConfigurableConversionService conversionService; // 占位符 private PropertyPlaceholderHelper nonStrictHelper; // private PropertyPlaceholderHelper strictHelper; // 设置是否抛出异常 private boolean ignoreUnresolvableNestedPlaceholders = false; // 占位符前缀 private String placeholderPrefix = SystemPropertyUtils.PLACEHOLDER_PREFIX; // 占位符后缀 private String placeholderSuffix = SystemPropertyUtils.PLACEHOLDER_SUFFIX; // 与默认值的分割 private String valueSeparator = SystemPropertyUtils.VALUE_SEPARATOR; // 必须要有的字段值 private final Set&lt;String> requiredProperties = new LinkedHashSet&lt;>(); 这些属性都是 ConfigurablePropertyResolver 接口所提供方法需要的属性，他所提供的方法都是设置和读取这些值，如下几个方法： public ConfigurableConversionService getConversionService() { // 需要提供独立的DefaultConversionService，而不是PropertySourcesPropertyResolver 使用的共享DefaultConversionService。 ConfigurableConversionService cs = this.conversionService; if (cs == null) { synchronized (this) { cs = this.conversionService; if (cs == null) { cs = new DefaultConversionService(); this.conversionService = cs; } } } return cs; } @Override public void setConversionService(ConfigurableConversionService conversionService) { Assert.notNull(conversionService, \"ConversionService must not be null\"); this.conversionService = conversionService; } public void setPlaceholderPrefix(String placeholderPrefix) { Assert.notNull(placeholderPrefix, \"'placeholderPrefix' must not be null\"); this.placeholderPrefix = placeholderPrefix; } public void setPlaceholderSuffix(String placeholderSuffix) { Assert.notNull(placeholderSuffix, \"'placeholderSuffix' must not be null\"); this.placeholderSuffix = placeholderSuffix; } 而对属性的访问则委托给子类 PropertySourcesPropertyResolver 实现。 public String getProperty(String key) { return getProperty(key, String.class); } public String getProperty(String key, String defaultValue) { String value = getProperty(key); return (value != null ? value : defaultValue); } public &lt;T> T getProperty(String key, Class&lt;T> targetType, T defaultValue) { T value = getProperty(key, targetType); return (value != null ? value : defaultValue); } public String getRequiredProperty(String key) throws IllegalStateException { String value = getProperty(key); if (value == null) { throw new IllegalStateException(\"Required key '\" + key + \"' not found\"); } return value; } public &lt;T> T getRequiredProperty(String key, Class&lt;T> valueType) throws IllegalStateException { T value = getProperty(key, valueType); if (value == null) { throw new IllegalStateException(\"Required key '\" + key + \"' not found\"); } return value; PropertySourcesPropertyResolver PropertyResolver 的实现者，他对一组 PropertySources 提供属性解析服务 它仅有一个成员变量：PropertySources。该成员变量内部存储着一组 PropertySource，表示 key-value 键值对的源的抽象基类，即一个 PropertySource 对象则是一个 key-value 键值对。如下： public abstract class PropertySource&lt;T> { protected final Log logger = LogFactory.getLog(getClass()); protected final String name; protected final T source; //...... } 对外公开的 getProperty() 都是委托给 getProperty(String key, Class&lt;T&gt; targetValueType, boolean resolveNestedPlaceholders) 实现，他有三个参数，分别表示为： key：获取的 key targetValueType： 目标 value 的类型 resolveNestedPlaceholders：是否解决嵌套占位符 源码如下： protected &lt;T> T getProperty(String key, Class&lt;T> targetValueType, boolean resolveNestedPlaceholders) { if (this.propertySources != null) { for (PropertySource&lt;?> propertySource : this.propertySources) { if (logger.isTraceEnabled()) { logger.trace(\"Searching for key '\" + key + \"' in PropertySource '\" + propertySource.getName() + \"'\"); } Object value = propertySource.getProperty(key); if (value != null) { if (resolveNestedPlaceholders &amp;&amp; value instanceof String) { value = resolveNestedPlaceholders((String) value); } logKeyFound(key, propertySource, value); return convertValueIfNecessary(value, targetValueType); } } } if (logger.isDebugEnabled()) { logger.debug(\"Could not find key '\" + key + \"' in any property source\"); } return null; } 首先从 propertySource 中获取指定 key 的 value 值，然后判断是否需要进行嵌套占位符解析，如果需要则调用 resolveNestedPlaceholders() 进行嵌套占位符解析，然后调用 convertValueIfNecessary() 进行类型转换。 resolveNestedPlaceholders() 该方法用于解析给定字符串中的占位符，同时根据 ignoreUnresolvableNestedPlaceholders 的值，来确定是否对不可解析的占位符的处理方法：是忽略还是抛出异常（该值由 setIgnoreUnresolvableNestedPlaceholders() 设置）。 protected String resolveNestedPlaceholders(String value) { return (this.ignoreUnresolvableNestedPlaceholders ? resolvePlaceholders(value) : resolveRequiredPlaceholders(value)); } 如果 this.ignoreUnresolvableNestedPlaceholders 为 true，则调用 resolvePlaceholders() ，否则调用 resolveRequiredPlaceholders()但是无论是哪个方法，最终都会到 doResolvePlaceholders()，该方法接收两个参数： String 类型的 text：待解析的字符串 PropertyPlaceholderHelper 类型的 helper：用于解析占位符的工具类。 private String doResolvePlaceholders(String text, PropertyPlaceholderHelper helper) { return helper.replacePlaceholders(text, this::getPropertyAsRawString); } PropertyPlaceholderHelper 是用于处理包含占位符值的字符串，构造该实例需要四个参数： placeholderPrefix：占位符前缀 placeholderSuffix：占位符后缀 valueSeparator：占位符变量与关联的默认值之间的分隔符 ignoreUnresolvablePlaceholders：指示是否忽略不可解析的占位符（true）或抛出异常（false） 构造函数如下： public PropertyPlaceholderHelper(String placeholderPrefix, String placeholderSuffix, @Nullable String valueSeparator, boolean ignoreUnresolvablePlaceholders) { Assert.notNull(placeholderPrefix, \"'placeholderPrefix' must not be null\"); Assert.notNull(placeholderSuffix, \"'placeholderSuffix' must not be null\"); this.placeholderPrefix = placeholderPrefix; this.placeholderSuffix = placeholderSuffix; String simplePrefixForSuffix = wellKnownSimplePrefixes.get(this.placeholderSuffix); if (simplePrefixForSuffix != null &amp;&amp; this.placeholderPrefix.endsWith(simplePrefixForSuffix)) { this.simplePrefix = simplePrefixForSuffix; } else { this.simplePrefix = this.placeholderPrefix; } this.valueSeparator = valueSeparator; this.ignoreUnresolvablePlaceholders = ignoreUnresolvablePlaceholders; } 就 PropertySourcesPropertyResolver 而言，其父类 AbstractPropertyResolver 已经对上述四个值做了定义：placeholderPrefix 为 ${，placeholderSuffix 为 }，valueSeparator 为 :，ignoreUnresolvablePlaceholders 默认为 false，当然我们也可以使用相应的 setter 方法自定义。 调用 PropertyPlaceholderHelper 的 replacePlaceholders() 对占位符进行处理，该方法接收两个参数，一个是待解析的字符串 value ，一个是 PlaceholderResolver 类型的 placeholderResolver，他是定义占位符解析的策略类。如下： public String replacePlaceholders(String value, PlaceholderResolver placeholderResolver) { Assert.notNull(value, \"'value' must not be null\"); return parseStringValue(value, placeholderResolver, new HashSet&lt;>()); } 内部委托给 parseStringValue() 实现： protected String parseStringValue( String value, PlaceholderResolver placeholderResolver, Set&lt;String> visitedPlaceholders) { StringBuilder result = new StringBuilder(value); // 检索前缀，${ int startIndex = value.indexOf(this.placeholderPrefix); while (startIndex != -1) { // 检索后缀 ,} int endIndex = findPlaceholderEndIndex(result, startIndex); if (endIndex != -1) { // 前缀和后缀之间的字符串 String placeholder = result.substring(startIndex + this.placeholderPrefix.length(), endIndex); String originalPlaceholder = placeholder; // 循环占位符 // 判断该占位符是否已经处理了 if (!visitedPlaceholders.add(originalPlaceholder)) { throw new IllegalArgumentException( \"Circular placeholder reference '\" + originalPlaceholder + \"' in property definitions\"); } // 递归调用，解析占位符 placeholder = parseStringValue(placeholder, placeholderResolver, visitedPlaceholders); // 获取值 String propVal = placeholderResolver.resolvePlaceholder(placeholder); // propval 为空，则提取默认值 if (propVal == null &amp;&amp; this.valueSeparator != null) { int separatorIndex = placeholder.indexOf(this.valueSeparator); if (separatorIndex != -1) { String actualPlaceholder = placeholder.substring(0, separatorIndex); String defaultValue = placeholder.substring(separatorIndex + this.valueSeparator.length()); propVal = placeholderResolver.resolvePlaceholder(actualPlaceholder); if (propVal == null) { propVal = defaultValue; } } } if (propVal != null) { // 递归调用，解析先前解析的占位符值中包含的占位符 propVal = parseStringValue(propVal, placeholderResolver, visitedPlaceholders); result.replace(startIndex, endIndex + this.placeholderSuffix.length(), propVal); if (logger.isTraceEnabled()) { logger.trace(\"Resolved placeholder '\" + placeholder + \"'\"); } startIndex = result.indexOf(this.placeholderPrefix, startIndex + propVal.length()); } else if (this.ignoreUnresolvablePlaceholders) { // Proceed with unprocessed value. startIndex = result.indexOf(this.placeholderPrefix, endIndex + this.placeholderSuffix.length()); } else { throw new IllegalArgumentException(\"Could not resolve placeholder '\" + placeholder + \"'\" + \" in value \\\"\" + value + \"\\\"\"); } // visitedPlaceholders.remove(originalPlaceholder); } else { startIndex = -1; } } return result.toString(); } 其实就是获取占位符 ${} 中间的值，这里面会涉及到一个递归的过程，因为可能会存在这种情况 ${${name}}。 convertValueIfNecessary() 该方法是不是感觉到非常的熟悉，该方法就是完成类型转换的。如下： protected &lt;T> T convertValueIfNecessary(Object value, @Nullable Class&lt;T> targetType) { if (targetType == null) { return (T) value; } ConversionService conversionServiceToUse = this.conversionService; if (conversionServiceToUse == null) { // Avoid initialization of shared DefaultConversionService if // no standard type conversion is needed in the first place... if (ClassUtils.isAssignableValue(targetType, value)) { return (T) value; } conversionServiceToUse = DefaultConversionService.getSharedInstance(); } return conversionServiceToUse.convert(value, targetType); } 首先获取类型转换服务 conversionService ，若为空，则判断是否可以通过反射来设置，如果可以则直接强转返回，否则构造一个 DefaultConversionService 实例，最后调用其 convert() 完成类型转换，后续就是 Spring 类型转换体系的事情了，如果对其不了解，可以参考小编这篇博客：IOC 之深入分析 Bean 的类型转换体系 Environment 表示当前应用程序正在运行的环境 应用程序的环境有两个关键方面：profile 和 properties。 properties 的方法由 PropertyResolver 定义。 profile 则表示当前的运行环境，对于应用程序中的 properties 而言，并不是所有的都会加载到系统中，只有其属性与 profile 一直才会被激活加载， 所以 Environment 对象的作用是确定哪些配置文件（如果有）当前处于活动状态，以及默认情况下哪些配置文件（如果有）应处于活动状态。properties 在几乎所有应用程序中都发挥着重要作用，并且有多种来源：属性文件，JVM 系统属性，系统环境变量，JNDI，servlet 上下文参数，ad-hoc 属性对象，映射等。同时它继承 PropertyResolver 接口，所以与属性相关的 Environment 对象其主要是为用户提供方便的服务接口，用于配置属性源和从中属性源中解析属性。 public interface Environment extends PropertyResolver { // 返回此环境下激活的配置文件集 String[] getActiveProfiles(); // 如果未设置激活配置文件，则返回默认的激活的配置文件集 String[] getDefaultProfiles(); boolean acceptsProfiles(String... profiles); } Environment 体系结构图如下： PropertyResolver：提供属性访问功能 Environment：提供访问和判断 profiles 的功能 ConfigurableEnvironment：提供设置激活的 profile 和默认的 profile 的功能以及操作 Properties 的工具 ConfigurableWebEnvironment：提供配置 Servlet 上下文和 Servlet 参数的功能 AbstractEnvironment：实现了 ConfigurableEnvironment 接口，默认属性和存储容器的定义，并且实现了 ConfigurableEnvironment 的方法，并且为子类预留可覆盖了扩展方法 StandardEnvironment：继承自 AbstractEnvironment ，非 Servlet(Web) 环境下的标准 Environment 实现 StandardServletEnvironment：继承自 StandardEnvironment ，Servlet(Web) 环境下的标准 Environment 实现 ConfigurableEnvironment 提供设置激活的 profile 和默认的 profile 的功能以及操作 Properties 的工具 该类除了继承 Environment 接口外还继承了 ConfigurablePropertyResolver 接口，所以它即具备了设置 profile 的功能也具备了操作 Properties 的功能。同时还允许客户端通过它设置和验证所需要的属性，自定义转换服务等功能。如下： public interface ConfigurableEnvironment extends Environment, ConfigurablePropertyResolver { // 指定该环境下的 profile 集 void setActiveProfiles(String... profiles); // 增加此环境的 profile void addActiveProfile(String profile); // 设置默认的 profile void setDefaultProfiles(String... profiles); // 返回此环境的 PropertySources MutablePropertySources getPropertySources(); // 尝试返回 System.getenv() 的值，若失败则返回通过 System.getenv(string) 的来访问各个键的映射 Map&lt;String, Object> getSystemEnvironment(); // 尝试返回 System.getProperties() 的值，若失败则返回通过 System.getProperties(string) 的来访问各个键的映射 Map&lt;String, Object> getSystemProperties(); void merge(ConfigurableEnvironment parent); } AbstractEnvironment Environment 的基础实现 允许通过设置 ACTIVE_PROFILES_PROPERTY_NAME 和DEFAULT_PROFILES_PROPERTY_NAME 属性指定活动和默认配置文件。子类的主要区别在于它们默认添加的 PropertySource 对象。而 AbstractEnvironment 则没有添加任何内容。子类应该通过受保护的 customizePropertySources(MutablePropertySources) 钩子提供属性源，而客户端应该使用ConfigurableEnvironment.getPropertySources()进行自定义并对MutablePropertySources API进行操作。 在 AbstractEnvironment 有两对变量，这两对变量维护着激活和默认配置 profile。如下： public static final String ACTIVE_PROFILES_PROPERTY_NAME = \"spring.profiles.active\"; private final Set&lt;String> activeProfiles = new LinkedHashSet&lt;>(); public static final String DEFAULT_PROFILES_PROPERTY_NAME = \"spring.profiles.default\"; private final Set&lt;String> defaultProfiles = new LinkedHashSet&lt;>(getReservedDefaultProfiles()); 由于实现方法较多，这里只关注两个方法：setActiveProfiles() 和 getActiveProfiles()。 setActiveProfiles() public void setActiveProfiles(String... profiles) { Assert.notNull(profiles, \"Profile array must not be null\"); if (logger.isDebugEnabled()) { logger.debug(\"Activating profiles \" + Arrays.asList(profiles)); } synchronized (this.activeProfiles) { this.activeProfiles.clear(); for (String profile : profiles) { validateProfile(profile); this.activeProfiles.add(profile); } } } 该方法其实就是操作 activeProfiles 集合，在每次设置之前都会将该集合清空重新添加，添加之前调用 validateProfile() 对添加的 profile 进行校验，如下： protected void validateProfile(String profile) { if (!StringUtils.hasText(profile)) { throw new IllegalArgumentException(\"Invalid profile [\" + profile + \"]: must contain text\"); } if (profile.charAt(0) == '!') { throw new IllegalArgumentException(\"Invalid profile [\" + profile + \"]: must not begin with ! operator\"); } } 这个校验过程比较弱，子类可以提供更加严格的校验规则。 getActiveProfiles() 从 getActiveProfiles() 中我们可以猜出这个方法实现的逻辑：获取 activeProfiles 集合即可。 public String[] getActiveProfiles() { return StringUtils.toStringArray(doGetActiveProfiles()); } 委托给 doGetActiveProfiles() 实现： protected Set&lt;String> doGetActiveProfiles() { synchronized (this.activeProfiles) { if (this.activeProfiles.isEmpty()) { String profiles = getProperty(ACTIVE_PROFILES_PROPERTY_NAME); if (StringUtils.hasText(profiles)) { setActiveProfiles(StringUtils.commaDelimitedListToStringArray( StringUtils.trimAllWhitespace(profiles))); } } return this.activeProfiles; } } 如果 activeProfiles 为空，则从 Properties 中获取 spring.profiles.active 配置，如果不为空，则调用 setActiveProfiles() 设置 profile，最后返回。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之BeanDefinition注册机：BeanDefinitionRegistry","date":"2020-01-25T13:56:16.000Z","path":"2020/01/25/86c712d3.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=4026 在学习Spring源码的过程中发现的好站+好贴，原创不易感谢作者。 Spring版本：Spring 5.0.6.RELEASE 将定义 bean 的资源文件解析成 BeanDefinition 后需要将其注入容器中，这个过程由 BeanDefinitionRegistry 来完成。 BeanDefinitionRegistry：向注册表中注册 BeanDefinition 实例，完成注册的过程。 下图是 BeanDefinitionRegistry 类结构图： BeanDefinitionRegistry 继承了 AliasRegistry 接口，其核心子类有三个：SimpleBeanDefinitionRegistry、DefaultListableBeanFactory、GenericApplicationContext。 AliasRegistry用于别名管理的通用型接口，作为 BeanDefinitionRegistry 的顶层接口。 AliasRegistry 定义了一些别名管理的方法。 public interface AliasRegistry { void registerAlias(String name, String alias); void removeAlias(String alias); boolean isAlias(String name); String[] getAliases(String name); } BeanDefinitionRegistryBeanDefinition 的注册接口，如 RootBeanDefinition 和 ChildBeanDefinition。它通常由 BeanFactories 实现，在 Spring 中已知的实现者为：DefaultListableBeanFactory 和 GenericApplicationContext。BeanDefinitionRegistry 是 Spring 的 Bean 工厂包中唯一封装 BeanDefinition 注册的接口。 BeanDefinitionRegistry 接口定义了关于 BeanDefinition 注册、注销、查询等一系列的操作。 public interface BeanDefinitionRegistry extends AliasRegistry { // 往注册表中注册一个新的 BeanDefinition 实例 void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException; // 移除注册表中已注册的 BeanDefinition 实例 void removeBeanDefinition(String beanName) throws NoSuchBeanDefinitionException; // 从注册中取得指定的 BeanDefinition 实例 BeanDefinition getBeanDefinition(String beanName) throws NoSuchBeanDefinitionException; // 判断 BeanDefinition 实例是否在注册表中（是否注册） boolean containsBeanDefinition(String beanName); // 取得注册表中所有 BeanDefinition 实例的 beanName（标识） String[] getBeanDefinitionNames(); // 返回注册表中 BeanDefinition 实例的数量 int getBeanDefinitionCount(); // beanName（标识）是否被占用 boolean isBeanNameInUse(String beanName); } SimpleBeanDefinitionRegistrySimpleBeanDefinitionRegistry 是 BeanDefinitionRegistry 一个简单的实现，它还继承 SimpleAliasRegistry（ AliasRegistry 的简单实现），它仅仅只提供注册表功能，无工厂功能。 SimpleBeanDefinitionRegistry 使用 ConcurrentHashMap 来存储注册的 BeanDefinition。 private final Map&lt;String, BeanDefinition> beanDefinitionMap = new ConcurrentHashMap&lt;>(64); 他对注册其中的 BeanDefinition 都是基于 beanDefinitionMap 这个集合来实现的，如下： @Override public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException { Assert.hasText(beanName, \"'beanName' must not be empty\"); Assert.notNull(beanDefinition, \"BeanDefinition must not be null\"); this.beanDefinitionMap.put(beanName, beanDefinition); } @Override public void removeBeanDefinition(String beanName) throws NoSuchBeanDefinitionException { if (this.beanDefinitionMap.remove(beanName) == null) { throw new NoSuchBeanDefinitionException(beanName); } } @Override public BeanDefinition getBeanDefinition(String beanName) throws NoSuchBeanDefinitionException { BeanDefinition bd = this.beanDefinitionMap.get(beanName); if (bd == null) { throw new NoSuchBeanDefinitionException(beanName); } return bd; } 实现简单、粗暴。 DefaultListableBeanFactoryDefaultListableBeanFactory，ConfigurableListableBeanFactory（其实就是 BeanFactory ） 和 BeanDefinitionRegistry 接口的默认实现：一个基于 BeanDefinition 元数据的完整 bean 工厂。 所以相对于 SimpleBeanDefinitionRegistry 而言，DefaultListableBeanFactory 则是一个具有注册功能的完整 bean 工厂。它同样是用 ConcurrentHashMap 数据结构来存储注册的 BeanDefinition。 // 注册表，由 BeanDefinition 的标识 （beanName） 与其实例组成 private final Map&lt;String, BeanDefinition> beanDefinitionMap = new ConcurrentHashMap&lt;String, bean>(64); // 标识（beanName）集合 private final List&lt;String> beanDefinitionNames = new ArrayList&lt;String>(64); 在看 registerBeanDefinition()： public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException { // 省略其他代码 else { if (hasBeanCreationStarted()) { // Cannot modify startup-time collection elements anymore (for stable iteration) synchronized (this.beanDefinitionMap) { this.beanDefinitionMap.put(beanName, beanDefinition); List&lt;String> updatedDefinitions = new ArrayList&lt;>(this.beanDefinitionNames.size() + 1); updatedDefinitions.addAll(this.beanDefinitionNames); updatedDefinitions.add(beanName); this.beanDefinitionNames = updatedDefinitions; if (this.manualSingletonNames.contains(beanName)) { Set&lt;String> updatedSingletons = new LinkedHashSet&lt;>(this.manualSingletonNames); updatedSingletons.remove(beanName); this.manualSingletonNames = updatedSingletons; } } } else { // 注册 BeanDefinition this.beanDefinitionMap.put(beanName, beanDefinition); this.beanDefinitionNames.add(beanName); this.manualSingletonNames.remove(beanName); } this.frozenBeanDefinitionNames = null; } if (existingDefinition != null || containsSingleton(beanName)) { resetBeanDefinition(beanName); } } 其实上面一堆代码最重要就只有一句： this.beanDefinitionMap.put(beanName, beanDefinition); removeBeanDefinition() 其实也是调用 beanDefinitionMap.remove(beanName)。 对于类 GenericApplicationContext ，查看源码你会发现他实现注册、注销功能都是委托 DefaultListableBeanFactory 实现的。 所以 BeanDefinition 注册并不是非常高大上的功能，内部就是用一个 Map 实现 ，并不是多么高大上的骚操作，所以有时候我们会潜意识地认为某些技术很高大上就觉得他很深奥，如果试着去一探究竟你会发现，原来这么简单。虽然 BeanDefinitionRegistry 实现简单，但是它作为 Spring IOC 容器的核心接口，其地位还是很重的。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之bean的实例化策略：InstantiationStrategy","date":"2020-01-24T12:59:40.000Z","path":"2020/01/24/25302edf.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=4022 在学习Spring源码的过程中发现的好站+好贴，原创不易感谢作者。 Spring版本：Spring 5.0.6.RELEASE 在开始分析 InstantiationStrategy 之前，我们先来简单回顾下 bean 的实例化过程： bean 的创建，主要是 AbstractAutowireCapableBeanFactory.doCreateBean() ，在这个方法中有 bean 的实例化、属性注入和初始化过程，对于 bean 的实例化过程这是根据 bean 的类型来判断的，如果是单例模式，则直接从 factoryBeanInstanceCache 缓存中获取，否则调用 createBeanInstance() 创建。 在 createBeanInstance() 中，如果 Supplier 不为空，则调用 obtainFromSupplier() 实例化 bean。如果 factory 不为空，则调用 instantiateUsingFactoryMethod() 实例化 bean ，如果都不是则调用 instantiateBean() 实例化bean 。但是无论是 instantiateUsingFactoryMethod() 还是 instantiateBean() 最后都一定会调用到 InstantiationStrategy 接口的 instantiate()。 InstantiationStrategyInstantiationStrategy 接口定义了 Spring Bean 实例化的策略，根据创建对象情况的不同，提供了三种策略：无参构造方法、有参构造方法、工厂方法。如下： public interface InstantiationStrategy { /** * 默认构造方法 */ Object instantiate(RootBeanDefinition bd, @Nullable String beanName, BeanFactory owner) throws BeansException; /** * 指定构造方法 */ Object instantiate(RootBeanDefinition bd, @Nullable String beanName, BeanFactory owner, Constructor&lt;?> ctor, @Nullable Object... args) throws BeansException; /** * 工厂方法 */ Object instantiate(RootBeanDefinition bd, @Nullable String beanName, BeanFactory owner, @Nullable Object factoryBean, Method factoryMethod, @Nullable Object... args) throws BeansException; } SimpleInstantiationStrategyInstantiationStrategy 接口有两个实现类：SimpleInstantiationStrategy 和 CglibSubclassingInstantiationStrategy。 SimpleInstantiationStrategy 对以上三个方法都做了简单的实现。 如果是工厂方法实例化，则直接使用反射创建对象，如下： public Object instantiate(RootBeanDefinition bd, @Nullable String beanName, BeanFactory owner, @Nullable Object factoryBean, final Method factoryMethod, @Nullable Object... args) { try { if (System.getSecurityManager() != null) { AccessController.doPrivileged((PrivilegedAction&lt;Object>) () -> { ReflectionUtils.makeAccessible(factoryMethod); return null; }); } else { ReflectionUtils.makeAccessible(factoryMethod); } Method priorInvokedFactoryMethod = currentlyInvokedFactoryMethod.get(); try { currentlyInvokedFactoryMethod.set(factoryMethod); Object result = factoryMethod.invoke(factoryBean, args); if (result == null) { result = new NullBean(); } return result; } finally { if (priorInvokedFactoryMethod != null) { currentlyInvokedFactoryMethod.set(priorInvokedFactoryMethod); } else { currentlyInvokedFactoryMethod.remove(); } } } // 省略 catch } 如果是构造方法实例化，则是先判断是否有 MethodOverrides，如果没有则是直接使用反射，如果有则就需要 CGLIB 实例化对象。如下： public Object instantiate(RootBeanDefinition bd, @Nullable String beanName, BeanFactory owner) { // Don't override the class with CGLIB if no overrides. if (!bd.hasMethodOverrides()) { Constructor&lt;?> constructorToUse; synchronized (bd.constructorArgumentLock) { constructorToUse = (Constructor&lt;?>) bd.resolvedConstructorOrFactoryMethod; if (constructorToUse == null) { final Class&lt;?> clazz = bd.getBeanClass(); if (clazz.isInterface()) { throw new BeanInstantiationException(clazz, \"Specified class is an interface\"); } try { if (System.getSecurityManager() != null) { constructorToUse = AccessController.doPrivileged( (PrivilegedExceptionAction&lt;Constructor&lt;?>>) clazz::getDeclaredConstructor); } else { constructorToUse = clazz.getDeclaredConstructor(); } bd.resolvedConstructorOrFactoryMethod = constructorToUse; } catch (Throwable ex) { throw new BeanInstantiationException(clazz, \"No default constructor found\", ex); } } } return BeanUtils.instantiateClass(constructorToUse); } else { // Must generate CGLIB subclass. return instantiateWithMethodInjection(bd, beanName, owner); } } public Object instantiate(RootBeanDefinition bd, @Nullable String beanName, BeanFactory owner, final Constructor&lt;?> ctor, @Nullable Object... args) { if (!bd.hasMethodOverrides()) { if (System.getSecurityManager() != null) { // use own privileged to change accessibility (when security is on) AccessController.doPrivileged((PrivilegedAction&lt;Object>) () -> { ReflectionUtils.makeAccessible(ctor); return null; }); } return (args != null ? BeanUtils.instantiateClass(ctor, args) : BeanUtils.instantiateClass(ctor)); } else { return instantiateWithMethodInjection(bd, beanName, owner, ctor, args); } } SimpleInstantiationStrategy 对 instantiateWithMethodInjection() 的实现任务交给了子类 CglibSubclassingInstantiationStrategy。 MethodOverrides对于 MethodOverrides，在 BeanDefinitionParserDelegate 类解析 &lt;bean/&gt; 的时候是否还记得这两个方法：parseLookupOverrideSubElements() 和 parseReplacedMethodSubElements() 这两个方法分别用于解析 lookup-method 和 replaced-method。parseLookupOverrideSubElements() 源码如下： 更多关于 lookup-method 和 replaced-method 请看：IOC 之解析 bean 标签：meta、lookup-method、replace-method CGLIB 实例化策略类 CglibSubclassingInstantiationStrategy 为 Spring 实例化 bean 的默认实例化策略，其主要功能还是对父类功能进行补充：其父类将 CGLIB 的实例化策略委托其实现。 // SimpleInstantiationStrategy protected Object instantiateWithMethodInjection(RootBeanDefinition bd, @Nullable String beanName, BeanFactory owner) { throw new UnsupportedOperationException(\"Method Injection not supported in SimpleInstantiationStrategy\"); } // CglibSubclassingInstantiationStrategy @Override protected Object instantiateWithMethodInjection(RootBeanDefinition bd, @Nullable String beanName, BeanFactory owner) { return instantiateWithMethodInjection(bd, beanName, owner, null); } CglibSubclassingInstantiationStrategy 实例化 bean 策略是通过其内部类 CglibSubclassCreator 来实现的。 protected Object instantiateWithMethodInjection(RootBeanDefinition bd, @Nullable String beanName, BeanFactory owner, @Nullable Constructor&lt;?> ctor, @Nullable Object... args) { return new CglibSubclassCreator(bd, owner).instantiate(ctor, args); } 创建 CglibSubclassCreator 实例然后调用其 instantiate()，该方法用于动态创建子类实例，同时实现所需要的 lookups（lookup-method、replace-method）。 public Object instantiate(@Nullable Constructor&lt;?> ctor, @Nullable Object... args) { Class&lt;?> subclass = createEnhancedSubclass(this.beanDefinition); Object instance; if (ctor == null) { instance = BeanUtils.instantiateClass(subclass); } else { try { Constructor&lt;?> enhancedSubclassConstructor = subclass.getConstructor(ctor.getParameterTypes()); instance = enhancedSubclassConstructor.newInstance(args); } catch (Exception ex) { throw new BeanInstantiationException(this.beanDefinition.getBeanClass(), \"Failed to invoke constructor for CGLIB enhanced subclass [\" + subclass.getName() + \"]\", ex); } } //这个地方解决一个bug，bug提交报告https://jira.spring.io/browse/SPR-10785 // SPR-10785: set callbacks directly on the instance instead of in the // enhanced class (via the Enhancer) in order to avoid memory leaks. Factory factory = (Factory) instance; factory.setCallbacks(new Callback[] {NoOp.INSTANCE, new LookupOverrideMethodInterceptor(this.beanDefinition, this.owner), new ReplaceOverrideMethodInterceptor(this.beanDefinition, this.owner)}); return instance; } 调用 createEnhancedSubclass() 为提供的 BeanDefinition 创建 bean 类的增强子类。 private Class&lt;?> createEnhancedSubclass(RootBeanDefinition beanDefinition) { // cglib里面的用法，对原始class进行增强，并设置callback Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(beanDefinition.getBeanClass()); enhancer.setNamingPolicy(SpringNamingPolicy.INSTANCE); if (this.owner instanceof ConfigurableBeanFactory) { ClassLoader cl = ((ConfigurableBeanFactory) this.owner).getBeanClassLoader(); enhancer.setStrategy(new ClassLoaderAwareGeneratorStrategy(cl)); } // 过滤，自定义逻辑来指定调用的callback下标 enhancer.setCallbackFilter(new MethodOverrideCallbackFilter(beanDefinition)); enhancer.setCallbackTypes(CALLBACK_TYPES); return enhancer.createClass(); } 获取子类增强 class 后，如果 Constructor 实例 ctr 为空，则调用默认构造函数（BeanUtils.instantiateClass()）来实例化类，否则则根据构造函数类型获取具体的构造器，调用 newInstance() 实例化类。在 createEnhancedSubclass() 我们注意两行代码： enhancer.setCallbackFilter(new MethodOverrideCallbackFilter(beanDefinition)); enhancer.setCallbackTypes(CALLBACK_TYPES); 通过 MethodOverrideCallbackFilter 来定义调用 callback 类型，MethodOverrideCallbackFilter 是用来定义 CGLIB 回调过滤方法的拦截器行为，它继承 CglibIdentitySupport 实现 CallbackFilter 接口， CallbackFilter 是 CGLIB 的一个回调过滤器，CglibIdentitySupport 则为 CGLIB 提供 hashCode() 和 equals() 方法，以确保 CGLIB 不会为每个 bean 生成不同的类。MethodOverrideCallbackFilter 实现 CallbackFilter accept()： public int accept(Method method) { MethodOverride methodOverride = getBeanDefinition().getMethodOverrides().getOverride(method); if (logger.isTraceEnabled()) { logger.trace(\"Override for '\" + method.getName() + \"' is [\" + methodOverride + \"]\"); } if (methodOverride == null) { return PASSTHROUGH; } else if (methodOverride instanceof LookupOverride) { return LOOKUP_OVERRIDE; } else if (methodOverride instanceof ReplaceOverride) { return METHOD_REPLACER; } throw new UnsupportedOperationException(\"Unexpected MethodOverride subclass: \" + methodOverride.getClass().getName()); } 根据 BeanDefinition 中定义的 MethodOverride 不同，返回不同的值， 这里返回的 PASSTHROUGH 、LOOKUP_OVERRIDE、METHOD_REPLACER 都是 Callbak 数组的下标，这里对应的数组为 CALLBACK_TYPES 数组，如下： private static final Class&lt;?>[] CALLBACK_TYPES = new Class&lt;?>[] {NoOp.class, LookupOverrideMethodInterceptor.class, ReplaceOverrideMethodInterceptor.class}; 这里又定义了两个熟悉的拦截器 ：LookupOverrideMethodInterceptor 和 ReplaceOverrideMethodInterceptor，两个拦截器分别对应两个不同的 callback 业务： LookupOverrideMethodInterceptor private static class LookupOverrideMethodInterceptor extends CglibIdentitySupport implements MethodInterceptor { private final BeanFactory owner; public LookupOverrideMethodInterceptor(RootBeanDefinition beanDefinition, BeanFactory owner) { super(beanDefinition); this.owner = owner; } @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy mp) throws Throwable { // Cast is safe, as CallbackFilter filters are used selectively. LookupOverride lo = (LookupOverride) getBeanDefinition().getMethodOverrides().getOverride(method); Assert.state(lo != null, \"LookupOverride not found\"); Object[] argsToUse = (args.length > 0 ? args : null); // if no-arg, don't insist on args at all if (StringUtils.hasText(lo.getBeanName())) { return (argsToUse != null ? this.owner.getBean(lo.getBeanName(), argsToUse) : this.owner.getBean(lo.getBeanName())); } else { return (argsToUse != null ? this.owner.getBean(method.getReturnType(), argsToUse) : this.owner.getBean(method.getReturnType())); } } } ReplaceOverrideMethodInterceptor private static class ReplaceOverrideMethodInterceptor extends CglibIdentitySupport implements MethodInterceptor { private final BeanFactory owner; public ReplaceOverrideMethodInterceptor(RootBeanDefinition beanDefinition, BeanFactory owner) { super(beanDefinition); this.owner = owner; } @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy mp) throws Throwable { ReplaceOverride ro = (ReplaceOverride) getBeanDefinition().getMethodOverrides().getOverride(method); Assert.state(ro != null, \"ReplaceOverride not found\"); // TODO could cache if a singleton for minor performance optimization MethodReplacer mr = this.owner.getBean(ro.getMethodReplacerBeanName(), MethodReplacer.class); return mr.reimplement(obj, method, args); } } 通过这两个拦截器，再加上这篇博客：IOC 之解析 bean 标签：meta、lookup-method、replace-method，是不是一道绝佳的美食。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之分析BeanWrapper","date":"2020-01-24T09:45:53.000Z","path":"2020/01/24/fcc18cc7.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=4020 在学习Spring源码的过程中发现的好站+好贴，原创不易感谢作者。 Spring版本：Spring 5.0.6.RELEASE 在实例化 bean 阶段，我们从 BeanDefinition 得到的并不是我们最终想要的 Bean 实例，而是 BeanWrapper 实例，如下： 所以这里 BeanWrapper 是一个从 BeanDefinition 到 Bean 直接的中间产物，我们可以称它为”低级 bean“，在一般情况下，我们不会在实际项目中用到它。 BeanWrapper 是 Spring 框架中重要的组件类，它就相当于一个代理类，Spring 委托 BeanWrapper 完成 Bean 属性的填充工作。 在 bean 实例被 InstantiatioonStrategy 创建出来后，Spring 容器会将 Bean 实例通过 BeanWrapper 包裹起来，是通过 BeanWrapper.setWrappedInstance() 完成的，如下： beanInstance 就是我们实例出来的 bean 实例，通过构造一个 BeanWrapper 实例对象进行包裹，如下： public BeanWrapperImpl(Object object) { super(object); } protected AbstractNestablePropertyAccessor(Object object) { registerDefaultEditors(); setWrappedInstance(object); } 下面小编就 BeanWrapper 来进行分析说明，先看整体的结构： 从上图可以看出 BeanWrapper 主要继承三个核心接口：PropertyAccessor、PropertyEditorRegistry、TypeConverter。 PropertyAccessor 可以访问属性的通用型接口（例如对象的 bean 属性或者对象中的字段），作为 BeanWrapper 的基础接口。 public interface PropertyAccessor { String NESTED_PROPERTY_SEPARATOR = \".\"; char NESTED_PROPERTY_SEPARATOR_CHAR = '.'; String PROPERTY_KEY_PREFIX = \"[\"; char PROPERTY_KEY_PREFIX_CHAR = '['; String PROPERTY_KEY_SUFFIX = \"]\"; char PROPERTY_KEY_SUFFIX_CHAR = ']'; boolean isReadableProperty(String propertyName); boolean isWritableProperty(String propertyName); Class&lt;?> getPropertyType(String propertyName) throws BeansException; TypeDescriptor getPropertyTypeDescriptor(String propertyName) throws BeansException; Object getPropertyValue(String propertyName) throws BeansException; void setPropertyValue(String propertyName, @Nullable Object value) throws BeansException; void setPropertyValue(PropertyValue pv) throws BeansException; void setPropertyValues(Map&lt;?, ?> map) throws BeansException; void setPropertyValues(PropertyValues pvs) throws BeansException; void setPropertyValues(PropertyValues pvs, boolean ignoreUnknown) throws BeansException; void setPropertyValues(PropertyValues pvs, boolean ignoreUnknown, boolean ignoreInvalid) throws BeansException; } 就上面的源码我们可以分解为四类方法： isReadableProperty()：判断指定 property 是否可读，是否包含 getter 方法 isWritableProperty()：判断指定 property 是否可写,是否包含 setter 方法 getPropertyType()：获取指定 propertyName 的类型 setPropertyValue()：设置指定 propertyValue PropertyEditorRegistry 用于注册 JavaBean 的 PropertyEditors，对 PropertyEditorRegistrar 起核心作用的中心接口。由 BeanWrapper 扩展，BeanWrapperImpl 和 DataBinder 实现。 public interface PropertyEditorRegistry { void registerCustomEditor(Class&lt;?> requiredType, PropertyEditor propertyEditor); void registerCustomEditor(@Nullable Class&lt;?> requiredType, @Nullable String propertyPath, PropertyEditor propertyEditor); @Nullable PropertyEditor findCustomEditor(@Nullable Class&lt;?> requiredType, @Nullable String propertyPath); } 根据接口提供的方法，PropertyEditorRegistry 就是用于 PropertyEditor 的注册和发现，而 PropertyEditor 是 Java 内省里面的接口，用于改变指定 property 属性的类型。 TypeConverter 定义类型转换的接口，通常与 PropertyEditorRegistry 接口一起实现（但不是必须），但由于 TypeConverter 是基于线程不安全的 PropertyEditors ，因此 TypeConverters 本身也不被视为线程安全。 这里小编解释下，在 Spring 3 后，不在采用 PropertyEditors 类作为 Spring 默认的类型转换接口，而是采用 ConversionService 体系，但 ConversionService 是线程安全的，所以在 Spring 3 后，如果你所选择的类型转换器是 ConversionService 而不是 PropertyEditors 那么 TypeConverters 则是线程安全的。 public interface TypeConverter { &lt;T> T convertIfNecessary(Object value, Class&lt;T> requiredType) throws TypeMismatchException; &lt;T> T convertIfNecessary(Object value, Class&lt;T> requiredType, MethodParameter methodParam) throws TypeMismatchException; &lt;T> T convertIfNecessary(Object value, Class&lt;T> requiredType, Field field) throws TypeMismatchException; } BeanWrapper 继承上述三个接口，那么它就具有三重身份： 属性编辑器 属性编辑器注册表 类型转换器 BeanWrapper 继承 ConfigurablePropertyAccessor 接口，该接口除了继承上面介绍的三个接口外还集成了 Spring 的 ConversionService 类型转换体系。 public interface ConfigurablePropertyAccessor extends PropertyAccessor, PropertyEditorRegistry, TypeConverter { void setConversionService(@Nullable ConversionService conversionService); @Nullable ConversionService getConversionService(); void setExtractOldValueForEditor(boolean extractOldValueForEditor); boolean isExtractOldValueForEditor(); void setAutoGrowNestedPaths(boolean autoGrowNestedPaths); boolean isAutoGrowNestedPaths(); } setConversionService() 和 getConversionService() 则是用于集成 Spring 的 ConversionService 类型转换体系。 BeanWrapper Spring 的 低级 JavaBean 基础结构的接口，一般不会直接使用，而是通过 BeanFactory 或者 DataBinder 隐式使用。它提供分析和操作标准 JavaBeans 的操作：获取和设置属性值、获取属性描述符以及查询属性的可读性/可写性的能力。 public interface BeanWrapper extends ConfigurablePropertyAccessor { void setAutoGrowCollectionLimit(int autoGrowCollectionLimit); int getAutoGrowCollectionLimit(); Object getWrappedInstance(); Class&lt;?> getWrappedClass(); PropertyDescriptor[] getPropertyDescriptors(); PropertyDescriptor getPropertyDescriptor(String propertyName) throws InvalidPropertyException; } 下面几个方法比较重要： 个对象有4个方法比较重要: getWrappedInstance()：获取包装对象的实例。 getWrappedClass()：获取包装对象的类型。 getPropertyDescriptors()：获取包装对象所有属性的 PropertyDescriptor 就是这个属性的上下文。 getPropertyDescriptor()：获取包装对象指定属性的上下文。 BeanWrapperImpl BeanWrapper 接口的默认实现，用于对Bean的包装，实现上面接口所定义的功能很简单包括设置获取被包装的对象，获取被包装bean的属性描述器 BeanWrapper 体系相比于 Spring 中其他体系是比较简单的，它作为 BeanDefinition 向 Bean 转换过程中的中间产物，承载了 bean 实例的包装、类型转换、属性的设置以及访问等重要作用。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之自定义类型转换器","date":"2020-01-24T06:34:54.000Z","path":"2020/01/24/10825e64.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=3985 在学习Spring源码的过程中发现的好站+好贴，原创不易感谢作者。 Spring版本：Spring 5.0.6.RELEASE 在上篇文章中分析了 Spring ConversionService 类型转换体系，这篇博客将利用 ConversionService 体系来实现自己的类型转换器。 ConversionService 是 Spring 类型转换器体系中的核心接口，它定义了是否可以完成转换（canConvert()） 与 类型转换（convert()）两类接口。 ConversionService 有三个子类，每个子类针对不同的类型转换： Converter&lt;S,T&gt;: 将 S 类型对象转为 T 类型对象。 GenericConverter: 会根据源类对象及目标类对象所在的宿主类中的上下文信息进行类型转换。 ConverterFactory: 将相同系列多个 “同质” Converter 封装在一起。 如果希望将一种类型的对象转换为另一种类型及其子类的对象(例如将 String 转换为 Number 及 Number 子类(Integer、Long、Double 等)对象)可使用该转换器工厂类。 如何自定义类型转换器？分两步走： 实现 Converter / GenericConverter / ConverterFactory 接口 将该类注册到 ConversionServiceFactoryBean 中。 ConversionServiceFactoryBean 实现了 InitializingBean 接口实现 afterPropertiesSet() ，我们知道在 Bean 实例化 bean 阶段，Spring 容器会检查当前 bean 是否实现了 InitializingBean 接口，如果是则执行相应的初始化方法。（关于 InitializingBean 详情请参考： IOC 之 深入分析 InitializingBean 和 init-method）。 afterPropertiesSet() 源码如下： public void afterPropertiesSet() { this.conversionService = createConversionService(); ConversionServiceFactory.registerConverters(this.converters, this.conversionService); } 首先调用 createConversionService() 初始化 conversionService 然后调用 ConversionServiceFactory.registerConverters() 将定义的 converters 注入到类型转换体系中。createConversionService() 其实就是创建一个 DefaultConversionService 实例对象，对于 DefaultConversionService 在上篇博客已经分析了，如有不了解的请移步上篇博文。这里直接分析 ConversionServiceFactory.registerConverters()，该方法是将定义的 converter 注册到目标 ConverterRegistry 中，我们知道 ConverterRegistry 是一个 Converter 注册器，他定义了一系列注册方法。 public static void registerConverters(@Nullable Set&lt;?> converters, ConverterRegistry registry) { if (converters != null) { for (Object converter : converters) { if (converter instanceof GenericConverter) { registry.addConverter((GenericConverter) converter); } else if (converter instanceof Converter&lt;?, ?>) { registry.addConverter((Converter&lt;?, ?>) converter); } else if (converter instanceof ConverterFactory&lt;?, ?>) { registry.addConverterFactory((ConverterFactory&lt;?, ?>) converter); } else { throw new IllegalArgumentException(\"Each converter object must implement one of the \" + \"Converter, ConverterFactory, or GenericConverter interfaces\"); } } } } 调用 ConverterRegistry 的 addConverter() 方法将转换器注册到容器中。所以在我们使用 Spring 容器的时候，Spring 将会自动识别出 IOC 容器中注册的 ConversionService 并且在 bean 属性注入阶段使用自定义的转换器完成属性的转换了。 实例定义 StudentConversionService 转换器： public class StudentConversionService implements Converter&lt;String,StudentService>{ @Override public StudentService convert(String source) { if(StringUtils.hasLength(source)){ String[] sources = source.split(\"#\"); StudentService studentService = new StudentService(); studentService.setAge(Integer.parseInt(sources[0])); studentService.setName(sources[1]); return studentService; } return null; } } 配置： &lt;bean id=\"conversionService\" class=\"org.springframework.context.support.ConversionServiceFactoryBean\"> &lt;property name=\"converters\"> &lt;set> &lt;ref bean=\"studentConversionService\"/> &lt;/set> &lt;/property> &lt;/bean> &lt;bean id=\"studentConversionService\" class=\"org.springframework.core.conversion.StudentConversionService\"/> &lt;bean id=\"student\" class=\"org.springframework.core.conversion.Student\"> &lt;property name=\"studentService\" value=\"18#chenssy\"/> &lt;/bean>","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之深入分析Bean的类型转换体系","date":"2020-01-24T01:38:37.000Z","path":"2020/01/24/683bb448.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=3983 在学习Spring源码的过程中发现的好站+好贴，原创不易感谢作者。 Spring版本：Spring 5.0.6.RELEASE 我们知道不管 bean 对象里面的属性时什么类型，他们都是通过 XML 、Properties 或者其他方式来配置这些属性对象类型的。在 Spring 容器加载过程中，这些属性都是以 String 类型加载进容器的，但是最终都需要将这些 String 类型的属性转换 Bean 对象属性所对应真正的类型，要想完成这种由字符串到具体对象的转换，就需要这种转换规则相关的信息，而这些信息以及转换过程由 Spring 类型转换体系来完成。 我们依然以 xml 为例，在 Spring 容器加载阶段，容器将 xml 文件中定义的 &lt;bean&gt; 解析为 BeanDefinition，BeanDefinition 中存储着我们定义一个 bean 需要的所有信息，包括属性，这些属性是以 String 类型的存储的。 当用户触发 Bean 实例化阶段时，Spring 容器会将这些属性转换为这些属性真正对应的类型。我们知道在 bean 实例化阶段，属性的注入是在实例化 bean 阶段的属性注入阶段，即 populateBean() 方法。在 populateBean() 中会将 BeanDefinition 中定义的属性值翻译为 PropertyValue 然后调用 applyPropertyValues() 进行属性应用。其中 PropertyValue 用于保存单个 bean 属性的信息和值的对象。在 applyPropertyValues() 中会调用 convertForProperty() 进行属性转换，如下： private Object convertForProperty( @Nullable Object value, String propertyName, BeanWrapper bw, TypeConverter converter) { if (converter instanceof BeanWrapperImpl) { return ((BeanWrapperImpl) converter).convertForProperty(value, propertyName); } else { PropertyDescriptor pd = bw.getPropertyDescriptor(propertyName); MethodParameter methodParam = BeanUtils.getWriteMethodParameter(pd); return converter.convertIfNecessary(value, pd.getPropertyType(), methodParam); } } 若 TypeConverter 为 BeanWrapperImpl 类型，则使用 BeanWrapperImpl 来进行类型转换，这里主要是因为 BeanWrapperImpl 实现了 PropertyEditorRegistry 接口。否则则调用 TypeConverter 的 convertIfNecessary() 进行类型转换。TypeConverter 是定义类型转换方法的接口，通常情况下与 PropertyEditorRegistry 配合使用实现类型转换。 convertIfNecessary() 的实现者有两个：DataBinder 和 TypeConverterSupport ，其中 DataBinder 主要用于参数绑定（熟悉 Spring MVC 的都应该知道这个类），TypeConverterSupport 则是 TypeConverter 的基本实现，使用的是 package-private 策略。 所以这里我们只需要关注 TypeConverterSupport 的 convertIfNecessary()，如下： public &lt;T> T convertIfNecessary(@Nullable Object value, @Nullable Class&lt;T> requiredType, @Nullable MethodParameter methodParam) throws TypeMismatchException { return doConvert(value, requiredType, methodParam, null); } private &lt;T> T doConvert(@Nullable Object value,@Nullable Class&lt;T> requiredType, @Nullable MethodParameter methodParam, @Nullable Field field) throws TypeMismatchException { Assert.state(this.typeConverterDelegate != null, \"No TypeConverterDelegate\"); try { if (field != null) { return this.typeConverterDelegate.convertIfNecessary(value, requiredType, field); } else { return this.typeConverterDelegate.convertIfNecessary(value, requiredType, methodParam); } } catch (ConverterNotFoundException | IllegalStateException ex) { throw new ConversionNotSupportedException(value, requiredType, ex); } catch (ConversionException | IllegalArgumentException ex) { throw new TypeMismatchException(value, requiredType, ex); } } 我们一直往下跟会跟踪到 TypeConverterDelegate 的 convertIfNecessary() ，会发现如下代码段： 如果没有自定义的编辑器则使用 ConversionService 。ConversionService 是 Spring 自 3 后推出来用来替代 PropertyEditor 转换模式的转换体系，接口定义如下： public interface ConversionService { boolean canConvert(@Nullable Class&lt;?> sourceType, Class&lt;?> targetType); boolean canConvert(@Nullable TypeDescriptor sourceType, TypeDescriptor targetType); @Nullable &lt;T> T convert(@Nullable Object source, Class&lt;T> targetType); @Nullable Object convert(@Nullable Object source, @Nullable TypeDescriptor sourceType, TypeDescriptor targetType); } 其 UML 类图如下： ConfigurableConversionService：ConversionService 的配置接口，继承 ConversionService 和 ConverterRegistry 两个接口，用于合并他们两者的操作，以便于通过 add 和 remove 的方式添加和删除转换器。 GenericConversionService：ConversionService 接口的基础实现，适用于大部分条件下的转换工作，通过 ConfigurableConversionService 接口间接地将 ConverterRegistry 实现为注册 API 。 DefaultConversionService：ConversionService 接口的默认实现，适用于大部分条件下的转换工作。 回归到 convertIfNecessary()，在该方法中如果没有自定义的属性编辑器则调用 ConversionService 接口的 convert()，方法定义如下： Object convert(@Nullable Object source, @Nullable TypeDescriptor sourceType, TypeDescriptor targetType); source：要转换的源对象，可以为 null sourceType：source 的类型的上下文，如果 source 为 null，则可以为 null targetType：source 要转换的类型的上下文。 convert() 将给定的源对象 source 转换为指定的 targetType。 TypeDescriptors 提供有关发生转换的源位置和目标位置的附加上下文，通常是对象字段或属性位置。方法由子类 GenericConversionService 实现： public Object convert(@Nullable Object source, @Nullable TypeDescriptor sourceType, TypeDescriptor targetType) { // 删掉 if ，其实就是上面的 null 判断 GenericConverter converter = getConverter(sourceType, targetType); if (converter != null) { Object result = ConversionUtils.invokeConverter(converter, source, sourceType, targetType); return handleResult(sourceType, targetType, result); } return handleConverterNotFound(source, sourceType, targetType); } 首先根据 sourceType 和 targetType 调用 getConverter() 获取 GenericConverter 对象 converter ，如果 converter 为 null，则调用 handleConverterNotFound()，否则调用 handleResult() 方法。getConverter() 如下： protected GenericConverter getConverter(TypeDescriptor sourceType, TypeDescriptor targetType) { ConverterCacheKey key = new ConverterCacheKey(sourceType, targetType); GenericConverter converter = this.converterCache.get(key); if (converter != null) { return (converter != NO_MATCH ? converter : null); } converter = this.converters.find(sourceType, targetType); if (converter == null) { converter = getDefaultConverter(sourceType, targetType); } if (converter != null) { this.converterCache.put(key, converter); return converter; } this.converterCache.put(key, NO_MATCH); return null; } 这段代码意图非常明确，从 converterCache 缓存中获取，如果存在返回，否则从 converters 中获取，然后加入到 converterCache 缓存中。converterCache 和 converters 是 GenericConversionService 维护的两个很重要的对象，其中 converterCache 用于存储 GenericConverter ，converters 对象为 GenericConversionService 的内部类。 private final Converters converters = new Converters(); private final Map&lt;ConverterCacheKey, GenericConverter> converterCache = new ConcurrentReferenceHashMap&lt;>(64); Converters 用于管理所有注册的转换器，其内部维护一个 Set 和 Map 的数据结构用于管理转换器，如下： private final Set&lt;GenericConverter> globalConverters = new LinkedHashSet&lt;>(); private final Map&lt;ConvertiblePair, ConvertersForPair> converters = new LinkedHashMap&lt;>(36); 同时提供了相应的方法（如 add、remove）操作这两个集合。在 getConverter() 中如果缓存 converterCache 中 不存在，则调用 Converters 对象的 find() 方法获取相应的 GenericConverter，如下： public GenericConverter find(TypeDescriptor sourceType, TypeDescriptor targetType) { // Search the full type hierarchy List&lt;Class&lt;?>> sourceCandidates = getClassHierarchy(sourceType.getType()); List&lt;Class&lt;?>> targetCandidates = getClassHierarchy(targetType.getType()); for (Class&lt;?> sourceCandidate : sourceCandidates) { for (Class&lt;?> targetCandidate : targetCandidates) { ConvertiblePair convertiblePair = new ConvertiblePair(sourceCandidate, targetCandidate); GenericConverter converter = getRegisteredConverter(sourceType, targetType, convertiblePair); if (converter != null) { return converter; } } } return null; } private GenericConverter getRegisteredConverter(TypeDescriptor sourceType, TypeDescriptor targetType, ConvertiblePair convertiblePair) { // Check specifically registered converters ConvertersForPair convertersForPair = this.converters.get(convertiblePair); if (convertersForPair != null) { GenericConverter converter = convertersForPair.getConverter(sourceType, targetType); if (converter != null) { return converter; } } // Check ConditionalConverters for a dynamic match for (GenericConverter globalConverter : this.globalConverters) { if (((ConditionalConverter) globalConverter).matches(sourceType, targetType)) { return globalConverter; } } return null; } 在 find() 中会根据 sourceType 和 targetType 去查询 Converters 中维护的 Map 中是否包括支持的注册类型，如果存在返回 GenericConverter ，如果没有存在返回 null。 当得到 GenericConverter 后，则调用其 convert() 进行类型转换。 Object convert(@Nullable Object source, TypeDescriptor sourceType, TypeDescriptor targetType); 到这里我们就可以得到 bean 属性定义的真正类型了。 GenericConverter 接口 GenericConverter 是一个转换接口，一个用于在两种或更多种类型之间转换的通用型转换器接口。它是 Converter SPI 体系中最灵活的，也是最复杂的接口，灵活性在于 GenericConverter 可以支持在多个源/目标类型对之间进行转换，同时也可以在类型转换过程中访问源/目标字段上下文。由于该接口足够复杂，所有当更简单的 Converter 或 ConverterFactory 接口足够使用时，通常不应使用此接口。其定义如下： public interface GenericConverter { @Nullable Set&lt;ConvertiblePair> getConvertibleTypes(); @Nullable Object convert(@Nullable Object source, TypeDescriptor sourceType, TypeDescriptor targetType); } GenericConverter 的子类有这么多（看类名就知道是干嘛的了）： 我们看一个子类的实现 StringToArrayConverter，该子类将逗号分隔的 String 转换为 Array。如下： public Object convert(@Nullable Object source, TypeDescriptor sourceType, TypeDescriptor targetType) { if (source == null) { return null; } String string = (String) source; String[] fields = StringUtils.commaDelimitedListToStringArray(string); TypeDescriptor targetElementType = targetType.getElementTypeDescriptor(); Assert.state(targetElementType != null, \"No target element type\"); Object target = Array.newInstance(targetElementType.getType(), fields.length); for (int i = 0; i &lt; fields.length; i++) { String sourceElement = fields[i]; Object targetElement = this.conversionService.convert(sourceElement.trim(), sourceType, targetElementType); Array.set(target, i, targetElement); } return target; } 在类型转换体系中，Spring 提供了非常多的类型转换器，除了上面的 GenericConverter，还有 Converter、ConditionalConverter、ConverterFactory。 Converter Converter 是一个将 S 类型的源对象转换为 T 类型的目标对象的转换器。该接口是线程安全的，所以可以共享。 public interface Converter&lt;S, T> { @Nullable T convert(S source); } 子类如下： ConditionalConverter ConditionalConverter 接口用于表示有条件的类型转换，通过转入的sourceType 与 targetType 判断转换能否匹配，只有可匹配的转换才会调用convert 方法进行转换，如下： public interface ConditionalConverter { boolean matches(TypeDescriptor sourceType, TypeDescriptor targetType); }ConditionalConverter 的子类如下： ConverterFactory 一个用于“远程”转换的转换工厂，可以将对象从 S 转换为 R 的子类型。 public interface ConverterFactory&lt;S, R> { &lt;T extends R> Converter&lt;S, T> getConverter(Class&lt;T> targetType); } 子类如下： 四种不同的转换器承载着不同的转换过程： Converter：用于 1:1 的 source -&gt; target 类型转换 ConverterFactory：用于 1:N 的 source -&gt; target 类型转换 GenericConverter用于 N:N 的 source -&gt; target 类型转换 ConditionalConverter：有条件的 source -&gt; target 类型转换 GenericConversionService 转换器介绍完了，我们再次回归到 ConversionService 接口中去，该接口定义了两类方法 canConvert() 和 convert()，其中 canConvert() 用于判 sourceType 能否转成 targetType ,而 convert() 用于将 source 转成转入的 TargetType 类型实例。这两类方法都是在 GenericConversionService 中实现。类 GenericConversionService 实现 ConfigurableConversionService 接口，而 ConfigurableConversionService 接口继承 ConversionService 和 ConverterRegistry。ConverterRegistry 提供了类型转换器的管理功能，他提供了四个 add 和 一个 remove 方法，支持注册/删除相应的类型转换器。GenericConversionService 作为一个基础实现类，它即支持了不同类型之间的转换，也对各类型转换器进行管理，主要是通过一个 Map 类型的 converterCache 和一个内部类 Converters。在上面已经分析了 GenericConversionService 执行类型转换的过程 cover()，下面我们就一个 addConverter() 来看看它是如何完成转换器的注入工作的。 public void addConverter(Converter&lt;?, ?> converter) { ResolvableType[] typeInfo = getRequiredTypeInfo(converter.getClass(), Converter.class); if (typeInfo == null &amp;&amp; converter instanceof DecoratingProxy) { typeInfo = getRequiredTypeInfo(((DecoratingProxy) converter).getDecoratedClass(), Converter.class); } if (typeInfo == null) { throw new IllegalArgumentException(\"Unable to determine source type &lt;S> and target type &lt;T> for your \" + \"Converter [\" + converter.getClass().getName() + \"]; does the class parameterize those types?\"); } addConverter(new ConverterAdapter(converter, typeInfo[0], typeInfo[1])); } 首先根据 converter 获取 ResolvableType，然后将其与 converter 封装成一个 ConverterAdapter 实例，最后调用 addConverter()。ResolvableType 用于封装 Java 的类型。ConverterAdapter 则是 Converter 的一个适配器， 它实现了 GenericConverter 和 ConditionalConverter 两个类型转换器。 addConverter() 如下： public void addConverter(GenericConverter converter) { this.converters.add(converter); invalidateCache(); } 直接调用内部类 Converters 的 add() 方法，如下： public void add(GenericConverter converter) { Set&lt;ConvertiblePair> convertibleTypes = converter.getConvertibleTypes(); if (convertibleTypes == null) { Assert.state(converter instanceof ConditionalConverter, \"Only conditional converters may return null convertible types\"); this.globalConverters.add(converter); } else { for (ConvertiblePair convertiblePair : convertibleTypes) { ConvertersForPair convertersForPair = getMatchableConverters(convertiblePair); convertersForPair.add(converter); } } } 首先调用 getConvertibleTypes() 获取 ConvertiblePair 集合，如果为空，则加入到 globalConverters 集合中，否则通过迭代的方式依次添加。ConvertiblePair 为 source-to-targer 的持有者，它持有 source 和 target 的 class 类型，如下： final class ConvertiblePair { private final Class&lt;?> sourceType; private final Class&lt;?> targetType; // 其他代码 } 在迭代过程中会根据 ConvertiblePair 获取相应的 ConvertersForPair ，然后 converter 转换器加入其中，ConvertiblePair 用于管理使用特定GenericConverter.ConvertiblePair 注册的转换器。如下： private static class ConvertersForPair { private final LinkedList&lt;GenericConverter> converters = new LinkedList&lt;>(); public void add(GenericConverter converter) { this.converters.addFirst(converter); } @Nullable public GenericConverter getConverter(TypeDescriptor sourceType, TypeDescriptor targetType) { for (GenericConverter converter : this.converters) { if (!(converter instanceof ConditionalGenericConverter) || ((ConditionalGenericConverter) converter).matches(sourceType, targetType)) { return converter; } } return null; } } 其实内部就是维护一个 LinkedList 集合。他内部有两个方法：add() 和 getConverter()，实现较为简单，这里就不多介绍了。 DefaultConversionService DefaultConversionService 是 ConversionService 的默认实现，它继承 GenericConversionService，GenericConversionService 主要用于转换器的注册和调用，DefaultConversionService 则是为 ConversionService 体系提供一些默认的转换器。在 DefaultConversionService 构造方法中就会添加默认的 Converter ，如下： public DefaultConversionService() { addDefaultConverters(this); } public static void addDefaultConverters(ConverterRegistry converterRegistry) { addScalarConverters(converterRegistry); addCollectionConverters(converterRegistry); converterRegistry.addConverter(new ByteBufferConverter((ConversionService) converterRegistry)); if (jsr310Available) { Jsr310ConverterRegistrar.registerJsr310Converters(converterRegistry); } converterRegistry.addConverter(new ObjectToObjectConverter()); converterRegistry.addConverter(new IdToEntityConverter((ConversionService) converterRegistry)); converterRegistry.addConverter(new FallbackObjectToStringConverter()); if (javaUtilOptionalClassAvailable) { converterRegistry.addConverter(new ObjectToOptionalConverter((ConversionService) converterRegistry)); } } 当然它还提供了一些其他的方法如 addCollectionConverters()、addScalarConverters() 用于注册其他类型的转换器。 至此，从 bean 属性的转换，到 Spring ConversionService 体系的转换器 Converter 以及转换器的管理都介绍完毕了。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之深入分析PropertyOverrideConfigurer","date":"2020-01-24T01:26:38.000Z","path":"2020/01/24/e5d90f02.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=3924 在学习Spring源码的过程中发现的好站+好贴，原创不易感谢作者。 Spring版本：Spring 5.0.6.RELEASE 在文章 IOC 之 深入分析 BeanFactoryPostProcessor 中提到，BeanFactoryPostProcessor 作用与 bean 完成加载之后与 bean 实例化之前，是 Spring 提供的一种强大的扩展机制，他有两个重要的子类，一个是 PropertyPlaceholderConfigurer，另一个是 PropertyOverrideConfigurer ，其中 PropertyPlaceholderConfigurer 允许我们通过配置 Properties 的方式来取代 bean 中定义的占位符，而 PropertyOverrideConfigurer 呢？正是我们这篇博客介绍的。 PropertyOverrideConfigurer 允许我们对 Spring 容器中配置的任何我们想处理的 bean 定义的 property 信息进行覆盖替换。 这个定义听起来有点儿玄乎，通俗点说就是我们可以通过 PropertyOverrideConfigurer 来覆盖任何 bean 中的任何属性，只要我们想。 PropertyOverrideConfigurer 的使用规则是 beanName.propertyName=value，这里需要注意的是 beanName，propertyName 则是该 bean 中存在的属性。 使用依然使用以前的例子，Student.class，我们只需要修改下配置文件，声明下 PropertyOverrideConfigurer 以及其加载的配置文件。如下： &lt;bean class=\"org.springframework.beans.factory.config.PropertyOverrideConfigurer\"> &lt;property name=\"locations\"> &lt;list> &lt;value>classpath:application.properties&lt;/value> &lt;/list> &lt;/property> &lt;/bean> &lt;bean id=\"student\" class=\"org.springframework.core.service.StudentService\"> &lt;property name=\"name\" value=\"chenssy\"/> &lt;/bean> 指定 student 的 name 属性值为 chenssy，声明 PropertyOverrideConfigurer 加载的文件为 application.properties，内容如下： student.name = chenssy-PropertyOverrideConfigurer 指定 beanName 为 student 的 bean 的 name 属性值为 chenssy-PropertyOverrideConfigurer。 测试打印 student 中的 name 属性值，如下： ApplicationContext context = new ClassPathXmlApplicationContext(\"spring.xml\"); StudentService studentService = (StudentService) context.getBean(\"student\"); System.out.println(\"student name:\" + studentService.getName()); 运行结果为： 从中可以看出 PropertyOverrideConfigurer 定义的文件取代了 bean 中默认的值。 下面我们看一个有趣的例子，如果我们一个 bean 中 PropertyPlaceholderConfigurer 和 PropertyOverrideConfigurer 都使用呢？那是显示谁定义的值呢？ 这里先简单分析下：如果PropertyOverrideConfigurer 先作用，那么 PropertyPlaceholderConfigurer 在匹配占位符的时候就找不到了，如果 PropertyOverrideConfigurer 后作用，也会直接取代 PropertyPlaceholderConfigurer 定义的值，所以无论如何都会显示 PropertyOverrideConfigurer 定义的值。 是不是这样呢？看如下例子： xml 配置文件调整如下： &lt;bean class=\"org.springframework.beans.factory.config.PropertyOverrideConfigurer\"> &lt;property name=\"locations\"> &lt;list> &lt;value>classpath:application1.properties&lt;/value> &lt;/list> &lt;/property> &lt;/bean> &lt;bean class=\"org.springframework.beans.factory.config.PropertyPlaceholderConfigurer\"> &lt;property name=\"locations\"> &lt;list> &lt;value>classpath:application2.properties&lt;/value> &lt;/list> &lt;/property> &lt;/bean> &lt;bean id=\"student\" class=\"org.springframework.core.service.StudentService\"> &lt;property name=\"name\" value=\"${studentService.name}\"/> &lt;/bean> 指定 PropertyPlaceholderConfigurer 加载文件为 application1.properties，PropertyPlaceholderConfigurer 加载文件为 application2.properties，student 的 name 属性使用占位符 ${studentService.name}。配置文件内容为： # application1.properties： student.name = chenssy-PropertyOverrideConfigurer # application2.properties： studentService.name = chenssy-PropertyPlaceholderConfigurer 测试程序依然是打印 name 属性值，运行结果如下： 所以，上面的分析没有错。 下面我们来分析 PropertyOverrideConfigurer 实现原理。其实如果了解 PropertyPlaceholderConfigurer 的实现机制的话，那么 PropertyOverrideConfigurer 也不难猜测：加载指定 Properties，迭代其中的属性值，依据 “.” 来得到 beanName（split(“.”)[0]），从容器中获取指定的 BeanDefinition，然后得到 name 属性，进行替换即可。 实现原理UML 结构图如下： 与 PropertyPlaceholderConfigurer 一样，也是继承 PropertyResourceConfigurer，我们知道 PropertyResourceConfigurer 对 BeanFactoryPostProcessor 的 postProcessBeanFactory() 提供了实现，在该实现中它会去读取指定配置文件中的内容，然后 processProperties() ，该方法是一个抽象方法，具体的实现由子类来实现，所以这里我们只需要看 PropertyOverrideConfigurer 中 processProperties() 中的具体实现，如下: protected void processProperties(ConfigurableListableBeanFactory beanFactory, Properties props) throws BeansException { // 迭代配置文件中的内容 for (Enumeration&lt;?> names = props.propertyNames(); names.hasMoreElements();) { String key = (String) names.nextElement(); try { processKey(beanFactory, key, props.getProperty(key)); } catch (BeansException ex) { String msg = \"Could not process key '\" + key + \"' in PropertyOverrideConfigurer\"; if (!this.ignoreInvalidKeys) { throw new BeanInitializationException(msg, ex); } if (logger.isDebugEnabled()) { logger.debug(msg, ex); } } } } 迭代 props 内容，依次调用 processKey()，如下: protected void processKey(ConfigurableListableBeanFactory factory, String key, String value) throws BeansException { // 判断是否存在 \".\" // 获取其索引位置 int separatorIndex = key.indexOf(this.beanNameSeparator); // 如果不存在，. 则抛出异常 if (separatorIndex == -1) { throw new BeanInitializationException(\"Invalid key '\" + key + \"': expected 'beanName\" + this.beanNameSeparator + \"property'\"); } // 得到 beanName String beanName = key.substring(0, separatorIndex); // 得到属性值 String beanProperty = key.substring(separatorIndex+1); this.beanNames.add(beanName); // 替换 applyPropertyValue(factory, beanName, beanProperty, value); if (logger.isDebugEnabled()) { logger.debug(\"Property '\" + key + \"' set to value [\" + value + \"]\"); } } 获取分割符 “.” 的索引位置，得到 beanName 以及相应的属性，然后调用 applyPropertyValue()，如下： protected void applyPropertyValue( ConfigurableListableBeanFactory factory, String beanName, String property, String value) { BeanDefinition bd = factory.getBeanDefinition(beanName); BeanDefinition bdToUse = bd; while (bd != null) { bdToUse = bd; bd = bd.getOriginatingBeanDefinition(); } PropertyValue pv = new PropertyValue(property, value); pv.setOptional(this.ignoreInvalidKeys); bdToUse.getPropertyValues().addPropertyValue(pv); } 从容器中获取 BeanDefinition ，然后根据属性 property 和 其值 value 构造成一个 PropertyValue 对象，最后调用 addPropertyValue() 方法。PropertyValue 是用于保存一组bean属性的信息和值的对像。 public MutablePropertyValues addPropertyValue(PropertyValue pv) { for (int i = 0; i &lt; this.propertyValueList.size(); i++) { PropertyValue currentPv = this.propertyValueList.get(i); if (currentPv.getName().equals(pv.getName())) { pv = mergeIfRequired(pv, currentPv); setPropertyValueAt(pv, i); return this; } } this.propertyValueList.add(pv); return this; } 添加 PropertyValue 对象，替换或者合并相同的属性值。整个过程其实与上面猜测相差不是很大。 至此，PropertyOverrideConfigurer 到这里也就分析完毕了。最后看下 PropertyPlaceholderConfigurer 和 PropertyOverrideConfigurer 整体的结构图：","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之PropertyPlaceholderConfigurer的应用","date":"2020-01-23T14:28:46.000Z","path":"2020/01/23/cd2eaad8.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=3839 在学习Spring源码的过程中发现的好站+好贴，原创不易感谢作者。 Spring版本：Spring 5.0.6.RELEASE 在博客 IOC 之 深入分析 PropertyPlaceholderConfigurer 中了解了 PropertyPlaceholderConfigurer 内部实现原理，她允许我们在 XML 配置文件中使用占位符并将这些占位符所代表的资源单独配置到简单的 properties 文件中来加载。 这个特性非常重要，因为它我们对 Bean 实例属性的配置变得非常容易控制了，主要使用场景有： 动态加载配置文件，多环境切换 属性加解密 下面我们就第一个应用场景来做说明。 利用 PropertyPlaceholderConfigurer 实现多环境切换 在我们项目开发过程中，都会存在多个环境，如 dev 、test 、prod 等等，各个环境的配置都会不一样，在传统的开发过程中我们都是在进行打包的时候进行人工干预，或者将配置文件放在系统外部，加载的时候指定加载目录，这种方式容易出错，那么有没有一种比较好的方式来解决这种情况呢？ 有，利用 PropertyPlaceholderConfigurer 的特性来动态加载配置文件，实现多环境切换。 首先我们定义四个 Properties 文件，如下： 内容如下： # application-dev.properties student.name=chenssy-dev # application-test.properties student.name=chenssy-test # application-prod.properties student.name=chenssy-prod 然后实现一个类，该类继承 PropertyPlaceholderConfigurer，实现 loadProperties()，根据环境的不同加载不同的配置文件，如下： public class CustomPropertyConfig extends PropertyPlaceholderConfigurer { private Resource[] locations; private PropertiesPersister propertiesPersister = new DefaultPropertiesPersister(); @Override public void setLocations(Resource[] locations) { this.locations = locations; } @Override public void setLocalOverride(boolean localOverride) { this.localOverride = localOverride; } /** * 覆盖这个方法，根据启动参数，动态读取配置文件 * @param props * @throws IOException */ @Override protected void loadProperties(Properties props) throws IOException { if (locations != null) { // locations 里面就已经包含了那三个定义的文件 for (Resource location : this.locations) { InputStream is = null; try { String filename = location.getFilename(); String env = \"application-\" + System.getProperty(\"spring.profiles.active\", \"dev\") + \".properties\"; // 找到我们需要的文件，加载 if (filename.contains(env)) { logger.info(\"Loading properties file from \" + location); is = location.getInputStream(); this.propertiesPersister.load(props, is); } } catch (IOException ex) { logger.info(\"读取配置文件失败.....\"); throw ex; } finally { if (is != null) { is.close(); } } } } } } 配置文件： &lt;bean id=\"PropertyPlaceholderConfigurer\" class=\"org.springframework.core.custom.CustomPropertyConfig\"> &lt;property name=\"locations\"> &lt;list> &lt;value>classpath:config/application-dev.properties&lt;/value> &lt;value>classpath:config/application-test.properties&lt;/value> &lt;value>classpath:config/application-prod.properties&lt;/value> &lt;/list> &lt;/property> &lt;/bean> &lt;bean id=\"studentService\" class=\"org.springframework.core.service.StudentService\"> &lt;property name=\"name\" value=\"${student.name}\"/> &lt;/bean> 在 idea 的 VM options 里面增加 -Dspring.profiles.active=dev，标志当前环境为 dev 环境。测试代码如下： ApplicationContext context = new ClassPathXmlApplicationContext(\"spring.xml\"); StudentService studentService = (StudentService) context.getBean(\"studentService\"); System.out.println(\"student name:\" + studentService.getName()); 运行结果： student name:chenssy-dev 当将 -Dspring.profiles.active 调整为 test，则打印结果则是 chenssy-test，这样就完全实现了根据不同的环境加载不同的配置，如果各位用过 Spring Boot 的话，这个就完全是 Spring Boot 里面的 profiles.active 。 可以看到，PropertyPlaceholderConfigurer 对于属性的配置非常灵活。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之深入分析PropertyPlaceholderConfigurer","date":"2020-01-23T14:22:02.000Z","path":"2020/01/23/99d35216.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=3837 在学习Spring源码的过程中发现的好站+好贴，原创不易感谢作者。 Spring版本：Spring 5.0.6.RELEASE 在上文 IOC 之 深入分析 BeanFactoryPostProcessor 介绍了 BeanFactoryPostProcessor，知道 BeanFactoryPostProcessor 作用域容器启动阶段，可以对解析好的 BeanDefinition 进行定制化处理，而其中 PropertyPlaceholderConfigurer 是其一个非常重要的应用，也是其子类，介绍如下： PropertyPlaceholderConfigurer 允许我们用 Properties 文件中的属性来定义应用上下文（配置文件或者注解） 什么意思，就是说我们在 XML 配置文件（或者其他方式，如注解方式）中使用占位符的方式来定义一些资源，并将这些占位符所代表的资源配置到 Properties 中，这样只需要对 Properties 文件进行修改即可，这个特性非常，在后面来介绍一种我们在项目中经常用到场景。 从 PropertyPlaceholderConfigurer 的结构图可以看出，它间接实现了 Aware 和 BeanFactoryPostProcessor 两大扩展接口，这里只需要关注 BeanFactoryPostProcessor 即可。 我们知道 BeanFactoryPostProcessor 提供了 postProcessBeanFactory()，在这个体系中该方法的是在 PropertyResourceConfigurer 中实现，该类为属性资源的配置类，他实现了 BeanFactoryPostProcessor 接口，如下： public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException { try { Properties mergedProps = mergeProperties(); // 转换合并属性 convertProperties(mergedProps); // 子类处理 processProperties(beanFactory, mergedProps); } catch (IOException ex) { throw new BeanInitializationException(\"Could not load properties\", ex); } } mergeProperties()：返回合并的 Properties 实例，Properties 实例维护这一组 key-value ，其实就是 Properties 配置文件中的内容。 convertProperties()：转换合并的值，其实就是将原始值替换为真正的值 processProperties()：前面两个步骤已经将配置文件中的值进行了处理，那么该方法就是真正的替换过程，该方法由子类实现。 在 PropertyPlaceholderConfigurer 重写 processProperties(): protected void processProperties(ConfigurableListableBeanFactory beanFactoryToProcess, Properties props) throws BeansException { StringValueResolver valueResolver = new PlaceholderResolvingStringValueResolver(props); doProcessProperties(beanFactoryToProcess, valueResolver); } 首先构造一个 PlaceholderResolvingStringValueResolver 类型的 StringValueResolver 实例。StringValueResolver 为一个解析 String 类型值的策略接口，该接口提供了 resolveStringValue() 方法用于解析 String 值。PlaceholderResolvingStringValueResolver 为其一个解析策略，构造方法如下： public PlaceholderResolvingStringValueResolver(Properties props) { this.helper = new PropertyPlaceholderHelper( placeholderPrefix, placeholderSuffix, valueSeparator, ignoreUnresolvablePlaceholders); this.resolver = new PropertyPlaceholderConfigurerResolver(props); } 在构造 String 值解析器 StringValueResolver 时，将已经解析的 Properties 实例对象封装在 PlaceholderResolver 实例 resolver 中。PlaceholderResolver 是一个用于解析字符串中包含占位符的替换值的策略接口，该接口有一个 resolvePlaceholder() 方法，用于返回占位符的替换值。还有一个 PropertyPlaceholderHelper 工具，从名字上面看应该是进行替换的。 得到 String 解析器的实例 valueResolver 后，则会调用 doProcessProperties() 方法来进行诊治的替换操作，该方法在父类 PlaceholderConfigurerSupport 中实现，如下： protected void doProcessProperties(ConfigurableListableBeanFactory beanFactoryToProcess, StringValueResolver valueResolver) { BeanDefinitionVisitor visitor = new BeanDefinitionVisitor(valueResolver); String[] beanNames = beanFactoryToProcess.getBeanDefinitionNames(); for (String curName : beanNames) { // 校验 // 1. 当前实例 PlaceholderConfigurerSupport 不在解析范围内 // 2. 同一个 Spring 容器 if (!(curName.equals(this.beanName) &amp;&amp; beanFactoryToProcess.equals(this.beanFactory))) { BeanDefinition bd = beanFactoryToProcess.getBeanDefinition(curName); try { visitor.visitBeanDefinition(bd); } catch (Exception ex) { throw new BeanDefinitionStoreException(bd.getResourceDescription(), curName, ex.getMessage(), ex); } } } // 别名的占位符 beanFactoryToProcess.resolveAliases(valueResolver); // 解析嵌入值的占位符，例如注释属性 beanFactoryToProcess.addEmbeddedValueResolver(valueResolver); } 流程如下： 根据 String 值解析策略 valueResolver 得到 BeanDefinitionVisitor 实例。BeanDefinitionVisitor 是 BeanDefinition 的访问者，我们通过它可以实现对 BeanDefinition 内容的进行访问，内容很多，例如Scope、PropertyValues、FactoryMethodName 等等。 得到该容器的所有 BeanName，然后对其进行访问（visitBeanDefinition()）。 解析别名的占位符 解析嵌入值的占位符，例如注释属性 这个方法核心在于 visitBeanDefinition() 的调用，如下： public void visitBeanDefinition(BeanDefinition beanDefinition) { visitParentName(beanDefinition); visitBeanClassName(beanDefinition); visitFactoryBeanName(beanDefinition); visitFactoryMethodName(beanDefinition); visitScope(beanDefinition); if (beanDefinition.hasPropertyValues()) { visitPropertyValues(beanDefinition.getPropertyValues()); } if (beanDefinition.hasConstructorArgumentValues()) { ConstructorArgumentValues cas = beanDefinition.getConstructorArgumentValues(); visitIndexedArgumentValues(cas.getIndexedArgumentValues()); visitGenericArgumentValues(cas.getGenericArgumentValues()); } } 我们可以看到该方法基本访问了 BeanDefinition 中所有值得访问的东西了，包括 parent 、class 、factory-bean 、factory-method 、scope 、property 、constructor-arg ，本篇文章的主题是 property，所以关注 visitPropertyValues() 即可。如下： protected void visitPropertyValues(MutablePropertyValues pvs) { PropertyValue[] pvArray = pvs.getPropertyValues(); for (PropertyValue pv : pvArray) { Object newVal = resolveValue(pv.getValue()); if (!ObjectUtils.nullSafeEquals(newVal, pv.getValue())) { pvs.add(pv.getName(), newVal); } } } 过程就是对属性数组进行遍历，调用 resolveValue() 对属性进行解析获取最新值，如果新值和旧值不等，则用新值替换旧值。resolveValue() 实现如下： protected Object resolveValue(@Nullable Object value) { // 由于 Properties 中的是 String，所以把前面一堆 if 去掉 else if (value instanceof String) { return resolveStringValue((String) value); } return value; } 由于配置的是 String 类型，所以只需要看 String 相关的，resolveStringValue() 实现如下： protected String resolveStringValue(String strVal) { if (this.valueResolver == null) { throw new IllegalStateException(\"No StringValueResolver specified - pass a resolver \" + \"object into the constructor or override the 'resolveStringValue' method\"); } String resolvedValue = this.valueResolver.resolveStringValue(strVal); return (strVal.equals(resolvedValue) ? strVal : resolvedValue); } valueResolver 是我们在构造 BeanDefinitionVisitor 实例时传入的 String 类型解析器 PlaceholderResolvingStringValueResolver，调用其 resolveStringValue() 如下： public String resolveStringValue(String strVal) throws BeansException { String resolved = this.helper.replacePlaceholders(strVal, this.resolver); if (trimValues) { resolved = resolved.trim(); } return (resolved.equals(nullValue) ? null : resolved); } helper 为 PropertyPlaceholderHelper 实例对象，而 PropertyPlaceholderHelper 则是处理应用程序中包含占位符的字符串工具类。在构造 helper 实例对象时需要传入了几个参数：placeholderPrefix、placeholderSuffix、valueSeparator，这些值在 PlaceholderConfigurerSupport 中定义如下： protected String placeholderPrefix = \"${\"; protected String placeholderSuffix = \"}\"; protected String valueSeparator = \":\"; 调用 replacePlaceholders() 进行占位符替换，如下： public String replacePlaceholders(String value, PlaceholderResolver placeholderResolver) { Assert.notNull(value, \"'value' must not be null\"); return parseStringValue(value, placeholderResolver, new HashSet&lt;>()); } 调用 parseStringValue()，这个方法是这篇博客最核心的地方，${} 占位符的替换： protected String parseStringValue( String value, PlaceholderResolver placeholderResolver, Set&lt;String> visitedPlaceholders) { StringBuilder result = new StringBuilder(value); // 获取前缀 \"${\" 的索引位置 int startIndex = value.indexOf(this.placeholderPrefix); while (startIndex != -1) { // 获取 后缀 \"}\" 的索引位置 int endIndex = findPlaceholderEndIndex(result, startIndex); if (endIndex != -1) { // 截取 \"${\" 和 \"}\" 中间的内容，这也就是我们在配置文件中对应的值 String placeholder = result.substring(startIndex + this.placeholderPrefix.length(), endIndex); String originalPlaceholder = placeholder; if (!visitedPlaceholders.add(originalPlaceholder)) { throw new IllegalArgumentException( \"Circular placeholder reference '\" + originalPlaceholder + \"' in property definitions\"); } // 解析占位符键中包含的占位符，真正的值 placeholder = parseStringValue(placeholder, placeholderResolver, visitedPlaceholders); // 从 Properties 中获取 placeHolder 对应的值 propVal String propVal = placeholderResolver.resolvePlaceholder(placeholder); // 如果不存在 if (propVal == null &amp;&amp; this.valueSeparator != null) { // 查询 : 的位置 int separatorIndex = placeholder.indexOf(this.valueSeparator); // 如果存在 : if (separatorIndex != -1) { // 获取 : 前面部分 actualPlaceholder String actualPlaceholder = placeholder.substring(0, separatorIndex); // 获取 : 后面部分 defaultValue String defaultValue = placeholder.substring(separatorIndex + this.valueSeparator.length()); // 从 Properties 中获取 actualPlaceholder 对应的值 propVal = placeholderResolver.resolvePlaceholder(actualPlaceholder); // 如果不存在 则返回 defaultValue if (propVal == null) { propVal = defaultValue; } } } if (propVal != null) { propVal = parseStringValue(propVal, placeholderResolver, visitedPlaceholders); result.replace(startIndex, endIndex + this.placeholderSuffix.length(), propVal); if (logger.isTraceEnabled()) { logger.trace(\"Resolved placeholder '\" + placeholder + \"'\"); } startIndex = result.indexOf(this.placeholderPrefix, startIndex + propVal.length()); } else if (this.ignoreUnresolvablePlaceholders) { // 忽略值 startIndex = result.indexOf(this.placeholderPrefix, endIndex + this.placeholderSuffix.length()); } else { throw new IllegalArgumentException(\"Could not resolve placeholder '\" + placeholder + \"'\" + \" in value \\\"\" + value + \"\\\"\"); } // visitedPlaceholders.remove(originalPlaceholder); } else { startIndex = -1; } } // 返回propVal，就是替换之后的值 return result.toString(); } 流程如下 获取占位符前缀 “${“ 的索引位置 startIndex 如果前缀 “${“ 存在，则从 “{” 后面开始获取占位符后缀 “}” 的索引位置 endIndex 如果前缀 “${” 和后缀 “}” 都存在，则截取中间部分 placeholder 从 Properties 中获取 placeHolder 对应的值 propVal 如果 propVal 为空，则判断占位符中是否存在 “:”，如果存在则对占位符进行分割处理，全面部分为 actualPlaceholder，后面部分 defaultValue，尝试从 Properties 中获取 actualPlaceholder 对应的值 propVal，如果不存在，则将 defaultValue 的值赋值给 propVal 返回 propVal，也就是 Properties 中对应的值","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之深入分析BeanFactoryPostProcessor","date":"2020-01-23T14:12:56.000Z","path":"2020/01/23/81b83a69.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=3342 在学习Spring源码的过程中发现的好站+好贴，原创不易感谢作者。 Spring版本：Spring 5.0.6.RELEASE 在博客 IOC 之 深入分析 BeanPostProcessor 深入介绍了 BeanPostProcessor 的实现机制。在这篇文章中提到 BeanPostProcessor 是 Spring 提供一种扩展机制，该机制允许我们在 Bean 实例化之后初始化之际对 Bean 进行增强处理（前、后置处理）。 同样在 Spring 容器启动阶段，Spring 也提供了一种容器扩展机制：BeanFactoryPostProcessor，该机制作用于容器启动阶段，允许我们在容器实例化 Bean 之前对注册到该容器的 BeanDefinition 做出修改。 BeanFactoryPostProcessorBeanFactoryPostProcessor 的机制就相当于给了我们在 bean 实例化之前最后一次修改 BeanDefinition 的机会，我们可以利用这个机会对 BeanDefinition 来进行一些额外的操作，比如更改某些 bean 的一些属性，给某些 Bean 增加一些其他的信息等等操作。 定义如下 public interface BeanFactoryPostProcessor { /** * 1、Modify the application context's internal bean factory after its standard initialization. * * 2、All bean definitions will have been loaded, but no beans will have been instantiated yet. This allows for overriding or adding properties even to eager-initializing beans. * * @param beanFactory the bean factory used by the application context * @throws org.springframework.beans.BeansException in case of errors */ void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException; } BeanFactoryPostProcessor 接口仅有一个 postProcessBeanFactory 方法，该方法接收一个 ConfigurableListableBeanFactory 类型的 beanFactory 参数。上面有两行注释： 1、表示了该方法的作用：在 standard initialization（实在是不知道这个怎么翻译：标准初始化？） 之后（已经就是已经完成了 BeanDefinition 的加载）对 bean factory 容器进行修改。其中参数 beanFactory 应该就是已经完成了 standard initialization 的 BeanFactory。 2、表示作用时机：所有的 BeanDefinition 已经完成了加载即加载至 BeanFactory 中，但是还没有完成初始化。 所以这里总结一句话就是：postProcessBeanFactory() 工作于BeanDefinition 加载完成之后，Bean 实例化之前，其主要作用是对加载 BeanDefinition 进行修改。 有一点需要需要注意的是在 postProcessBeanFactory() 中千万不能进行 Bean 的实例化工作，因为这样会导致 bean 过早实例化，会产生严重后果，我们始终需要注意的是 BeanFactoryPostProcessor 是与 BeanDefinition 打交道的，如果想要与 Bean 打交道，请使用 BeanPostProcessor。 与 BeanPostProcessor 一样，BeanFactoryPostProcessor 同样支持排序，一个容器可以同时拥有多个 BeanFactoryPostProcessor，这个时候如果我们比较在乎他们的顺序的话，可以实现 Ordered 接口。 如果要自定义 BeanFactoryPostProcessor 直接实现该接口即可。 实例public class BeanFactoryPostProcessor_1 implements BeanFactoryPostProcessor,Ordered{ @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException { System.out.println(\"调用 BeanFactoryPostProcessor_1 ...\"); System.out.println(\"容器中有 BeanDefinition 的个数：\" + beanFactory.getBeanDefinitionCount()); // 获取指定的 BeanDefinition BeanDefinition bd = beanFactory.getBeanDefinition(\"studentService\"); MutablePropertyValues pvs = bd.getPropertyValues(); pvs.addPropertyValue(\"name\",\"chenssy1\"); pvs.addPropertyValue(\"age\",15); } @Override public int getOrder() { return 1; } } public class BeanFactoryPostProcessor_2 implements BeanFactoryPostProcessor , Ordered{ @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException { System.out.println(\"调用 BeanFactoryPostProcessor_2 ...\"); // 获取指定的 BeanDefinition BeanDefinition bd = beanFactory.getBeanDefinition(\"studentService\"); MutablePropertyValues pvs = bd.getPropertyValues(); pvs.addPropertyValue(\"age\",18); } @Override public int getOrder() { return 2; } } 提供了两个自定义的 BeanFactoryPostProcessor ，都继承 BeanFactoryPostProcessor 和 Ordered，其中 BeanFactoryPostProcessor_1 改变 name 和 age 的值，BeanFactoryPostProcessor_2 该变 age 的值。Ordered 分别为 1 和 2。 &lt;bean id=\"studentService\" class=\"org.springframework.core.service.StudentService\"> &lt;property name=\"name\" value=\"chenssy\"/> &lt;property name=\"age\" value=\"10\"/> &lt;/bean> &lt;bean class=\"org.springframework.core.test.BeanFactoryPostProcessor_1\"/> &lt;bean class=\"org.springframework.core.test.BeanFactoryPostProcessor_2\"/> studentService 设置 name 和 age 分别为 chenss 和 10。 ApplicationContext context = new ClassPathXmlApplicationContext(\"spring.xml\"); StudentService studentService = (StudentService) context.getBean(\"studentService\"); System.out.println(\"student name:\" + studentService.getName() + \"-- age:\" + studentService.getAge()); 运行结果： 调用 BeanFactoryPostProcessor_1 ... 容器中有 BeanDefinition 的个数：3 调用 BeanFactoryPostProcessor_2 ... student name:chenssy1-- age:18 看到运行结果，其实对上面的运行流程就已经一清二楚了。这里就不过多阐述了。 在上面测试方法中，我们使用的是 ApplicationContext ，对于 ApplicationContext 来说，使用 BeanFactoryPostProcessor 非常方便，因为他会自动识别配置文件中的 BeanFactoryPostProcessor 并且完成注册和调用，我们只需要简单的配置声明即可。 而对于 BeanFactory 容器来说则不行，他和 BeanPostProcessor 一样需要容器主动去进行注册调用，方法如下： BeanFactoryPostProcessor_1 beanFactoryPostProcessor1 = new BeanFactoryPostProcessor_1(); beanFactoryPostProcessor1.postProcessBeanFactory(factory); 至于 ApplicationContext 是如何自动识别和调用，这个我们后续在分析 ApplicationContext 时会做详细说明的，当然，如果有兴趣的同学可以提前看。 诚然，一般情况下我们是不会主动去自定义 BeanFactoryPostProcessor ，其实 Spring 为我们提供了几个常用的 BeanFactoryPostProcessor，他们是PropertyPlaceholderConfigurer 和 PropertyOverrideConfigurer ，其中 PropertyPlaceholderConfigurer 允许我们在 XML 配置文件中使用占位符并将这些占位符所代表的资源单独配置到简单的 properties 文件中来加载，PropertyOverrideConfigurer 则允许我们使用占位符来明确表明bean 定义中的 property 与 properties 文件中的各配置项之间的对应关系，这两个类在我们大型项目中有非常重要的作用。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之深入分析InitializingBean和init-method","date":"2020-01-23T13:57:33.000Z","path":"2020/01/23/3af7524a.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=3340 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE Spring 在 bean 初始化时进行三个检测扩展，也就是说我们可以对 bean 进行三个不同的定制化处理，前面两篇博客 IOC 之 深入分析 Aware 接口 和 IOC 之 深入分析 BeanPostProcessor 已经分析了 Aware 接口族 和 BeanPostProcessor 接口，这篇分析 InitializingBean 接口和 init-method 方法。 InitializingBeanSpring 的 InitializingBean 接口为 bean 提供了定义初始化方法的方式，它仅包含了一个方法：afterPropertiesSet()。 public interface InitializingBean { /** * 该方法在 BeanFactory 设置完了所有属性之后被调用 * 该方法允许 bean 实例设置了所有 bean 属性时执行初始化工作，如果该过程出现了错误则需要抛出异常 */ void afterPropertiesSet() throws Exception; } Spring 在完成实例化后，设置完所有属性，进行 “Aware 接口” 和 “BeanPostProcessor 前置处理”之后，会接着检测当前 bean 对象是否实现了 InitializingBean 接口，如果是，则会调用其 afterPropertiesSet() 进一步调整 bean 实例对象的状态。 public class InitializingBeanTest implements InitializingBean { private String name; @Override public void afterPropertiesSet() throws Exception { System.out.println(\"InitializingBeanTest initializing...\"); this.name = \"chenssy 2 号\"; } public String getName() { return name; } public void setName(String name) { this.name = name; } } // 配置项 &lt;bean id=\"initializingBeanTest\" class=\"org.springframework.core.test.InitializingBeanTest\"> &lt;property name=\"name\" value=\"chenssy 1 号\"/> &lt;/bean> // 测试代码 InitializingBeanTest test = (InitializingBeanTest) factory.getBean(\"initializingBeanTest\"); System.out.println(\"name ：\" + test.getName()); 执行结果： 在这个示例中改变了 InitializingBeanTest 示例的 name 属性，也就是说 在 afterPropertiesSet() 中我们是可以改变 bean 的属性的，这相当于 Spring 容器又给我们提供了一种可以改变 bean 实例对象的方法。 上面提到 bean 初始化阶段（initializeBean() ） Spring 容器会主动检查当前 bean 是否已经实现了 InitializingBean 接口，如果实现了则会调用其 afterPropertiesSet() ,这个主动检查、调用的动作是由 invokeInitMethods() 来完成的。 protected void invokeInitMethods( String beanName, final Object bean, @Nullable RootBeanDefinition mbd) throws Throwable { // 是否实现 InitializingBean // 如果实现了 InitializingBean 接口，则只掉调用bean的 afterPropertiesSet() boolean isInitializingBean = (bean instanceof InitializingBean); if (isInitializingBean &amp;&amp; (mbd == null || !mbd.isExternallyManagedInitMethod(\"afterPropertiesSet\"))) { if (logger.isDebugEnabled()) { logger.debug(\"Invoking afterPropertiesSet() on bean with name '\" + beanName + \"'\"); } if (System.getSecurityManager() != null) { try { AccessController.doPrivileged((PrivilegedExceptionAction&lt;Object>) () -> { ((InitializingBean) bean).afterPropertiesSet(); return null; }, getAccessControlContext()); } catch (PrivilegedActionException pae) { throw pae.getException(); } } else { // 直接调用 afterPropertiesSet() ((InitializingBean) bean).afterPropertiesSet(); } } if (mbd != null &amp;&amp; bean.getClass() != NullBean.class) { // 判断是否指定了 init-method()， // 如果指定了 init-method()，则再调用制定的init-method String initMethodName = mbd.getInitMethodName(); if (StringUtils.hasLength(initMethodName) &amp;&amp; !(isInitializingBean &amp;&amp; \"afterPropertiesSet\".equals(initMethodName)) &amp;&amp; !mbd.isExternallyManagedInitMethod(initMethodName)) { // 利用反射机制执行 invokeCustomInitMethod(beanName, bean, mbd); } } } 首先检测当前 bean 是否实现了 InitializingBean 接口，如果实现了则调用其 afterPropertiesSet()，然后再检查是否也指定了 init-method()，如果指定了则通过反射机制调用指定的 init-method()。 虽然该接口为 Spring 容器的扩展性立下了汗马功劳，但是如果真的让我们的业务对象来实现这个接口就显得不是那么的友好了，Spring 的一个核心理念就是无侵入性，但是如果我们业务类实现这个接口就显得 Spring 容器具有侵入性了。 所以 Spring 还提供了另外一种实现的方式：init-method 方法 init-method()在分析分析 &lt;bean&gt; 标签解析过程中我们提到了有关于 init-method 属性，该属性用于在 bean 初始化时指定执行方法，可以用来替代实现 InitializingBean 接口。 public class InitializingBeanTest { private String name; public String getName() { return name; } public void setName(String name) { this.name = name; } public void setOtherName(){ System.out.println(\"InitializingBeanTest setOtherName...\"); this.name = \"chenssy 3 号\"; } } 配置文件： &lt;bean id=\"initializingBeanTest\" class=\"org.springframework.core.test.InitializingBeanTest\" init-method=\"setOtherName\"> &lt;property name=\"name\" value=\"chenssy 1 号\"/> &lt;/bean> 执行结果: 完全可以达到和 InitializingBean 一样的效果，而且在代码中我们没有看到丝毫 Spring 侵入的现象。 所以通过 init-method 我们可以使用业务对象中定义的任何方法来实现 bean 实例对象的初始化定制化，而不再受制于 InitializingBean的 afterPropertiesSet()。同时我们可以使用 &lt;beans&gt; 标签的 default-init-method 属性来统一指定初始化方法，这样就省了需要在每个 &lt;bean&gt; 标签中都设置 init-method 这样的繁琐工作了。 比如在 default-init-method 规定所有初始化操作全部以 initBean() 命名。如下： 从 invokeInitMethods() 中，我们知道 init-method 指定的方法会在 afterPropertiesSet() 之后执行，如果 afterPropertiesSet() 中出现了异常，则 init-method 是不会执行的，而且由于 init-method 采用的是反射执行的方式，所以 afterPropertiesSet() 的执行效率一般会高些，但是并不能排除我们要优先使用 init-method，主要是因为它消除了 bean 对 Spring 的依赖，Spring 没有侵入到我们业务代码，这样会更加符合 Spring 的理念。 诚然，init-method 是基于 xml 配置文件的，就目前而言，我们的工程几乎都摒弃了配置，而采用注释的方式，那么 @PreDestory 可能适合你，当然这个注解我们后面分析。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之深入分析BeanPostProcessor","date":"2020-01-22T01:36:11.000Z","path":"2020/01/22/aa8c9efa.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=3338 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE Spring 作为优秀的开源框架，它为我们提供了丰富的可扩展点，除了前面提到的 Aware 接口，还包括其他部分，其中一个很重要的就是 BeanPostProcessor。 这篇文章主要介绍 BeanPostProcessor 的使用以及其实现原理。我们先看 BeanPostProcessor 的定位： BeanPostProcessor 的作用：在 Bean 完成实例化后，如果我们需要对其进行一些配置、增加一些自己的处理逻辑，那么请使用 BeanPostProcessor。 BeanPostProcessor 实例首先定义一个类，该类实现 BeanPostProcessor 接口，如下： public class BeanPostProcessorTest implements BeanPostProcessor{ @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { System.out.println(\"Bean [\" + beanName + \"] 开始初始化\"); // 这里一定要返回 bean，不能返回 null return bean; } @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { System.out.println(\"Bean [\" + beanName + \"] 完成初始化\"); return bean; } public void display(){ System.out.println(\"hello BeanPostProcessor!!!\"); } } 测试方法如下： ClassPathResource resource = new ClassPathResource(\"spring.xml\"); DefaultListableBeanFactory factory = new DefaultListableBeanFactory(); XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(factory); reader.loadBeanDefinitions(resource); BeanPostProcessorTest test = (BeanPostProcessorTest) factory.getBean(\"beanPostProcessorTest\"); test.display(); 运行结果： 运行结果比较奇怪，为什么没有执行 postProcessBeforeInitialization() 和 postProcessAfterInitialization() 呢？ 我们 debug 跟踪下代码，这两个方法在 initializeBean() 方法处调用下，如下： debug，在 postProcessBeforeInitialization()方法中结果如下： 这段代码是通过迭代 getBeanPostProcessors() 返回的结果集来调用 postProcessBeforeInitialization()，但是在这里我们看到该方法返回的结果集为空，所以肯定不会执行相应的 postProcessBeforeInitialization() 方法咯。怎么办？ 答案不言而喻：只需要 getBeanPostProcessors() 返回的结果集中存在至少一个元素即可，该方法定义如下： public List&lt;BeanPostProcessor> getBeanPostProcessors() { return this.beanPostProcessors; } 返回的 beanPostProcessors 是一个 private 的 List ，也就是说只要该类中存在 beanPostProcessors.add() 的调用我们就找到了入口，在类 AbstractBeanFactory 中找到了如下代码： @Override public void addBeanPostProcessor(BeanPostProcessor beanPostProcessor) { Assert.notNull(beanPostProcessor, \"BeanPostProcessor must not be null\"); this.beanPostProcessors.remove(beanPostProcessor); this.beanPostProcessors.add(beanPostProcessor); if (beanPostProcessor instanceof InstantiationAwareBeanPostProcessor) { this.hasInstantiationAwareBeanPostProcessors = true; } if (beanPostProcessor instanceof DestructionAwareBeanPostProcessor) { this.hasDestructionAwareBeanPostProcessors = true; } } 该方法是由 AbstractBeanFactory 的父类 ConfigurableBeanFactory 定义，它的核心意思就是将指定 BeanPostProcessor 注册到该 BeanFactory 创建的 bean 中，同时它是按照插入的顺序进行注册的，完全忽略 Ordered 接口所表达任何排序语义（在 BeanPostProcessor 中我们提供一个 Ordered 顺序，这个后面讲解）。 到这里应该就比较熟悉了，其实只需要显示调用 addBeanPostProcessor() 就可以了，加入如下代码。 BeanPostProcessorTest beanPostProcessorTest = new BeanPostProcessorTest(); factory.addBeanPostProcessor(beanPostProcessorTest); 运行结果： 其实还有一种更加简单的方法，这个我们后面再说，先看 BeanPostProcessor 的原理。 BeanPostProcessor 基本原理BeanPostProcessor 接口定义如下： public interface BeanPostProcessor { @Nullable default Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { return bean; } @Nullable default Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { return bean; } } BeanPostProcessor 可以理解为是 Spring 的一个工厂钩子（其实 Spring 提供一系列的钩子，如 Aware 、InitializingBean、DisposableBean），它是 Spring 提供的对象实例化阶段强有力的扩展点，允许 Spring 在实例化 bean 阶段对其进行定制化修改，比较常见的使用场景是处理标记接口实现类或者为当前对象提供代理实现（例如AOP）。 一般普通的 BeanFactory 是不支持自动注册 BeanPostProcessor 的，需要我们手动调用 addBeanPostProcessor() 进行注册，注册后的 BeanPostProcessor 适用于所有该 BeanFactory 创建的 bean，但是 ApplicationContext 可以在其 bean 定义中自动检测所有的 BeanPostProcessor 并自动完成注册，同时将他们应用到随后创建的任何 bean 中。 postProcessBeforeInitialization() 和 postProcessAfterInitialization() 两个方法都接收一个 Object 类型的 bean，一个 String 类型的 beanName，其中 bean 是已经实例化了的 instanceBean，能拿到这个你是不是可以对它为所欲为了？ 这两个方法是初始化 bean 的前后置处理器，他们应用 invokeInitMethods() 前后。如下图： 代码层次上面已经贴出来，这里再贴一次： 两者源码如下： @Override public Object applyBeanPostProcessorsBeforeInitialization(Object existingBean, String beanName) throws BeansException { Object result = existingBean; for (BeanPostProcessor beanProcessor : getBeanPostProcessors()) { Object current = beanProcessor.postProcessBeforeInitialization(result, beanName); if (current == null) { return result; } result = current; } return result; } @Override public Object applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName) throws BeansException { Object result = existingBean; for (BeanPostProcessor beanProcessor : getBeanPostProcessors()) { Object current = beanProcessor.postProcessAfterInitialization(result, beanName); if (current == null) { return result; } result = current; } return result; } getBeanPostProcessors() 返回的是 beanPostProcessors 集合，该集合里面存放就是我们自定义的 BeanPostProcessor，如果该集合中存在元素则调用相应的方法，否则就直接返回 bean 了。这也是为什么使用 BeanFactory 容器是无法输出自定义 BeanPostProcessor 里面的内容，因为在 BeanFactory.getBean() 的过程中根本就没有将我们自定义的 BeanPostProcessor 注入进来，所以要想 BeanFactory 容器 的 BeanPostProcessor 生效我们必须手动调用 addBeanPostProcessor() 将定义的 BeanPostProcessor 注册到相应的 BeanFactory 中。但是 ApplicationContext 不需要手动，因为 ApplicationContext 会自动检测并完成注册。 ApplicationContext 实现自动注册的原因在于我们构造一个 ApplicationContext 实例对象的时候会调用 registerBeanPostProcessors() 方法将检测到的 BeanPostProcessor 注入到 ApplicationContext 容器中，同时应用到该容器创建的 bean 中。 /** * 实例化并调用已经注入的 BeanPostProcessor * 必须在应用中 bean 实例化之前调用 */ protected void registerBeanPostProcessors(ConfigurableListableBeanFactory beanFactory) { PostProcessorRegistrationDelegate.registerBeanPostProcessors(beanFactory, this); } public static void registerBeanPostProcessors( ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) { // 获取所有的 BeanPostProcessor 的 beanName // 这些 beanName 都已经全部加载到容器中去，但是没有实例化 String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false); // 记录所有的beanProcessor数量 int beanProcessorTargetCount = beanFactory.getBeanPostProcessorCount() + 1 + postProcessorNames.length; // 注册 BeanPostProcessorChecker，它主要是用于在 BeanPostProcessor 实例化期间记录日志 // 当 Spring 中高配置的后置处理器还没有注册就已经开始了 bean 的实例化过程，这个时候便会打印 BeanPostProcessorChecker 中的内容 beanFactory.addBeanPostProcessor(new PostProcessorRegistrationDelegate.BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount)); // PriorityOrdered 保证顺序 List&lt;BeanPostProcessor> priorityOrderedPostProcessors = new ArrayList&lt;>(); // MergedBeanDefinitionPostProcessor List&lt;BeanPostProcessor> internalPostProcessors = new ArrayList&lt;>(); // 使用 Ordered 保证顺序 List&lt;String> orderedPostProcessorNames = new ArrayList&lt;>(); // 没有顺序 List&lt;String> nonOrderedPostProcessorNames = new ArrayList&lt;>(); for (String ppName : postProcessorNames) { // PriorityOrdered if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) { // 调用 getBean 获取 bean 实例对象 BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); priorityOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) { internalPostProcessors.add(pp); } } // Ordered else if (beanFactory.isTypeMatch(ppName, Ordered.class)) { orderedPostProcessorNames.add(ppName); } else { // 无序 nonOrderedPostProcessorNames.add(ppName); } } // 第一步注册所有实现了 PriorityOrdered 的BeanPostProcessor // 先排序 sortPostProcessors(priorityOrderedPostProcessors, beanFactory); // 后注册 registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors); // 第二步注册所有实现了 Ordered 的 BeanPostProcessor List&lt;BeanPostProcessor> orderedPostProcessors = new ArrayList&lt;>(); for (String ppName : orderedPostProcessorNames) { BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); orderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) { internalPostProcessors.add(pp); } } sortPostProcessors(orderedPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, orderedPostProcessors); // 第三步注册所有无序的 BeanPostProcessor List&lt;BeanPostProcessor> nonOrderedPostProcessors = new ArrayList&lt;>(); for (String ppName : nonOrderedPostProcessorNames) { BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); nonOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) { internalPostProcessors.add(pp); } } registerBeanPostProcessors(beanFactory, nonOrderedPostProcessors); // 最后，注册所有的 MergedBeanDefinitionPostProcessor 类型的 BeanPostProcessor sortPostProcessors(internalPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, internalPostProcessors); // 加入ApplicationListenerDetector（探测器） // 重新注册 BeanPostProcessor 以检测内部 bean，因为 ApplicationListeners 将其移动到处理器链的末尾 beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(applicationContext)); } 方法首先 beanFactory 获取注册到该 BeanFactory 中所有 BeanPostProcessor 类型的 beanName，其实就是找所有实现了 BeanPostProcessor 接口的 bean ，然后迭代这些 bean，将其按照PriorityOrdered、Ordered、无序的顺序添加至相应的 List 集合中，最后依次调用 sortPostProcessors() 进行排序处理和 registerBeanPostProcessors() 完成注册。排序很简单，如果 beanFactory 为 DefaultListableBeanFactory 则返回 BeanFactory 所依赖的比较器，否则反正默认的比较器(OrderComparator)，然后调用 sort() 即可。如下： private static void sortPostProcessors(List&lt;?> postProcessors, ConfigurableListableBeanFactory beanFactory) { Comparator&lt;Object> comparatorToUse = null; if (beanFactory instanceof DefaultListableBeanFactory) { comparatorToUse = ((DefaultListableBeanFactory) beanFactory).getDependencyComparator(); } if (comparatorToUse == null) { comparatorToUse = OrderComparator.INSTANCE; } postProcessors.sort(comparatorToUse); } 而对于注册同样是调用 AbstractBeanFactory.addBeanPostProcessor() 方法完成注册，如下： private static void registerBeanPostProcessors( ConfigurableListableBeanFactory beanFactory, List&lt;BeanPostProcessor> postProcessors) { for (BeanPostProcessor postProcessor : postProcessors) { beanFactory.addBeanPostProcessor(postProcessor); } } 至此，BeanPostProcessor 已经分析完毕了，这里简单总结下： BeanPostProcessor 的作用域是容器级别的，它只和所在的容器相关 ，当 BeanPostProcessor 完成注册后，它会应用于所有跟它在同一个容器内的 bean。 BeanFactory 和 ApplicationContext 对 BeanPostProcessor 的处理不同，ApplicationContext 会自动检测所有实现了 BeanPostProcessor 接口的 bean，并完成注册，但是使用 BeanFactory 容器时则需要手动调用 addBeanPostProcessor() 完成注册 ApplicationContext 的 BeanPostProcessor 支持 Ordered，而 BeanFactory 的 BeanPostProcessor 是不支持的，原因在于ApplicationContext 会对 BeanPostProcessor 进行 Ordered 检测并完成排序，而 BeanFactory 中的 BeanPostProcessor 只跟注册的顺序有关。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之深入分析Aware接口","date":"2020-01-22T01:20:19.000Z","path":"2020/01/22/26a31db5.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=3335 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE doCreateBean() 方法主要干三件事情： 实例化 bean 对象：createBeanInstance() 属性注入：populateBean() 初始化 bean 对象：initializeBean() 而初始化 bean 对象时也是干了三件事情： 激活 Aware 方法 后置处理器的应用 激活自定义的 init 方法 接下来将会详细分析这三件事情，这篇主要分析 Aware 接口。 Aware 接口定义如下： /** * Marker superinterface indicating that a bean is eligible to be * notified by the Spring container of a particular framework object * through a callback-style method. Actual method signature is * determined by individual subinterfaces, but should typically * consist of just one void-returning method that accepts a single * argument. * * &lt;p>Note that merely implementing {@link Aware} provides no default * functionality. Rather, processing must be done explicitly, for example * in a {@link org.springframework.beans.factory.config.BeanPostProcessor BeanPostProcessor}. * Refer to {@link org.springframework.context.support.ApplicationContextAwareProcessor} * and {@link org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory} * for examples of processing {@code *Aware} interface callbacks. * * @author Chris Beams * @since 3.1 */ public interface Aware { } Aware 接口为 Spring 容器的核心接口，是一个具有标识作用的超级接口，实现了该接口的 bean 是具有被 Spring 容器通知的能力，通知的方式是采用回调的方式。 Aware 接口是一个空接口，实际的方法签名由各个子接口来确定，且该接口通常只会有一个接收单参数的 set 方法，该 set 方法的命名方式为 set + 去掉接口名中的 Aware 后缀，即 XxxAware 接口，则方法定义为 setXxx()，例如 BeanNameAware（setBeanName），ApplicationContextAware（setApplicationContext）。 Aware 的子接口需要提供一个 setXxx 方法，我们知道 set 是设置属性值的方法，即 Aware 类接口的 setXxx 方法其实就是设置 xxx 属性值的。 Aware 的含义是感知的、感应的，那么在 Spring 容器中是如何实现感知并设置属性值得呢？我们可以从初始化 bean 中的激活 Aware 的方法 invokeAwareMethods() 中看到一点点，如下： private void invokeAwareMethods(final String beanName, final Object bean) { if (bean instanceof Aware) { if (bean instanceof BeanNameAware) { ((BeanNameAware) bean).setBeanName(beanName); } if (bean instanceof BeanClassLoaderAware) { ClassLoader bcl = getBeanClassLoader(); if (bcl != null) { ((BeanClassLoaderAware) bean).setBeanClassLoader(bcl); } } if (bean instanceof BeanFactoryAware) { ((BeanFactoryAware) bean).setBeanFactory(AbstractAutowireCapableBeanFactory.this); } } } 首先判断 bean 实例是否属于 Aware 接口的范畴，如果是的话，则调用实例的 setXxx() 方法给实例设置 xxx 属性值，在 invokeAwareMethods() 方法主要是设置 beanName，beanClassLoader、BeanFactory 中三个属性值。 Spring 提供了一系列的 Aware 接口，如下图（部分）： 上面只是一部分子类，从这里我们可以看到 Spring 提供的 Aware 接口是是何其多。同时从上图我们也看到了几个比较熟悉的接口，如 BeanClassLoaderAware、BeanFactoryAware、BeanNameAware，下面就这三个接口来做一个简单的演示，先看各自的定义： public interface BeanClassLoaderAware extends Aware { /** * 将 BeanClassLoader 提供给 bean 实例回调 * 在 bean 属性填充之后、初始化回调之前回调， * 例如InitializingBean的InitializingBean.afterPropertiesSet（）方法或自定义init方法 */ void setBeanClassLoader(ClassLoader classLoader); } public interface BeanFactoryAware extends Aware { /** * 将 BeanFactory 提供给 bean 实例回调 * 调用时机和 setBeanClassLoader 一样 */ void setBeanFactory(BeanFactory beanFactory) throws BeansException; } public interface BeanNameAware extends Aware { /** * 在创建此 bean 的 bean工厂中设置 beanName */ void setBeanName(String name); } public interface ApplicationContextAware extends Aware { /** * 设置此 bean 对象的 ApplicationContext，通常，该方法用于初始化对象 */ void setApplicationContext(ApplicationContext applicationContext) throws BeansException; } 下面简单演示下上面四个接口的使用方法： public class MyApplicationAware implements BeanNameAware,BeanFactoryAware,BeanClassLoaderAware,ApplicationContextAware{ private String beanName; private BeanFactory beanFactory; private ClassLoader classLoader; private ApplicationContext applicationContext; @Override public void setBeanClassLoader(ClassLoader classLoader) { System.out.println(\"调用了 BeanClassLoaderAware 的 setBeanClassLoader 方法\"); this.classLoader = classLoader; } @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException { System.out.println(\"调用了 BeanFactoryAware 的 setBeanFactory 方法\"); this.beanFactory = beanFactory; } @Override public void setBeanName(String name) { System.out.println(\"调用了 BeanNameAware 的 setBeanName 方法\"); this.beanName = name; } @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { System.out.println(\"调用了 ApplicationContextAware 的 setApplicationContext 方法\"); this.applicationContext = applicationContext; } public void display(){ System.out.println(\"beanName:\" + beanName); System.out.println(\"是否为单例：\" + beanFactory.isSingleton(beanName)); System.out.println(\"系统环境为：\" + applicationContext.getEnvironment()); } } 测试方法如下: public static void main(String[] args) { ClassPathResource resource = new ClassPathResource(\"spring.xml\"); DefaultListableBeanFactory factory = new DefaultListableBeanFactory(); XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(factory); reader.loadBeanDefinitions(resource); MyApplicationAware applicationAware = (MyApplicationAware) factory.getBean(\"myApplicationAware\"); applicationAware.display(); } 运行结果： 从该运行结果可以看出，这里只执行了三个 Aware 接口的 set 方法，原因就是痛 getBean() 调用时在激活 Aware 接口时只检测了 BeanNameAware、BeanClassLoaderAware、BeanFactoryAware 三个 Aware 接口。如果将测试方法调整为下面： public static void main(String[] args) { ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"spring.xml\"); MyApplicationAware applicationAware = (MyApplicationAware) applicationContext.getBean(\"myApplicationAware\"); applicationAware.display(); } 则运行结果如下： 从这了我们基本上就可以 Aware 真正的含义是什么了？ 感知，其实是 Spring 容器在初始化主动检测当前 bean 是否实现了 Aware 接口，如果实现了则回调其 set 方法将相应的参数设置给该 bean ，这个时候该 bean 就从 Spring 容器中取得相应的资源。 最后列出部分常用的 Aware 子接口，便于日后查询： LoadTimeWeaverAware：加载Spring Bean时织入第三方模块，如AspectJ BeanClassLoaderAware：加载Spring Bean的类加载器 BootstrapContextAware：资源适配器BootstrapContext，如JCA,CCI ResourceLoaderAware：底层访问资源的加载器 BeanFactoryAware：声明BeanFactory PortletConfigAware：PortletConfig PortletContextAware：PortletContext ServletConfigAware：ServletConfig ServletContextAware：ServletContext MessageSourceAware：国际化 ApplicationEventPublisherAware：应用事件 NotificationPublisherAware：JMX通知 BeanNameAware：声明Spring Bean的名字","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之加载Bean——总结篇","date":"2020-01-21T03:29:39.000Z","path":"2020/01/21/abeafe18.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=2905 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE 在Spring bean 解析篇深入分析了一个配置文件经历了哪些过程转变成了 BeanDefinition，但是这个 BeanDefinition 并不是我们真正想要的想要的 bean，因为它还仅仅只是承载了我们需要的目标 bean 的信息，从 BeanDefinition 到我们需要的目标还需要一个漫长的 bean 的初始化阶段。 在 Spring bean 加载阶段已经详细分析了初始化 bean 的过程，所以这里做一个概括性的总结。 bean 的初始化节点由第一次调用 getBean()(显式或者隐式)开启，所以我们从这个方法开始。 public Object getBean(String name) throws BeansException { return doGetBean(name, null, null, false); } protected &lt;T> T doGetBean(final String name, @Nullable final Class&lt;T> requiredType, @Nullable final Object[] args, boolean typeCheckOnly) throws BeansException { // 获取 beanName，这里是一个转换动作，将 name 转换Wie beanName final String beanName = transformedBeanName(name); Object bean; // 从缓存中或者实例工厂中获取 bean // *** 这里会涉及到解决循环依赖 bean 的问题 Object sharedInstance = getSingleton(beanName); if (sharedInstance != null &amp;&amp; args == null) { if (logger.isDebugEnabled()) { if (isSingletonCurrentlyInCreation(beanName)) { logger.debug(\"Returning eagerly cached instance of singleton bean '\" + beanName + \"' that is not fully initialized yet - a consequence of a circular reference\"); } else { logger.debug(\"Returning cached instance of singleton bean '\" + beanName + \"'\"); } } bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); } else { // 因为 Spring 只解决单例模式下得循环依赖，在原型模式下如果存在循环依赖则会抛出异常 // **关于循环依赖后续会单独出文详细说明** if (isPrototypeCurrentlyInCreation(beanName)) { throw new BeanCurrentlyInCreationException(beanName); } // 如果容器中没有找到，则从父类容器中加载 BeanFactory parentBeanFactory = getParentBeanFactory(); if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) { String nameToLookup = originalBeanName(name); if (parentBeanFactory instanceof AbstractBeanFactory) { return ((AbstractBeanFactory) parentBeanFactory).doGetBean( nameToLookup, requiredType, args, typeCheckOnly); } else if (args != null) { return (T) parentBeanFactory.getBean(nameToLookup, args); } else { return parentBeanFactory.getBean(nameToLookup, requiredType); } } // 如果不是仅仅做类型检查则是创建bean，这里需要记录 if (!typeCheckOnly) { markBeanAsCreated(beanName); } try { // 从容器中获取 beanName 相应的 GenericBeanDefinition，并将其转换为 RootBeanDefinition final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); // 检查给定的合并的 BeanDefinition checkMergedBeanDefinition(mbd, beanName, args); // 处理所依赖的 bean String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) { for (String dep : dependsOn) { // 若给定的依赖 bean 已经注册为依赖给定的b ean // 循环依赖的情况 if (isDependent(beanName, dep)) { throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Circular depends-on relationship between '\" + beanName + \"' and '\" + dep + \"'\"); } // 缓存依赖调用 registerDependentBean(dep, beanName); try { getBean(dep); } catch (NoSuchBeanDefinitionException ex) { throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"'\" + beanName + \"' depends on missing bean '\" + dep + \"'\", ex); } } } // bean 实例化 // 单例模式 if (mbd.isSingleton()) { sharedInstance = getSingleton(beanName, () -> { try { return createBean(beanName, mbd, args); } catch (BeansException ex) { // 显示从单利缓存中删除 bean 实例 // 因为单例模式下为了解决循环依赖，可能他已经存在了，所以销毁它 destroySingleton(beanName); throw ex; } }); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); } // 原型模式 else if (mbd.isPrototype()) { // It's a prototype -> create a new instance. Object prototypeInstance = null; try { beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); } finally { afterPrototypeCreation(beanName); } bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); } else { // 从指定的 scope 下创建 bean String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); if (scope == null) { throw new IllegalStateException(\"No Scope registered for scope name '\" + scopeName + \"'\"); } try { Object scopedInstance = scope.get(beanName, () -> { beforePrototypeCreation(beanName); try { return createBean(beanName, mbd, args); } finally { afterPrototypeCreation(beanName); } }); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); } catch (IllegalStateException ex) { throw new BeanCreationException(beanName, \"Scope '\" + scopeName + \"' is not active for the current thread; consider \" + \"defining a scoped proxy for this bean if you intend to refer to it from a singleton\", ex); } } } catch (BeansException ex) { cleanupAfterBeanCreationFailure(beanName); throw ex; } } // 检查需要的类型是否符合 bean 的实际类型 if (requiredType != null &amp;&amp; !requiredType.isInstance(bean)) { try { T convertedBean = getTypeConverter().convertIfNecessary(bean, requiredType); if (convertedBean == null) { throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); } return convertedBean; } catch (TypeMismatchException ex) { if (logger.isDebugEnabled()) { logger.debug(\"Failed to convert bean '\" + name + \"' to required type '\" + ClassUtils.getQualifiedName(requiredType) + \"'\", ex); } throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); } } return (T) bean; } 内部调用 doGetBean() 方法，doGetBean() 的代码量比较多，从这里就可以看出 bean 的加载过程是一个非常复杂的过程，会涉及到各种各样的情况处理。doGetBean() 可以分为以下几个过程。 转换 beanName。因为我们调用 getBean() 方法传入的 name 并不一定就是 beanName，可以传入 aliasName，FactoryBean，所以这里需要进行简单的转换过程。 尝试从缓存中加载单例 bean。 bean 的实例化。 原型模式的依赖检查。因为 Spring 只会解决单例模式的循环依赖，对于原型模式的循环依赖都是直接抛出 BeanCurrentlyInCreationException 异常。 尝试从 parentBeanFactory 获取 bean 实例。如果 parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName) 则尝试从 parentBeanFactory 中获取 bean 实例对象，因为 !containsBeanDefinition(beanName) 就意味着定义的 xml 文件中没有 beanName 相应的配置，这个时候就只能从 parentBeanFactory 中获取。 获取 RootBeanDefinition，并对其进行合并检查。从缓存中获取已经解析的 RootBeanDefinition，同时如果父类不为 null 的话，则会合并父类的属性。 依赖检查。某个 bean 依赖其他 bean ，则需要先加载依赖的 bean。 对不同的 scope 进行处理。 类型转换处理。如果传递的 requiredType 不为 null，则需要检测所得到 bean 的类型是否与该 requiredType 一致，如果不一致则尝试转换，当然也要能够转换成功，否则抛出 BeanNotOfRequiredTypeException 异常。 下面就以下几个方面进行阐述，说明 Spring bean 的加载过程。 从缓存中获取 bean 创建 bean 实例对象 从 bean 实例中获取对象 从缓存中获取 beanSpring 中根据 scope 可以将 bean 分为以下几类：singleton、prototype 和 其他，这样分的原因在于 Spring 在对不同 scope 处理的时候是这么处理的。 singleton：在 Spring 的 IoC 容器中只存在一个对象实例，所有该对象的引用都共享这个实例。Spring 容器只会创建该 bean 定义的唯一实例，这个实例会被保存到缓存中，并且对该bean的所有后续请求和引用都将返回该缓存中的对象实例。 prototype：每次对该bean的请求都会创建一个新的实例 其他：其他包括 request、session、global session： request：每次 http 请求将会有各自的 bean 实例。 session：在一个 http session 中，一个 bean 定义对应一个 bean 实例。 global session：在一个全局的 http session 中，一个 bean 定义对应一个 bean 实例。 所以从缓存中获取的 bean 一定是 singleton bean，这也是 Spring 为何只解决 singleton bean 的循环依赖。调用 getSingleton() 从缓存中获取 singleton bean。 public Object getSingleton(String beanName) { return getSingleton(beanName, true); } protected Object getSingleton(String beanName, boolean allowEarlyReference) { Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) { synchronized (this.singletonObjects) { singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) { ObjectFactory&lt;?> singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) { singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); } } } } return singletonObject; } getSingleton() 就是从 singletonObjects、earlySingletonObjects、 singletonFactories 三个缓存中获取，这里也是 Spring 解决 bean 循环依赖的关键之处。详细内容请查看如下内容： IOC之从单例缓存中获取单例 bean 创建 bean 实例对象如果缓存中没有，也没有 parentBeanFactory ，则会调用 createBean() 创建 bean 实例，该方法主要是在处理不同 scope 的 bean 的时候进行调用。 protected abstract Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException 该方法是定义在 AbstractBeanFactory 中的虚拟方法，其含义是根据给定的 BeanDefinition 和 args实例化一个 bean 对象，如果该 BeanDefinition 存在父类，则该 BeanDefinition 已经合并了父类的属性。所有 Bean 实例的创建都会委托给该方法实现。 方法接受三个参数： beanName：bean 的名字 mbd：已经合并了父类属性的（如果有的话）BeanDefinition args：用于构造函数或者工厂方法创建 bean 实例对象的参数 该抽象方法的默认实现是在类 AbstractAutowireCapableBeanFactory 中实现，该方法其实只是做一些检查和验证工作，真正的初始化工作是由 doCreateBean() 实现，如下： protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException { // BeanWrapper是对Bean的包装，其接口中所定义的功能很简单包括设置获取被包装的对象，获取被包装bean的属性描述器 BeanWrapper instanceWrapper = null; // 单例模型，则从未完成的 FactoryBean 缓存中删除 if (mbd.isSingleton()) {anceWrapper = this.factoryBeanInstanceCache.remove(beanName); } // 使用合适的实例化策略来创建新的实例：工厂方法、构造函数自动注入、简单初始化 if (instanceWrapper == null) { instanceWrapper = createBeanInstance(beanName, mbd, args); } // 包装的实例对象 final Object bean = instanceWrapper.getWrappedInstance(); // 包装的实例对象的类型 Class&lt;?> beanType = instanceWrapper.getWrappedClass(); if (beanType != NullBean.class) { mbd.resolvedTargetType = beanType; } // 检测是否有后置处理 // 如果有后置处理，则允许后置处理修改 BeanDefinition synchronized (mbd.postProcessingLock) { if (!mbd.postProcessed) { try { // applyMergedBeanDefinitionPostProcessors // 后置处理修改 BeanDefinition applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); } catch (Throwable ex) { throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Post-processing of merged bean definition failed\", ex); } mbd.postProcessed = true; } } // 解决单例模式的循环依赖 // 单例模式 &amp; 运行循环依赖&amp;当前单例 bean 是否正在被创建 boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) { if (logger.isDebugEnabled()) { logger.debug(\"Eagerly caching bean '\" + beanName + \"' to allow for resolving potential circular references\"); } // 提前将创建的 bean 实例加入到ectFactory 中 // 这里是为了后期避免循环依赖 addSingletonFactory(beanName, () -> getEarlyBeanReference(beanName, mbd, bean)); } /* * 开始初始化 bean 实例对象 */ Object exposedObject = bean; try { // 对 bean 进行填充，将各个属性值注入，其中，可能存在依赖于其他 bean 的属性 // 则会递归初始依赖 bean populateBean(beanName, mbd, instanceWrapper); // 调用初始化方法 exposedObject = initializeBean(beanName, exposedObject, mbd); } catch (Throwable ex) { if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) { throw (BeanCreationException) ex; } else { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Initialization of bean failed\", ex); } } /** * 循环依赖处理 */ if (earlySingletonExposure) { // 获取 earlySingletonReference Object earlySingletonReference = getSingleton(beanName, false); // 只有在存在循环依赖的情况下，earlySingletonReference 才不会为空 if (earlySingletonReference != null) { // 如果 exposedObject 没有在初始化方法中被改变，也就是没有被增强 if (exposedObject == bean) { exposedObject = earlySingletonReference; } // 处理依赖 else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) { String[] dependentBeans = getDependentBeans(beanName); Set&lt;String> actualDependentBeans = new LinkedHashSet&lt;>(dependentBeans.length); for (String dependentBean : dependentBeans) { if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) { actualDependentBeans.add(dependentBean); } } if (!actualDependentBeans.isEmpty()) { throw new BeanCurrentlyInCreationException(beanName, \"Bean with name '\" + beanName + \"' has been injected into other beans [\" + StringUtils.collectionToCommaDelimitedString(actualDependentBeans) + \"] in its raw version as part of a circular reference, but has eventually been \" + \"wrapped. This means that said other beans do not use the final version of the \" + \"bean. This is often the result of over-eager type matching - consider using \" + \"'getBeanNamesOfType' with the 'allowEagerInit' flag turned off, for example.\"); } } } } try { // 注册 bean registerDisposableBeanIfNecessary(beanName, bean, mbd); } catch (BeanDefinitionValidationException ex) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Invalid destruction signature\", ex); } return exposedObject; } doCreateBean() 是创建 bean 实例的核心方法，它的整体思路是： 如果是单例模式，则清除 factoryBeanInstanceCache 缓存，同时返回 BeanWrapper 实例对象，当然如果存在。 如果缓存中没有 BeanWrapper 或者不是单例模式，则调用 createBeanInstance() 实例化 bean，主要是将 BeanDefinition 转换为 BeanWrapper MergedBeanDefinitionPostProcessor 的应用 单例模式的循环依赖处理 调用 populateBean() 进行属性填充。将所有属性填充至 bean 的实例中 调用 initializeBean() 初始化 bean 依赖检查 注册 DisposableBean 实例化 bean如果缓存中没有 BeanWrapper 实例对象或者该 bean 不是 singleton，则调用 createBeanInstance() 创建 bean 实例。该方法主要是根据参数 BeanDefinition、args[] 来调用构造函数实例化 bean 对象。过程较为复杂，如下： protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) { // 解析 bean，将 bean 类名解析为 class 引用 Class&lt;?> beanClass = resolveBeanClass(mbd, beanName); if (beanClass != null &amp;&amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;&amp; !mbd.isNonPublicAccessAllowed()) { throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Bean class isn't public, and non-public access not allowed: \" + beanClass.getName()); } // 如果存在 Supplier 回调，则使用给定的回调方法初始化策略 Supplier&lt;?> instanceSupplier = mbd.getInstanceSupplier(); if (instanceSupplier != null) { return obtainFromSupplier(instanceSupplier, beanName); } // 如果工厂方法不为空，则使用工厂方法初始化策略 if (mbd.getFactoryMethodName() != null) { return instantiateUsingFactoryMethod(beanName, mbd, args); } boolean resolved = false; boolean autowireNecessary = false; if (args == null) { // constructorArgumentLock 构造函数的常用锁 synchronized (mbd.constructorArgumentLock) { // 如果已缓存的解析的构造函数或者工厂方法不为空，则可以利用构造函数解析 // 因为需要根据参数确认到底使用哪个构造函数，该过程比较消耗性能，所有采用缓存机制 if (mbd.resolvedConstructorOrFactoryMethod != null) { resolved = true; autowireNecessary = mbd.constructorArgumentsResolved; } } } // 已经解析好了，直接注入即可 if (resolved) { // 自动注入，调用构造函数自动注入 if (autowireNecessary) { return autowireConstructor(beanName, mbd, null, null); } else { // 使用默认构造函数构造 return instantiateBean(beanName, mbd); } } // 确定解析的构造函数 // 主要是检查已经注册的 SmartInstantiationAwareBeanPostProcessor Constructor&lt;?>[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName); if (ctors != null || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_CONSTRUCTOR || mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args)) { // 构造函数自动注入 return autowireConstructor(beanName, mbd, ctors, args); } //使用默认构造函数注入 return instantiateBean(beanName, mbd); } 实例化 bean 是一个复杂的过程，其主要的逻辑为： 如果存在 Supplier 回调，则调用 obtainFromSupplier() 进行初始化 如果存在工厂方法，则使用工厂方法进行初始化 首先判断缓存，如果缓存中存在，即已经解析过了，则直接使用已经解析了的，根据 constructorArgumentsResolved 参数来判断是使用构造函数自动注入还是默认构造函数 如果缓存中没有，则需要先确定到底使用哪个构造函数来完成解析工作，因为一个类有多个构造函数，每个构造函数都有不同的构造参数，所以需要根据参数来锁定构造函数并完成初始化，如果存在参数则使用相应的带有参数的构造函数，否则使用默认构造函数。 其实核心思想还是在于根据不同的情况执行不同的实例化策略，主要是包括如下四种策略： Supplier 回调 instantiateUsingFactoryMethod() 工厂方法初始化 autowireConstructor()，构造函数自动注入初始化 instantiateBean()，默认构造函数注入 其实无论哪种策略，他们的实现逻辑都差不多：确定构造函数和构造方法，然后实例化。只不过相对于 Supplier 回调和默认构造函数注入而言，工厂方法初始化和构造函数自动注入初始化会比较复杂，因为他们构造函数和构造参数的不确定性，Spring 需要花大量的精力来确定构造函数和构造参数，如果确定了则好办，直接选择实例化策略即可。当然在实例化的时候会根据是否有需要覆盖或者动态替换掉的方法，因为存在覆盖或者织入的话需要创建动态代理将方法织入，这个时候就只能选择 CGLIB 的方式来实例化，否则直接利用反射的方式即可。 属性填充属性填充其实就是将 BeanDefinition 的属性值赋值给 BeanWrapper 实例对象的过程。在填充的过程需要根据注入的类型不同来区分是根据类型注入还是名字注入，当然在这个过程还会涉及循环依赖的问题的。 protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) { // 没有实例化对象 if (bw == null) { // 有属性抛出异常 if (mbd.hasPropertyValues()) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Cannot apply property values to null instance\"); } else { // 没有属性直接返回 return; } } // 在设置属性之前给 InstantiationAwareBeanPostProcessors 最后一次改变 bean 的机会 boolean continueWithPropertyPopulation = true; // bena 不是\"合成\"的，即未由应用程序本身定义 // 是否持有 InstantiationAwareBeanPostProcessor if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) { // 迭代所有的 BeanPostProcessors for (BeanPostProcessor bp : getBeanPostProcessors()) { // 如果为 InstantiationAwareBeanPostProcessor if (bp instanceof InstantiationAwareBeanPostProcessor) { InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; // 返回值为是否继续填充 bean // postProcessAfterInstantiation：如果应该在 bean上面设置属性则返回true，否则返回false // 一般情况下，应该是返回true，返回 false 的话， // 将会阻止在此 Bean 实例上调用任何后续的 InstantiationAwareBeanPostProcessor 实例。 if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) { continueWithPropertyPopulation = false; break; } } } } // 如果后续处理器发出停止填充命令，则终止后续操作 if (!continueWithPropertyPopulation) { return; } // bean 的属性值 PropertyValues pvs = (mbd.hasPropertyValues() ? mbd.getPropertyValues() : null); if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) { // 将 PropertyValues 封装成 MutablePropertyValues 对象 // MutablePropertyValues 允许对属性进行简单的操作， // 并提供构造函数以支持Map的深度复制和构造。 MutablePropertyValues newPvs = new MutablePropertyValues(pvs); // 根据名称自动注入 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME) { autowireByName(beanName, mbd, bw, newPvs); } // 根据类型自动注入 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) { autowireByType(beanName, mbd, bw, newPvs); } pvs = newPvs; } // 是否已经注册了 InstantiationAwareBeanPostProcessors boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors(); // 是否需要进行依赖检查 boolean needsDepCheck = (mbd.getDependencyCheck() != RootBeanDefinition.DEPENDENCY_CHECK_NONE); if (hasInstAwareBpps || needsDepCheck) { if (pvs == null) { pvs = mbd.getPropertyValues(); } // 从 bw 对象中提取 PropertyDescriptor 结果集 // PropertyDescriptor：可以通过一对存取方法提取一个属性 PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); if (hasInstAwareBpps) { for (BeanPostProcessor bp : getBeanPostProcessors()) { if (bp instanceof InstantiationAwareBeanPostProcessor) { InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; // 对所有需要依赖检查的属性进行后处理 pvs = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvs == null) { return; } } } } if (needsDepCheck) { // 依赖检查，对应 depends-on 属性 checkDependencies(beanName, mbd, filteredPds, pvs); } } if (pvs != null) { // 将属性应用到 bean 中 applyPropertyValues(beanName, mbd, bw, pvs); } } 处理流程如下： 根据 hasInstantiationAwareBeanPostProcessors 属性来判断是否需要在注入属性之前给 InstantiationAwareBeanPostProcessors 最后一次改变 bean 的机会，此过程可以控制 Spring 是否继续进行属性填充。 根据注入类型的不同来判断是根据名称来自动注入（autowireByName()）还是根据类型来自动注入（autowireByType()），统一存入到 PropertyValues 中，PropertyValues 用于描述 bean 的属性。 判断是否需要进行 BeanPostProcessor 和 依赖检测。 将所有 PropertyValues 中的属性填充到 BeanWrapper 中。 初始化 bean初始化 bean 为 createBean() 的最后一个过程，该过程主要做三件事情： 激活 Aware 方法 后置处理器的应用 激活自定义的 init 方法 protected Object initializeBean(final String beanName, final Object bean, @Nullable RootBeanDefinition mbd) { if (System.getSecurityManager() != null) { AccessController.doPrivileged((PrivilegedAction&lt;Object>) () -> { // 激活 Aware 方法 invokeAwareMethods(beanName, bean); return null; }, getAccessControlContext()); } else { // 对特殊的 bean 处理：Aware、BeanClassLoaderAware、BeanFactoryAware invokeAwareMethods(beanName, bean); } Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) { // 后处理器 wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); } try { // 激活用户自定义的 init 方法 invokeInitMethods(beanName, wrappedBean, mbd); } catch (Throwable ex) { throw new BeanCreationException( (mbd != null ? mbd.getResourceDescription() : null), beanName, \"Invocation of init method failed\", ex); } if (mbd == null || !mbd.isSynthetic()) { // 后处理器 wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); } return wrappedBean; } 从 bean 实例中获取对象无论是从单例缓存中获取的 bean 实例 还是通过 createBean() 创建的 bean 实例，最终都会调用 getObjectForBeanInstance() ，该方法是根据传入的 bean 实例获取对象，按照 Spring 的传统，该方法也只是做一些检测工作，真正的实现逻辑是委托给 getObjectFromFactoryBean() 实现。 protected Object getObjectFromFactoryBean(FactoryBean&lt;?> factory, String beanName, boolean shouldPostProcess) { // 为单例模式且缓存中存在 if (factory.isSingleton() &amp;&amp; containsSingleton(beanName)) { synchronized (getSingletonMutex()) { // 从缓存中获取指定的 factoryBean Object object = this.factoryBeanObjectCache.get(beanName); if (object == null) { // 为空，则从 FactoryBean 中获取对象 object = doGetObjectFromFactoryBean(factory, beanName); // 从缓存中获取 Object alreadyThere = this.factoryBeanObjectCache.get(beanName); // **我实在是不明白这里这么做的原因，这里是干嘛？？？** if (alreadyThere != null) { object = alreadyThere; } else { // 需要后续处理 if (shouldPostProcess) { // 若该 bean 处于创建中，则返回非处理对象，而不是存储它 if (isSingletonCurrentlyInCreation(beanName)) { return object; } // 前置处理 beforeSingletonCreation(beanName); try { // 对从 FactoryBean 获取的对象进行后处理 // 生成的对象将暴露给bean引用 object = postProcessObjectFromFactoryBean(object, beanName); } catch (Throwable ex) { throw new BeanCreationException(beanName, \"Post-processing of FactoryBean's singleton object failed\", ex); } finally { // 后置处理 afterSingletonCreation(beanName); } } // 缓存 if (containsSingleton(beanName)) { this.factoryBeanObjectCache.put(beanName, object); } } } return object; } } else { // 非单例 Object object = doGetObjectFromFactoryBean(factory, beanName); if (shouldPostProcess) { try { object = postProcessObjectFromFactoryBean(object, beanName); } catch (Throwable ex) { throw new BeanCreationException(beanName, \"Post-processing of FactoryBean's object failed\", ex); } } return object; } } 主要流程如下： 若为单例且单例 bean 缓存中存在 beanName，则进行后续处理（跳转到下一步），否则则从 FactoryBean 中获取 bean 实例对象，如果接受后置处理，则调用 postProcessObjectFromFactoryBean() 进行后置处理。 首先获取锁（其实我们在前面篇幅中发现了大量的同步锁，锁住的对象都是 this.singletonObjects， 主要是因为在单例模式中必须要保证全局唯一），然后从 factoryBeanObjectCache 缓存中获取实例对象 object，若 object 为空，则调用 doGetObjectFromFactoryBean()方法从 FactoryBean 获取对象，其实内部就是调用 FactoryBean.getObject()。 如果需要后续处理，则进行进一步处理，步骤如下： 若该 bean 处于创建中（isSingletonCurrentlyInCreation），则返回非处理对象，而不是存储它 调用 beforeSingletonCreation() 进行创建之前的处理。默认实现将该 bean 标志为当前创建的。 调用 postProcessObjectFromFactoryBean() 对从 FactoryBean 获取的 bean 实例对象进行后置处理，默认实现是按照原样直接返回，具体实现是在 AbstractAutowireCapableBeanFactory 中实现的，当然子类也可以重写它，比如应用后置处理 调用 afterSingletonCreation() 进行创建 bean 之后的处理，默认实现是将该 bean 标记为不再在创建中。 最后加入到 FactoryBeans 缓存中。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之Bean的初始化","date":"2020-01-21T03:19:45.000Z","path":"2020/01/21/e8e94997.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=2890 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE 一个 bean 经历了 createBeanInstance() 被创建出来，然后又经过一番属性注入，依赖处理，历经千辛万苦，千锤百炼，终于有点儿 bean 实例的样子，能堪大任了，只需要经历最后一步就破茧成蝶了。 这最后一步就是初始化，也就是 initializeBean()，所以这篇文章我们分析 doCreateBean() 中最后一步：初始化 bean。 protected Object initializeBean(final String beanName, final Object bean, @Nullable RootBeanDefinition mbd) { if (System.getSecurityManager() != null) { AccessController.doPrivileged((PrivilegedAction&lt;Object>) () -> { // 激活 Aware 方法 invokeAwareMethods(beanName, bean); return null; }, getAccessControlContext()); } else { // 对特殊的 bean 处理：Aware、BeanClassLoaderAware、BeanFactoryAware invokeAwareMethods(beanName, bean); } Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) { // 后处理器 wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); } try { // 激活用户自定义的 init 方法 invokeInitMethods(beanName, wrappedBean, mbd); } catch (Throwable ex) { throw new BeanCreationException( (mbd != null ? mbd.getResourceDescription() : null), beanName, \"Invocation of init method failed\", ex); } if (mbd == null || !mbd.isSynthetic()) { // 后处理器 wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); } return wrappedBean; } 初始化 bean 的方法其实就是三个步骤的处理，而这三个步骤主要还是根据用户设定的来进行初始化，这三个过程为： 激活 Aware 方法 后置处理器的应用 激活自定义的 init 方法 激活 Aware 方法 Aware ,英文翻译是意识到的，感知的，Spring 提供了诸多类似xxxxAware 的接口用于辅助 Spring Bean 以编程的方式调用 Spring 容器，通过实现这些接口，可以增强 Spring Bean 的功能。 Spring 提供了如下系列的 Aware 接口： LoadTimeWeaverAware：加载Spring Bean时织入第三方模块，如AspectJ BeanClassLoaderAware：加载Spring Bean的类加载器 BootstrapContextAware：资源适配器BootstrapContext，如JCA,CCI ResourceLoaderAware：底层访问资源的加载器 BeanFactoryAware：声明BeanFactory PortletConfigAware：PortletConfig PortletContextAware：PortletContext ServletConfigAware：ServletConfig ServletContextAware：ServletContext MessageSourceAware：国际化 ApplicationEventPublisherAware：应用事件 NotificationPublisherAware：JMX通知 BeanNameAware：声明Spring Bean的名字 invokeAwareMethods() 源码如下： private void invokeAwareMethods(final String beanName, final Object bean) { if (bean instanceof Aware) { if (bean instanceof BeanNameAware) { ((BeanNameAware) bean).setBeanName(beanName); } if (bean instanceof BeanClassLoaderAware) { ClassLoader bcl = getBeanClassLoader(); if (bcl != null) { ((BeanClassLoaderAware) bean).setBeanClassLoader(bcl); } } if (bean instanceof BeanFactoryAware) { ((BeanFactoryAware) bean).setBeanFactory(AbstractAutowireCapableBeanFactory.this); } } } 这里代码就没有什么好说的，主要是处理 BeanNameAware、BeanClassLoaderAware、BeanFactoryAware。 后置处理器的应用 BeanPostProcessor 在前面介绍 bean 加载的过程曾多次遇到，这是 Spring 中开放式框架中必不可少的一个亮点。 BeanPostProcessor 的作用是：如果我们想要在 Spring 容器完成 Bean 的实例化，配置和其他的初始化后添加一些自己的逻辑处理，那么请使用该接口，这个接口给与了用户充足的权限去更改或者扩展 Spring，是我们对 Spring 进行扩展和增强处理一个必不可少的接口。 public Object applyBeanPostProcessorsBeforeInitialization(Object existingBean, String beanName) throws BeansException { Object result = existingBean; for (BeanPostProcessor beanProcessor : getBeanPostProcessors()) { Object current = beanProcessor.postProcessBeforeInitialization(result, beanName); if (current == null) { return result; } result = current; } return result; } @Override public Object applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName) throws BeansException { Object result = existingBean; for (BeanPostProcessor beanProcessor : getBeanPostProcessors()) { Object current = beanProcessor.postProcessAfterInitialization(result, beanName); if (current == null) { return result; } result = current; } return result; } 其实逻辑就是通过 getBeanPostProcessors() 获取定义的 BeanPostProcessor ，然后分别调用其 postProcessBeforeInitialization()、postProcessAfterInitialization() 进行业务处理。 激活自定义的 init 方法 如果熟悉 &lt;bean&gt; 标签的配置，一定不会忘记 init-method 方法，该方法的执行就是在这里执行的。 protected void invokeInitMethods(String beanName, final Object bean, @Nullable RootBeanDefinition mbd) throws Throwable { // 首先会检查是否是 InitializingBean ，如果是的话需要调用 afterPropertiesSet() boolean isInitializingBean = (bean instanceof InitializingBean); if (isInitializingBean &amp;&amp; (mbd == null || !mbd.isExternallyManagedInitMethod(\"afterPropertiesSet\"))) { if (logger.isDebugEnabled()) { logger.debug(\"Invoking afterPropertiesSet() on bean with name '\" + beanName + \"'\"); } if (System.getSecurityManager() != null) { try { AccessController.doPrivileged((PrivilegedExceptionAction&lt;Object>) () -> { ((InitializingBean) bean).afterPropertiesSet(); return null; }, getAccessControlContext()); } catch (PrivilegedActionException pae) { throw pae.getException(); } } else { // 属性初始化的处理 ((InitializingBean) bean).afterPropertiesSet(); } } if (mbd != null &amp;&amp; bean.getClass() != NullBean.class) { String initMethodName = mbd.getInitMethodName(); if (StringUtils.hasLength(initMethodName) &amp;&amp; !(isInitializingBean &amp;&amp; \"afterPropertiesSet\".equals(initMethodName)) &amp;&amp; !mbd.isExternallyManagedInitMethod(initMethodName)) { // 激活用户自定义的 初始化方法 invokeCustomInitMethod(beanName, bean, mbd); } } } 首先检查是否为 InitializingBean ，如果是的话需要执行 afterPropertiesSet()，因为我们除了可以使用 init-method 来自定初始化方法外，还可以实现 InitializingBean 接口，该接口仅有一个 afterPropertiesSet() 方法，而两者的执行先后顺序是先 afterPropertiesSet() 后 init-method。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之循环依赖","date":"2020-01-21T02:41:04.000Z","path":"2020/01/21/7ee1f554.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=2887 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE 这篇分析 doCreateBean() 第三个过程：循环依赖处理。 其实循环依赖并不仅仅只是在 doCreateBean() 中处理，其实在整个加载 bean 的过程中都有涉及，所以下篇内容并不仅仅只局限于 doCreateBean()，而是从整个 Bean 的加载过程进行分析。 什么是循环依赖循环依赖其实就是循环引用，就是两个或者两个以上的 bean 互相引用对方，最终形成一个闭环，如 A 依赖 B，B 依赖 C，C 依赖 A，如下： 循环依赖 其实就是一个死循环的过程，在初始化 A 的时候发现引用了 B，这时就会去初始化 B，然后又发现 B 引用 C，跑去初始化 C，初始化 C 的时候发现引用了 A，则又会去初始化 A，依次循环永不退出，除非有终结条件。 Spring 循环依赖的场景有两种： 构造器的循环依赖 field 属性的循环依赖 对于构造器的循环依赖，Spring 是无法解决的，只能抛出 BeanCurrentlyInCreationException 异常表示循环依赖，所以下面我们分析的都是基于 field 属性的循环依赖。 在博客 IOC 之开启 bean 的加载 中提到，Spring 只解决 scope 为 singleton 的循环依赖，对于scope 为 prototype 的 bean Spring 无法解决，直接抛出 BeanCurrentlyInCreationException 异常。 为什么 Spring 不处理 prototype bean，其实如果理解 Spring 是如何解决 singleton bean 的循环依赖就明白了。 解决循环依赖我们先从加载 bean 最初始的方法 doGetBean() 开始。 在 doGetBean() 中，首先会根据 beanName 从单例 bean 缓存中获取，如果不为空则直接返回。 Object sharedInstance = getSingleton(beanName); 调用 getSingleton() 方法从单例缓存中获取，如下： protected Object getSingleton(String beanName, boolean allowEarlyReference) { Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) { synchronized (this.singletonObjects) { singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) { ObjectFactory&lt;?> singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) { singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); } } } } return singletonObject; } 这个方法主要是从三个缓存中获取，分别是：singletonObjects、earlySingletonObjects、singletonFactories，三者定义如下： /** Cache of singleton objects: bean name --> bean instance */ private final Map&lt;String, Object> singletonObjects = new ConcurrentHashMap&lt;>(256); /** Cache of singleton factories: bean name --> ObjectFactory */ private final Map&lt;String, ObjectFactory&lt;?>> singletonFactories = new HashMap&lt;>(16); /** Cache of early singleton objects: bean name --> bean instance */ private final Map&lt;String, Object> earlySingletonObjects = new HashMap&lt;>(16); 意义如下： singletonObjects：单例对象的cache singletonFactories ： 单例对象工厂的cache earlySingletonObjects ：提前暴光的单例对象的Cache 他们就是 Spring 解决 singleton bean 循环依赖的关键因素所在，我称他们为三级缓存，第一级为 singletonObjects，第二级为 earlySingletonObjects，第三级为 singletonFactories。 这里我们可以通过 getSingleton() 看到他们是如何配合的，这分析该方法之前，提下其中的 isSingletonCurrentlyInCreation() 和 allowEarlyReference。 isSingletonCurrentlyInCreation()：判断当前 singleton bean 是否处于创建中。bean 处于创建中也就是说 bean 在初始化但是没有完成初始化，有一个这样的过程其实和 Spring 解决 bean 循环依赖的理念相辅相成，因为 Spring 解决 singleton bean 的核心就在于提前曝光 bean。 allowEarlyReference：从字面意思上面理解就是允许提前拿到引用。其实真正的意思是是否允许从 singletonFactories 缓存中通过 getObject() 拿到对象，为什么会有这样一个字段呢？原因就在于 singletonFactories 才是 Spring 解决 singleton bean 的诀窍所在，这个我们后续分析。 getSingleton() 整个过程如下： 首先从一级缓存 singletonObjects 获取 如果没有且当前指定的 beanName 正在创建，就再从二级缓存中 earlySingletonObjects 获取 如果还是没有获取到且运行 singletonFactories 通过 getObject() 获取，则从三级缓存 singletonFactories 获取 如果获取到则，通过其 getObject() 获取对象，并将其加入到二级缓存 earlySingletonObjects 中 从三级缓存 singletonFactories 删除，如下： singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); 这样就从三级缓存升级到二级缓存了。 上面是从缓存中获取，但是缓存中的数据从哪里添加进来的呢？一直往下跟会发现在 doCreateBean() ( AbstractAutowireCapableBeanFactory ) 中，有这么一段代码： boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) { if (logger.isDebugEnabled()) { logger.debug(\"Eagerly caching bean '\" + beanName + \"' to allow for resolving potential circular references\"); } addSingletonFactory(beanName, () -> getEarlyBeanReference(beanName, mbd, bean)); } 如果 earlySingletonExposure == true 的话，则调用 addSingletonFactory() 将他们添加到缓存中，但是一个 bean 要具备如下条件才会添加至缓存中： 单例 运行提前暴露 bean 当前 bean 正在创建中 addSingletonFactory() 代码如下： protected void addSingletonFactory(String beanName, ObjectFactory&lt;?> singletonFactory) { Assert.notNull(singletonFactory, \"Singleton factory must not be null\"); synchronized (this.singletonObjects) { if (!this.singletonObjects.containsKey(beanName)) { this.singletonFactories.put(beanName, singletonFactory); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); } } } 从这段代码我们可以看出 singletonFactories 这个三级缓存才是解决 Spring Bean 循环依赖的诀窍所在。 同时这段代码发生在 createBeanInstance() 方法之后，也就是说这个 bean 其实已经被创建出来了，但是它还不是很完美（没有进行属性填充和初始化），但是对于其他依赖它的对象而言已经足够了（可以根据对象引用定位到堆中对象），能够被认出来了，所以 Spring 在这个时候选择将该对象提前曝光出来让大家认识认识。 介绍到这里我们发现三级缓存 singletonFactories 和 二级缓存 earlySingletonObjects 中的值都有出处了，那一级缓存在哪里设置的呢？在类 DefaultSingletonBeanRegistry 中可以发现这个 addSingleton() 方法，源码如下： protected void addSingleton(String beanName, Object singletonObject) { synchronized (this.singletonObjects) { this.singletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); } } 添加至一级缓存，同时从二级、三级缓存中删除。这个方法在我们创建 bean 的链路中有哪个地方引用呢？ 在 doGetBean() 处理不同 scope 时，如果是 singleton，则调用 getSingleton()，如下： 前面几篇博客已经分析了 createBean()，这里就不再阐述了，我们关注方法 getSingleton() 代码如下： public Object getSingleton(String beanName, ObjectFactory&lt;?> singletonFactory) { Assert.notNull(beanName, \"Bean name must not be null\"); synchronized (this.singletonObjects) { Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) { //.... try { singletonObject = singletonFactory.getObject(); newSingleton = true; } //..... if (newSingleton) { addSingleton(beanName, singletonObject); } } return singletonObject; } } 至此，Spring 关于 singleton bean 循环依赖已经分析完毕了。 我们基本上可以确定 Spring 解决循环依赖的方案了： Spring 在创建 bean 的时候并不是等它完全完成，而是在创建过程中将创建中的 bean 的 ObjectFactory 提前曝光（即加入到 singletonFactories 缓存中），这样一旦下一个 bean 创建的时候需要依赖 bean ，则直接使用 ObjectFactory 的 getObject() 获取了，也就是 getSingleton() 中的代码片段了。 到这里，关于 Spring 解决 bean 循环依赖就已经分析完毕了。 最后来描述下就上面那个循环依赖 Spring 解决的过程： 首先 A 完成初始化第一步并将自己提前曝光出来（通过 ObjectFactory 将自己提前曝光），在初始化的时候，发现自己依赖对象 B，此时就会去尝试 get(B)，这个时候发现 B 还没有被创建出来，然后 B 就走创建流程，在 B 初始化的时候，同样发现自己依赖 C，C 也没有被创建出来，这个时候 C 又开始初始化进程，但是在初始化的过程中发现自己依赖 A，于是尝试 get(A)，这个时候由于 A 已经添加至缓存中（一般都是添加至三级缓存 singletonFactories ），通过 ObjectFactory 提前曝光，所以可以通过 ObjectFactory.getObject() 拿到 A 对象，C 拿到 A 对象后顺利完成初始化，然后将自己添加到一级缓存中，回到 B ，B 也可以拿到 C 对象，完成初始化，A 可以顺利拿到 B 完成初始化。到这里整个链路就已经完成了初始化过程了。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之属性填充","date":"2020-01-20T02:51:28.000Z","path":"2020/01/20/1293fb33.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=2885 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE doCreateBean() 主要用于完成 bean 的创建和初始化工作，我们可以将其分为四个过程： 第一个过程实例化 bean 已经在前面两篇博客分析完毕了，这篇博客开始分析 属性填充，也就是 populateBean()，该函数的作用是将 BeanDefinition 中的属性值赋值给 BeanWrapper 实例对象。 protected void populateBean( ]String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) { // 没有实例化对象 if (bw == null) { // 有属性抛出异常 if (mbd.hasPropertyValues()) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Cannot apply property values to null instance\"); } else { // 没有属性直接返回 return; } } // 在设置属性之前给 InstantiationAwareBeanPostProcessors 最后一次改变 bean 的机会 boolean continueWithPropertyPopulation = true; // bena 不是\"合成\"的，即未由应用程序本身定义 // 是否持有 InstantiationAwareBeanPostProcessor if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) { // 迭代所有的 BeanPostProcessors for (BeanPostProcessor bp : getBeanPostProcessors()) { // 如果为 InstantiationAwareBeanPostProcessor if (bp instanceof InstantiationAwareBeanPostProcessor) { InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; // 返回值为是否继续填充 bean // postProcessAfterInstantiation：如果应该在 bean上面设置属性则返回true，否则返回false // 一般情况下，应该是返回true，返回 false 的话， // 将会阻止在此 Bean 实例上调用任何后续的 InstantiationAwareBeanPostProcessor 实例。 if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) { continueWithPropertyPopulation = false; break; } } } } // 如果后续处理器发出停止填充命令，则终止后续操作 if (!continueWithPropertyPopulation) { return; } // bean 的属性值 PropertyValues pvs = (mbd.hasPropertyValues() ? mbd.getPropertyValues() : null); if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) { // 将 PropertyValues 封装成 MutablePropertyValues 对象 // MutablePropertyValues 允许对属性进行简单的操作， // 并提供构造函数以支持Map的深度复制和构造。 MutablePropertyValues newPvs = new MutablePropertyValues(pvs); // 根据名称自动注入 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME) { autowireByName(beanName, mbd, bw, newPvs); } // 根据类型自动注入 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) { autowireByType(beanName, mbd, bw, newPvs); } pvs = newPvs; } // 是否已经注册了 InstantiationAwareBeanPostProcessors boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors(); // 是否需要进行依赖检查 boolean needsDepCheck = (mbd.getDependencyCheck() != RootBeanDefinition.DEPENDENCY_CHECK_NONE); if (hasInstAwareBpps || needsDepCheck) { if (pvs == null) { pvs = mbd.getPropertyValues(); } // 从 bw 对象中提取 PropertyDescriptor 结果集 // PropertyDescriptor：可以通过一对存取方法提取一个属性 PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); if (hasInstAwareBpps) { for (BeanPostProcessor bp : getBeanPostProcessors()) { if (bp instanceof InstantiationAwareBeanPostProcessor) { InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; // 对所有需要依赖检查的属性进行后处理 pvs = ibp.postProcessPropertyValues( pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvs == null) { return; } } } } if (needsDepCheck) { // 依赖检查，对应 depends-on 属性 checkDependencies(beanName, mbd, filteredPds, pvs); } } if (pvs != null) { // 将属性应用到 bean 中 applyPropertyValues(beanName, mbd, bw, pvs); } } 处理流程如下： 根据 hasInstantiationAwareBeanPostProcessors 属性来判断是否需要在注入属性之前给 InstantiationAwareBeanPostProcessors 最后一次改变 bean 的机会，此过程可以控制 Spring 是否继续进行属性填充。 根据注入类型的不同来判断是根据名称来自动注入（autowireByName()）还是根据类型来自动注入（autowireByType()），统一存入到 PropertyValues 中，PropertyValues 用于描述 bean 的属性。 判断是否需要进行 BeanPostProcessor 和 依赖检测。 将所有 PropertyValues 中的属性填充到 BeanWrapper 中。 自动注入Spring 会根据注入类型（ byName / byType ）的不同，调用不同的方法（autowireByName() / autowireByType()）来注入属性值。 autowireByName() 方法 autowireByName() 是根据属性名称完成自动依赖注入的，代码如下： protected void autowireByName( String beanName, AbstractBeanDefinition mbd, BeanWrapper bw, MutablePropertyValues pvs) { // 对 Bean 对象中非简单属性 String[] propertyNames = unsatisfiedNonSimpleProperties(mbd, bw); for (String propertyName : propertyNames) { // 如果容器中包含指定名称的 bean，则将该 bean 注入到 bean中 if (containsBean(propertyName)) { // 递归初始化相关 bean Object bean = getBean(propertyName); // 为指定名称的属性赋予属性值 pvs.add(propertyName, bean); // 属性依赖注入 registerDependentBean(propertyName, beanName); if (logger.isDebugEnabled()) { logger.debug( \"Added autowiring by name from bean name '\" + beanName + \"' via property '\" + propertyName + \"' to bean named '\" + propertyName + \"'\"); } } else { if (logger.isTraceEnabled()) { logger.trace(\"Not autowiring property '\" + propertyName + \"' of bean '\" + beanName + \"' by name: no matching bean found\"); } } } } 该方法逻辑很简单，获取该 bean 的非简单属性，什么叫做非简单属性呢？就是类型为对象类型的属性，但是这里并不是将所有的对象类型都都会找到，比如 8 个原始类型，String 类型 ，Number类型、Date类型、URL类型、URI类型等都会被忽略，如下： protected String[] unsatisfiedNonSimpleProperties( AbstractBeanDefinition mbd, BeanWrapper bw) { Set&lt;String> result = new TreeSet&lt;>(); PropertyValues pvs = mbd.getPropertyValues(); PropertyDescriptor[] pds = bw.getPropertyDescriptors(); for (PropertyDescriptor pd : pds) { if (pd.getWriteMethod() != null &amp;&amp; !isExcludedFromDependencyCheck(pd) &amp;&amp; !pvs.contains(pd.getName()) &amp;&amp; !BeanUtils.isSimpleProperty(pd.getPropertyType())) { result.add(pd.getName()); } } return StringUtils.toStringArray(result); } 过滤条件为：有可写方法、依赖检测中没有被忽略、不是简单属性类型。其实这里获取的就是需要依赖注入的属性。 获取需要依赖注入的属性后，通过迭代、递归的方式初始化相关的 bean，然后调用 registerDependentBean() 完成注册依赖，如下： public void registerDependentBean(String beanName, String dependentBeanName) { String canonicalName = canonicalName(beanName); synchronized (this.dependentBeanMap) { Set&lt;String> dependentBeans = this.dependentBeanMap.computeIfAbsent(canonicalName, k -> new LinkedHashSet&lt;>(8)); if (!dependentBeans.add(dependentBeanName)) { return; } } synchronized (this.dependenciesForBeanMap) { Set&lt;String> dependenciesForBean = this.dependenciesForBeanMap.computeIfAbsent(dependentBeanName, k -> new LinkedHashSet&lt;>(8)); dependenciesForBean.add(canonicalName); } } autowireByType() protected void autowireByType( String beanName, AbstractBeanDefinition mbd, BeanWrapper bw, MutablePropertyValues pvs) { // 获取 TypeConverter 实例 // 使用自定义的 TypeConverter，用于取代默认的 PropertyEditor 机制 TypeConverter converter = getCustomTypeConverter(); if (converter == null) { converter = bw; } Set&lt;String> autowiredBeanNames = new LinkedHashSet&lt;>(4); // 获取非简单属性 String[] propertyNames = unsatisfiedNonSimpleProperties(mbd, bw); for (String propertyName : propertyNames) { try { // 获取 PropertyDescriptor 实例 PropertyDescriptor pd = bw.getPropertyDescriptor(propertyName); // 不要尝试按类型 if (Object.class != pd.getPropertyType()) { // 探测指定属性的 set 方法 MethodParameter methodParam = BeanUtils.getWriteMethodParameter(pd); boolean eager = !PriorityOrdered.class.isInstance(bw.getWrappedInstance()); DependencyDescriptor desc = new AbstractAutowireCapableBeanFactory .AutowireByTypeDependencyDescriptor(methodParam, eager); // 解析指定 beanName 的属性所匹配的值，并把解析到的属性名称存储在 autowiredBeanNames 中 // 当属性存在过个封装 bean 时将会找到所有匹配的 bean 并将其注入 Object autowiredArgument = resolveDependency(desc, beanName, autowiredBeanNames, converter); if (autowiredArgument != null) { pvs.add(propertyName, autowiredArgument); } // 迭代方式注入 bean for (String autowiredBeanName : autowibeanredBeanNames) { registerDependentBean(autowiredBeanName, beanName); if (logger.isDebugEnabled()) { logger.debug(\"Autowiring by type from bean name '\" + beanName + \"' via property '\" + propertyName + \"' to bean named '\" + autowiredBeanName + \"'\"); } } autowiredBeanNames.clear(); } } catch (BeansException ex) { throw new UnsatisfiedDependencyException( mbd.getResourceDescription(), beanName, propertyName, ex); } } } 其实主要过程和根据名称自动注入差不多都是找到需要依赖注入的属性，然后通过迭代的方式寻找所匹配的 bean，最后调用 registerDependentBean() 注册依赖。不过相对于 autowireByName() 而言，根据类型寻找相匹配的 bean 过程比较复杂，下面我们就分析这个复杂的过程，如下： public Object resolveDependency(DependencyDescriptor descriptor, @Nullable String requestingBeanName, @Nullable Set&lt;String> autowiredBeanNames, @Nullable TypeConverter typeConverter) throws BeansException { // 初始化参数名称发现器，该方法并不会在这个时候尝试检索参数名称 // getParameterNameDiscoverer 返回 parameterNameDiscoverer 实例，parameterNameDiscoverer 方法参数名称的解析器 descriptor.initParameterNameDiscovery(getParameterNameDiscoverer()); // 依赖类型为 Optional 类型 if (Optional.class == descriptor.getDependencyType()) { // 创建 Optional 实例依赖类型 return createOptionalDependency(descriptor, requestingBeanName); } // 依赖类型为ObjectFactory、ObjectProvider else if (ObjectFactory.class == descriptor.getDependencyType() || ObjectProvider.class == descriptor.getDependencyType()) { // ObjectFactory / ObjectProvider 用于 用于延迟解析依赖项 return new DefaultListableBeanFactory.DependencyObjectProvider(descriptor, requestingBeanName); } else if (javaxInjectProviderClass == descriptor.getDependencyType()) { // javaxInjectProviderClass 类注入的特殊处理 return new DefaultListableBeanFactory.Jsr330ProviderFactory().createDependencyProvider(descriptor, requestingBeanName); } else { // 为实际依赖关系目标的延迟解析构建代理 // 默认实现返回 null Object result = getAutowireCandidateResolver().getLazyResolutionProxyIfNecessary( descriptor, requestingBeanName); if (result == null) { // 通用处理逻辑 result = doResolveDependency(descriptor, requestingBeanName, autowiredBeanNames, typeConverter); } return result; } } 这里我们关注通用处理逻辑：doResolveDependency()，如下： public Object doResolveDependency( DependencyDescriptor descriptor, @Nullable String beanName, @Nullable Set&lt;String> autowiredBeanNames, @Nullable TypeConverter typeConverter) throws BeansException { // 注入点 InjectionPoint previousInjectionPoint = ConstructorResolver.setCurrentInjectionPoint(descriptor); try { // 针对给定的工厂给定一个快捷实现的方式，例如考虑一些预先解析的信息 // 在进入所有bean的常规类型匹配算法之前，解析算法将首先尝试通过此方法解析快捷方式。 // 子类可以覆盖此方法 Object shortcut = descriptor.resolveShortcut(this); if (shortcut != null) { // 返回快捷的解析信息 return shortcut; } // 依赖的类型 Class&lt;?> type = descriptor.getDependencyType(); // 支持 Spring 的注解 @value Object value = getAutowireCandidateResolver().getSuggestedValue(descriptor); if (value != null) { if (value instanceof String) { String strVal = resolveEmbeddedValue((String) value); BeanDefinition bd = (beanName != null &amp;&amp; containsBean(beanName) ? getMergedBeanDefinition(beanName) : null); value = evaluateBeanDefinitionString(strVal, bd); } TypeConverter converter = (typeConverter != null ? typeConverter : getTypeConverter()); return (descriptor.getField() != null ? converter.convertIfNecessary(value, type, descriptor.getField()) : converter.convertIfNecessary(value, type, descriptor.getMethodParameter())); } // 解析复合 bean，其实就是对 bean 的属性进行解析 // 包括：数组、Collection 、Map 类型 Object multipleBeans = resolveMultipleBeans(descriptor, beanName, autowiredBeanNames, typeConverter); if (multipleBeans != null) { return multipleBeans; } // 查找与类型相匹配的 bean // 返回值构成为：key = 匹配的 beanName，value = beanName 对应的实例化 bean Map&lt;String, Object> matchingBeans = findAutowireCandidates(beanName, type, descriptor); // 没有找到，检验 @autowire 的 require 是否为 true if (matchingBeans.isEmpty()) { // 如果 @autowire 的 require 属性为 true ，但是没有找到相应的匹配项，则抛出异常 if (isRequired(descriptor)) { raiseNoMatchingBeanFound(type, descriptor.getResolvableType(), descriptor); } return null; } String autowiredBeanName; Object instanceCandidate; if (matchingBeans.size() > 1) { // 确认给定 bean autowire 的候选者 // 按照 @Primary 和 @Priority 的顺序 autowiredBeanName = determineAutowireCandidate(matchingBeans, descriptor); if (autowiredBeanName == null) { if (isRequired(descriptor) || !indicatesMultipleBeans(type)) { // 唯一性处理 return descriptor.resolveNotUnique(type, matchingBeans); } else { // 在可选的Collection / Map的情况下， // 默默地忽略一个非唯一的情况：可能它是一个多个常规bean的空集合 return null; } } instanceCandidate = matchingBeans.get(autowiredBeanName); } else { // We have exactly one match. Map.Entry&lt;Staring, Object> entry = matchingBeans.entrySet().iterator().next(); autowiredBeanName = entry.getKey(); instanceCandidate = entry.getValue(); } if (autowiredBeanNames != null) { autowiredBeanNames.add(autowiredBeanName); } if (instanceCandidate instanceof Class) { instanceCandidate = descriptor.resolveCandidate(autowiredBeanName, type, this); } Object result = instanceCandidate; if (result instanceof NullBean) { if (isRequired(descriptor)) { raiseNoMatchingBeanFound(type, descriptor.getResolvableType(), descriptor); } result = null; } if (!ClassUtils.isAssignableValue(type, result)) { throw new BeanNotOfRequiredTypeException( autowiredBeanName, type, instanceCandidate.getClass()); } return result; } finally { ConstructorResolver.setCurrentInjectionPoint(previousInjectionPoint); } } 到这里就已经完成了所有属性的注入了。populateBean() 该方法就已经完成了一大半工作了，下一步则是对依赖 bean 的检测和 PostProcessor 处理，这个我们后面分析，下面分析该方法的最后一步：applyPropertyValues() applyPropertyValues其实上面只是完成了所有注入属性的获取，将获取的属性封装在 PropertyValues 的实例对象 pvs 中，并没有应用到已经实例化的 bean 中，而 applyPropertyValues() 则是完成这一步骤的。 protected void applyPropertyValues( String beanName, BeanDefinition mbd, BeanWrapper bw, PropertyValues pvs) { if (pvs.isEmpty()) { return; } if (System.getSecurityManager() != null &amp;&amp; bw instanceof BeanWrapperImpl) { ((BeanWrapperImpl) bw).setSecurityContext(getAccessControlContext()); } // MutablePropertyValues 类型属性 MutablePropertyValues mpvs = null; // 原始类型 List&lt;PropertyValue> original; if (pvs instanceof MutablePropertyValues) { mpvs = (MutablePropertyValues) pvs; if (mpvs.isConverted()) { try { // 设置到 BeanWrapper 中去 bw.setPropertyValues(mpvs); return; } catch (BeansException ex) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Error setting property values\", ex); } } original = mpvs.getPropertyValueList(); } else { // 如果 pvs 不是 MutablePropertyValues 类型，则直接使用原始类型 original = Arrays.asList(pvs.getPropertyValues()); } // 获取 TypeConverter TypeConverter converter = getCustomTypeConverter(); if (converter == null) { converter = bw; } // 获取对应的解析器 BeanDefinitionValueResolver valueResolver = new BeanDefinitionValueResolver(this, beanName, mbd, converter); // Create a deep copy, resolving any references for values. List&lt;PropertyValue> deepCopy = new ArrayList&lt;>(original.size()); boolean resolveNecessary = false; // 遍历属性，将属性转换为对应类的对应属性的类型 for (PropertyValue pv : original) { if (pv.isConverted()) { deepCopy.add(pv); } else { String propertyName = pv.getName(); Object originalValue = pv.getValue(); Object resolvedValue = valueResolver.resolveValueIfNecessary(pv, originalValue); Object convertedValue = resolvedValue; boolean convertible = bw.isWritableProperty(propertyName) &amp;&amp; !PropertyAccessorUtils.isNestedOrIndexedProperty(propertyName); if (convertible) { convertedValue = convertForProperty(resolvedValue, propertyName, bw, converter); } // Possibly store converted value in merged bean definition, // in order to avoid re-conversion for every created bean instance. if (resolvedValue == originalValue) { if (convertible) { pv.setConvertedValue(convertedValue); } deepCopy.add(pv); } else if (convertible &amp;&amp; originalValue instanceof TypedStringValue &amp;&amp; !((TypedStringValue) originalValue).isDynamic() &amp;&amp; !(convertedValue instanceof Collection || ObjectUtils.isArray(convertedValue))) { pv.setConvertedValue(convertedValue); deepCopy.add(pv); } else { resolveNecessary = true; deepCopy.add(new PropertyValue(pv, convertedValue)); } } } if (mpvs != null &amp;&amp; !resolveNecessary) { mpvs.setConverted(); } // Set our (possibly massaged) deep copy. try { bw.setPropertyValues(new MutablePropertyValues(deepCopy)); } catch (BeansException ex) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Error setting property values\", ex); } } 至此，doCreateBean() 第二个过程：属性填充 已经分析完成了。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之构造函数实例化bean","date":"2020-01-20T01:20:08.000Z","path":"2020/01/20/cdc6fa32.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=2850 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE createBeanInstance() 用于实例化 bean，它会根据不同情况选择不同的实例化策略来完成 bean 的初始化，主要包括： Supplier 回调：obtainFromSupplier() 工厂方法初始化：instantiateUsingFactoryMethod() 构造函数自动注入初始化：autowireConstructor() 默认构造函数注入：instantiateBean() 在( IOC 之 Factory 实例化 bean) 中分析了 Supplier 回调和工厂方法初始化，这篇分析两个构造函数注入。 autowireConstructor()这个初始化方法我们可以简单理解为是带有参数的初始化 bean 。代码段如下： public BeanWrapper autowireConstructor( final String beanName, final RootBeanDefinition mbd, @Nullable Constructor&lt;?>[] chosenCtors, @Nullable final Object[] explicitArgs) { // 封装 BeanWrapperImpl 并完成初始化 BeanWrapperImpl bw = new BeanWrapperImpl(); this.beanFactory.initBeanWrapper(bw); // 构造函数 Constructor&lt;?> constructorToUse = null; // 构造参数 ArgumentsHolder argsHolderToUse = null; Object[] argsToUse = null; /* * 确定构造参数 */ // 如果 getBean() 已经传递，则直接使用 if (explicitArgs != null) { argsToUse = explicitArgs; } else { /* * 尝试从缓存中获取 */ Object[] argsToResolve = null; synchronized (mbd.constructorArgumentLock) { // 缓存中的构造函数或者工厂方法 constructorToUse = (Constructor&lt;?>) mbd.resolvedConstructorOrFactoryMethod; if (constructorToUse != null &amp;&amp; mbd.constructorArgumentsResolved) { // 缓存中的构造参数 argsToUse = mbd.resolvedConstructorArguments; if (argsToUse == null) { argsToResolve = mbd.preparedConstructorArguments; } } } // 缓存中存在,则解析存储在 BeanDefinition 中的参数 // 如给定方法的构造函数 A(int ,int )，则通过此方法后就会把配置文件中的(\"1\",\"1\")转换为 (1,1) // 缓存中的值可能是原始值也有可能是最终值 if (argsToResolve != null) { argsToUse = resolvePreparedArguments(beanName, mbd, bw, constructorToUse, argsToResolve); } } /* * 没有缓存，则尝试从配置文件中获取 */ if (constructorToUse == null) { // 是否需要解析构造器 boolean autowiring = ( chosenCtors != null || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_CONSTRUCTOR); // 用于承载解析后的构造函数参数的值 ConstructorArgumentValues resolvedValues = null; int minNrOfArgs; if (explicitArgs != null) { minNrOfArgs = explicitArgs.length; } else { // 从 BeanDefinition 中获取构造参数，也就是从配置文件中提取构造参数 ConstructorArgumentValues cargs = mbd.getConstructorArgumentValues(); resolvedValues = new ConstructorArgumentValues(); // 解析构造函数的参数 // 将该 bean 的构造函数参数解析为 resolvedValues 对象，其中会涉及到其他 bean minNrOfArgs = resolveConstructorArguments(beanName, mbd, bw, cargs, resolvedValues); } /* * 获取指定的构造函数 */ // 根据前面的判断，chosenCtors 应该为 null Constructor&lt;?>[] candidates = chosenCtors; if (candidates == null) { // 获取 bean 的 class Class&lt;?> beanClass = mbd.getBeanClass(); try { // 根据 class 获取所有的构造函数 candidates = (mbd.isNonPublicAccessAllowed() ? beanClass.getDeclaredConstructors() : beanClass.getConstructors()); } catch (Throwable ex) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Resolution of declared constructors on bean Class [\" + beanClass.getName() + \"] from ClassLoader [\" + beanClass.getClassLoader() + \"] failed\", ex); } } // 对构造函数进行排序处理 // public 构造函数优先参数数量降序，非public 构造函数参数数量降序 AutowireUtils.sortConstructors(candidates); // 最小参数类型权重 int minTypeDiffWeight = Integer.MAX_VALUE; Set&lt;Constructor&lt;?>> ambiguousConstructors = null; LinkedList&lt;UnsatisfiedDependencyException> causes = null; // 迭代所有构造函数 for (Constructor&lt;?> candidate : candidates) { // 获取该构造函数的参数类型 Class&lt;?>[] paramTypes = candidate.getParameterTypes(); // 如果已经找到选用的构造函数或者需要的参数个数小于当前的构造函数参数个数，则终止 // 因为已经按照参数个数降序排列了 if (constructorToUse != null &amp;&amp; argsToUse.length > paramTypes.length) { break; } // 参数个数不等，继续 if (paramTypes.length &lt; minNrOfArgs) { continue; } // 参数持有者 ArgumentsHolder argsHolder; // 有参数 if (resolvedValues != null) { try { // 注释上获取参数名称 String[] paramNames = ConstructorPropertiesChecker.evaluate(candidate, paramTypes.length); if (paramNames == null) { // 获取构造函数、方法参数的探测器 ParameterNameDiscoverer pnd = this.beanFactory.getParameterNameDiscoverer(); if (pnd != null) { // 通过探测器获取构造函数的参数名称 paramNames = pnd.getParameterNames(candidate); } } // 根据构造函数和构造参数创建参数持有者 argsHolder = createArgumentArray( beanName, mbd, resolvedValues, bw, paramTypes, paramNames, getUserDeclaredConstructor(candidate), autowiring); } catch (UnsatisfiedDependencyException ex) { if (this.beanFactory.logger.isTraceEnabled()) { this.beanFactory.logger.trace( \"Ignoring constructor [\" + candidate + \"] of bean '\" + beanName + \"': \" + ex); } // Swallow and try next constructor. if (causes == null) { causes = new LinkedList&lt;>(); } causes.add(ex); continue; } } else { // 构造函数没有参数 if (paramTypes.length != explicitArgs.length) { continue; } argsHolder = new ArgumentsHolder(explicitArgs); } // isLenientConstructorResolution 判断解析构造函数的时候是否以宽松模式还是严格模式 // 严格模式：解析构造函数时，必须所有的都需要匹配，否则抛出异常 // 宽松模式：使用具有\"最接近的模式\"进行匹配 // typeDiffWeight：类型差异权重 int typeDiffWeight = (mbd.isLenientConstructorResolution() ? argsHolder.getTypeDifferenceWeight(paramTypes) : argsHolder.getAssignabilityWeight(paramTypes)); // 如果它代表着当前最接近的匹配则选择其作为构造函数 if (typeDiffWeight &lt; minTypeDiffWeight) { constructorToUse = candidate; argsHolderToUse = argsHolder; argsToUse = argsHolder.arguments; minTypeDiffWeight = typeDiffWeight; ambiguousConstructors = null; } else if (constructorToUse != null &amp;&amp; typeDiffWeight == minTypeDiffWeight) { if (ambiguousConstructors == null) { ambiguousConstructors = new LinkedHashSet&lt;>(); ambiguousConstructors.add(constructorToUse); } ambiguousConstructors.add(candidate); } } if (constructorToUse == null) { if (causes != null) { UnsatisfiedDependencyException ex = causes.removeLast(); for (Exception cause : causes) { this.beanFactory.onSuppressedException(cause); } throw ex; } throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Could not resolve matching constructor \" + \"(hint: specify index/type/name arguments for simple parameters to avoid type ambiguities)\"); } else if (ambiguousConstructors != null &amp;&amp; !mbd.isLenientConstructorResolution()) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Ambiguous constructor matches found in bean '\" + beanName + \"' \" + \"(hint: specify index/type/name arguments for simple parameters to avoid type ambiguities): \" + ambiguousConstructors); } // 将构造函数、构造参数保存到缓存中 if (explicitArgs == null) { argsHolderToUse.storeCache(mbd, constructorToUse); } } try { // 获取创建 bean 的策略 final InstantiationStrategy strategy = beanFactory.getInstantiationStrategy(); Object beanInstance; if (System.getSecurityManager() != null) { final Constructor&lt;?> ctorToUse = constructorToUse; final Object[] argumentsToUse = argsToUse; // 实例化 bean beanInstance = AccessController.doPrivileged( (PrivilegedAction&lt;Object>) () -> strategy.instantiate(mbd, beanName, beanFactory, ctorToUse, argumentsToUse), beanFactory.getAccessControlContext()); } else { // 实例化bean beanInstance = strategy.instantiate( mbd, beanName, this.beanFactory, constructorToUse, argsToUse); } // 将构造的 bean 加入到 BeanWrapper 实例中 bw.setBeanInstance(beanInstance); return bw; } catch (Throwable ex) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Bean instantiation via constructor failed\", ex); } } 代码与 instantiateUsingFactoryMethod() 一样，又长又难懂，但是如果理解了 instantiateUsingFactoryMethod() 初始化 bean 的过程，那么 autowireConstructor() 也不存在什么难的地方了，一句话概括：首先确定构造函数参数、构造函数，然后调用相应的初始化策略进行 bean 的初始化。关于如何确定构造函数、构造参数，该部分逻辑和 instantiateUsingFactoryMethod() 基本一致，所以这里不再重复阐述了，具体过程请移步IOC 之 Factory 实例化 bean，这里我们重点分析初始化策略。 对于初始化策略，首先是获取实例化 bean 的策略，如下： final InstantiationStrategy strategy = beanFactory.getInstantiationStrategy(); 然后是调用其 instantiate()方法，该方法在 SimpleInstantiationStrategy 中实现，如下： public Object instantiate( RootBeanDefinition bd, @Nullable String beanName, BeanFactory owner) { // 没有覆盖 // 直接使用反射实例化即可 if (!bd.hasMethodOverrides()) { // 重新检测获取下构造函数 // 该构造函数是经过前面 N 多复杂过程确认的构造函数 Constructor&lt;?> constructorToUse; synchronized (bd.constructorArgumentLock) { // 获取已经解析的构造函数 constructorToUse = (Constructor&lt;?>) bd.resolvedConstructorOrFactoryMethod; // 如果为 null，从 class 中解析获取，并设置 if (constructorToUse == null) { final Class&lt;?> clazz = bd.getBeanClass(); if (clazz.isInterface()) { throw new BeanInstantiationException(clazz, \"Specified class is an interface\"); } try { if (System.getSecurityManager() != null) { constructorToUse = AccessController.doPrivileged( (PrivilegedExceptionAction&lt;Constructor&lt;?>>) clazz::getDeclaredConstructor); } else { constructorToUse = clazz.getDeclaredConstructor(); } bd.resolvedConstructorOrFactoryMethod = constructorToUse; } catch (Throwable ex) { throw new BeanInstantiationException(clazz, \"No default constructor found\", ex); } } } // 通过BeanUtils直接使用构造器对象实例化bean return BeanUtils.instantiateClass(constructorToUse); } else { // 生成CGLIB创建的子类对象 return instantiateWithMethodInjection(bd, beanName, owner); } } 如果该 bean 没有配置 lookup-method、replaced-method 标签或者 @Lookup 注解，则直接通过反射的方式实例化 bean 即可，方便快捷，但是如果存在需要覆盖的方法或者动态替换的方法则需要使用 CGLIB 进行动态代理，因为可以在创建代理的同时将动态方法织入类中。 反射 调用工具类 BeanUtils 的 instantiateClass() 方法完成反射工作： public static &lt;T> T instantiateClass(Constructor&lt;T> ctor, Object... args) throws BeanInstantiationException { Assert.notNull(ctor, \"Constructor must not be null\"); try { ReflectionUtils.makeAccessible(ctor); return (KotlinDetector.isKotlinType(ctor.getDeclaringClass()) ? KotlinDelegate.instantiateClass(ctor, args) : ctor.newInstance(args)); } // 省略一些 catch } CGLIB protected Object instantiateWithMethodInjection( RootBeanDefinition bd, @Nullable String beanName, BeanFactory owner) { throw new UnsupportedOperationException( \"Method Injection not supported in SimpleInstantiationStrategy\"); } 方法默认是没有实现的，具体过程由其子类 CglibSubclassingInstantiationStrategy 实现： protected Object instantiateWithMethodInjection( RootBeanDefinition bd, @Nullable String beanName, BeanFactory owner) { return instantiateWithMethodInjection(bd, beanName, owner, null); } protected Object instantiateWithMethodInjection (RootBeanDefinition bd, @Nullable String beanName, BeanFactory owner, @Nullable Constructor&lt;?> ctor, @Nullable Object... args) { // 通过CGLIB生成一个子类对象 return new CglibSubclassCreator(bd, owner).instantiate(ctor, args); } 创建一个 CglibSubclassCreator 对象，调用其 instantiate() 方法生成其子类对象： public Object instantiate(@Nullable Constructor&lt;?> ctor, @Nullable Object... args) { // 通过 Cglib 创建一个代理类 Class&lt;?> subclass = createEnhancedSubclass(this.beanDefinition); Object instance; // 没有构造器，通过 BeanUtils 使用默认构造器创建一个bean实例 if (ctor == null) { instance = BeanUtils.instantiateClass(subclass); } else { try { // 获取代理类对应的构造器对象，并实例化 bean Constructor&lt;?> enhancedSubclassConstructor = subclass.getConstructor(ctor.getParameterTypes()); instance = enhancedSubclassConstructor.newInstance(args); } catch (Exception ex) { throw new BeanInstantiationException( this.beanDefinition.getBeanClass(), \"Failed to invoke constructor for CGLIB enhanced subclass [\" + subclass.getName() + \"]\", ex); } } // 为了避免memory leaks异常，直接在bean实例上设置回调对象 Factory factory = (Factory) instance; factory.setCallbacks(new Callback[] { NoOp.INSTANCE, new CglibSubclassingInstantiationStrategy .LookupOverrideMethodInterceptor( this.beanDefinition, this.owner), new CglibSubclassingInstantiationStrategy .ReplaceOverrideMethodInterceptor(this.beanDefinition, this.owner)}); return instance; } 到这类 CGLIB 的方式分析完毕了，当然这里还没有具体分析 CGLIB 生成子类的详细过程，具体的过程等后续分析 AOP 的时候再详细地介绍。 instantiateBean()protected BeanWrapper instantiateBean( final String beanName, final RootBeanDefinition mbd) { try { Object beanInstance; final BeanFactory parent = this; if (System.getSecurityManager() != null) { beanInstance = AccessController .doPrivileged((PrivilegedAction&lt;Object>) () -> getInstantiationStrategy() .instantiate(mbd, beanName, parent), getAccessControlContext()); } else { beanInstance = getInstantiationStrategy().instantiate(mbd, beanName, parent); } BeanWrapper bw = new BeanWrapperImpl(beanInstance); initBeanWrapper(bw); return bw; } catch (Throwable ex) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Instantiation of bean failed\", ex); } } 这个方法相比于 instantiateUsingFactoryMethod() 、 autowireConstructor() 方法实在是太简单了，因为它没有参数，所以不需要确认经过复杂的过来来确定构造器、构造参数，所以这里就不过多阐述了。 对于 createBeanInstance() 而言，他就是选择合适实例化策略来为 bean 创建实例对象，具体的策略有：Supplier 回调方式、工厂方法初始化、构造函数自动注入初始化、默认构造函数注入。 其中工厂方法初始化和构造函数自动注入初始化两种方式最为复杂，主要是因为构造函数和构造参数的不确定性，Spring 需要花大量的精力来确定构造函数和构造参数，如果确定了则好办，直接选择实例化策略即可。当然在实例化的时候会根据是否有需要覆盖或者动态替换掉的方法，因为存在覆盖或者织入的话需要创建动态代理将方法织入，这个时候就只能选择 CGLIB 的方式来实例化，否则直接利用反射的方式即可，方便快捷。 到这里 createBeanInstance() 的过程就已经分析完毕了。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之Factory实例化bean","date":"2020-01-19T03:19:07.000Z","path":"2020/01/19/6271d9d2.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=2848 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE 这篇我们关注创建 bean 过程中的第一个步骤：实例化 bean，对应的方法为：createBeanInstance()，如下： protected BeanWrapper createBeanInstance( String beanName, RootBeanDefinition mbd, @Nullable Object[] args) { // 解析 bean，将 bean 类名解析为 class 引用 Class&lt;?> beanClass = resolveBeanClass(mbd, beanName); if (beanClass != null &amp;&amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;&amp; !mbd.isNonPublicAccessAllowed()) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Bean class isn't public, and non-public access not allowed: \" + beanClass.getName()); } // 如果存在 Supplier 回调，则使用给定的回调方法初始化策略 Supplier&lt;?> instanceSupplier = mbd.getInstanceSupplier(); if (instanceSupplier != null) { return obtainFromSupplier(instanceSupplier, beanName); } // 如果工厂方法不为空，则使用工厂方法初始化策略 if (mbd.getFactoryMethodName() != null) { return instantiateUsingFactoryMethod(beanName, mbd, args); } boolean resolved = false; boolean autowireNecessary = false; if (args == null) { // constructorArgumentLock 构造函数的常用锁 synchronized (mbd.constructorArgumentLock) { // 如果已缓存的解析的构造函数或者工厂方法不为空，则可以利用构造函数解析 // 因为需要根据参数确认到底使用哪个构造函数，该过程比较消耗性能，所有采用缓存机制 if (mbd.resolvedConstructorOrFactoryMethod != null) { resolved = true; autowireNecessary = mbd.constructorArgumentsResolved; } } } // 已经解析好了，直接注入即可 if (resolved) { // 自动注入，调用构造函数自动注入 if (autowireNecessary) { return autowireConstructor(beanName, mbd, null, null); } else { // 使用默认构造函数构造 return instantiateBean(beanName, mbd); } } // 确定解析的构造函数 // 主要是检查已经注册的 SmartInstantiationAwareBeanPostProcessor Constructor&lt;?>[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName); if (ctors != null || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_CONSTRUCTOR || mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args)) { // 构造函数自动注入 return autowireConstructor(beanName, mbd, ctors, args); } //使用默认构造函数注入 return instantiateBean(beanName, mbd); } 实例化 bean 是一个复杂的过程，其主要的逻辑为： 如果存在 Supplier 回调，则调用 obtainFromSupplier() 进行初始化 如果存在工厂方法，则使用工厂方法进行初始化 首先判断缓存，如果缓存中存在，即已经解析过了，则直接使用已经解析了的，根据 constructorArgumentsResolved 参数来判断是使用构造函数自动注入还是默认构造函数 如果缓存中没有，则需要先确定到底使用哪个构造函数来完成解析工作，因为一个类有多个构造函数，每个构造函数都有不同的构造参数，所以需要根据参数来锁定构造函数并完成初始化，如果存在参数则使用相应的带有参数的构造函数，否则使用默认构造函数。 下面就上面四种情况做分别说明。 obtainFromSupplier()Supplier&lt;?> instanceSupplier = mbd.getInstanceSupplier(); if (instanceSupplier != null) { return obtainFromSupplier(instanceSupplier, beanName); } 首先从 BeanDefinition 中获取 Supplier，如果不为空，则调用 obtainFromSupplier() 。那么 Supplier 是什么呢？在这之前也没有提到过这个字段。 public interface Supplier&lt;T> { T get(); } Supplier 接口仅有一个功能性的 get()，该方法会返回一个 T 类型的对象，有点儿类似工厂方法。这个接口有什么作用？用于指定创建 bean 的回调，如果我们设置了这样的回调，那么其他的构造器或者工厂方法都会没有用。在什么设置该参数呢？Spring 提供了相应的 setter 方法，如下： public void setInstanceSupplier(@Nullable Supplier&lt;?> instanceSupplier) { this.instanceSupplier = instanceSupplier; } 在构造 BeanDefinition 的时候设置了该值，如下（以 RootBeanDefinition 为例）： public &lt;T> RootBeanDefinition(@Nullable Class&lt;T> beanClass, String scope, @Nullable Supplier&lt;T> instanceSupplier) { super(); setBeanClass(beanClass); setScope(scope); setInstanceSupplier(instanceSupplier); } 如果设置了 instanceSupplier 则调用 obtainFromSupplier() 完成 bean 的初始化，如下： protected BeanWrapper obtainFromSupplier(Supplier&lt;?> instanceSupplier, String beanName) { String outerBean = this.currentlyCreatedBean.get(); this.currentlyCreatedBean.set(beanName); Object instance; try { // 调用 Supplier 的 get()，返回一个对象 instance = instanceSupplier.get(); } finally { if (outerBean != null) { this.currentlyCreatedBean.set(outerBean); } else { this.currentlyCreatedBean.remove(); } } // 根据对象构造 BeanWrapper 对象 BeanWrapper bw = new BeanWrapperImpl(instance); // 初始化 BeanWrapper initBeanWrapper(bw); return bw; } 代码很简单，调用 调用 Supplier 的 get() 方法，获得一个 bean 实例对象，然后根据该实例对象构造一个 BeanWrapper 对象 bw，最后初始化该对象。有关于 BeanWrapper 后面专门出文讲解。 instantiateUsingFactoryMethod()如果存在工厂方法，则调用 instantiateUsingFactoryMethod() 完成 bean 的初始化工作（方法实现比较长，细节比较复杂，各位就硬着头皮看吧）。 protected BeanWrapper instantiateUsingFactoryMethod( String beanName, RootBeanDefinition mbd, @Nullable Object[] explicitArgs) { return new ConstructorResolver(this) .instantiateUsingFactoryMethod(beanName, mbd, explicitArgs); } 构造一个 ConstructorResolver 对象，然后调用其 instantiateUsingFactoryMethod() 方法。ConstructorResolver 是构造方法或者工厂类初始化 bean 的委托类。 public BeanWrapper instantiateUsingFactoryMethod( final String beanName, final RootBeanDefinition mbd, @Nullable final Object[] explicitArgs) { // 构造 BeanWrapperImpl 对象 BeanWrapperImpl bw = new BeanWrapperImpl(); // 初始化 BeanWrapperImpl // 向BeanWrapper对象中添加 ConversionService 对象和属性编辑器 PropertyEditor 对象 // this.beanFactory.initBeanWrapper(bw); Object factoryBean; Class&lt;?> factoryClass; boolean isStatic; // 工厂名不为空 String factoryBeanName = mbd.getFactoryBeanName(); if (factoryBeanName != null) { if (factoryBeanName.equals(beanName)) { throw new BeanDefinitionStoreException( mbd.getResourceDescription(), beanName, \"factory-bean reference points back to the same bean definition\"); } // 获取工厂实例 factoryBean = this.beanFactory.getBean(factoryBeanName); if (mbd.isSingleton() &amp;&amp; this.beanFactory.containsSingleton(beanName)) { throw new ImplicitlyAppearedSingletonException(); } factoryClass = factoryBean.getClass(); isStatic = false; } else { // 工厂名为空，则其可能是一个静态工厂 // 静态工厂创建bean，必须要提供工厂的全类名 if (!mbd.hasBeanClass()) { throw new BeanDefinitionStoreException( mbd.getResourceDescription(), beanName, \"bean definition declares neither a bean class nor a factory-bean reference\"); } factoryBean = null; factoryClass = mbd.getBeanClass(); isStatic = true; } // 工厂方法 Method factoryMethodToUse = null; ConstructorResolver.ArgumentsHolder argsHolderToUse = null; // 参数 Object[] argsToUse = null; // 工厂方法的参数 // 如果指定了构造参数则直接使用 // 在调用 getBean 方法的时候指定了方法参数 if (explicitArgs != null) { argsToUse = explicitArgs; } else { // 没有指定，则尝试从配置文件中解析 Object[] argsToResolve = null; // 首先尝试从缓存中获取 synchronized (mbd.constructorArgumentLock) { // 获取缓存中的构造函数或者工厂方法 factoryMethodToUse = (Method) mbd.resolvedConstructorOrFactoryMethod; if (factoryMethodToUse != null &amp;&amp; mbd.constructorArgumentsResolved) { // 获取缓存中的构造参数 argsToUse = mbd.resolvedConstructorArguments; if (argsToUse == null) { // 获取缓存中的构造函数参数的包可见字段 argsToResolve = mbd.preparedConstructorArguments; } } } // 缓存中存在,则解析存储在 BeanDefinition 中的参数 // 如给定方法的构造函数 A(int ,int )，则通过此方法后就会把配置文件中的(\"1\",\"1\")转换为 (1,1) // 缓存中的值可能是原始值也有可能是最终值 if (argsToResolve != null) { argsToUse = resolvePreparedArguments( beanName, mbd, bw, factoryMethodToUse, argsToResolve); } } // if (factoryMethodToUse == null || argsToUse == null) { // 获取工厂方法的类全名称 factoryClass = ClassUtils.getUserClass(factoryClass); // 获取所有待定方法 Method[] rawCandidates = getCandidateMethods(factoryClass, mbd); // 检索所有方法，这里是对方法进行过滤 List&lt;Method> candidateSet = new ArrayList&lt;>(); for (Method candidate : rawCandidates) { // 如果有static 且为工厂方法，则添加到 candidateSet 中 if (Modifier.isStatic(candidate.getModifiers()) == isStatic &amp;&amp; mbd.isFactoryMethod(candidate)) { candidateSet.add(candidate); } } Method[] candidates = candidateSet.toArray(new Method[0]); // 排序构造函数 // public 构造函数优先参数数量降序，非public 构造函数参数数量降序 AutowireUtils.sortFactoryMethods(candidates); // 用于承载解析后的构造函数参数的值 ConstructorArgumentValues resolvedValues = null; boolean autowiring = (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_CONSTRUCTOR); int minTypeDiffWeight = Integer.MAX_VALUE; Set&lt;Method> ambiguousFactoryMethods = null; int minNrOfArgs; if (explicitArgs != null) { minNrOfArgs = explicitArgs.length; } else { // getBean() 没有传递参数，则需要解析保存在 BeanDefinition 构造函数中指定的参数 if (mbd.hasConstructorArgumentValues()) { // 构造函数的参数 ConstructorArgumentValues cargs = mbd.getConstructorArgumentValues(); resolvedValues = new ConstructorArgumentValues(); // 解析构造函数的参数 // 将该 bean 的构造函数参数解析为 resolvedValues 对象，其中会涉及到其他 bean minNrOfArgs = resolveConstructorArguments(beanName, mbd, bw, cargs, resolvedValues); } else { minNrOfArgs = 0; } } LinkedList&lt;UnsatisfiedDependencyException> causes = null; for (Method candidate : candidates) { // 方法体的参数 Class&lt;?>[] paramTypes = candidate.getParameterTypes(); if (paramTypes.length >= minNrOfArgs) { // 保存参数的对象 ArgumentsHolder argsHolder; // getBean()传递了参数 if (explicitArgs != null){ // 显示给定参数，参数长度必须完全匹配 if (paramTypes.length != explicitArgs.length) { continue; } // 根据参数创建参数持有者 argsHolder = new ArgumentsHolder(explicitArgs); } else { // 为提供参数，解析构造参数 try { String[] paramNames = null; // 获取 ParameterNameDiscoverer 对象 // ParameterNameDiscoverer 是用于解析方法和构造函数的参数名称的接口，为参数名称探测器 ParameterNameDiscoverer pnd = this.beanFactory.getParameterNameDiscoverer(); if (pnd != null) { // 获取指定构造函数的参数名称 paramNames = pnd.getParameterNames(candidate); } // 在已经解析的构造函数参数值的情况下，创建一个参数持有者对象 argsHolder = createArgumentArray( beanName, mbd, resolvedValues, bw, paramTypes, paramNames, candidate, autowiring); } catch (UnsatisfiedDependencyException ex) { if (this.beanFactory.logger.isTraceEnabled()) { this.beanFactory.logger.trace( \"Ignoring factory method [\" + candidate + \"] of bean '\" + beanName + \"': \" + ex); } if (causes == null) { causes = new LinkedList&lt;>(); } causes.add(ex); continue; } } // isLenientConstructorResolution 判断解析构造函数的时候是否以宽松模式还是严格模式 // 严格模式：解析构造函数时，必须所有的都需要匹配，否则抛出异常 // 宽松模式：使用具有\"最接近的模式\"进行匹配 // typeDiffWeight：类型差异权重 int typeDiffWeight = (mbd.isLenientConstructorResolution() ? argsHolder.getTypeDifferenceWeight(paramTypes) :argsHolder.getAssignabilityWeight(paramTypes)); // 代表最接近的类型匹配，则选择作为构造函数 if (typeDiffWeight &lt; minTypeDiffWeight) { factoryMethodToUse = candidate; argsHolderToUse = argsHolder; argsToUse = argsHolder.arguments; minTypeDiffWeight = typeDiffWeight; ambiguousFactoryMethods = null; } // 如果具有相同参数数量的方法具有相同的类型差异权重，则收集此类型选项 // 但是，仅在非宽松构造函数解析模式下执行该检查，并显式忽略重写方法（具有相同的参数签名） else if (factoryMethodToUse != null &amp;&amp; typeDiffWeight == minTypeDiffWeight &amp;&amp; !mbd.isLenientConstructorResolution() &amp;&amp; paramTypes.length == factoryMethodToUse.getParameterCount() &amp;&amp; !Arrays.equals(paramTypes, factoryMethodToUse.getParameterTypes())) { // 查找到多个可匹配的方法 if (ambiguousFactoryMethods == null) { ambiguousFactoryMethods = new LinkedHashSet&lt;>(); ambiguousFactoryMethods.add(factoryMethodToUse); } ambiguousFactoryMethods.add(candidate); } } } // 没有可执行的工厂方法，抛出异常 if (factoryMethodToUse == null) { if (causes != null) { UnsatisfiedDependencyException ex = causes.removeLast(); for (Exception cause : causes) { this.beanFactory.onSuppressedException(cause); } throw ex; } List&lt;String> argTypes = new ArrayList&lt;>(minNrOfArgs); if (explicitArgs != null) { for (Object arg : explicitArgs) { argTypes.add(arg != null ? arg.getClass().getSimpleName() : \"null\"); } } else if (resolvedValues != null){ Set&lt;ConstructorArgumentValues.ValueHolder> valueHolders = new LinkedHashSet&lt;>(resolvedValues.getArgumentCount()); valueHolders.addAll(resolvedValues.getIndexedArgumentValues().values()); valueHolders.addAll(resolvedValues.getGenericArgumentValues()); for (ConstructorArgumentValues.ValueHolder value : valueHolders) { String argType = (value.getType() != null ? ClassUtils.getShortName(value.getType()) : (value.getValue() != null ? value.getValue().getClass().getSimpleName() : \"null\")); argTypes.add(argType); } } String argDesc = StringUtils.collectionToCommaDelimitedString(argTypes); throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"No matching factory method found: \" + (mbd.getFactoryBeanName() != null ? \"factory bean '\" + mbd.getFactoryBeanName() + \"'; \" : \"\") + \"factory method '\" + mbd.getFactoryMethodName() + \"(\" + argDesc + \")'. \" + \"Check that a method with the specified name \" + (minNrOfArgs > 0 ? \"and arguments \" : \"\") + \"exists and that it is \" + (isStatic ? \"static\" : \"non-static\") + \".\"); } else if (void.class == factoryMethodToUse.getReturnType()) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Invalid factory method '\" + mbd.getFactoryMethodName() + \"': needs to have a non-void return type!\"); } else if (ambiguousFactoryMethods != null) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Ambiguous factory method matches found in bean '\" + beanName + \"' \" + \"(hint: specify index/type/name arguments for simple parameters to avoid type ambiguities): \" + ambiguousFactoryMethods); } if (explicitArgs == null &amp;&amp; argsHolderToUse != null) { // 将解析的构造函数加入缓存 argsHolderToUse.storeCache(mbd, factoryMethodToUse); } } try { // 实例化 bean Object beanInstance; if (System.getSecurityManager() != null) { final Object fb = factoryBean; final Method factoryMethod = factoryMethodToUse; final Object[] args = argsToUse; // 通过执行工厂方法来创建bean示例 beanInstance = AccessController.doPrivileged( (PrivilegedAction&lt;Object>) () -> beanFactory.getInstantiationStrategy() .instantiate( mbd, beanName, beanFactory, fb, factoryMethod, args), beanFactory.getAccessControlContext()); } else { // 通过执行工厂方法来创建bean示例 beanInstance = this.beanFactory.getInstantiationStrategy().instantiate( mbd, beanName, this.beanFactory, factoryBean, factoryMethodToUse, argsToUse); } // 包装为 BeanWraper 对象 bw.setBeanInstance(beanInstance); return bw; } catch (Throwable ex) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Bean instantiation via factory method failed\", ex); } } instantiateUsingFactoryMethod() 方法体实在是太大了，处理细节感觉很复杂，中间断断续续的。吐槽这里的代码风格，完全不符合我们前面看的 Spring 代码风格。Spring 的一贯做法是将一个复杂逻辑进行拆分，分为多个细小的模块进行嵌套，每个模块负责一部分功能，模块与模块之间层层嵌套，上一层一般都是对下一层的总结和概括，这样就会使得每一层的逻辑变得清晰易懂。 回归到上面的方法体，虽然代码体量大，但是总体我们还是可看清楚这个方法要做的事情。 一句话概括就是：确定工厂对象，然后获取构造函数和构造参数，最后调用 InstantiationStrategy 对象的 instantiate() 来创建 bean 实例。 下面我们就这个句概括的话进行拆分并详细说明。 确定工厂对象首先获取工厂方法名，若工厂方法名不为空，则调用 beanFactory.getBean() 获取工厂对象，若为空，则可能为一个静态工厂，对于静态工厂则必须提供工厂类的全类名，同时设置 factoryBean = null 构造参数确认 工厂对象确定后，则是确认构造参数。构造参数的确认主要分为三种情况：explicitArgs 参数、缓存中获取、配置文件中解析。 explicitArgs 参数 explicitArgs 参数是我们调用 getBean() 时传递景来，一般该参数，该参数就是用于初始化 bean 时所传递的参数，如果该参数不为空，则可以确定构造函数的参数就是它了。 缓存中获取 在该方法的最后，我们会发现这样一段代码：argsHolderToUse.storeCache(mbd, factoryMethodToUse) ，这段代码主要是将构造函数、构造参数保存到缓存中，如下： public void storeCache(RootBeanDefinition mbd, Executable constructorOrFactoryMethod) { synchronized (mbd.constructorArgumentLock) { mbd.resolvedConstructorOrFactoryMethod = constructorOrFactoryMethod; mbd.constructorArgumentsResolved = true; if (this.resolveNecessary) { mbd.preparedConstructorArguments = this.preparedArguments; } else { mbd.resolvedConstructorArguments = this.arguments; } } } 其中涉及到的几个参数 constructorArgumentLock、resolvedConstructorOrFactoryMethod、constructorArgumentsResolved、resolvedConstructorArguments。这些参数都是跟构造函数、构造函数缓存有关的。 constructorArgumentLock：构造函数的缓存锁 resolvedConstructorOrFactoryMethod：缓存已经解析的构造函数或者工厂方法 constructorArgumentsResolved：标记字段，标记构造函数、参数已经解析了。默认为false resolvedConstructorArguments：缓存已经解析的构造函数参数，包可见字段 所以从缓存中获取就是提取这几个参数的值，如下： synchronized (mbd.constructorArgumentLock) { // 获取缓存中的构造函数或者工厂方法 factoryMethodToUse = (Method) mbd.resolvedConstructorOrFactoryMethod; if (factoryMethodToUse != null &amp;&amp; mbd.constructorArgumentsResolved) { // 获取缓存中的构造参数 argsToUse = mbd.resolvedConstructorArguments; if (argsToUse == null) { // 获取缓存中的构造函数参数的包可见字段 argsToResolve = mbd.preparedConstructorArguments; } } } 如果缓存中存在构造参数，则需要调用 resolvePreparedArguments() 方法进行转换，因为缓存中的值有可能是最终值也有可能不是最终值，比如我们构造函数中的类型为 Integer 类型的 1 ，但是原始的参数类型有可能是 String 类型的 1 ，所以即便是从缓存中得到了构造参数也需要经过一番的类型转换确保参数类型完全对应。 配置文件中解析 即没有通过传递参数的方式传递构造参数，缓存中也没有，那就只能通过解析配置文件获取构造参数了。 在 bean 解析类的博文中我们了解了，配置文件中的信息都会转换到 BeanDefinition 实例对象中，所以配置文件中的参数可以直接通过 BeanDefinition 对象获取。代码如下： if (mbd.hasConstructorArgumentValues()) { // 构造函数的参数 ConstructorArgumentValues cargs = mbd.getConstructorArgumentValues(); resolvedValues = new ConstructorArgumentValues(); // 解析构造函数的参数 // 将该 bean 的构造函数参数解析为 resolvedValues 对象，其中会涉及到其他 bean minNrOfArgs = resolveConstructorArguments(beanName, mbd, bw, cargs, resolvedValues); } 通过 BeanDefinition 的 getConstructorArgumentValues() 就可以获取构造信息了，有了构造信息就可以获取相关的参数值信息了，获取的参数信息包括直接值和引用，这一步骤的处理交由 resolveConstructorArguments() 完成，该方法会将构造参数信息解析为 resolvedValues 对象 并返回解析到的参数个数。 构造函数 确定构造参数后，下一步则是确定构造函数。第一步则是通过 getCandidateMethods() 获取所有的构造方法，同时对构造方法进行刷选，然后在对其进行排序处理（AutowireUtils.sortFactoryMethods(candidates)），排序的主要目的是为了能够更加方便的找到匹配的构造函数，因为构造函数的确认是根据参数个数确认的。 排序的规则是：public 构造函数优先参数数量降序、非 public 构造参数数量降序。 通过迭代 candidates（包含了所有要匹配的构造函数）的方式，一次比较其参数，如果显示提供了参数（explicitArgs != null），则直接比较两者是否相等，如果相等则表示找到了，否则继续比较。 如果没有显示提供参数，则需要获取 ParameterNameDiscoverer 对象，该对象为参数名称探测器，主要用于发现方法和构造函数的参数名称。 将参数包装成 ArgumentsHolder 对象，该对象用于保存参数，我们称之为参数持有者。当将对象包装成 ArgumentsHolder 对象后，我们就可以通过它来进行构造函数匹配，匹配分为严格模式和宽松模式。 严格模式：解析构造函数时，必须所有参数都需要匹配，否则抛出异常 宽松模式：使用具有”最接近的模式”进行匹配 判断的依据是根据 BeanDefinition 的 isLenientConstructorResolution 属性（该参数是我们在构造 AbstractBeanDefinition 对象是传递的）来获取类型差异权重（typeDiffWeight） 的。如果 typeDiffWeight &lt; minTypeDiffWeight ，则代表“最接近的模式”，选择其作为构造函数，否则只有两者具有相同的参数数量且类型差异权重相等才会纳入考虑范围。 至此，构造函数已经确认了。 创建 bean 实例 工厂对象、构造函数、构造参数都已经确认了，则最后一步就是调用 InstantiationStrategy 对象的 instantiate() 来创建 bean 实例，如下： public Object instantiate( RootBeanDefinition bd, @Nullable String beanName, BeanFactory owner, @Nullable Object factoryBean, final Method factoryMethod, @Nullable Object... args) { try { if (System.getSecurityManager() != null) { AccessController.doPrivileged((PrivilegedAction&lt;Object>) () -> { ReflectionUtils.makeAccessible(factoryMethod); return null; }); } else { ReflectionUtils.makeAccessible(factoryMethod); } Method priorInvokedFactoryMethod = currentlyInvokedFactoryMethod.get(); try { currentlyInvokedFactoryMethod.set(factoryMethod); // 执行工厂方法，并返回实例 Object result = factoryMethod.invoke(factoryBean, args); if (result == null) { result = new NullBean(); } return result; } finally { if (priorInvokedFactoryMethod != null) { currentlyInvokedFactoryMethod.set(priorInvokedFactoryMethod); } else { currentlyInvokedFactoryMethod.remove(); } } } // 省略一波 catch } instantiate() 最核心的部分就是利用 Java 反射执行工厂方法并返回创建好的实例，也就是这段代码： Object result = factoryMethod.invoke(factoryBean, args); 到这里 instantiateUsingFactoryMethod() 已经分析完毕了。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之开启Bean的实例化进程","date":"2020-01-19T02:19:06.000Z","path":"2020/01/19/1ad7c22b.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=2846 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE 在上篇博客IOC 之 分析各 scope 的 bean 创建中有一个核心方法没有讲到 createBean() ，该方法的如下： protected abstract Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException; 该方法定义在 AbstractBeanFactory 中。其含义是根据给定的 BeanDefinition 和 args实例化一个 bean 对象，如果该 BeanDefinition 存在父类，则该 BeanDefinition 已经合并了父类的属性。所有 Bean 实例的创建都会委托给该方法实现。 方法接受三个参数： beanName：bean 的名字 mbd：已经合并了父类属性的（如果有的话）BeanDefinition args：用于构造函数或者工厂方法创建 bean 实例对象的参数 该抽象方法的默认实现是在类 AbstractAutowireCapableBeanFactory 中实现，如下： protected Object createBean( String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException { if (logger.isDebugEnabled()) { logger.debug(\"Creating instance of bean '\" + beanName + \"'\"); } RootBeanDefinition mbdToUse = mbd; // 确保此时的 bean 已经被解析了 // 如果获取的class 属性不为null，则克隆该 BeanDefinition // 主要是因为该动态解析的 class 无法保存到到共享的 BeanDefinition Class&lt;?> resolvedClass = resolveBeanClass(mbd, beanName); if (resolvedClass != null &amp;&amp; !mbd.hasBeanClass() &amp;&amp; mbd.getBeanClassName() != null) { mbdToUse = new RootBeanDefinition(mbd); mbdToUse.setBeanClass(resolvedClass); } try { // 验证和准备覆盖方法 mbdToUse.prepareMethodOverrides(); } catch (BeanDefinitionValidationException ex) { throw new BeanDefinitionStoreException(mbdToUse.getResourceDescription(), beanName, \"Validation of method overrides failed\", ex); } try { // 给 BeanPostProcessors 一个机会用来返回一个代理类而不是真正的类实例 // AOP 的功能就是基于这个地方 Object bean = resolveBeforeInstantiation(beanName, mbdToUse); if (bean != null) { return bean; } } catch (Throwable ex) { throw new BeanCreationException(mbdToUse.getResourceDescription(), beanName, \"BeanPostProcessor before instantiation of bean failed\", ex); } try { // 执行真正创建 bean 的过程 Object beanInstance = doCreateBean(beanName, mbdToUse, args); if (logger.isDebugEnabled()) { logger.debug(\"Finished creating instance of bean '\" + beanName + \"'\"); } return beanInstance; } catch (BeanCreationException | ImplicitlyAppearedSingletonException ex) { throw ex; } catch (Throwable ex) { throw new BeanCreationException( mbdToUse.getResourceDescription(), beanName, \"Unexpected exception during bean creation\", ex); } } 过程如下： 解析指定 BeanDefinition 的 class 处理 override 属性 实例化的前置处理 创建 bean 解析指定 BeanDefinition 的 class Class&lt;?> resolvedClass = resolveBeanClass(mbd, beanName) 这个方法主要是解析 bean definition 的 class 类，并将已经解析的 Class 存储在 bean definition 中以供后面使用。如果解析的 class 不为空，则会将该 BeanDefinition 进行克隆至 mbdToUse，这样做的主要目的是以为动态解析的 class 是无法保存到共享的 BeanDefinition 中。 处理 override 属性大家还记得 lookup-method 和 replace-method 这两个配置功能？在博客 【死磕 Spring】—– IOC 之解析Bean：解析 bean 标签（三） 中已经详细分析了这两个标签的用法和解析过程，知道解析过程其实就是讲这两个配置存放在 BeanDefinition 中的 methodOverrides 属性中，我们知道在 bean 实例化的过程中如果检测到存在 methodOverrides，则会动态地位为当前 bean 生成代理并使用对应的拦截器为 bean 做增强处理。具体的实现我们后续分析，现在先看 mbdToUse.prepareMethodOverrides() 都干了些什么事，如下： public void prepareMethodOverrides() throws BeanDefinitionValidationException { if (hasMethodOverrides()) { Set&lt;MethodOverride> overrides = getMethodOverrides().getOverrides(); synchronized (overrides) { for (MethodOverride mo : overrides) { prepareMethodOverride(mo); } } } } 如果存在 methodOverrides 则获取所有的 override method ，然后通过迭代的方法一次调用 prepareMethodOverride() ，如下： protected void prepareMethodOverride(MethodOverride mo) throws BeanDefinitionValidationException { int count = ClassUtils.getMethodCountForName(getBeanClass(), mo.getMethodName()); if (count == 0) { throw new BeanDefinitionValidationException( \"Invalid method override: no method with name '\" + mo.getMethodName() + \"' on class [\" + getBeanClassName() + \"]\"); } else if (count == 1) { mo.setOverloaded(false); } } 根据方法名称从 class 中获取该方法名的个数，如果为 0 则抛出异常，如果 为 1 则设置该重载方法没有被重载。若一个类中存在多个重载方法，则在方法调用的时候还需要根据参数类型来判断到底重载的是哪个方法。在设置重载的时候其实这里做了一个小小优化，那就是当 count == 1 时，设置 overloaded = false，这样表示该方法没有重载，这样在后续调用的时候便可以直接找到方法而不需要进行方法参数的校验。 诚然，其实 mbdToUse.prepareMethodOverrides() 并没有做什么实质性的工作，只是对 methodOverrides 属性做了一些简单的校验而已。 实例化的前置处理 resolveBeforeInstantiation() 的作用是给 BeanPostProcessors 后置处理器返回一个代理对象的机会，其实在调用该方法之前 Spring 一直都没有创建 bean ，那么这里返回一个 bean 的代理类有什么作用呢？作用体现在后面的 if 判断： if (bean != null) { return bean; } 如果代理对象不为空，则直接返回代理对象，这一步骤有非常重要的作用，Spring 后续实现 AOP 就是基于这个地方判断的。 protected Object resolveBeforeInstantiation(String beanName, RootBeanDefinition mbd) { Object bean = null; if (!Boolean.FALSE.equals(mbd.beforeInstantiationResolved)) { if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) { Class&lt;?> targetType = determineTargetType(beanName, mbd); if (targetType != null) { bean = applyBeanPostProcessorsBeforeInstantiation(targetType, beanName); if (bean != null) { bean = applyBeanPostProcessorsAfterInitialization(bean, beanName); } } } mbd.beforeInstantiationResolved = (bean != null); } return bean; } 这个方法核心就在于 applyBeanPostProcessorsBeforeInstantiation() 和 applyBeanPostProcessorsAfterInitialization() 两个方法，before 为实例化前的后处理器应用，after 为实例化后的后处理器应用，由于本文的主题是创建 bean，关于 Bean 的增强处理后续 LZ 会单独出博文来做详细说明。 创建 bean 如果没有代理对象，就只能走常规的路线进行 bean 的创建了，该过程有 doCreateBean() 实现，如下： protected Object doCreateBean( final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException { // BeanWrapper是对Bean的包装，其接口中所定义的功能很简单包括设置获取被包装的对象， // 获取被包装bean的属性描述器 BeanWrapper instanceWrapper = null; // 单例模型，则从未完成的 FactoryBean 缓存中删除 if (mbd.isSingleton()) { anceWrapper = this.factoryBeanInstanceCache.remove(beanName); } // 使用合适的实例化策略来创建新的实例：工厂方法、构造函数自动注入、简单初始化 if (instanceWrapper == null) { instanceWrapper = createBeanInstance(beanName, mbd, args); } // 包装的实例对象 final Object bean = instanceWrapper.getWrappedInstance(); // 包装的实例对象的类型 Class&lt;?> beanType = instanceWrapper.getWrappedClass(); if (beanType != NullBean.class) { mbd.resolvedTargetType = beanType; } // 检测是否有后置处理 // 如果有后置处理，则允许后置处理修改 BeanDefinition synchronized (mbd.postProcessingLock) { if (!mbd.postProcessed) { try { // applyMergedBeanDefinitionPostProcessors // 后置处理修改 BeanDefinition applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); } catch (Throwable ex) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Post-processing of merged bean definition failed\", ex); } mbd.postProcessed = true; } } // 解决单例模式的循环依赖 // 单例模式 &amp; 运行循环依赖&amp;当前单例 bean 是否正在被创建 boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) { if (logger.isDebugEnabled()) { logger.debug(\"Eagerly caching bean '\" + beanName + \"' to allow for resolving potential circular references\"); } // 提前将创建的 bean 实例加入到ectFactory 中 // 这里是为了后期避免循环依赖 addSingletonFactory(beanName, () -> getEarlyBeanReference(beanName, mbd, bean)); } /* * 开始初始化 bean 实例对象 */ Object exposedObject = bean; try { // 对 bean 进行填充，将各个属性值注入，其中，可能存在依赖于其他 bean 的属性 // 则会递归初始依赖 bean populateBean(beanName, mbd, instanceWrapper); // 调用初始化方法 exposedObject = initializeBean(beanName, exposedObject, mbd); } catch (Throwable ex) { if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) { throw (BeanCreationException) ex; } else { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Initialization of bean failed\", ex); } } /** * 循环依赖处理 */ if (earlySingletonExposure) { // 获取 earlySingletonReference Object earlySingletonReference = getSingleton(beanName, false); // 只有在存在循环依赖的情况下，earlySingletonReference 才不会为空 if (earlySingletonReference != null) { // 如果 exposedObject 没有在初始化方法中被改变，也就是没有被增强 if (exposedObject == bean) { exposedObject = earlySingletonReference; } // 处理依赖 else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) { String[] dependentBeans = getDependentBeans(beanName); Set&lt;String> actualDependentBeans = new LinkedHashSet&lt;>(dependentBeans.length); for (String dependentBean : dependentBeans) { if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) { actualDependentBeans.add(dependentBean); } } if (!actualDependentBeans.isEmpty()) { throw new BeanCurrentlyInCreationException( beanName, \"Bean with name '\" + beanName + \"' has been injected into other beans [\" + StringUtils.collectionToCommaDelimitedString(actualDependentBeans) + \"] in its raw version as part of a circular reference, but has eventually been \" +\"wrapped. This means that said other beans do not use the final version of the \" + \"bean. This is often the result of over-eager type matching - consider using \" + \"'getBeanNamesOfType' with the 'allowEagerInit' flag turned off, for example.\"); } } } } try { // 注册 bean registerDisposableBeanIfNecessary(beanName, bean, mbd); } catch (BeanDefinitionValidationException ex) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Invalid destruction signature\", ex); } return exposedObject; } 整体的思路： 如果是单例模式，则清除 factoryBeanInstanceCache 缓存，同时返回 BeanWrapper 实例对象，当然如果存在。 如果缓存中没有 BeanWrapper 或者不是单例模式，则调用 createBeanInstance() 实例化 bean，主要是将 BeanDefinition 转换为 BeanWrapper MergedBeanDefinitionPostProcessor 的应用 单例模式的循环依赖处理 调用 populateBean() 进行属性填充。将所有属性填充至 bean 的实例中 调用 initializeBean() 初始化 bean 依赖检查 注册 DisposableBean doCreateBean() 完成 bean 的创建和初始化工作，内容太多，这里就只列出整体思路，下文开始将该方法进行拆分进行详细讲解，分布从以下几个方面进行阐述： createBeanInstance() 实例化 bean populateBean() 属性填充 循环依赖的处理 initializeBean() 初始化 bean","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之分析各scope的bean创建","date":"2020-01-18T02:23:01.000Z","path":"2020/01/18/13d2205c.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=2839 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE singleton Spring 的 scope 默认为 singleton，其初始化的代码如下： if (mbd.isSingleton()) { sharedInstance = getSingleton(beanName, () -> { try { return createBean(beanName, mbd, args); } catch (BeansException ex) { destroySingleton(beanName); throw ex; } }); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); } 第一部分分析了从缓存中获取单例模式的 bean，但是如果缓存中不存在呢？ 则需要从头开始加载 bean，这个过程由 getSingleton() 实现。 public Object getSingleton(String beanName, ObjectFactory&lt;?> singletonFactory) { Assert.notNull(beanName, \"Bean name must not be null\"); // 全局加锁 synchronized (this.singletonObjects) { // 从缓存中检查一遍 // 因为 singleton 模式其实就是复用已经创建的 bean 所以这步骤必须检查 Object singletonObject = this.singletonObjects.get(beanName); // 为空，开始加载过程 if (singletonObject == null) { // 省略 部分代码 // 加载前置处理 beforeSingletonCreation(beanName); boolean newSingleton = false; // 省略代码 try { // 初始化 bean // 这个过程其实是调用 createBean() 方法 singletonObject = singletonFactory.getObject(); newSingleton = true; } // 省略 catch 部分 } finally { // 后置处理 afterSingletonCreation(beanName); } // 加入缓存中 if (newSingleton) { addSingleton(beanName, singletonObject); } } // 直接返回 return singletonObject; } 其实这个过程并没有真正创建 bean，仅仅只是做了一部分准备和预处理步骤，真正获取单例 bean 的方法其实是由 singletonFactory.getObject() 这部分实现，而 singletonFactory 由回调方法产生。 那么这个方法做了哪些准备呢？ 再次检查缓存是否已经加载过，如果已经加载了则直接返回，否则开始加载过程。 调用 beforeSingletonCreation() 记录加载单例 bean 之前的加载状态，即前置处理。 调用参数传递的 ObjectFactory 的 getObject() 实例化 bean。 调用 afterSingletonCreation() 进行加载单例后的后置处理。 将结果记录并加入值缓存中，同时删除加载 bean 过程中所记录的一些辅助状态。 流程中涉及的三个方法 beforeSingletonCreation() 与 afterSingletonCreation() 在博客 IOC 之 缓存中获取单例 bean 中分析过了，所以这里不再阐述了，我们看另外一个方法 addSingleton()。 protected void addSingleton(String beanName, Object singletonObject) { synchronized (this.singletonObjects) { this.singletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); } } 一个 put、一个 add、两个 remove。 singletonObjects 单例 bean 的缓存 singletonFactories 单例 bean Factory 的缓存 earlySingletonObjects “早期”创建的单例 bean 的缓存 registeredSingletons 已经注册的单例缓存。 加载了单例 bean 后，调用 getObjectForBeanInstance() 从 bean 实例中获取对象。该方法已经在 IOC 之 缓存中获取单例 bean 详细分析了。 原型模式 else if (mbd.isPrototype()) { Object prototypeInstance = null; try { beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); } finally { afterPrototypeCreation(beanName); } bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); } 原型模式的初始化过程很简单：直接创建一个新的实例就可以了。 过程如下： 调用 beforeSingletonCreation() 记录加载原型模式 bean 之前的加载状态，即前置处理。 调用 createBean() 创建一个 bean 实例对象。 调用 afterSingletonCreation() 进行加载原型模式 bean 后的后置处理。 调用 getObjectForBeanInstance() 从 bean 实例中获取对象。 其他作用域 String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); if (scope == null) { throw new IllegalStateException( \"No Scope registered for scope name '\" + scopeName + \"'\"); } try { Object scopedInstance = scope.get(beanName, () -> { beforePrototypeCreation(beanName); try { return createBean(beanName, mbd, args); } finally { afterPrototypeCreation(beanName); } }); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); } catch (IllegalStateException ex) { throw new BeanCreationException( beanName, \"Scope '\" + scopeName + \"' is not active for the current thread; consider \" + \"defining a scoped proxy for this bean if you intend to refer to it from a singleton\", ex); } 核心流程和原型模式一样，只不过获取 bean 实例是由 scope.get() 实现，如下： public Object get(String name, ObjectFactory&lt;?> objectFactory) { // 获取 scope 缓存 Map&lt;String, Object> scope = this.threadScope.get(); Object scopedObject = scope.get(name); if (scopedObject == null) { scopedObject = objectFactory.getObject(); // 加入缓存 scope.put(name, scopedObject); } return scopedObject; } 对于上面三个模块，其中最重要的有两个方法： createBean()和getObjectForBeanInstance()。 这两个方法在上面三个模块都有调用，createBean() 后续详细说明，getObjectForBeanInstance() 在博客IOC 之 缓存中获取单例 bean 中有详细讲解，这里再次阐述下（此段内容来自《Spring 源码深度解析》）：这个方法主要是验证以下我们得到的 bean 的正确性，其实就是检测当前 bean 是否是 FactoryBean 类型的 bean，如果是，那么需要调用该 bean 对应的 FactoryBean 实例的 getObject() 作为返回值。无论是从缓存中获得到的 bean 还是通过不同的 scope 策略加载的 bean 都只是最原始的 bean 状态，并不一定就是我们最终想要的 bean。 举个例子，加入我们需要对工厂 bean 进行处理，那么这里得到的其实是工厂 bean 的初始状态，但是我们真正需要的是工厂 bean 中定义 factory-method 方法中返回的 bean，而 getObjectForBeanInstance() 就是完成这个工作的。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之parentBeanFactory与依赖处理","date":"2020-01-17T01:56:43.000Z","path":"2020/01/17/c4a8e2a2.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=2810 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE 继上篇博客 加载 bean 之 缓存中获取单例 bean,如果从单例缓存中没有获取到单例 bean，则说明两种情况： 该 bean 的 scope 不是 singleton 该 bean 的 scope 是 singleton ,但是没有初始化完成 针对这两种情况 Spring 是如何处理的呢？统一加载并完成初始化！ 这部分内容的篇幅较长，拆分为两部分： 第一部分主要是一些检测、parentBeanFactory 以及依赖处理。 第二部分则是各个 scope 的初始化。 if (isPrototypeCurrentlyInCreation(beanName)) { throw new BeanCurrentlyInCreationException(beanName); } // Check if bean definition exists in this factory. BeanFactory parentBeanFactory = getParentBeanFactory(); if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) { // Not found -> check parent. String nameToLookup = originalBeanName(name); if (parentBeanFactory instanceof AbstractBeanFactory) { return ((AbstractBeanFactory) parentBeanFactory).doGetBean( nameToLookup, requiredType, args, typeCheckOnly); } else if (args != null) { // Delegation to parent with explicit args. return (T) parentBeanFactory.getBean(nameToLookup, args); } else { // No args -> delegate to standard getBean method. return parentBeanFactory.getBean(nameToLookup, requiredType); } } if (!typeCheckOnly) { markBeanAsCreated(beanName); } try { final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); // Guarantee initialization of beans that the current bean depends on. String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) { for (String dep : dependsOn) { if (isDependent(beanName, dep)) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Circular depends-on relationship between '\" + beanName + \"' and '\" + dep + \"'\"); } registerDependentBean(dep, beanName); try { getBean(dep); } catch (NoSuchBeanDefinitionException ex) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"'\" + beanName + \"' depends on missing bean '\" + dep + \"'\", ex); } } } } // 省略很多代码 这段代码主要处理如下几个部分： 检测。若当前 bean 在创建，则抛出 BeanCurrentlyInCreationException 异常。 如果 beanDefinitionMap 中不存在 beanName 的 BeanDefinition（即在 Spring bean 初始化过程中没有加载），则尝试从 parentBeanFactory 中加载。 判断是否为类型检查。 从 mergedBeanDefinitions 中获取 beanName 对应的 RootBeanDefinition，如果这个 BeanDefinition 是子 Bean 的话，则会合并父类的相关属性。 依赖处理。 检测 在前面就提过，Spring 只解决单例模式下的循环依赖，对于原型模式的循环依赖则是抛出 BeanCurrentlyInCreationException 异常，所以首先检查该 beanName 是否处于原型模式下的循环依赖。如下： if (isPrototypeCurrentlyInCreation(beanName)) { throw new BeanCurrentlyInCreationException(beanName); } 调用 isPrototypeCurrentlyInCreation() 判断当前 bean 是否正在创建，如下： protected boolean isPrototypeCurrentlyInCreation(String beanName) { Object curVal = this.prototypesCurrentlyInCreation.get(); return (curVal != null &amp;&amp; (curVal.equals(beanName) || (curVal instanceof Set &amp;&amp; ((Set&lt;?>) curVal).contains(beanName)))); } 其实检测逻辑和单例模式一样，一个“集合”存放着正在创建的 bean，从该集合中进行判断即可，只不过单例模式的“集合”为 Set ，而原型模式的则是 ThreadLocal，prototypesCurrentlyInCreation 定义如下： private final ThreadLocal&lt;Object> prototypesCurrentlyInCreation = new NamedThreadLocal&lt;>(\"Prototype beans currently in creation\"); 检查父类 BeanFactory 若 containsBeanDefinition 中不存在 beanName 相对应的 BeanDefinition，则从 parentBeanFactory 中获取。 // 获取 parentBeanFactory BeanFactory parentBeanFactory = getParentBeanFactory(); // parentBeanFactory 不为空且 beanDefinitionMap 中不存该 name 的 BeanDefinition if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) { // 确定原始 beanName String nameToLookup = originalBeanName(name); // 若为 AbstractBeanFactory 类型，委托父类处理 if (parentBeanFactory instanceof AbstractBeanFactory) { return ((AbstractBeanFactory) parentBeanFactory).doGetBean( nameToLookup, requiredType, args, typeCheckOnly); } else if (args != null) { // 委托给构造函数 getBean() 处理 return (T) parentBeanFactory.getBean(nameToLookup, args); } else { // 没有 args，委托给标准的 getBean() 处理 return parentBeanFactory.getBean(nameToLookup, requiredType); } } 整个过程较为简单，都是委托 parentBeanFactory 的 getBean() 进行处理，只不过在获取之前对 name 进行简单的处理，主要是想获取原始的 beanName，如下： protected String originalBeanName(String name) { String beanName = transformedBeanName(name); if (name.startsWith(FACTORY_BEAN_PREFIX)) { beanName = FACTORY_BEAN_PREFIX + beanName; } return beanName; } transformedBeanName() 是对 name 进行转换，获取真正的 beanName，因为我们传递的可能是 aliasName（这个过程在博客 IOC 之 开启 bean 的加载 中分析 transformedBeanName() 有详细说明），如果 name 是以 “&amp;” 开头的，则加上 “&amp;”，因为在 transformedBeanName() 将 “&amp;” 去掉了，这里补上。 类型检查 参数 typeCheckOnly 是用来判断调用 getBean() 是否为类型检查获取 bean。如果不是仅仅做类型检查则是创建bean，则需要调用 markBeanAsCreated() 记录： protected void markBeanAsCreated(String beanName) { // 没有创建 if (!this.alreadyCreated.contains(beanName)) { // 加上全局锁 synchronized (this.mergedBeanDefinitions) { // 再次检查一次：DCL 双检查模式 if (!this.alreadyCreated.contains(beanName)) { // 从 mergedBeanDefinitions 中删除 beanName， // 并在下次访问时重新创建它。 clearMergedBeanDefinition(beanName); // 添加到已创建bean 集合中 this.alreadyCreated.add(beanName); } } } } 获取 RootBeanDefinition final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); 调用 getMergedLocalBeanDefinition() 获取相对应的 BeanDefinition，如下： protected RootBeanDefinition getMergedLocalBeanDefinition(String beanName) throws BeansException { // 快速从缓存中获取，如果不为空，则直接返回 RootBeanDefinition mbd = this.mergedBeanDefinitions.get(beanName); if (mbd != null) { return mbd; } // 获取 RootBeanDefinition， // 如果返回的 BeanDefinition 是子类 bean 的话，则合并父类相关属性 return getMergedBeanDefinition(beanName, getBeanDefinition(beanName)); } 首先直接从 mergedBeanDefinitions 缓存中获取相应的 RootBeanDefinition，如果存在则直接返回否则调用 getMergedBeanDefinition() 获取 RootBeanDefinition，若获取的 BeanDefinition 为子 BeanDefinition，则需要合并父类的相关属性。 处理依赖 如果一个 bean 有依赖 bean 的话，那么在初始化该 bean 时是需要先初始化它所依赖的 bean。 // 获取依赖。 // 在初始化 bean 时解析 depends-on 标签时设置 String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) { // 迭代依赖 for (String dep : dependsOn) { // 检验依赖的bean 是否已经注册给当前 bean 获取其他传递依赖bean if (isDependent(beanName, dep)) { throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Circular depends-on relationship between '\" + beanName + \"' and '\" + dep + \"'\"); } // 注册到依赖bean中 registerDependentBean(dep, beanName); try { // 调用 getBean 初始化依赖bean getBean(dep); } catch (NoSuchBeanDefinitionException ex) { throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"'\" + beanName + \"' depends on missing bean '\" + dep + \"'\", ex); } } } 这段代码逻辑是：通过迭代的方式依次对依赖 bean 进行检测、校验，如果通过则调用 getBean() 实例化依赖 bean。 isDependent() 是校验该依赖是否已经注册给当前 bean。 protected boolean isDependent(String beanName, String dependentBeanName) { synchronized (this.dependentBeanMap) { return isDependent(beanName, dependentBeanName, null); } } 同步加锁给 dependentBeanMap 对象，然后调用 isDependent() 校验。dependentBeanMap 对象保存的是依赖 beanName 之间的映射关系：beanName - &gt; 依赖 beanName 的集合 private boolean isDependent(String beanName, String dependentBeanName, @Nullable Set&lt;String> alreadySeen) { // alreadySeen 已经检测的依赖 bean if (alreadySeen != null &amp;&amp; alreadySeen.contains(beanName)) { return false; } // 获取原始 beanName String canonicalName = canonicalName(beanName); // 获取当前 beanName 的依赖集合 Set&lt;String> dependentBeans = this.dependentBeanMap.get(canonicalName); // 不存在依赖，返回false if (dependentBeans == null) { return false; } // 存在，则证明存在已经注册的依赖 if (dependentBeans.contains(dependentBeanName)) { return true; } // 递归检测依赖 for (String transitiveDependency : dependentBeans) { if (alreadySeen == null) { alreadySeen = new HashSet&lt;>(); } alreadySeen.add(beanName); if (isDependent(transitiveDependency, dependentBeanName, alreadySeen)) { return true; } } return false; } 如果校验成功，则调用 registerDependentBean() 将该依赖进行注册，便于在销毁 bean 之前对其进行销毁。 public void registerDependentBean(String beanName, String dependentBeanName) { String canonicalName = canonicalName(beanName); synchronized (this.dependentBeanMap) { Set&lt;String> dependentBeans = this.dependentBeanMap.computeIfAbsent( canonicalName, k -> new LinkedHashSet&lt;>(8)); if (!dependentBeans.add(dependentBeanName)) { return; } } synchronized (this.dependenciesForBeanMap) { Set&lt;String> dependenciesForBean = this.dependenciesForBeanMap.computeIfAbsent( dependentBeanName, k -> new LinkedHashSet&lt;>(8)); dependenciesForBean.add(canonicalName); } } 其实将就是该映射关系保存到两个集合中：dependentBeanMap、dependenciesForBeanMap。 最后调用 getBean() 实例化依赖 bean。 至此，加载 bean 的第二个部分也分析完毕了。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之从单例缓存中获取单例bean","date":"2020-01-16T12:33:19.000Z","path":"2020/01/16/c9c155de.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=2808 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE 从这篇博客开始我们开始加载 bean 的第一个步骤，从缓存中获取 bean，代码片段如下： Object sharedInstance = getSingleton(beanName); if (sharedInstance != null &amp;&amp; args == null) { if (logger.isDebugEnabled()) { if (isSingletonCurrentlyInCreation(beanName)) { logger.debug(\"Returning eagerly cached instance of singleton bean '\" + beanName + \"' that is not fully initialized yet - a consequence of a circular reference\"); } else { logger.debug(\"Returning cached instance of singleton bean '\" + beanName + \"'\"); } } bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); } 首先调用 getSingleton() 从缓存中获取 bean，在上篇博客 IOC 之 开启 bean 的加载 提到过，Spring 对单例模式的 bean 只会创建一次，后续如果再获取该 bean 则是直接从单例缓存中获取，该过程就体现在 getSingleton() 中。如下： public Object getSingleton(String beanName) { return getSingleton(beanName, true); } protected Object getSingleton(String beanName, boolean allowEarlyReference) { // 从单例缓冲中加载 bean Object singletonObject = this.singletonObjects.get(beanName); // 缓存中的 bean 为空，且当前 bean 正在创建 if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) { // 加锁 synchronized (this.singletonObjects) { // 从 earlySingletonObjects 获取 singletonObject = this.earlySingletonObjects.get(beanName); // earlySingletonObjects 中没有，且允许提前创建 if (singletonObject == null &amp;&amp; allowEarlyReference) { // 从 singletonFactories 中获取对应的 ObjectFactory ObjectFactory&lt;?> singletonFactory = this.singletonFactories.get(beanName); // ObjectFactory 不为空，则创建 bean if (singletonFactory != null) { singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); } } } } return singletonObject; } 这段代码非常简单，首先从 singletonObjects 中获取，若为空且当前 bean 正在创建中，则从 earlySingletonObjects 中获取，若为空且允许提前创建则从 singletonFactories 中获取相应的 ObjectFactory ，若不为空，则调用其 getObject() 创建 bean，然后将其加入到 earlySingletonObjects，然后从 singletonFactories 删除。 总体逻辑就是根据 beanName 依次检测这三个 Map，若为空，从下一个，否则返回。 这三个 Map 存放的都有各自的功能，如下： singletonObjects ：存放的是单例 bean，对应关系为 bean name --&gt; bean instance earlySingletonObjects：存放的是早期的 bean，对应关系也是 bean name --&gt; bean instance。它与 singletonObjects 区别在于 earlySingletonObjects 中存放的 bean 不一定是完整的，从上面过程中我们可以了解，bean 在创建过程中就已经加入到 earlySingletonObjects 中了，所以当在 bean 的创建过程中就可以通过 getBean() 方法获取。这个 Map 也是解决循环依赖的关键所在。 singletonFactories：存放的是 ObjectFactory，可以理解为创建单例 bean 的 factory，对应关系是 bean name --&gt; ObjectFactory 在上面代码中还有一个非常重要的检测方法 isSingletonCurrentlyInCreation(beanName)，该方法用于判断该 beanName 对应的 bean 是否在创建过程中，注意这个过程讲的是整个工厂中。如下： public boolean isSingletonCurrentlyInCreation(String beanName) { return this.singletonsCurrentlyInCreation.contains(beanName); } 从这段代码中我们可以预测，在 bean 创建过程中都会将其加入到 singletonsCurrentlyInCreation 集合中，具体是在什么时候加的，我们后面分析。 到这里从缓存中获取 bean 的过程已经分析完毕了，我们再看开篇的代码段，从缓存中获取 bean 后，若其不为 null 且 args 为空，则会调用 getObjectForBeanInstance() 处理。 为什么会有这么一段呢？因为我们从缓存中获取的 bean 是最原始的 bean 并不一定使我们最终想要的 bean，怎么办呢？调用 getObjectForBeanInstance() 进行处理，该方法的定义为获取给定 bean 实例的对象，该对象要么是 bean 实例本身，要么就是 FactoryBean 创建的对象，如下： protected Object getObjectForBeanInstance( Object beanInstance, String name, String beanName, @Nullable RootBeanDefinition mbd) { // 若为工厂类引用（name 以 &amp; 开头） if (BeanFactoryUtils.isFactoryDereference(name)) { // 如果是 NullBean，则直接返回 if (beanInstance instanceof NullBean) { return beanInstance; } // 如果 beanInstance 不是 FactoryBean 类型，则抛出异常 if (!(beanInstance instanceof FactoryBean)) { throw new BeanIsNotAFactoryException(transformedBeanName(name), beanInstance.getClass()); } } // 到这里我们就有了一个 bean 实例，当然该实例可能是会是是一个正常的 bean 又或者是一个 FactoryBean // 如果是 FactoryBean，我我们则创建该 bean if (!(beanInstance instanceof FactoryBean) || BeanFactoryUtils.isFactoryDereference(name)) { return beanInstance; } // 加载 FactoryBean Object object = null; // 若 BeanDefinition 为 null，则从缓存中加载 if (mbd == null) { object = getCachedObjectForFactoryBean(beanName); } // 若 object 依然为空，则可以确认，beanInstance 一定是 FactoryBean if (object == null) { FactoryBean&lt;?> factory = (FactoryBean&lt;?>) beanInstance; // if (mbd == null &amp;&amp; containsBeanDefinition(beanName)) { mbd = getMergedLocalBeanDefinition(beanName); } // 是否是用户定义的而不是应用程序本身定义的 boolean synthetic = (mbd != null &amp;&amp; mbd.isSynthetic()); // 核心处理类 object = getObjectFromFactoryBean(factory, beanName, !synthetic); } return object; } 该方法主要是进行检测工作的，主要如下： 若 name 为工厂相关的（以 &amp; 开头），且 beanInstance 为 NullBean 类型则直接返回，如果 beanInstance 不为 FactoryBean 类型则抛出 BeanIsNotAFactoryException 异常。这里主要是校验 beanInstance 的正确性。 如果 beanInstance 不为 FactoryBean 类型或者 name 也不是与工厂相关的，则直接返回。这里主要是对非 FactoryBean 类型处理。 如果 BeanDefinition 为空，则从 factoryBeanObjectCache 中加载，如果还是空，则可以断定 beanInstance 一定是 FactoryBean 类型，则委托 getObjectFromFactoryBean() 方法处理 从上面可以看出 getObjectForBeanInstance() 主要是返回给定的 bean 实例对象，当然该实例对象为非 FactoryBean 类型，对于 FactoryBean 类型的 bean，则是委托 getObjectFromFactoryBean() 从 FactoryBean 获取 bean 实例对象。 protected Object getObjectFromFactoryBean(FactoryBean&lt;?> factory, String beanName, boolean shouldPostProcess) { // 为单例模式且缓存中存在 if (factory.isSingleton() &amp;&amp; containsSingleton(beanName)) { synchronized (getSingletonMutex()) { // 从缓存中获取指定的 factoryBean Object object = this.factoryBeanObjectCache.get(beanName); if (object == null) { // 为空，则从 FactoryBean 中获取对象 object = doGetObjectFromFactoryBean(factory, beanName); // 从缓存中获取 Object alreadyThere = this.factoryBeanObjectCache.get(beanName); // **我实在是不明白这里这么做的原因，这里是干嘛？？？** if (alreadyThere != null) { object = alreadyThere; } else { // 需要后续处理 if (shouldPostProcess) { // 若该 bean 处于创建中，则返回非处理对象，而不是存储它 if (isSingletonCurrentlyInCreation(beanName)) { return object; } // 前置处理 beforeSingletonCreation(beanName); try { // 对从 FactoryBean 获取的对象进行后处理 // 生成的对象将暴露给bean引用 object = postProcessObjectFromFactoryBean(object, beanName); } catch (Throwable ex) { throw new BeanCreationException( beanName, \"Post-processing of FactoryBean's singleton object failed\", ex); } finally { // 后置处理 afterSingletonCreation(beanName); } } // 缓存 if (containsSingleton(beanName)) { this.factoryBeanObjectCache.put(beanName, object); } } } return object; } } else { // 非单例 Object object = doGetObjectFromFactoryBean(factory, beanName); if (shouldPostProcess) { try { object = postProcessObjectFromFactoryBean(object, beanName); } catch (Throwable ex) { throw new BeanCreationException( beanName, \"Post-processing of FactoryBean's object failed\", ex); } } return object; } } 主要流程如下： 若为单例且单例 bean 缓存中存在 beanName，则进行后续处理（跳转到下一步），否则则从 FactoryBean 中获取 bean 实例对象，如果接受后置处理，则调用 postProcessObjectFromFactoryBean() 进行后置处理。 首先获取锁（其实我们在前面篇幅中发现了大量的同步锁，锁住的对象都是 this.singletonObjects， 主要是因为在单例模式中必须要保证全局唯一），然后从 factoryBeanObjectCache 缓存中获取实例对象 object，若 object 为空，则调用 doGetObjectFromFactoryBean()方法从 FactoryBean 获取对象，其实内部就是调用 FactoryBean.getObject()。 如果需要后续处理，则进行进一步处理，步骤如下： 若该 bean 处于创建中（isSingletonCurrentlyInCreation），则返回非处理对象，而不是存储它 调用 beforeSingletonCreation() 进行创建之前的处理。默认实现将该 bean 标志为当前创建的。 调用 postProcessObjectFromFactoryBean() 对从 FactoryBean 获取的 bean 实例对象进行后置处理，默认实现是按照原样直接返回，具体实现是在 AbstractAutowireCapableBeanFactory 中实现的，当然子类也可以重写它，比如应用后置处理 调用 afterSingletonCreation() 进行创建 bean 之后的处理，默认实现是将该 bean 标记为不再在创建中。 最后加入到 FactoryBeans 缓存中。 该方法应该就是创建 bean 实例对象中的核心方法之一了。这里我们关注三个方法：beforeSingletonCreation() 、 afterSingletonCreation() 、 postProcessObjectFromFactoryBean()。可能有小伙伴觉得前面两个方法不是很重要，LZ 可以肯定告诉你，这两方法是非常重要的操作，因为他们记录着 bean 的加载状态，是检测当前 bean 是否处于创建中的关键之处，对解决 bean 循环依赖起着关键作用。before 方法用于标志当前 bean 处于创建中，after 则是移除。其实在这篇博客刚刚开始就已经提到了 isSingletonCurrentlyInCreation() 是用于检测当前 bean 是否处于创建之中，如下： public boolean isSingletonCurrentlyInCreation(String beanName) { return this.singletonsCurrentlyInCreation.contains(beanName); } 是根据 singletonsCurrentlyInCreation 集合中是否包含了 beanName，集合的元素则一定是在 beforeSingletonCreation() 中添加的，如下： protected void beforeSingletonCreation(String beanName) { if (!this.inCreationCheckExclusions.contains(beanName) &amp;&amp; !this.singletonsCurrentlyInCreation.add(beanName)) { throw new BeanCurrentlyInCreationException(beanName); } } afterSingletonCreation() 为移除，则一定就是对 singletonsCurrentlyInCreation 集合 remove 了，如下： protected void afterSingletonCreation(String beanName) { if (!this.inCreationCheckExclusions.contains(beanName) &amp;&amp; !this.singletonsCurrentlyInCreation.remove(beanName)) { throw new IllegalStateException(\"Singleton '\" + beanName + \"' isn't currently in creation\"); } } postProcessObjectFromFactoryBean() 是对从 FactoryBean 处获取的 bean 实例对象进行后置处理，其默认实现是直接返回 object 对象，不做任何处理，子类可以重写，例如应用后处理器。 AbstractAutowireCapableBeanFactory 对其提供了实现，如下： protected Object postProcessObjectFromFactoryBean(Object object, String beanName) { return applyBeanPostProcessorsAfterInitialization(object, beanName); } 该方法的定义为：对所有的 {@code postProcessAfterInitialization} 进行回调注册 BeanPostProcessors，让他们能够后期处理从 FactoryBean 中获取的对象。下面是具体实现： public Object applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName) throws BeansException { Object result = existingBean; for (BeanPostProcessor beanProcessor : getBeanPostProcessors()) { Object current = beanProcessor.postProcessAfterInitialization(result, beanName); if (current == null) { return result; } result = current; } return result; } 对于后置处理器，这里我们不做过多阐述，后面会专门的博文进行详细介绍， 这里我们只需要记住一点：尽可能保证所有 bean 初始化后都会调用注册的 BeanPostProcessor.postProcessAfterInitialization() 方法进行处理，在实际开发过程中大可以针对此特性设计自己的业务逻辑。 至此，从缓存中获取 bean 对象过程已经分析完毕了。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之开启bean的加载","date":"2020-01-15T10:00:37.000Z","path":"2020/01/15/27d87789.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=2806 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE (此图来自《Spring 揭秘》) Spring IOC容器所起的作用如上图所示，它会以某种方式加载 Configuration Metadata，将其解析注册到容器内部，然后回根据这些信息绑定整个系统的对象，最终组装成一个可用的基于轻量级容器的应用系统。 Spring 在实现上述功能中，将整个流程分为两个阶段：容器初始化阶段和加载bean 阶段。 容器初始化阶段：首先通过某种方式加载 Configuration Metadata (主要是依据 Resource、ResourceLoader 两个体系)，然后容器会对加载的 Configuration MetaData 进行解析和分析，并将分析的信息组装成 BeanDefinition，并将其保存注册到相应的 BeanDefinitionRegistry 中。至此，Spring IOC 的初始化工作完成。 加载 bean 阶段：经过容器初始化阶段后，应用程序中定义的 bean 信息已经全部加载到系统中了，当我们显示或者隐式地调用 getBean() 时，则会触发加载 bean 阶段。在这阶段，容器会首先检查所请求的对象是否已经初始化完成了，如果没有，则会根据注册的 bean 信息实例化请求的对象，并为其注册依赖，然后将其返回给请求方。至此第二个阶段也已经完成。 当我们显示或者隐式地调用 getBean() 时，则会触发加载 bean 阶段。如下： public Object getBean(String name) throws BeansException { return doGetBean(name, null, null, false); } 内部调用 doGetBean() 方法，其接受四个参数： name：要获取 bean 的名字 requiredType：要获取 bean 的类型 args：创建 bean 时传递的参数。这个参数仅限于创建 bean 时使用 typeCheckOnly：是否为类型检查 这个方法的代码比较长，各位耐心看下： protected &lt;T> T doGetBean( final String name, @Nullable final Class&lt;T> requiredType, @Nullable final Object[] args, boolean typeCheckOnly) throws BeansException { // 获取 beanName，这里是一个转换动作，将 name 转换Wie beanName final String beanName = transformedBeanName(name); Object bean; // 从缓存中或者实例工厂中获取 bean // *** 这里会涉及到解决循环依赖 bean 的问题 Object sharedInstance = getSingleton(beanName); if (sharedInstance != null &amp;&amp; args == null) { if (logger.isDebugEnabled()) { if (isSingletonCurrentlyInCreation(beanName)) { logger.debug(\"Returning eagerly cached instance of singleton bean '\" + beanName + \"' that is not fully initialized yet - a consequence of a circular reference\"); } else { logger.debug(\"Returning cached instance of singleton bean '\" + beanName + \"'\"); } } bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); } else { // 因为 Spring 只解决单例模式下得循环依赖，在原型模式下如果存在循环依赖则会抛出异常 // **关于循环依赖后续会单独出文详细说明** if (isPrototypeCurrentlyInCreation(beanName)) { throw new BeanCurrentlyInCreationException(beanName); } // 如果容器中没有找到，则从父类容器中加载 BeanFactory parentBeanFactory = getParentBeanFactory(); if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) { String nameToLookup = originalBeanName(name); if (parentBeanFactory instanceof AbstractBeanFactory) { return ((AbstractBeanFactory) parentBeanFactory).doGetBean( nameToLookup, requiredType, args, typeCheckOnly); } else if (args != null) { return (T) parentBeanFactory.getBean(nameToLookup, args); } else { return parentBeanFactory.getBean(nameToLookup, requiredType); } } // 如果不是仅仅做类型检查则是创建bean，这里需要记录 if (!typeCheckOnly) { markBeanAsCreated(beanName); } try { // 从容器中获取 beanName 相应的 GenericBeanDefinition，并将其转换为 RootBeanDefinition final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); // 检查给定的合并的 BeanDefinition checkMergedBeanDefinition(mbd, beanName, args); // 处理所依赖的 bean String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) { for (String dep : dependsOn) { // 若给定的依赖 bean 已经注册为依赖给定的b ean // 循环依赖的情况 if (isDependent(beanName, dep)) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Circular depends-on relationship between '\" + beanName + \"' and '\" + dep + \"'\"); } // 缓存依赖调用 registerDependentBean(dep, beanName); try { getBean(dep); } catch (NoSuchBeanDefinitionException ex) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"'\" + beanName + \"' depends on missing bean '\" + dep + \"'\", ex); } } } // bean 实例化 // 单例模式 if (mbd.isSingleton()) { sharedInstance = getSingleton(beanName, () -> { try { return createBean(beanName, mbd, args); } catch (BeansException ex) { // 显示从单利缓存中删除 bean 实例 // 因为单例模式下为了解决循环依赖，可能他已经存在了，所以销毁它 destroySingleton(beanName); throw ex; } }); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); } // 原型模式 else if (mbd.isPrototype()) { // It's a prototype -> create a new instance. Object prototypeInstance = null; try { beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); } finally { afterPrototypeCreation(beanName); } bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); } else { // 从指定的 scope 下创建 bean String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); if (scope == null) { throw new IllegalStateException( \"No Scope registered for scope name '\" + scopeName + \"'\"); } try { Object scopedInstance = scope.get(beanName, () -> { beforePrototypeCreation(beanName); try { return createBean(beanName, mbd, args); } finally { afterPrototypeCreation(beanName); } }); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); } catch (IllegalStateException ex) { throw new BeanCreationException( beanName, \"Scope '\" + scopeName + \"' is not active for the current thread; consider \" + \"defining a scoped proxy for this bean if you intend to refer to it from a singleton\", ex); } } } catch (BeansException ex) { cleanupAfterBeanCreationFailure(beanName); throw ex; } } // 检查需要的类型是否符合 bean 的实际类型 if (requiredType != null &amp;&amp; !requiredType.isInstance(bean)) { try { T convertedBean = getTypeConverter().convertIfNecessary(bean, requiredType); if (convertedBean == null) { throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); } return convertedBean; } catch (TypeMismatchException ex) { if (logger.isDebugEnabled()) { logger.debug(\"Failed to convert bean '\" + name + \"' to required type '\" + ClassUtils.getQualifiedName(requiredType) + \"'\", ex); } throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); } } return (T) bean; } 代码是相当长，处理逻辑也是相当复杂，下面将其进行拆分阐述。 1.获取 beanName final String beanName = transformedBeanName(name); 这里传递的是 name，不一定就是 beanName，可能是 aliasName，也有可能是 FactoryBean，所以这里需要调用 transformedBeanName() 方法对 name 进行一番转换，主要如下： protected String transformedBeanName(String name) { return canonicalName(BeanFactoryUtils.transformedBeanName(name)); } // 去除 FactoryBean 的修饰符 public static String transformedBeanName(String name) { Assert.notNull(name, \"'name' must not be null\"); String beanName = name; while (beanName.startsWith(BeanFactory.FACTORY_BEAN_PREFIX)) { beanName = beanName.substring(BeanFactory.FACTORY_BEAN_PREFIX.length()); } return beanName; } // 转换 aliasName public String canonicalName(String name) { String canonicalName = name; // Handle aliasing... String resolvedName; do { resolvedName = this.aliasMap.get(canonicalName); if (resolvedName != null) { canonicalName = resolvedName; } } while (resolvedName != null); return canonicalName; } 主要处理过程包括两步： 去除 FactoryBean 的修饰符。如果 name 以 “&amp;” 为前缀，那么会去掉该 “&amp;”，例如，name = &quot;&amp;studentService&quot;，则会是 name = &quot;studentService&quot;。 取指定的 alias 所表示的最终 beanName。主要是一个循环获取 beanName 的过程，例如别名 A 指向名称为 B 的 bean 则返回 B，若 别名 A 指向别名 B，别名 B 指向名称为 C 的 bean，则返回 C。 2.从单例 bean 缓存中获取 bean 对应代码段如下： Object sharedInstance = getSingleton(beanName); if (sharedInstance != null &amp;&amp; args == null) { if (logger.isDebugEnabled()) { if (isSingletonCurrentlyInCreation(beanName)) { logger.debug(\"Returning eagerly cached instance of singleton bean '\" + beanName + \"' that is not fully initialized yet - a consequence of a circular reference\"); } else { logger.debug(\"Returning cached instance of singleton bean '\" + beanName + \"'\"); } } bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); } 我们知道单例模式的 bean 在整个过程中只会被创建一次，第一次创建后会将该 bean 加载到缓存中，后面在获取 bean 就会直接从单例缓存中获取。如果从缓存中得到了 bean，则需要调用 getObjectForBeanInstance() 对 bean 进行实例化处理，因为缓存中记录的是最原始的 bean 状态，我们得到的不一定是我们最终想要的 bean。 3.原型模式依赖检查与 parentBeanFactory 对应代码段 if (isPrototypeCurrentlyInCreation(beanName)) { throw new BeanCurrentlyInCreationException(beanName); } // Check if bean definition exists in this factory. BeanFactory parentBeanFactory = getParentBeanFactory(); if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) { // Not found -> check parent. String nameToLookup = originalBeanName(name); if (parentBeanFactory instanceof AbstractBeanFactory) { return ((AbstractBeanFactory) parentBeanFactory).doGetBean( nameToLookup, requiredType, args, typeCheckOnly); } else if (args != null) { // Delegation to parent with explicit args. return (T) parentBeanFactory.getBean(nameToLookup, args); } else { // No args -> delegate to standard getBean method. return parentBeanFactory.getBean(nameToLookup, requiredType); } } Spring 只处理单例模式下得循环依赖，对于原型模式的循环依赖直接抛出异常。主要原因还是在于 Spring 解决循环依赖的策略有关。对于单例模式 Spring 在创建 bean 的时候并不是等 bean 完全创建完成后才会将 bean 添加至缓存中，而是不等 bean 创建完成就会将创建 bean 的 ObjectFactory 提早加入到缓存中，这样一旦下一个 bean 创建的时候需要依赖 bean 时则直接使用 ObjectFactroy。但是原型模式我们知道是没法使用缓存的，所以 Spring 对原型模式的循环依赖处理策略则是不处理（关于循环依赖后面会有单独文章说明）。 如果容器缓存中没有相对应的 BeanDefinition 则会尝试从父类工厂（parentBeanFactory）中加载，然后再去递归调用 getBean()。 4. 依赖处理 对应源码如下： String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) { for (String dep : dependsOn) { if (isDependent(beanName, dep)) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Circular depends-on relationship between '\" + beanName + \"' and '\" + dep + \"'\"); } registerDependentBean(dep, beanName); try { getBean(dep); } catch (NoSuchBeanDefinitionException ex) { throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"'\" + beanName + \"' depends on missing bean '\" + dep + \"'\", ex); } } } 每个 bean 都不是单独工作的，它会依赖其他 bean，其他 bean 也会依赖它，对于依赖的 bean ，它会优先加载，所以在 Spring 的加载顺序中，在初始化某一个 bean 的时候首先会初始化这个 bean 的依赖。 作用域处理 Spring bean 的作用域默认为 singleton，当然还有其他作用域，如prototype、request、session 等，不同的作用域会有不同的初始化策略。 类型转换 在调用 doGetBean() 方法时，有一个 requiredType 参数，该参数的功能就是将返回的 bean 转换为 requiredType 类型。当然就一般而言我们是不需要进行类型转换的，也就是 requiredType 为空（比如 getBean(String name)），但有可能会存在这种情况，比如我们返回的 bean 类型为 String，我们在使用的时候需要将其转换为 Integer，那么这个时候 requiredType 就有用武之地了。当然我们一般是不需要这样做的。 至此 getBean() 过程讲解完了。后续将会对该过程进行拆分，更加详细的说明，弄清楚其中的来龙去脉，所以这篇博客只能算是 Spring bean 加载过程的一个概览。 拆分主要是分为三个部分： 分析从缓存中获取单例 bean，以及对 bean 的实例中获取对象 如果从单例缓存中获取 bean，Spring 是怎么加载的呢？所以第二部分是分析 bean 加载，以及 bean 的依赖处理 bean 已经加载了，依赖也处理完毕了，第三部分则分析各个作用域的 bean 初始化过程。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IoC之装载BeanDefinitions总结","date":"2020-01-14T04:08:09.000Z","path":"2020/01/14/af13201.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=todo 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE 前面分析了 IoC BeanDefinition 装载的整个过程，这篇就这些内容做一个总结将其连贯起来。 在前文提过，IoC 容器的初始化过程分为三步骤：Resource 定位、BeanDefinition 的载入和解析，BeanDefinition 注册。 Resource 定位。我们一般用外部资源来描述 Bean 对象，所以在初始化 IoC 容器的第一步就是需要定位这个外部资源。在上一篇博客（《IoC 之 Spring 统一资源加载策略》）已经详细说明了资源加载的过程。 BeanDefinition 的装载和解析 装载就是 BeanDefinition 的载入。 读取、解析 Resource 资源，也就是将用户定义的 Bean 表示成 IoC 容器的内部数据结构：BeanDefinition 在 IoC 容器内部维护着一个 BeanDefinition Map 的数据结构 在配置文件中每一个 都对应着一个 BeanDefinition 对象。 BeanDefinition 注册 向 IoC 容器注册在第二步解析好的 BeanDefinition，这个过程是通过 BeanDefinitionRegistry 接口来实现的。 在 IoC 容器内部其实是将第二个过程解析得到的 BeanDefinition 注入到一个 HashMap 容器中，IoC 容器就是通过这个 HashMap 来维护这些 BeanDefinition 的。 在这里需要注意的一点是这个过程并没有完成依赖注入（Bean 创建），Bean 创建是发生在应用第一次调用 #getBean(...) 方法，向容器索要 Bean 时。 当然我们可以通过设置预处理，即对某个 Bean 设置 lazyinit = false 属性，那么这个 Bean 的依赖注入就会在容器初始化的时候完成。 在博客 《 IoC 之加载 BeanDefinition》 中提供过一段代码，这里我们同样也以这段代码作为我们研究 IoC 初始化过程的开端，如下： ClassPathResource resource = new ClassPathResource(\"bean.xml\"); DefaultListableBeanFactory factory = new DefaultListableBeanFactory(); XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(factory); reader.loadBeanDefinitions(resource); 刚刚开始的时候可能对上面这几行代码不知道什么意思，现在应该就一目了然了： ClassPathResource resource = new ClassPathResource(&quot;bean.xml&quot;); ： 根据 Xml 配置文件创建 Resource 资源对象。 ClassPathResource 是 Resource 接口的子类，bean.xml 文件中的内容是我们定义的 Bean 信息。 DefaultListableBeanFactory factory = new DefaultListableBeanFactory(); ：创建一个 BeanFactory 。 DefaultListableBeanFactory 是 BeanFactory 的一个子类，BeanFactory 作为一个接口，其实它本身是不具有独立使用的功能的，而 DefaultListableBeanFactory 则是真正可以独立使用的 IoC 容器，它是整个 Spring IoC 的始祖，在后续会有专门的文章来分析它。 XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(factory); ：创建 XmlBeanDefinitionReader 读取器，用于载入 BeanDefinition 。 reader.loadBeanDefinitions(resource);：开始 BeanDefinition 的载入和注册进程，完成后的 BeanDefinition 放置在 IoC 容器中。 1. Resource 定位Spring 为了解决资源定位的问题，提供了两个接口：Resource、ResourceLoader，其中： Resource 接口是 Spring 统一资源的抽象接口 ResourceLoader 则是 Spring 资源加载的统一抽象。 关于Resource、ResourceLoader 的更多知识请关注 《IoC 之 Spring 统一资源加载策略》 Resource 资源的定位需要 Resource 和 ResourceLoader 两个接口互相配合，在上面那段代码中 new ClassPathResource(&quot;bean.xml&quot;) 为我们定义了资源，那么 ResourceLoader 则是在什么时候初始化的呢？ 看 XmlBeanDefinitionReader 构造方法： // XmlBeanDefinitionReader.java public XmlBeanDefinitionReader(BeanDefinitionRegistry registry) { super(registry); } 直接调用父类 AbstractBeanDefinitionReader 构造方法，代码如下： // AbstractBeanDefinitionReader.java protected AbstractBeanDefinitionReader(BeanDefinitionRegistry registry) { Assert.notNull(registry, \"BeanDefinitionRegistry must not be null\"); this.registry = registry; // Determine ResourceLoader to use. if (this.registry instanceof ResourceLoader) { this.resourceLoader = (ResourceLoader) this.registry; } else { this.resourceLoader = new PathMatchingResourcePatternResolver(); } // Inherit Environment if possible if (this.registry instanceof EnvironmentCapable) { this.environment = ((EnvironmentCapable) this.registry).getEnvironment(); } else { this.environment = new StandardEnvironment(); } } 核心在于设置 resourceLoader 这段，如果设置了 ResourceLoader 则用设置的，否则使用 PathMatchingResourcePatternResolver ，该类是一个集大成者的 ResourceLoader。 2. BeanDefinition 的载入和解析reader.loadBeanDefinitions(resource); 代码段，开启 BeanDefinition 的解析过程。如下： // XmlBeanDefinitionReader.java @Override public int loadBeanDefinitions(Resource resource) throws BeanDefinitionStoreException { return loadBeanDefinitions(new EncodedResource(resource)); } 在这个方法会将资源 resource 包装成一个 EncodedResource 实例对象，然后调用 #loadBeanDefinitions(EncodedResource encodedResource) 方法。 而将 Resource 封装成 EncodedResource 主要是为了对 Resource 进行编码，保证内容读取的正确性。代码如下： // XmlBeanDefinitionReader.java public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException { // ... 省略一些代码 try { // 将资源文件转为 InputStream 的 IO 流 InputStream inputStream = encodedResource.getResource().getInputStream(); try { // 从 InputStream 中得到 XML 的解析源 InputSource inputSource = new InputSource(inputStream); if (encodedResource.getEncoding() != null) { inputSource.setEncoding(encodedResource.getEncoding()); } // ... 具体的读取过程 return doLoadBeanDefinitions(inputSource, encodedResource.getResource()); } finally { inputStream.close(); } } // 省略一些代码 } 从 encodedResource 源中获取 xml 的解析源，然后调用 #doLoadBeanDefinitions(InputSource inputSource, Resource resource) 方法，执行具体的解析过程。 // XmlBeanDefinitionReader.java protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException { try { // 获取 XML Document 实例 Document doc = doLoadDocument(inputSource, resource); // 根据 Document 实例，注册 Bean 信息 int count = registerBeanDefinitions(doc, resource); return count; } // ... 省略一堆配置 } 在该方法中主要做两件事： 1、根据 xml 解析源获取相应的 Document 对象。 2、调用 #registerBeanDefinitions(Document doc, Resource resource) 方法，开启 BeanDefinition 的解析注册过程。 2.1 转换为 Document 对象调用 #doLoadDocument(InputSource inputSource, Resource resource) 方法，会将 Bean 定义的资源转换为 Document 对象。代码如下： // XmlBeanDefinitionReader.java protected Document doLoadDocument(InputSource inputSource, Resource resource) throws Exception { return this.documentLoader.loadDocument(inputSource, getEntityResolver(), this.errorHandler, getValidationModeForResource(resource), isNamespaceAware()); } 该方法接受五个参数： inputSource ：加载 Document 的 Resource 源。 entityResolver：解析文件的解析器。 【重要】详细解析，见 《 IoC 之获取 Document 对象》 。 errorHandler ：处理加载 Document 对象的过程的错误。 validationMode ：验证模式。 【重要】详细解析，见 《 IoC 之获取验证模型》 。 namespaceAware ：命名空间支持。如果要提供对 XML 名称空间的支持，则为 true 。 #loadDocument(InputSource inputSource, EntityResolver entityResolver, ErrorHandler errorHandler, int validationMode, boolean namespaceAware) 方法，在类 DefaultDocumentLoader 中提供了实现。代码如下： // DefaultDocumentLoader.java @Override public Document loadDocument(InputSource inputSource, EntityResolver entityResolver, ErrorHandler errorHandler, int validationMode, boolean namespaceAware) throws Exception { // 创建 DocumentBuilderFactory DocumentBuilderFactory factory = createDocumentBuilderFactory(validationMode, namespaceAware); // 创建 DocumentBuilder DocumentBuilder builder = createDocumentBuilder(factory, entityResolver, errorHandler); // 解析 XML InputSource 返回 Document 对象 return builder.parse(inputSource); } 2.2 注册 BeanDefinition 流程这到这里，就已经将定义的 Bean 资源文件，载入并转换为 Document 对象了。 那么，下一步就是如何将其解析为 SpringIoC 管理的 BeanDefinition 对象，并将其注册到容器中。 这个过程由方法 #registerBeanDefinitions(Document doc, Resource resource) 方法来实现。代码如下： // XmlBeanDefinitionReader.java public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException { // 创建 BeanDefinitionDocumentReader 对象 BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); // 获取已注册的 BeanDefinition 数量 int countBefore = getRegistry().getBeanDefinitionCount(); // 创建 XmlReaderContext 对象 // 注册 BeanDefinition documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); // 计算新注册的 BeanDefinition 数量 return getRegistry().getBeanDefinitionCount() - countBefore; } 首先，创建 BeanDefinition 的解析器 BeanDefinitionDocumentReader 。 然后，调用该 BeanDefinitionDocumentReader 的 #registerBeanDefinitions(Document doc, XmlReaderContext readerContext) 方法，开启解析过程，这里使用的是委派模式，具体的实现由子类 DefaultBeanDefinitionDocumentReader 完成。代码如下： // DefaultBeanDefinitionDocumentReader.java @Override public void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) { this.readerContext = readerContext; // 获得 XML Document Root Element // 执行注册 BeanDefinition doRegisterBeanDefinitions(doc.getDocumentElement()); } 2.2.1 对 Document 对象的解析从 Document 对象中获取根元素 root，然后调用 ``#doRegisterBeanDefinitions(Element root)` 方法，开启真正的解析过程。代码如下： // DefaultBeanDefinitionDocumentReader.java protected void doRegisterBeanDefinitions(Element root) { // ... 省略部分代码（非核心） this.delegate = createDelegate(getReaderContext(), root, parent); // 解析前处理 preProcessXml(root); // 解析 parseBeanDefinitions(root, this.delegate); // 解析后处理 postProcessXml(root); } #preProcessXml(Element root)、#postProcessXml(Element root) 为前置、后置增强处理，目前 Spring 中都是空实现。 #parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) 是对根元素 root 的解析注册过程。代码如下： // DefaultBeanDefinitionDocumentReader.java protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) { // 如果根节点使用默认命名空间，执行默认解析 if (delegate.isDefaultNamespace(root)) { // 遍历子节点 NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) { Node node = nl.item(i); if (node instanceof Element) { Element ele = (Element) node; // 如果该节点使用默认命名空间，执行默认解析 if (delegate.isDefaultNamespace(ele)) { parseDefaultElement(ele, delegate); // 如果该节点非默认命名空间，执行自定义解析 } else { delegate.parseCustomElement(ele); } } } // 如果根节点非默认命名空间，执行自定义解析 } else { delegate.parseCustomElement(root); } } 迭代 root 元素的所有子节点，对其进行判断： 若节点为默认命名空间，则调用 #parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) 方法，开启默认标签的解析注册过程。 否则，调用 BeanDefinitionParserDelegate#parseCustomElement(Element ele) 方法，开启自定义标签的解析注册过程。 2.2.1.1 默认标签解析若定义的元素节点使用的是 Spring 默认命名空间，则调用 #parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) 方法，进行默认标签解析。代码如下： // DefaultBeanDefinitionDocumentReader.java private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) { if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) { // import importBeanDefinitionResource(ele); } else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) { // alias processAliasRegistration(ele); } else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) { // bean processBeanDefinition(ele, delegate); } else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) { // beans // recurse doRegisterBeanDefinitions(ele); } } 对四大标签：import、alias、bean、beans进行解析。其中 bean 标签的解析为核心工作。 2.2.1.2 自定义标签解析对于默认标签则由 parseCustomElement(Element ele) 方法，负责解析。代码如下： // BeanDefinitionParserDelegate.java @Nullable public BeanDefinition parseCustomElement(Element ele) { return parseCustomElement(ele, null); } @Nullable public BeanDefinition parseCustomElement(Element ele, @Nullable BeanDefinition containingBd) { // 获取 namespaceUri String namespaceUri = getNamespaceURI(ele); if (namespaceUri == null) { return null; } // 根据 namespaceUri 获取相应的 Handler NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri); if (handler == null) { error(\"Unable to locate Spring NamespaceHandler for XML schema namespace [\" + namespaceUri + \"]\", ele); return null; } // 调用自定义的 Handler 处理 return handler.parse(ele, new ParserContext(this.readerContext, this, containingBd)); } 获取节点的 namespaceUri，然后根据该 namespaceUri 获取相对应的 NamespaceHandler，最后调用 NamespaceHandler 的 #parse(Element element, ParserContext parserContext) 方法，即完成自定义标签的解析和注入。 2.2.2 注册 BeanDefinition经过上面的解析，则将 Document 对象里面的 Bean 标签解析成了一个个的 BeanDefinition ，下一步则是将这些 BeanDefinition 注册到 IoC 容器中。动作的触发是在解析 Bean 标签完成后，代码如下： // DefaultBeanDefinitionDocumentReader.java protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) { // 进行 bean 元素解析。 // 如果解析成功，则返回 BeanDefinitionHolder 对象。 // 而 BeanDefinitionHolder 为 name 和 alias 的 BeanDefinition 对象 // 如果解析失败，则返回 null 。 BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); if (bdHolder != null) { // 进行自定义标签处理 bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); try { // 进行 BeanDefinition 的注册 // Register the final decorated instance. BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry()); } catch (BeanDefinitionStoreException ex) { getReaderContext().error(\"Failed to register bean definition with name '\" + bdHolder.getBeanName() + \"'\", ele, ex); } // 发出响应事件，通知相关的监听器，已完成该 Bean 标签的解析。 // Send registration event. getReaderContext().fireComponentRegistered( new BeanComponentDefinition(bdHolder)); } } 调用 BeanDefinitionReaderUtils.registerBeanDefinition() 方法，来注册。 其实，这里面也是调用 BeanDefinitionRegistry 的 #registerBeanDefinition(String beanName, BeanDefinition beanDefinition) 方法，来注册 BeanDefinition 。 不过，最终的实现是在 DefaultListableBeanFactory 中实现，代码如下： // DefaultListableBeanFactory.java @Override public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException { // ...省略校验相关的代码 // 从缓存中获取指定 beanName 的 BeanDefinition BeanDefinition existingDefinition = this.beanDefinitionMap.get(beanName); // 如果已经存在 if (existingDefinition != null) { // 如果存在但是不允许覆盖，抛出异常 if (!isAllowBeanDefinitionOverriding()) { throw new BeanDefinitionOverrideException(beanName, beanDefinition,existingDefinition); } else { // ...省略 logger 打印日志相关的代码 } // 【重点】允许覆盖，直接覆盖原有的 BeanDefinition 到 beanDefinitionMap 中。 this.beanDefinitionMap.put(beanName, beanDefinition); // 如果未存在 } else { // ... 省略非核心的代码 // 【重点】添加到 BeanDefinition 到 beanDefinitionMap 中。 this.beanDefinitionMap.put(beanName, beanDefinition); } // 重新设置 beanName 对应的缓存 if (existingDefinition != null || containsSingleton(beanName)) { resetBeanDefinition(beanName); } } 这段代码最核心的部分是这句 this.beanDefinitionMap.put(beanName, beanDefinition) 代码段。所以，注册过程也不是那么的高大上，就是利用一个 Map 的集合对象来存放：key 是 beanName，value 是 BeanDefinition 对象。 3. 小结至此，整个 IoC 的初始化过程就已经完成了，从 Bean 资源的定位，转换为 Document 对象，接着对其进行解析，最后注册到 IoC 容器中，都已经完美地完成了。 现在 IoC 容器中已经建立了整个 Bean 的配置信息，这些 Bean 可以被检索、使用、维护，他们是控制反转的基础，是后面注入 Bean 的依赖。最后用一张流程图来结束这篇总结之文。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IoC之注册解析的BeanDefinitions","date":"2020-01-13T07:04:56.000Z","path":"2020/01/13/a9bec556.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=2763 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE DefaultBeanDefinitionDocumentReader.processBeanDefinition() 完成 Bean 标签解析的核心工作，如下： protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) { BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); if (bdHolder != null) { bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); try { // Register the final decorated instance. BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry()); } catch (BeanDefinitionStoreException ex) { getReaderContext().error(\"Failed to register bean definition with name '\" + bdHolder.getBeanName() + \"'\", ele, ex); } // Send registration event. getReaderContext().fireComponentRegistered( new BeanComponentDefinition(bdHolder)); } } 解析工作分为三步： 解析默认标签； 解析默认标签后下得自定义标签； 注册解析后的 BeanDefinition。 经过前面两个步骤的解析，这时的 BeanDefinition 已经可以满足后续的使用要求了，那么接下来的工作就是将这些 BeanDefinition 进行注册，也就是完成第三步。 注册 BeanDefinition 由 BeanDefinitionReaderUtils.registerBeanDefinition() 完成。 如下： public static void registerBeanDefinition( BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry) throws BeanDefinitionStoreException { // 注册 beanName String beanName = definitionHolder.getBeanName(); registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition()); // 注册 alias String[] aliases = definitionHolder.getAliases(); if (aliases != null) { for (String alias : aliases) { registry.registerAlias(beanName, alias); } } } 首先通过 beanName 注册 BeanDefinition ， 然后再注册别名 alias。 BeanDefinition 的注册由接口 BeanDefinitionRegistry 定义。 通过 beanName 注册 BeanDefinitionRegistry.registerBeanDefinition() 实现通过 beanName 注册 BeanDefinition，如下： public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException { // 校验 beanName 与 beanDefinition Assert.hasText(beanName, \"Bean name must not be empty\"); Assert.notNull(beanDefinition, \"BeanDefinition must not be null\"); if (beanDefinition instanceof AbstractBeanDefinition) { try { // 校验 BeanDefinition // 这是注册前的最后一次校验了，主要是对属性 methodOverrides 进行校验 ((AbstractBeanDefinition) beanDefinition).validate(); } catch (BeanDefinitionValidationException ex) { throw new BeanDefinitionStoreException( beanDefinition.getResourceDescription(), beanName,\"Validation of bean definition failed\", ex); } } BeanDefinition oldBeanDefinition; // 从缓存中获取指定 beanName 的 BeanDefinition oldBeanDefinition = this.beanDefinitionMap.get(beanName); /** * 如果存在 */ if (oldBeanDefinition != null) { // 如果存在但是不允许覆盖，抛出异常 if (!isAllowBeanDefinitionOverriding()) { throw new BeanDefinitionStoreException( beanDefinition.getResourceDescription(), beanName, \"Cannot register bean definition [\" + beanDefinition + \"] for bean '\" + beanName + \"': There is already [\" + oldBeanDefinition + \"] bound.\"); } // else if (oldBeanDefinition.getRole() &lt; beanDefinition.getRole()) { // e.g. was ROLE_APPLICATION, // now overriding with ROLE_SUPPORT or ROLE_INFRASTRUCTURE if (this.logger.isWarnEnabled()) { this.logger.warn( \"Overriding user-defined bean definition for bean '\" + beanName + \"' with a framework-generated bean definition: replacing [\" + oldBeanDefinition + \"] with [\" + beanDefinition + \"]\"); } } // 覆盖 beanDefinition 与 被覆盖的 beanDefinition 不是同类 else if (!beanDefinition.equals(oldBeanDefinition)) { if (this.logger.isInfoEnabled()) { this.logger.info( \"Overriding bean definition for bean '\" + beanName + \"' with a different definition: replacing [\" + oldBeanDefinition + \"] with [\" + beanDefinition + \"]\"); } } else { if (this.logger.isDebugEnabled()) { this.logger.debug( \"Overriding bean definition for bean '\" + beanName + \"' with an equivalent definition: replacing [\" + oldBeanDefinition + \"] with [\" + beanDefinition + \"]\"); } } // 允许覆盖，直接覆盖原有的 BeanDefinition this.beanDefinitionMap.put(beanName, beanDefinition); } /** * 不存在 */ else { // 检测创建 Bean 阶段是否已经开启，如果开启了则需要对 beanDefinitionMap 进行并发控制 if (hasBeanCreationStarted()) { // beanDefinitionMap 为全局变量，避免并发情况 synchronized (this.beanDefinitionMap) { // this.beanDefinitionMap.put(beanName, beanDefinition); List&lt;String> updatedDefinitions = new ArrayList&lt;>(this.beanDefinitionNames.size() + 1); updatedDefinitions.addAll(this.beanDefinitionNames); updatedDefinitions.add(beanName); this.beanDefinitionNames = updatedDefinitions; if (this.manualSingletonNames.contains(beanName)) { Set&lt;String> updatedSingletons = new LinkedHashSet&lt;>(this.manualSingletonNames); updatedSingletons.remove(beanName); this.manualSingletonNames = updatedSingletons; } } } else { // 不会存在并发情况，直接设置 this.beanDefinitionMap.put(beanName, beanDefinition); this.beanDefinitionNames.add(beanName); this.manualSingletonNames.remove(beanName); } this.frozenBeanDefinitionNames = null; } if (oldBeanDefinition != null || containsSingleton(beanName)) { // 重新设置 beanName 对应的缓存 resetBeanDefinition(beanName); } } 处理过程如下： 首先 BeanDefinition 进行校验，该校验也是注册过程中的最后一次校验了，主要是对 AbstractBeanDefinition 的 methodOverrides 属性进行校验 根据 beanName 从缓存中获取 BeanDefinition，如果缓存中存在，则根据 allowBeanDefinitionOverriding 标志来判断是否允许覆盖，如果允许则直接覆盖，否则抛出 BeanDefinitionStoreException 异常 若缓存中没有指定 beanName 的 BeanDefinition，则判断当前阶段是否已经开始了 Bean 的创建阶段&lt;&gt;，如果是，则需要对 beanDefinitionMap 进行加锁控制并发问题，否则直接设置即可。对于 hasBeanCreationStarted() 方法后续做详细介绍，这里不过多阐述。 若缓存中存在该 beanName 或者 单利 bean 集合中存在该 beanName，则调用 resetBeanDefinition() 重置 BeanDefinition 缓存。 其实整段代码的核心就在于 this.beanDefinitionMap.put(beanName, beanDefinition); 。 BeanDefinition 的缓存也不是神奇的东西，就是定义 map ，key 为 beanName，value 为 BeanDefinition。 注册 alias BeanDefinitionRegistry.registerAlias 完成 alias 的注册。 public void registerAlias(String name, String alias) { // 校验 name 、 alias Assert.hasText(name, \"'name' must not be empty\"); Assert.hasText(alias, \"'alias' must not be empty\"); synchronized (this.aliasMap) { // name == alias 则去掉alias if (alias.equals(name)) { this.aliasMap.remove(alias); } else { // 缓存缓存记录 String registeredName = this.aliasMap.get(alias); if (registeredName != null) { // 缓存中的相等，则直接返回 if (registeredName.equals(name)) { // An existing alias - no need to re-register return; } // 不允许则抛出异常 if (!allowAliasOverriding()) { throw new IllegalStateException( \"Cannot register alias '\" + alias + \"' for name '\" + name + \"': It is already registered for name '\" + registeredName + \"'.\"); } } // 当 A --> B 存在时，如果再次出现 A --> B --> C 则抛出异常 checkForAliasCircle(name, alias); // 注册 alias this.aliasMap.put(alias, name); } } } 注册 alias 和注册 BeanDefinition 的过程差不多。在最后调用了 checkForAliasCircle() 来对别名进行了检测。 public boolean hasAlias(String name, String alias) { for (Map.Entry&lt;String, String> entry : this.aliasMap.entrySet()) { String registeredName = entry.getValue(); if (registeredName.equals(name)) { String registeredAlias = entry.getKey(); return (registeredAlias.equals(alias) || hasAlias(registeredAlias, alias)); } } return false; } 如果 name 、 alias 为 1 、3 ，则构成 （1,3），加入集合中存在（A,1）、（3,A）的情况则会出错。 到这里 BeanDefinition、alias 都已经注入到缓存中，下一步则是等待初始化使用了。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IoC之解析bean标签：解析自定义标签","date":"2020-01-12T08:35:19.000Z","path":"2020/01/12/61e43345.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=2841 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE 获取 Document 对象后，会根据该对象和 Resource 资源对象调用 registerBeanDefinitions() 方法，开始注册 BeanDefinitions 之旅。在注册 BeanDefinitions 过程中会调用 parseBeanDefinitions() 开启 BeanDefinition 的解析过程。在该方法中，它会根据命名空间的不同调用不同的方法进行解析，如果是默认的命名空间，则调用 parseDefaultElement() 进行默认标签解析，否则调用 parseCustomElement() 方法进行自定义标签解析。 使用自定义标签扩展 Spring 自定义标签配置一般需要以下几个步骤： 创建一个需要扩展的组件 定义一个 XSD 文件，用于描述组件内容 创建一个实现 AbstractSingleBeanDefinitionParser 接口的类，用来解析 XSD 文件中的定义和组件定义 创建一个 Handler，继承 NamespaceHandlerSupport ，用于将组件注册到 Spring 容器 编写 Spring.handlers 和 Spring.schemas 文件 下面就按照上面的步骤来实现一个自定义标签组件。 创建组件 该组件就是一个普通的 JavaBean，没有任何特别之处。 public class User { private String id; private String userName; private String email; } 定义 XSD 文件&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;xsd:schema xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns=\"http://www.cmsblogs.com/schema/user\" targetNamespace=\"http://www.cmsblogs.com/schema/user\" elementFormDefault=\"qualified\"> &lt;xsd:element name=\"user\"> &lt;xsd:complexType> &lt;xsd:attribute name=\"id\" type=\"xsd:string\" /> &lt;xsd:attribute name=\"userName\" type=\"xsd:string\" /> &lt;xsd:attribute name=\"email\" type=\"xsd:string\" /> &lt;/xsd:complexType> &lt;/xsd:element> &lt;/xsd:schema> 上面除了对 User 这个 JavaBean 进行了描述外，还定义了 xmlns=&quot;http://www.cmsblogs.com/schema/user&quot; targetNamespace=&quot;http://www.cmsblogs.com/schema/user&quot; 这两个值，这两个值在后面是有大作用的。 Parser 类定义一个 Parser 类，该类继承 AbstractSingleBeanDefinitionParser ，并实现 getBeanClass() 和 doParse() 两个方法。主要是用于解析 XSD 文件中的定义和组件定义。 public class UserDefinitionParser extends AbstractSingleBeanDefinitionParser { @Override protected Class&lt;?> getBeanClass(Element element) { return User.class; } @Override protected void doParse(Element element, BeanDefinitionBuilder builder) { String id = element.getAttribute(\"id\"); String userName=element.getAttribute(\"userName\"); String email=element.getAttribute(\"email\"); if(StringUtils.hasText(id)){ builder.addPropertyValue(\"id\",id); } if(StringUtils.hasText(userName)){ builder.addPropertyValue(\"userName\", userName); } if(StringUtils.hasText(email)){ builder.addPropertyValue(\"email\", email); } } } Handler 类定义 Handler 类，继承 NamespaceHandlerSupport ,主要目的是将组件注册到 Spring 容器中。 public class UserNamespaceHandler extends NamespaceHandlerSupport { @Override public void init() { registerBeanDefinitionParser(\"user\",new UserDefinitionParser()); } } Spring.handlershttp://www.cmsblogs.com/schema/user=org.springframework.core.customelement.UserNamespaceHandler Spring.schemashttp://www.cmsblogs.com/schema/user.xsd=user.xsd 经过上面几个步骤，就可以使用自定义的标签了。在 xml 配置文件中使用如下： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:myTag=\"http://www.cmsblogs.com/schema/user\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.cmsblogs.com/schema/user http://www.cmsblogs.com/schema/user.xsd\"> &lt;myTag:user id=\"user\" email=\"12233445566@qq.com\" userName=\"chenssy\" /> &lt;/beans> 测试： public static void main(String[] args){ ApplicationContext context = new ClassPathXmlApplicationContext(\"spring.xml\"); User user = (User) context.getBean(\"user\"); System.out.println(user.getUserName() + \"----\" + user.getEmail()); } 运行结果： 解析自定义标签上面已经演示了 Spring 自定义标签的使用，下面就来分析自定义标签的解析过程。DefaultBeanDefinitionDocumentReader.parseBeanDefinitions() 负责标签的解析工作，其中它根据命名空间的不同进行不同标签的解析，其中自定义标签由 delegate.parseCustomElement() 实现。如下： public BeanDefinition parseCustomElement(Element ele) { return parseCustomElement(ele, null); } 调用 parseCustomElement() 方法，如下： public BeanDefinition parseCustomElement(Element ele, @Nullable BeanDefinition containingBd) { // 获取 namespaceUri String namespaceUri = getNamespaceURI(ele); if (namespaceUri == null) { return null; } // 根据 namespaceUri 获取相应的 Handler NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri); if (handler == null) { error(\"Unable to locate Spring NamespaceHandler for XML schema namespace [\" + namespaceUri + \"]\", ele); return null; } // 调用自定义的 Handler 处理 return handler.parse(ele, new ParserContext(this.readerContext, this, containingBd)); } 处理过程分为三步： 获取 namespaceUri 根据 namespaceUri 获取相应的 Handler 调用自定义的 Handler 处理 这个处理过程很简单明了，根据 namespaceUri 获取 Handler，这个映射关系我们在 Spring.handlers 中已经定义了，所以只需要找到该类，然后初始化返回，最后调用该 Handler 对象的 parse() 方法处理，该方法我们也提供了实现。所以上面的核心就在于怎么找到该 Handler 类。调用方法为：this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri)``getNamespaceHandlerResolver() 方法返回的命名空间的解析器，该解析定义在 XmlReaderContext 中，如下： public final NamespaceHandlerResolver getNamespaceHandlerResolver() { return this.namespaceHandlerResolver; } 这里直接返回，那是在什么时候初始化的呢？ 这里需要回退到博文：IoC之注册BeanDefinitions ，在这篇博客中提到在注册 BeanDefinition 时： 首先是通过 createBeanDefinitionDocumentReader() 获取 Document 解析器 BeanDefinitionDocumentReader 实例 然后调用该实例 registerBeanDefinitions() 方法进行注册。 registerBeanDefinitions()方法需要提供两个参数： 一个是 Document 实例 doc 一个是 XmlReaderContext 实例 readerContext readerContext 实例对象由 createReaderContext() 方法提供。namespaceHandlerResolver 实例对象就是在这个时候初始化的。如下： public XmlReaderContext createReaderContext(Resource resource) { return new XmlReaderContext(resource, this.problemReporter, this.eventListener, this.sourceExtractor, this, getNamespaceHandlerResolver()); } XmlReaderContext 构造函数中最后一个参数就是 NamespaceHandlerResolver 对象，该对象由 getNamespaceHandlerResolver() 提供，如下： public NamespaceHandlerResolver getNamespaceHandlerResolver() { if (this.namespaceHandlerResolver == null) { this.namespaceHandlerResolver = createDefaultNamespaceHandlerResolver(); } return this.namespaceHandlerResolver; } protected NamespaceHandlerResolver createDefaultNamespaceHandlerResolver() { ClassLoader cl = (getResourceLoader() != null ? getResourceLoader().getClassLoader() : getBeanClassLoader()); return new DefaultNamespaceHandlerResolver(cl); } 所以 getNamespaceHandlerResolver().resolve(namespaceUri) 调用的就是 DefaultNamespaceHandlerResolver 的 resolve()。如下： public NamespaceHandler resolve(String namespaceUri) { // 获取所有已经配置的 Handler 映射 Map&lt;String, Object> handlerMappings = getHandlerMappings(); // 根据 namespaceUri 获取 handler的信息：这里一般都是类路径 Object handlerOrClassName = handlerMappings.get(namespaceUri); if (handlerOrClassName == null) { return null; } else if (handlerOrClassName instanceof NamespaceHandler) { // 如果已经做过解析，直接返回 return (NamespaceHandler) handlerOrClassName; } else { String className = (String) handlerOrClassName; try { Class&lt;?> handlerClass = ClassUtils.forName(className, this.classLoader); if (!NamespaceHandler.class.isAssignableFrom(handlerClass)) { throw new FatalBeanException(\"Class [\" + className + \"] for namespace [\" + namespaceUri + \"] does not implement the [\" + NamespaceHandler.class.getName() + \"] interface\"); } // 初始化类 NamespaceHandler namespaceHandler = (NamespaceHandler) BeanUtils.instantiateClass(handlerClass); // 调用 init() 方法 namespaceHandler.init(); // 记录在缓存 handlerMappings.put(namespaceUri, namespaceHandler); return namespaceHandler; } catch (ClassNotFoundException ex) { throw new FatalBeanException(\"Could not find NamespaceHandler class [\" + className + \"] for namespace [\" + namespaceUri + \"]\", ex); } catch (LinkageError err) { throw new FatalBeanException( \"Unresolvable class definition for NamespaceHandler class [\" + className + \"] for namespace [\" + namespaceUri + \"]\", err); } } } 首先调用 getHandlerMappings() 获取所有配置文件中的映射关系 handlerMappings ，该关系为 &lt;命名空间,类路径&gt;，然后根据命名空间 namespaceUri 从映射关系中获取相应的信息，如果为空或者已经初始化了就直接返回，否则根据反射对其进行初始化，同时调用其 init() 方法，最后将该 Handler 对象缓存。 init() 方法主要是将自定义标签解析器进行注册，如我们自定义的 init() ： @Override public void init() { registerBeanDefinitionParser(\"user\",new UserDefinitionParser()); } 直接调用父类的 registerBeanDefinitionParser() 方法进行注册： protected final void registerBeanDefinitionParser( String elementName, BeanDefinitionParser parser) { this.parsers.put(elementName, parser); } 其实就是将映射关系放在一个 Map 结构的 parsers 对象中：private final Map parsers 。 完成后返回 NamespaceHandler 对象，然后调用其 parse() 方法开始自定义标签的解析，如下： public BeanDefinition parse(Element element, ParserContext parserContext) { BeanDefinitionParser parser = findParserForElement(element, parserContext); return (parser != null ? parser.parse(element, parserContext) : null); } 调用 findParserForElement() 方法获取 BeanDefinitionParser 实例，其实就是获取在 init() 方法里面注册的实例对象。如下： private BeanDefinitionParser findParserForElement( Element element, ParserContext parserContext) { String localName = parserContext.getDelegate().getLocalName(element); BeanDefinitionParser parser = this.parsers.get(localName); if (parser == null) { parserContext.getReaderContext().fatal( \"Cannot locate BeanDefinitionParser for element [\" + localName + \"]\", element); } return parser; } 获取 localName，在上面的例子中就是 ： user 然后从 Map 实例 parsers 中获取 BeanDefinitionParser 对象。 返回 BeanDefinitionParser 对象后，调用其 parse()，该方法在 AbstractBeanDefinitionParser 中实现： public final BeanDefinition parse( Element element, ParserContext parserContext) { AbstractBeanDefinition definition = parseInternal(element, parserContext); if (definition != null &amp;&amp; !parserContext.isNested()) { try { String id = resolveId(element, definition, parserContext); if (!StringUtils.hasText(id)) { parserContext.getReaderContext().error( \"Id is required for element '\" + parserContext.getDelegate().getLocalName(element) + \"' when used as a top-level tag\", element); } String[] aliases = null; if (shouldParseNameAsAliases()) { String name = element.getAttribute(NAME_ATTRIBUTE); if (StringUtils.hasLength(name)) { aliases = StringUtils.trimArrayElements( StringUtils.commaDelimitedListToStringArray(name)); } } BeanDefinitionHolder holder = new BeanDefinitionHolder(definition, id, aliases); registerBeanDefinition(holder, parserContext.getRegistry()); if (shouldFireEvents()) { BeanComponentDefinition componentDefinition = new BeanComponentDefinition(holder); postProcessComponentDefinition(componentDefinition); parserContext.registerComponent(componentDefinition); } } catch (BeanDefinitionStoreException ex) { String msg = ex.getMessage(); parserContext.getReaderContext().error((msg != null ? msg : ex.toString()), element); return null; } } return definition; } 核心在方法 parseInternal() 为什么这么说，以为该方法返回的是 AbstractBeanDefinition 对象，从前面默认标签的解析工作中我们就可以判断该方法就是将标签解析为 AbstractBeanDefinition ，且后续代码都是将 AbstractBeanDefinition 转换为 BeanDefinitionHolder，所以真正的解析工作都交由 parseInternal() 实现，如下： protected final AbstractBeanDefinition parseInternal( Element element, ParserContext parserContext) { // 获取 BeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(); // 获取父类元素 String parentName = getParentName(element); if (parentName != null) { builder.getRawBeanDefinition().setParentName(parentName); } // 获取自定义标签中的 class，这个时候会去调用自定义解析中的 getBeanClass() Class&lt;?> beanClass = getBeanClass(element); if (beanClass != null) { builder.getRawBeanDefinition().setBeanClass(beanClass); } else { // beanClass 为 null，意味着子类并没有重写 getBeanClass() 方法， // 则尝试去判断是否重写了 getBeanClassName() String beanClassName = getBeanClassName(element); if (beanClassName != null) { builder.getRawBeanDefinition().setBeanClassName(beanClassName); } } builder.getRawBeanDefinition().setSource(parserContext.extractSource(element)); BeanDefinition containingBd = parserContext.getContainingBeanDefinition(); if (containingBd != null) { // Inner bean definition must receive same scope as containing bean. builder.setScope(containingBd.getScope()); } if (parserContext.isDefaultLazyInit()) { // Default-lazy-init applies to custom bean definitions as well. builder.setLazyInit(true); } // 调用子类的 doParse() 进行解析 doParse(element, parserContext, builder); return builder.getBeanDefinition(); } 在该方法中我们主要关注两个方法：getBeanClass() 、doParse()。对于 getBeanClass() 方法，AbstractSingleBeanDefinitionParser 类并没有提供具体实现，而是直接返回 null，意味着它希望子类能够重写该方法，当然如果没有重写该方法，这会去调用 getBeanClassName() ，判断子类是否已经重写了该方法。对于 doParse() 则是直接空实现。所以对于 parseInternal() 而言它总是期待它的子类能够实现 getBeanClass()、doParse()，其中 doParse() 尤为重要，如果你不提供实现，怎么来解析自定义标签呢？最后将自定义的解析器：UserDefinitionParser 再次回观。 public class UserDefinitionParser extends AbstractSingleBeanDefinitionParser { @Override protected Class&lt;?> getBeanClass(Element element) { return User.class; } @Override protected void doParse(Element element, BeanDefinitionBuilder builder) { String id = element.getAttribute(\"id\"); String userName=element.getAttribute(\"userName\"); String email=element.getAttribute(\"email\"); if(StringUtils.hasText(id)){ builder.addPropertyValue(\"id\",id); } if(StringUtils.hasText(userName)){ builder.addPropertyValue(\"userName\", userName); } if(StringUtils.hasText(email)){ builder.addPropertyValue(\"email\", email); } } } 至此，自定义标签的解析过程已经分析完成了。其实整个过程还是较为简单： 首先会加载 handlers 文件，将其中内容进行一个解析，形成 &lt;namespaceUri,类路径&gt; 这样的一个映射 然后根据获取的 namespaceUri 就可以得到相应的类路径，对其进行初始化等到相应的 Handler 对象 调用 parse() 方法，在该方法中根据标签的 localName 得到相应的 BeanDefinitionParser 实例对象 调用 parse() ，该方法定义在 AbstractBeanDefinitionParser 抽象类中，核心逻辑封装在其 parseInternal() 中，该方法返回一个 AbstractBeanDefinition 实例对象，其主要是在 AbstractSingleBeanDefinitionParser 中实现，对于自定义的 Parser 类，其需要实现 getBeanClass() 或者 getBeanClassName() 和 doParse()。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之解析bean标签：constructor-arg、property子元素","date":"2020-01-11T08:21:50.000Z","path":"2020/01/11/686a3d12.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=2754 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE constructor-arg 子元素举个小栗子： public class StudentService { private String name; private Integer age; private BookService bookService; StudentService(String name, Integer age, BookService bookService){ this.name = name; this.age = age; this.bookService = bookService; } } &lt;bean id=\"bookService\" class=\"org.springframework.core.service.BookService\"/> &lt;bean id=\"studentService\" class=\"org.springframework.core.service.StudentService\"> &lt;constructor-arg index=\"0\" value=\"chenssy\"/> &lt;constructor-arg name=\"age\" value=\"100\"/> &lt;constructor-arg name=\"bookService\" ref=\"bookService\"/> &lt;/bean> StudentService 定义一个构造函数，配置文件中使用 constructor-arg 元素对其配置，该元素可以实现对 StudentService 自动寻找对应的构造函数，并在初始化的时候将值当做参数进行设置。parseConstructorArgElements() 方法完成 constructor-arg 子元素的解析。 public void parseConstructorArgElements(Element beanEle, BeanDefinition bd) { NodeList nl = beanEle.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) { Node node = nl.item(i); if (isCandidateElement(node) &amp;&amp; nodeNameEquals(node, CONSTRUCTOR_ARG_ELEMENT)) { parseConstructorArgElement((Element) node, bd); } } } 遍历所有子元素，如果为 constructor-arg 则调用 parseConstructorArgElement() 进行解析。 public void parseConstructorArgElement(Element ele, BeanDefinition bd) { // 提取 index、type、name 属性值 String indexAttr = ele.getAttribute(INDEX_ATTRIBUTE); String typeAttr = ele.getAttribute(TYPE_ATTRIBUTE); String nameAttr = ele.getAttribute(NAME_ATTRIBUTE); // 如果有index if (StringUtils.hasLength(indexAttr)) { try { int index = Integer.parseInt(indexAttr); if (index &lt; 0) { error(\"'index' cannot be lower than 0\", ele); } else { try { // 构造一个 ConstructorArgumentEntry 并将其加入到 ParseState 中 this.parseState.push(new ConstructorArgumentEntry(index)); // 解析 ele 对应属性元素 Object value = parsePropertyValue(ele, bd, null); // 根据解析的属性元素构造一个 valueHolder 对象 ConstructorArgumentValues.ValueHolder valueHolder = new ConstructorArgumentValues.ValueHolder(value); if (StringUtils.hasLength(typeAttr)) { valueHolder.setType(typeAttr); } if (StringUtils.hasLength(nameAttr)) { valueHolder.setName(nameAttr); } // valueHolder.setSource(extractSource(ele)); // 不允许重复指定相同参数 if (bd.getConstructorArgumentValues() .hasIndexedArgumentValue(index)) { error(\"Ambiguous constructor-arg entries for index \" + index, ele); } else { // 加入到 indexedArgumentValues 中国 bd.getConstructorArgumentValues() .addIndexedArgumentValue(index, valueHolder); } } finally { this.parseState.pop(); } } } catch (NumberFormatException ex) { error(\"Attribute 'index' of tag 'constructor-arg' must be an integer\", ele); } } else { try { this.parseState.push(new ConstructorArgumentEntry()); Object value = parsePropertyValue(ele, bd, null); ConstructorArgumentValues.ValueHolder valueHolder = new ConstructorArgumentValues.ValueHolder(value); if (StringUtils.hasLength(typeAttr)) { valueHolder.setType(typeAttr); } if (StringUtils.hasLength(nameAttr)) { valueHolder.setName(nameAttr); } valueHolder.setSource(extractSource(ele)); bd.getConstructorArgumentValues().addGenericArgumentValue(valueHolder); } finally { this.parseState.pop(); } } } 首先获取 index、type、name 三个属性值，然后根据是否存在 index 来区分。 其实两者逻辑都差不多，总共分为如下几个步骤（以有 index 为例）： 构造 ConstructorArgumentEntry 对象并将其加入到 ParseState 队列中。 ConstructorArgumentEntry 表示构造函数的参数。 调用 parsePropertyValue() 解析 constructor-arg 子元素，返回结果值 根据解析的结果值构造 ConstructorArgumentValues.ValueHolder 实例对象 将 type、name 封装到 ConstructorArgumentValues.ValueHolder 中，然后将 ValueHolder 实例对象添加到 indexedArgumentValues 中。 无 index 的处理逻辑差不多，只有几点不同： 构造 ConstructorArgumentEntry 对象时是调用无参构造函数； 最后是将 ValueHolder 实例添加到 genericArgumentValues 中。 parsePropertyValue() 对子元素进一步解析。 public Object parsePropertyValue(Element ele, BeanDefinition bd, @Nullable String propertyName) { String elementName = (propertyName != null) ? \"&lt;property> element for property '\" + propertyName + \"'\" : \"&lt;constructor-arg> element\"; NodeList nl = ele.getChildNodes(); Element subElement = null; for (int i = 0; i &lt; nl.getLength(); i++) { Node node = nl.item(i); // meta 、description 不处理 if (node instanceof Element &amp;&amp; !nodeNameEquals(node, DESCRIPTION_ELEMENT) &amp;&amp; !nodeNameEquals(node, META_ELEMENT)) { // Child element is what we're looking for. if (subElement != null) { error(elementName + \" must not contain more than one sub-element\", ele); } else { subElement = (Element) node; } } } // 解析 ref 元素 boolean hasRefAttribute = ele.hasAttribute(REF_ATTRIBUTE); // 解析 value 元素 boolean hasValueAttribute = ele.hasAttribute(VALUE_ATTRIBUTE); // constructor-arg 子元素有两种情况不存在 // 1. 即存在 ref 又存在 value // 2. 存在 ref 或者 value，但是又有子元素 if ((hasRefAttribute &amp;&amp; hasValueAttribute) || ((hasRefAttribute || hasValueAttribute) &amp;&amp; subElement != null)) { error(elementName + \" is only allowed to contain either 'ref' attribute OR \" + \" 'value' attribute OR sub-element\", ele); } if (hasRefAttribute) { // 获取 ref 属性值 String refName = ele.getAttribute(REF_ATTRIBUTE); if (!StringUtils.hasText(refName)) { error(elementName + \" contains empty 'ref' attribute\", ele); } // 将 ref 属性值构造为 RuntimeBeanReference 实例对象 RuntimeBeanReference ref = new RuntimeBeanReference(refName); ref.setSource(extractSource(ele)); return ref; } else if (hasValueAttribute) { // 解析 value 属性值，构造 TypedStringValue 实例对象 TypedStringValue valueHolder = new TypedStringValue( ele.getAttribute(VALUE_ATTRIBUTE)); valueHolder.setSource(extractSource(ele)); return valueHolder; } else if (subElement != null) { // 解析子元素 return parsePropertySubElement(subElement, bd); } else { // Neither child element nor \"ref\" or \"value\" attribute found. error(elementName + \" must specify a ref or value\", ele); return null; } } 提取 constructor-arg 子元素的 ref 和 value 的属性值，对其进行判断，以下两种情况是不允许存在的 ref 和 value 属性同时存在 存在 ref 或者 value 且又有子元素 若存在 ref 属性，则获取其值并将其封装进 RuntimeBeanReference 实例对象中 若存在 value 属性，则获取其值并将其封装进 TypedStringValue 实例对象中 如果子元素不为空，则调用 parsePropertySubElement() 进行子元素进一步处理 对于 constructor-arg 子元素的嵌套子元素，需要调用 parsePropertySubElement() 进一步处理。 public Object parsePropertySubElement(Element ele, @Nullable BeanDefinition bd) { return parsePropertySubElement(ele, bd, null); } public Object parsePropertySubElement( Element ele, @Nullable BeanDefinition bd, @Nullable String defaultValueType) { if (!isDefaultNamespace(ele)) { return parseNestedCustomElement(ele, bd); } else if (nodeNameEquals(ele, BEAN_ELEMENT)) { BeanDefinitionHolder nestedBd = parseBeanDefinitionElement(ele, bd); if (nestedBd != null) { nestedBd = decorateBeanDefinitionIfRequired(ele, nestedBd, bd); } return nestedBd; } else if (nodeNameEquals(ele, REF_ELEMENT)) { // A generic reference to any name of any bean. String refName = ele.getAttribute(BEAN_REF_ATTRIBUTE); boolean toParent = false; if (!StringUtils.hasLength(refName)) { // A reference to the id of another bean in a parent context. refName = ele.getAttribute(PARENT_REF_ATTRIBUTE); toParent = true; if (!StringUtils.hasLength(refName)) { error(\"'bean' or 'parent' is required for &lt;ref> element\", ele); return null; } } if (!StringUtils.hasText(refName)) { error(\"&lt;ref> element contains empty target attribute\", ele); return null; } RuntimeBeanReference ref = new RuntimeBeanReference(refName, toParent); ref.setSource(extractSource(ele)); return ref; } else if (nodeNameEquals(ele, IDREF_ELEMENT)) { return parseIdRefElement(ele); } else if (nodeNameEquals(ele, VALUE_ELEMENT)) { return parseValueElement(ele, defaultValueType); } else if (nodeNameEquals(ele, NULL_ELEMENT)) { // It's a distinguished null value. Let's wrap it in a TypedStringValue // object in order to preserve the source location. TypedStringValue nullHolder = new TypedStringValue(null); nullHolder.setSource(extractSource(ele)); return nullHolder; } else if (nodeNameEquals(ele, ARRAY_ELEMENT)) { return parseArrayElement(ele, bd); } else if (nodeNameEquals(ele, LIST_ELEMENT)) { return parseListElement(ele, bd); } else if (nodeNameEquals(ele, SET_ELEMENT)) { return parseSetElement(ele, bd); } else if (nodeNameEquals(ele, MAP_ELEMENT)) { return parseMapElement(ele, bd); } else if (nodeNameEquals(ele, PROPS_ELEMENT)) { return parsePropsElement(ele); } else { error(\"Unknown property sub-element: [\" + ele.getNodeName() + \"]\", ele); return null; } } 上面对各个子类进行分类处理，详细情况如果各位有兴趣可以移步源码进行深一步的探究。 property 子元素我们一般使用如下方式来使用 property 子元素。 &lt;bean id=\"studentService\" class=\"org.springframework.core.service.StudentService\"> &lt;property name=\"name\" value=\"chenssy\"/> &lt;property name=\"age\" value=\"18\"/> &lt;/bean> 对于 property 子元素的解析，Spring 调用 parsePropertyElements()。如下： public void parsePropertyElements(Element beanEle, BeanDefinition bd) { NodeList nl = beanEle.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) { Node node = nl.item(i); if (isCandidateElement(node) &amp;&amp; nodeNameEquals(node, PROPERTY_ELEMENT)) { parsePropertyElement((Element) node, bd); } } } 和 constructor-arg 子元素差不多，同样是提取所有的 property 的子元素，然后调用 parsePropertyElement() 进行分析。 public void parsePropertyElement(Element ele, BeanDefinition bd) { // 获取 name 属性 String propertyName = ele.getAttribute(NAME_ATTRIBUTE); if (!StringUtils.hasLength(propertyName)) { error(\"Tag 'property' must have a 'name' attribute\", ele); return; } this.parseState.push(new PropertyEntry(propertyName)); try { // 如果存在相同的 name if (bd.getPropertyValues().contains(propertyName)) { error(\"Multiple 'property' definitions for property '\" + propertyName + \"'\", ele); return; } // 解析属性值 Object val = parsePropertyValue(ele, bd, propertyName); // 根据解析的属性值构造 PropertyValue 实例对象 PropertyValue pv = new PropertyValue(propertyName, val); parseMetaElements(ele, pv); pv.setSource(extractSource(ele)); // 添加到 MutablePropertyValues 中 bd.getPropertyValues().addPropertyValue(pv); } finally { this.parseState.pop(); } } 与解析 constructor-arg 子元素步骤差不多。调用 parsePropertyValue() 解析子元素属性值，然后根据该值构造 PropertyValue 实例对象并将其添加到 BeanDefinition 中的 MutablePropertyValues 中。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IoC之解析bean标签：meta、lookup-method、replace-method","date":"2020-01-10T07:36:53.000Z","path":"2020/01/10/fa973ffe.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=2736 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE 在 IOC 之解析 Bean 标签：BeanDefinition中已经完成了对 Bean 标签属性的解析工作，这篇博文开始分析子元素的解析。 完成 Bean 标签基本属性解析后，会依次调用 parseMetaElements()、parseLookupOverrideSubElements()、parseReplacedMethodSubElements() 对子元素 meta、lookup-method、replace-method 完成解析。三个子元素的作用如下： meta：元数据。 lookup-method：Spring 动态改变 bean 里方法的实现。 方法执行返回的对象，使用 Spring 内原有的这类对象替换，通过改变方法返回值来动态改变方法。内部实现为使用 cglib 方法，重新生成子类，重写配置的方法和返回对象，达到动态改变的效果。 replace-method：Spring 动态改变 bean 里方法的实现。 需要改变的方法，使用 Spring 内原有其他类（需要继承接口org.springframework.beans.factory.support.MethodReplacer）的逻辑，替换这个方法。通过改变方法执行逻辑来动态改变方法。 meta 子元素 meta ：元数据。当需要使用里面的信息时可以通过key获取 meta 所声明的 key 并不会在 Bean 中体现，只是一个额外的声明，当我们需要使用里面的信息时，通过 BeanDefinition 的 getAttribute() 获取。该子元素的解析过程如下： public void parseMetaElements(Element ele, BeanMetadataAttributeAccessor attributeAccessor) { NodeList nl = ele.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) { Node node = nl.item(i); if (isCandidateElement(node) &amp;&amp; nodeNameEquals(node, META_ELEMENT)) { Element metaElement = (Element) node; String key = metaElement.getAttribute(KEY_ATTRIBUTE); String value = metaElement.getAttribute(VALUE_ATTRIBUTE); BeanMetadataAttribute attribute = new BeanMetadataAttribute(key, value); attribute.setSource(extractSource(metaElement)); attributeAccessor.addMetadataAttribute(attribute); } } } 解析过程较为简单，获取相应的 key - value 构建 BeanMetadataAttribute 对象，然后通过 addMetadataAttribute() 加入到 AbstractBeanDefinition 中。 代码 如下： public void addMetadataAttribute(BeanMetadataAttribute attribute) { super.setAttribute(attribute.getName(), attribute); } 委托 AttributeAccessorSupport 实现，如下： public void setAttribute(String name, @Nullable Object value) { Assert.notNull(name, \"Name must not be null\"); if (value != null) { this.attributes.put(name, value); } else { removeAttribute(name); } } AttributeAccessorSupport 是接口 AttributeAccessor 的实现者。 AttributeAccessor 接口定义了与其他对象的元数据进行连接和访问的约定，可以通过该接口对属性进行获取、设置、删除操作。 设置元数据后，则可以通过 getAttribute() 获取,如下： public Object getAttribute(String name) { BeanMetadataAttribute attribute = (BeanMetadataAttribute) super.getAttribute(name); return (attribute != null ? attribute.getValue() : null); } lookup-method 子元素 lookup-method ：获取器注入，是把一个方法声明为返回某种类型的 bean 但实际要返回的 bean 是在配置文件里面配置的。该方法可以用于设计一些可插拔的功能上，解除程序依赖。 直接上例子： public interface Car { void display(); } public class Bmw implements Car{ @Override public void display() { System.out.println(\"我是 BMW\"); } } public class Hongqi implements Car{ @Override public void display() { System.out.println(\"我是 hongqi\"); } } public abstract class Display { public void display(){ getCar().display(); } public abstract Car getCar(); } public static void main(String[] args) { ApplicationContext context = new ClassPathXmlApplicationContext(\"classpath:spring.xml\"); Display display = (Display) context.getBean(\"display\"); display.display(); } } 配置内容如下： &lt;bean id=\"display\" class=\"org.springframework.core.test1.Display\"> &lt;lookup-method name=\"getCar\" bean=\"hongqi\"/> &lt;/bean> 运行结果为： 我是 hongqi 如果将 bean=&quot;hognqi&quot; 替换为 bean=&quot;bmw&quot;，则运行结果变成： 我是 BMW 看了这个示例，我们初步了解了 looku-method 子元素提供的功能了，其解析过程如下： public void parseLookupOverrideSubElements(Element beanEle, MethodOverrides overrides) { NodeList nl = beanEle.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) { Node node = nl.item(i); if (isCandidateElement(node) &amp;&amp; nodeNameEquals(node, LOOKUP_METHOD_ELEMENT)) { Element ele = (Element) node; String methodName = ele.getAttribute(NAME_ATTRIBUTE); String beanRef = ele.getAttribute(BEAN_ELEMENT); LookupOverride override = new LookupOverride(methodName, beanRef); override.setSource(extractSource(ele)); overrides.addOverride(override); } } } 解析过程和 meta 子元素没有多大区别，同样是解析 methodName、beanRef 构造一个 LookupOverride 对象，然后覆盖即可。在实例化 Bean 的时候，再详细阐述具体的实现过程，这里仅仅只是一个标记作用。 replace-method 子元素 replaced-method ：可以在运行时调用新的方法替换现有的方法，还能动态的更新原有方法的逻辑 该标签使用方法和 lookup-method 标签差不多，只不过替代方法的类需要实现 MethodReplacer 接口。如下: public class Method { public void display(){ System.out.println(\"我是原始方法\"); } } public class MethodReplace implements MethodReplacer { @Override public Object reimplement(Object obj, Method method, Object[] args) throws Throwable { System.out.println(\"我是替换方法\"); return null; } } public static void main(String[] args) { ApplicationContext context = new ClassPathXmlApplicationContext(\"classpath:spring.xml\"); Method method = (Method) context.getBean(\"method\"); method.display(); } 如果 spring.xml 文件如下： &lt;bean id=\"methodReplace\" class=\"org.springframework.core.test1.MethodReplace\"/> &lt;bean id=\"method\" class=\"org.springframework.core.test1.Method\"/> 则运行结果为： 我是原始方法 增加 replaced-method 子元素： &lt;bean id=\"methodReplace\" class=\"org.springframework.core.test1.MethodReplace\"/> &lt;bean id=\"method\" class=\"org.springframework.core.test1.Method\"> &lt;replaced-method name=\"display\" replacer=\"methodReplace\"/> &lt;/bean> 运行结果为： 我是替换方法 上面代码演示了 replaced-method 子元素的用法，下面再看看该子元素的解析过程。 public void parseReplacedMethodSubElements(Element beanEle, MethodOverrides overrides) { NodeList nl = beanEle.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) { Node node = nl.item(i); if (isCandidateElement(node) &amp;&amp; nodeNameEquals(node, REPLACED_METHOD_ELEMENT)) { Element replacedMethodEle = (Element) node; String name = replacedMethodEle.getAttribute(NAME_ATTRIBUTE); String callback = replacedMethodEle.getAttribute(REPLACER_ATTRIBUTE); ReplaceOverride replaceOverride = new ReplaceOverride(name, callback); // Look for arg-type match elements. List&lt;Element> argTypeEles = DomUtils .getChildElementsByTagName(replacedMethodEle, ARG_TYPE_ELEMENT); for (Element argTypeEle : argTypeEles) { String match = argTypeEle.getAttribute(ARG_TYPE_MATCH_ATTRIBUTE); match = (StringUtils.hasText(match) ? match : DomUtils.getTextValue(argTypeEle)); if (StringUtils.hasText(match)) { replaceOverride.addTypeIdentifier(match); } } replaceOverride.setSource(extractSource(replacedMethodEle)); overrides.addOverride(replaceOverride); } } } 该子元素和 lookup-method 资源的解析过程差不多，同样是提取 name 和 replacer 属性构建 ReplaceOverride 对象，然后记录到 AbstractBeanDefinition 中的 methodOverrides 属性中。 对于 lookup-method 和 replaced-method 两个子元素是如何使用以完成他们所提供的功能，在后续实例化 Bean 的时候会做详细说明。 这两个标签很少使用","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之解析bean标签：BeanDefinition","date":"2020-01-09T07:04:56.000Z","path":"2020/01/09/af1473fe.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=2736 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE BeanDefinitionBeanDefinition 是一个接口，它描述了一个 Bean 实例，包括属性值、构造方法值和继承自它的类的更多信息。 代码如下： public interface BeanDefinition extends AttributeAccessor, BeanMetadataElement { String SCOPE_SINGLETON = ConfigurableBeanFactory.SCOPE_SINGLETON; String SCOPE_PROTOTYPE = ConfigurableBeanFactory.SCOPE_PROTOTYPE; int ROLE_APPLICATION = 0; int ROLE_SUPPORT = 1; int ROLE_INFRASTRUCTURE = 2; // Modifiable attributes void setParentName(@Nullable String parentName); @Nullable String getParentName(); void setBeanClassName(@Nullable String beanClassName); @Nullable String getBeanClassName(); void setScope(@Nullable String scope); @Nullable String getScope(); void setLazyInit(boolean lazyInit); boolean isLazyInit(); void setDependsOn(@Nullable String... dependsOn); @Nullable String[] getDependsOn(); void setAutowireCandidate(boolean autowireCandidate); boolean isAutowireCandidate(); void setPrimary(boolean primary); boolean isPrimary(); void setFactoryBeanName(@Nullable String factoryBeanName); @Nullable String getFactoryBeanName(); void setFactoryMethodName(@Nullable String factoryMethodName); @Nullable String getFactoryMethodName(); ConstructorArgumentValues getConstructorArgumentValues(); default boolean hasConstructorArgumentValues() { return !getConstructorArgumentValues().isEmpty(); } MutablePropertyValues getPropertyValues(); default boolean hasPropertyValues() { return !getPropertyValues().isEmpty(); } // Read-only attributes boolean isSingleton(); boolean isPrototype(); boolean isAbstract(); int getRole(); @Nullable String getDescription(); @Nullable String getResourceDescription(); @Nullable BeanDefinition getOriginatingBeanDefinition(); } 父类BeanDefinition继承 AttributeAccessor 和 BeanMetadataElement 接口。两个接口定义如下： AttributeAccessor ：定义了与其它对象的（元数据）进行连接和访问的约定，即对属性的修改，包括获取、设置、删除。 代码如下： public interface AttributeAccessor { void setAttribute(String name, @Nullable Object value); @Nullable Object getAttribute(String name); @Nullable Object removeAttribute(String name); boolean hasAttribute(String name); String[] attributeNames(); } BeanMetadataElement：Bean 元对象持有的配置元素可以通过getSource() 方法来获取。 代码如下： public interface BeanMetadataElement { @Nullable Object getSource(); } 子类BeanDefinition 整个结构如下图： 我们常用的三个实现类有：ChildBeanDefinition、GenericBeanDefinition、RootBeanDefinition，三者都继承 AbstractBeanDefinition。如果配置文件中定义了父 和 子 ，则父 用 RootBeanDefinition表示，子 用 ChildBeanDefinition 表示，而没有父的就使用RootBeanDefinition 表示。GenericBeanDefinition 为一站式服务类。AbstractBeanDefinition对三个子类共同的类信息进行抽象。 解析 Bean 标签在 BeanDefinitionParserDelegate.parseBeanDefinitionElement() 中完成 Bean 的解析，返回的是一个已经完成对 标签解析的 BeanDefinition 实例。 createBeanDefinition在该方法内部，首先调用 createBeanDefinition() 方法创建一个用于承载属性的 GenericBeanDefinition 实例，如下： protected AbstractBeanDefinition createBeanDefinition( @Nullable String className, @Nullable String parentName) throws ClassNotFoundException { return BeanDefinitionReaderUtils.createBeanDefinition( parentName, className, this.readerContext.getBeanClassLoader()); } 委托 BeanDefinitionReaderUtils 创建，如下： public static AbstractBeanDefinition createBeanDefinition( @Nullable String parentName, @Nullable String className, @Nullable ClassLoader classLoader) throws ClassNotFoundException { GenericBeanDefinition bd = new GenericBeanDefinition(); bd.setParentName(parentName); if (className != null) { if (classLoader != null) { bd.setBeanClass(ClassUtils.forName(className, classLoader)); } else { bd.setBeanClassName(className); } } return bd; } 该方法主要是设置 parentName 、className、classLoader。 parseBeanDefinitionAttributes创建完 GenericBeanDefinition 实例后，再调用 parseBeanDefinitionAttributes() ，该方法将创建好的 GenericBeanDefinition 实例当做参数，对 Bean 标签的所有属性进行解析，如下： public AbstractBeanDefinition parseBeanDefinitionAttributes( Element ele, String beanName, @Nullable BeanDefinition containingBean, AbstractBeanDefinition bd) { // 解析 scope 标签 if (ele.hasAttribute(SINGLETON_ATTRIBUTE)) { error(\"Old 1.x 'singleton' attribute in use - upgrade to 'scope' declaration\", ele); } else if (ele.hasAttribute(SCOPE_ATTRIBUTE)) { bd.setScope(ele.getAttribute(SCOPE_ATTRIBUTE)); } else if (containingBean != null) { // Take default from containing bean in case of an inner bean definition. bd.setScope(containingBean.getScope()); } // 解析 abstract 标签 if (ele.hasAttribute(ABSTRACT_ATTRIBUTE)) { bd.setAbstract(TRUE_VALUE.equals(ele.getAttribute(ABSTRACT_ATTRIBUTE))); } // 解析 lazy-init 标签 String lazyInit = ele.getAttribute(LAZY_INIT_ATTRIBUTE); if (DEFAULT_VALUE.equals(lazyInit)) { lazyInit = this.defaults.getLazyInit(); } bd.setLazyInit(TRUE_VALUE.equals(lazyInit)); // 解析 autowire 标签 String autowire = ele.getAttribute(AUTOWIRE_ATTRIBUTE); bd.setAutowireMode(getAutowireMode(autowire)); // 解析 depends-on 标签 if (ele.hasAttribute(DEPENDS_ON_ATTRIBUTE)) { String dependsOn = ele.getAttribute(DEPENDS_ON_ATTRIBUTE); bd.setDependsOn(StringUtils.tokenizeToStringArray(dependsOn, MULTI_VALUE_ATTRIBUTE_DELIMITERS)); } // 解析 autowire-candidate 标签 String autowireCandidate = ele.getAttribute(AUTOWIRE_CANDIDATE_ATTRIBUTE); if (\"\".equals(autowireCandidate) || DEFAULT_VALUE.equals(autowireCandidate)) { String candidatePattern = this.defaults.getAutowireCandidates(); if (candidatePattern != null) { String[] patterns = StringUtils.commaDelimitedListToStringArray(candidatePattern); bd.setAutowireCandidate(PatternMatchUtils.simpleMatch(patterns, beanName)); } } else { bd.setAutowireCandidate(TRUE_VALUE.equals(autowireCandidate)); } // 解析 primay 标签 if (ele.hasAttribute(PRIMARY_ATTRIBUTE)) { bd.setPrimary(TRUE_VALUE.equals(ele.getAttribute(PRIMARY_ATTRIBUTE))); } // 解析 init-method 标签 if (ele.hasAttribute(INIT_METHOD_ATTRIBUTE)) { String initMethodName = ele.getAttribute(INIT_METHOD_ATTRIBUTE); bd.setInitMethodName(initMethodName); } else if (this.defaults.getInitMethod() != null) { bd.setInitMethodName(this.defaults.getInitMethod()); bd.setEnforceInitMethod(false); } // 解析 destroy-mothod 标签 if (ele.hasAttribute(DESTROY_METHOD_ATTRIBUTE)) { String destroyMethodName = ele.getAttribute(DESTROY_METHOD_ATTRIBUTE); bd.setDestroyMethodName(destroyMethodName); } else if (this.defaults.getDestroyMethod() != null) { bd.setDestroyMethodName(this.defaults.getDestroyMethod()); bd.setEnforceDestroyMethod(false); } // 解析 factory-method 标签 if (ele.hasAttribute(FACTORY_METHOD_ATTRIBUTE)) { bd.setFactoryMethodName(ele.getAttribute(FACTORY_METHOD_ATTRIBUTE)); } if (ele.hasAttribute(FACTORY_BEAN_ATTRIBUTE)) { bd.setFactoryBeanName(ele.getAttribute(FACTORY_BEAN_ATTRIBUTE)); } return bd; } 从上面代码我们可以清晰地看到对 Bean 标签属性的解析，这些属性我们在工作中都或多或少用到过。 完成 Bean 标签基本属性解析后，会依次调用 parseMetaElements()、parseLookupOverrideSubElements()、parseReplacedMethodSubElements() 对子元素 meta、lookup-method、replace-method 完成解析。下篇博文将会对这三个子元素进行详细说明。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之解析bean标签：开启解析进程","date":"2020-01-08T06:28:53.000Z","path":"2020/01/08/fb623179.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=2731 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE import 标签解析完毕了，再看 Spring 中最复杂也是最重要的标签 bean 标签的解析过程。 在方法 parseDefaultElement() 中，如果遇到标签 为 bean 则调用 processBeanDefinition() 方法进行 bean 标签解析，如下： protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) { BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); if (bdHolder != null) { bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); try { // Register the final decorated instance. BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry()); } catch (BeanDefinitionStoreException ex) { getReaderContext().error(\"Failed to register bean definition with name '\" + bdHolder.getBeanName() + \"'\", ele, ex); } // Send registration event. getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder)); } } 整个过程分为四个步骤 调用 BeanDefinitionParserDelegate.parseBeanDefinitionElement() 进行元素解析，解析过程中如果失败，返回 null，错误由 ProblemReporter 处理。如果解析成功则返回 BeanDefinitionHolder 实例 bdHolder。BeanDefinitionHolder 为持有 name 和 alias 的 BeanDefinition。 若实例 bdHolder 不为空，则调用 BeanDefinitionParserDelegate.decorateBeanDefinitionIfRequired() 进行自定义标签处理 解析完成后，则调用 BeanDefinitionReaderUtils.registerBeanDefinition() 对 bdHolder 进行注册 发出响应事件，通知相关的监听器，完成 Bean 标签解析 先看方法 parseBeanDefinitionElement()，如下： public BeanDefinitionHolder parseBeanDefinitionElement(Element ele, @Nullable BeanDefinition containingBean) { // 解析 ID 属性 String id = ele.getAttribute(ID_ATTRIBUTE); // 解析 name 属性 String nameAttr = ele.getAttribute(NAME_ATTRIBUTE); // 分割 name 属性 List&lt;String> aliases = new ArrayList&lt;>(); if (StringUtils.hasLength(nameAttr)) { String[] nameArr = StringUtils.tokenizeToStringArray(nameAttr, MULTI_VALUE_ATTRIBUTE_DELIMITERS); aliases.addAll(Arrays.asList(nameArr)); } String beanName = id; if (!StringUtils.hasText(beanName) &amp;&amp; !aliases.isEmpty()) { beanName = aliases.remove(0); if (logger.isDebugEnabled()) { logger.debug(\"No XML 'id' specified - using '\" + beanName + \"' as bean name and \" + aliases + \" as aliases\"); } } // 检查 name 的唯一性 if (containingBean == null) { checkNameUniqueness(beanName, aliases, ele); } // 解析 属性，构造 AbstractBeanDefinition AbstractBeanDefinition beanDefinition = parseBeanDefinitionElement(ele, beanName, containingBean); if (beanDefinition != null) { // 如果 beanName 不存在，则根据条件构造一个 beanName if (!StringUtils.hasText(beanName)) { try { if (containingBean != null) { beanName = BeanDefinitionReaderUtils.generateBeanName( beanDefinition, this.readerContext.getRegistry(), true); } else { beanName = this.readerContext.generateBeanName(beanDefinition); String beanClassName = beanDefinition.getBeanClassName(); if (beanClassName != null &amp;&amp; beanName.startsWith(beanClassName) &amp;&amp; beanName.length() > beanClassName.length() &amp;&amp; !this.readerContext.getRegistry().isBeanNameInUse(beanClassName)) { aliases.add(beanClassName); } } if (logger.isDebugEnabled()) { logger.debug(\"Neither XML 'id' nor 'name' specified - \" + \"using generated bean name [\" + beanName + \"]\"); } } catch (Exception ex) { error(ex.getMessage(), ele); return null; } } String[] aliasesArray = StringUtils.toStringArray(aliases); // 封装 BeanDefinitionHolder return new BeanDefinitionHolder(beanDefinition, beanName, aliasesArray); } return null; } 这个方法还没有对 Bean 标签进行解析，只是在解析动作之前做了一些功能架构，主要的工作有： 解析 id、name 属性，确定 alias 集合，检测 beanName 是否唯一 调用方法 parseBeanDefinitionElement() 对属性进行解析并封装成 GenericBeanDefinition 实例 beanDefinition 根据所获取的信息（beanName、aliases、beanDefinition）构造 BeanDefinitionHolder 实例对象并返回。 这里有必要说下 beanName 的命名规则：如果 id 不为空，则 beanName = id；如果 id 为空，但是 alias 不空，则 beanName 为 alias 的第一个元素，如果两者都为空，则根据默认规则来设置 beanName。 上面三个步骤第二个步骤为核心方法，它主要承担解析 Bean 标签中所有的属性值。如下： public AbstractBeanDefinition parseBeanDefinitionElement( Element ele, String beanName, @Nullable BeanDefinition containingBean) { this.parseState.push(new BeanEntry(beanName)); String className = null; // 解析 class 属性 if (ele.hasAttribute(CLASS_ATTRIBUTE)) { className = ele.getAttribute(CLASS_ATTRIBUTE).trim(); } String parent = null; // 解析 parent 属性 if (ele.hasAttribute(PARENT_ATTRIBUTE)) { parent = ele.getAttribute(PARENT_ATTRIBUTE); } try { // 创建用于承载属性的 GenericBeanDefinition 实例 AbstractBeanDefinition bd = createBeanDefinition(className, parent); // 解析默认 bean 的各种属性 parseBeanDefinitionAttributes(ele, beanName, containingBean, bd); // 提取 description bd.setDescription(DomUtils.getChildElementValueByTagName(ele, DESCRIPTION_ELEMENT)); // 解析元数据 parseMetaElements(ele, bd); // 解析 lookup-method 属性 parseLookupOverrideSubElements(ele, bd.getMethodOverrides()); // 解析 replaced-method 属性 parseReplacedMethodSubElements(ele, bd.getMethodOverrides()); // 解析构造函数参数 parseConstructorArgElements(ele, bd); // 解析 property 子元素 parsePropertyElements(ele, bd); // 解析 qualifier 子元素 parseQualifierElements(ele, bd); bd.setResource(this.readerContext.getResource()); bd.setSource(extractSource(ele)); return bd; } catch (ClassNotFoundException ex) { error(\"Bean class [\" + className + \"] not found\", ele, ex); } catch (NoClassDefFoundError err) { error(\"Class that bean class [\" + className + \"] depends on not found\", ele, err); } catch (Throwable ex) { error(\"Unexpected failure during bean definition parsing\", ele, ex); } finally { this.parseState.pop(); } return null; } 到这里，Bean 标签的所有属性我们都可以看到其解析的过程，也就说到这里我们已经解析一个基本可用的 BeanDefinition。 由于解析过程较为漫长，篇幅较大，为了更好的观看体验，将这篇博文进行拆分。下篇博客主要介绍 BeanDefinition，以及解析默认 Bean 的过程（parseBeanDefinitionAttributes()） – - IOC 之解析Bean：解析 import 标签","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IoC之解析Bean：解析import标签","date":"2020-01-07T04:13:51.000Z","path":"2020/01/07/3f8e0ea3.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=2724 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE 在IOC 之 注册 BeanDefinition中分析到，Spring 中有两种解析 Bean 的方式。如果根节点或者子节点采用默认命名空间的话，则调用 parseDefaultElement() 进行默认标签解析，否则调用 delegate.parseCustomElement() 方法进行自定义解析。所以，以下博客就这两个方法进行详细分析说明，先从默认标签解析过程开始，源码如下： private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) { // 对 import 标签的解析 if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) { importBeanDefinitionResource(ele); } // 对 alias 标签的解析 else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) { processAliasRegistration(ele); } // 对 bean 标签的解析 else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) { processBeanDefinition(ele, delegate); } // 对 beans 标签的解析 else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) { // recurse doRegisterBeanDefinitions(ele); } } 方法的功能一目了然，分别是对四种不同的标签进行解析，分别是 import、alias、bean、beans。咱门从第一个标签 import 开始。 import 标签的处理经历过 Spring 配置文件的小伙伴都知道，如果工程比较大，配置文件的维护会让人觉得恐怖，文件太多了，想象将所有的配置都放在一个 spring.xml 配置文件中，哪种后怕感是不是很明显？所有针对这种情况 Spring 提供了一个分模块的思路，利用 import 标签，例如我们可以构造一个这样的 spring.xml。 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"> &lt;import resource=\"spring-student.xml\"/> &lt;import resource=\"spring-student-dtd.xml\"/> &lt;/beans> spring.xml 配置文件中使用 import 标签的方式导入其他模块的配置文件。 如果有配置需要修改直接修改相应配置文件即可。 若有新的模块需要引入直接增加 import 即可。 这样大大简化了配置后期维护的复杂度，同时也易于管理。 importBeanDefinitionResourceSpring 利用 importBeanDefinitionResource() 方法完成对 import 标签的解析。 protected void importBeanDefinitionResource(Element ele) { // 获取 resource 的属性值 String location = ele.getAttribute(RESOURCE_ATTRIBUTE); // 为空，直接退出 if (!StringUtils.hasText(location)) { getReaderContext().error(\"Resource location must not be empty\", ele); return; } // 解析系统属性，格式如 ：\"${user.dir}\" location = getReaderContext().getEnvironment().resolveRequiredPlaceholders(location); Set&lt;Resource> actualResources = new LinkedHashSet&lt;>(4); // 判断 location 是相对路径还是绝对路径 boolean absoluteLocation = false; try { absoluteLocation = ResourcePatternUtils.isUrl(location) || ResourceUtils.toURI(location).isAbsolute(); } catch (URISyntaxException ex) { // cannot convert to an URI, considering the location relative // unless it is the well-known Spring prefix \"classpath*:\" } // 绝对路径 if (absoluteLocation) { try { // 直接根据地质加载相应的配置文件 int importCount = getReaderContext() .getReader().loadBeanDefinitions(location, actualResources); if (logger.isDebugEnabled()) { logger.debug(\"Imported \" + importCount + \" bean definitions from URL location [\" + location + \"]\"); } } catch (BeanDefinitionStoreException ex) { getReaderContext().error( \"Failed to import bean definitions from URL location [\" + location + \"]\", ele, ex); } } else { // 相对路径则根据相应的地质计算出绝对路径地址 try { int importCount; Resource relativeResource = getReaderContext() .getResource().createRelative(location); if (relativeResource.exists()) { importCount = getReaderContext() .getReader().loadBeanDefinitions(relativeResource); actualResources.add(relativeResource); } else { String baseLocation = getReaderContext() .getResource().getURL().toString(); importCount = getReaderContext().getReader() .loadBeanDefinitions( StringUtils.applyRelativePath(baseLocation, location), actualResources); } if (logger.isDebugEnabled()) { logger.debug(\"Imported \" + importCount + \" bean definitions from relative location [\" + location + \"]\"); } } catch (IOException ex) { getReaderContext().error(\"Failed to resolve current resource location\", ele, ex); } catch (BeanDefinitionStoreException ex) { getReaderContext() .error(\"Failed to import bean definitions from relative location [\" + location + \"]\", ele, ex); } } // 解析成功后，进行监听器激活处理 Resource[] actResArray = actualResources.toArray(new Resource[0]); getReaderContext().fireImportProcessed(location, actResArray, extractSource(ele)); } 解析 import 过程较为清晰，整个过程如下： 获取 source 属性的值，该值表示资源的路径 解析路径中的系统属性，如”${user.dir}“ 判断资源路径 location 是绝对路径还是相对路径 如果是绝对路径，则调递归调用 Bean 的解析过程，进行另一次的解析 如果是相对路径，则先计算出绝对路径得到 Resource，然后进行解析 通知监听器，完成解析 判断路径 方法通过以下方法来判断 location 是为相对路径还是绝对路径： absoluteLocation = ResourcePatternUtils.isUrl(location) || ResourceUtils.toURI(location).isAbsolute(); 判断绝对路径的规则如下： 以 classpath*: 或者 classpath: 开头为绝对路径 能够通过该 location 构建出 java.net.URL为绝对路径 根据 location 构造 java.net.URI 判断调用 isAbsolute() 判断是否为绝对路径 绝对路径 如果 location 为绝对路径则调用 loadBeanDefinitions()，该方法在 AbstractBeanDefinitionReader 中定义。 public int loadBeanDefinitions(String location, @Nullable Set&lt;Resource> actualResources) throws BeanDefinitionStoreException { ResourceLoader resourceLoader = getResourceLoader(); if (resourceLoader == null) { throw new BeanDefinitionStoreException( \"Cannot import bean definitions from location [\" + location + \"]: no ResourceLoader available\"); } if (resourceLoader instanceof ResourcePatternResolver) { // Resource pattern matching available. try { Resource[] resources = ((ResourcePatternResolver) resourceLoader) .getResources(location); int loadCount = loadBeanDefinitions(resources); if (actualResources != null) { for (Resource resource : resources) { actualResources.add(resource); } } if (logger.isDebugEnabled()) { logger.debug(\"Loaded \" + loadCount + \" bean definitions from location pattern [\" + location + \"]\"); } return loadCount; } catch (IOException ex) { throw new BeanDefinitionStoreException( \"Could not resolve bean definition resource pattern [\" + location + \"]\", ex); } } else { // Can only load single resources by absolute URL. Resource resource = resourceLoader.getResource(location); int loadCount = loadBeanDefinitions(resource); if (actualResources != null) { actualResources.add(resource); } if (logger.isDebugEnabled()) { logger.debug(\"Loaded \" + loadCount + \" bean definitions from location [\" + location + \"]\"); } return loadCount; } } 整个逻辑比较简单： 首先获取 ResourceLoader 然后根据不同的 ResourceLoader 执行不同的逻辑，主要是可能存在多个 Resource 最终都会回归到 XmlBeanDefinitionReader.loadBeanDefinitions() ，所以这是一个递归的过程。 获得到的 Resource 的对象或数组，都会添加到 actualResources 中。 相对路径如果是相对路径则会根据相应的 Resource 计算出相应的绝对路径，然后 根据该路径构造一个 Resource，若该 Resource 存在，则调用 XmlBeanDefinitionReader.loadBeanDefinitions() 进行 BeanDefinition 加载 否则构造一个绝对 location ，调用 AbstractBeanDefinitionReader.loadBeanDefinitions() 方法，与绝对路径过程一样。 至此，import 标签解析完毕，整个过程比较清晰明了：获取 source 属性值，得到正确的资源路径，然后调用 loadBeanDefinitions() 方法进行递归的 BeanDefinition 加载","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IoC之注册BeanDefinitions","date":"2020-01-06T10:53:34.000Z","path":"2020/01/06/9de498cf.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=2697 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE 获取 Document 对象后，会根据该对象和 Resource 资源对象调用 registerBeanDefinitions() 方法，开始注册 BeanDefinitions 之旅。如下： public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException { BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); int countBefore = getRegistry().getBeanDefinitionCount(); documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); return getRegistry().getBeanDefinitionCount() - countBefore; } 首先调用 createBeanDefinitionDocumentReader() 方法实例化 BeanDefinitionDocumentReader 对象，然后获取统计前 BeanDefinition 的个数，最后调用 registerBeanDefinitions() 注册 BeanDefinition。 实例化 BeanDefinitionDocumentReader 对象方法如下： protected BeanDefinitionDocumentReader createBeanDefinitionDocumentReader() { return BeanDefinitionDocumentReader.class.cast(BeanUtils .instantiateClass(this.documentReaderClass)); } 注册 BeanDefinition 的方法 registerBeanDefinitions() 是在接口 BeanDefinitionDocumentReader 中定义，如下： void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) throws BeanDefinitionStoreException; 从给定的 Document 对象中解析定义的 BeanDefinition 并将他们注册到注册表中。 方法接收两个参数，待解析的 Document 对象，以及解析器的当前上下文，包括目标注册表和被解析的资源。其中 readerContext 是根据 Resource 来创建的，如下： public XmlReaderContext createReaderContext(Resource resource) { return new XmlReaderContext(resource, this.problemReporter, this.eventListener, this.sourceExtractor, this, getNamespaceHandlerResolver()); } DefaultBeanDefinitionDocumentReader 对该方法提供了实现： public void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) { this.readerContext = readerContext; logger.debug(\"Loading bean definitions\"); Element root = doc.getDocumentElement(); doRegisterBeanDefinitions(root); } 调用 doRegisterBeanDefinitions() 开启注册 BeanDefinition 之旅。 protected void doRegisterBeanDefinitions(Element root) { BeanDefinitionParserDelegate parent = this.delegate; this.delegate = createDelegate(getReaderContext(), root, parent); if (this.delegate.isDefaultNamespace(root)) { // 处理 profile String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE); if (StringUtils.hasText(profileSpec)) { String[] specifiedProfiles = StringUtils.tokenizeToStringArray( profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS); if (!getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) { if (logger.isInfoEnabled()) { logger.info( \"Skipped XML bean definition file due to specified profiles [\" + profileSpec + \"] not matching: \" + getReaderContext().getResource()); } return; } } } // 解析前处理 preProcessXml(root); // 解析 parseBeanDefinitions(root, this.delegate); // 解析后处理 postProcessXml(root); this.delegate = parent; } 程序首先处理 profile属性，profile主要用于我们切换环境，比如切换开发、测试、生产环境，非常方便。然后调用 parseBeanDefinitions() 进行解析动作，不过在该方法之前之后分别调用 preProcessXml() 和 postProcessXml() 方法来进行前、后处理，目前这两个方法都是空实现，交由子类来实现。 protected void preProcessXml(Element root) { } protected void postProcessXml(Element root) { } parseBeanDefinitions() 定义如下： protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) { if (delegate.isDefaultNamespace(root)) { NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) { Node node = nl.item(i); if (node instanceof Element) { Element ele = (Element) node; if (delegate.isDefaultNamespace(ele)) { parseDefaultElement(ele, delegate); } else { delegate.parseCustomElement(ele); } } } } else { delegate.parseCustomElement(root); } } 最终解析动作落地在两个方法处：parseDefaultElement(ele, delegate) 和 delegate.parseCustomElement(root)。我们知道在 Spring 有两种 Bean 声明方式： 配置文件式声明：&lt;bean id=&quot;studentService&quot; class=&quot;org.springframework.core.StudentService&quot;/&gt; 自定义注解方式：&lt;tx:annotation-driven&gt; 两种方式的读取和解析都存在较大的差异，所以采用不同的解析方法，如果根节点或者子节点采用默认命名空间的话，则调用 parseDefaultElement() 进行解析，否则调用 delegate.parseCustomElement() 方法进行自定义解析。 至此，doLoadBeanDefinitions() 中做的三件事情已经全部分析完毕，下面将对 Bean 的解析过程做详细分析说明。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之获取Document对象","date":"2020-01-05T06:21:04.000Z","path":"2020/01/05/13336b20.html","text":"在 XmlBeanDefinitionReader.doLoadDocument() 方法中做了两件事情，一是调用 getValidationModeForResource() 获取 XML 的验证模式，二是调用 DocumentLoader.loadDocument() 获取 Document 对象。上篇博客已经分析了获取 XML 验证模式（IOC 之 获取验证模型），这篇我们分析获取 Document 对象。 DocumentLoader获取 Document 的策略由接口 DocumentLoader 定义，如下： public interface DocumentLoader { Document loadDocument( InputSource inputSource, EntityResolver entityResolver, ErrorHandler errorHandler, int validationMode, boolean namespaceAware) throws Exception; } DocumentLoader 中只有一个方法 loadDocument() ，该方法接收五个参数： inputSource：加载 Document 的 Resource 源 entityResolver：解析文件的解析器 errorHandler：处理加载 Document 对象的过程的错误 validationMode：验证模式 namespaceAware：命名空间支持。 如果要提供对 XML 名称空间的支持，则为true 该方法由 DocumentLoader 的默认实现类 DefaultDocumentLoader 实现，如下： public Document loadDocument(InputSource inputSource, EntityResolver entityResolver, ErrorHandler errorHandler, int validationMode, boolean namespaceAware) throws Exception { DocumentBuilderFactory factory = createDocumentBuilderFactory(validationMode, namespaceAware); if (logger.isDebugEnabled()) { logger.debug(\"Using JAXP provider [\" + factory.getClass().getName() + \"]\"); } DocumentBuilder builder = createDocumentBuilder(factory, entityResolver, errorHandler); return builder.parse(inputSource); } 首先调用 createDocumentBuilderFactory() 创建 DocumentBuilderFactory ，再通过该 factory 创建 DocumentBuilder，最后解析 InputSource 返回 Document 对象。 EntityResolverloadDocument() 获取 Document 对象时，有一个参数 entityResolver ，该参数是通过 getEntityResolver() 获取的。 getEntityResolver() 返回指定的解析器，如果没有指定，则构造一个未指定的默认解析器。 protected EntityResolver getEntityResolver() { if (this.entityResolver == null) { ResourceLoader resourceLoader = getResourceLoader(); if (resourceLoader != null) { this.entityResolver = new ResourceEntityResolver(resourceLoader); } else { this.entityResolver = new DelegatingEntityResolver(getBeanClassLoader()); } } return this.entityResolver; } 如果 ResourceLoader 不为 null，则根据指定的 ResourceLoader 创建一个 ResourceEntityResolver。 如果 ResourceLoader 为null，则创建 一个 DelegatingEntityResolver，该 Resolver 委托给默认的 BeansDtdResolver 和 PluggableSchemaResolver 。 涉及子类 ResourceEntityResolver：继承自 EntityResolver ，通过 ResourceLoader 来解析实体的引用。 DelegatingEntityResolver：EntityResolver 的实现，分别代理了 dtd 的 BeansDtdResolver 和 xml schemas 的 PluggableSchemaResolver。 BeansDtdResolver ： spring bean dtd 解析器。EntityResolver 的实现，用来从 classpath 或者 jar 文件加载 dtd。 PluggableSchemaResolver：使用一系列 Map 文件将 schema url 解析到本地 classpath 资源 getEntityResolver() 返回 EntityResolver ，那这个 EntityResolver 到底是什么呢？ If a SAX application needs to implement customized handling for external entities, it must implement this interface and register an instance with the SAX driver using the setEntityResolver method.就是说：如果 SAX 应用程序需要实现自定义处理外部实体，则必须实现此接口并使用 setEntityResolver() 向 SAX 驱动器注册一个实例。 如下： public class MyResolver implements EntityResolver { public InputSource resolveEntity (String publicId, String systemId){ if (systemId.equals(\"http://www.myhost.com/today\")){ MyReader reader = new MyReader(); return new InputSource(reader); } else { // use the default behaviour return null; } } } 我们首先将 spring-student.xml 文件中的 XSD 声明的地址改掉，如下： 如果我们再次运行，则会报如下错误： 从上面的错误可以看到，是在进行文档验证时，无法根据声明找到 XSD 验证文件而导致无法进行 XML 文件验证。在(IOC 之 获取验证模型)中讲到，如果要解析一个 XML 文件，SAX 首先会读取该 XML 文档上的声明，然后根据声明去寻找相应的 DTD 定义，以便对文档进行验证。默认的加载规则是通过网络方式下载验证文件，而在实际生产环境中我们会遇到网络中断或者不可用状态，那么就应用就会因为无法下载验证文件而报错。 EntityResolver 的作用就是应用本身可以提供一个如何寻找验证文件的方法，即自定义实现。 接口声明如下： public interface EntityResolver { public abstract InputSource resolveEntity (String publicId,String systemId) throws SAXException, IOException; } 接口方法接收两个参数 publicId 和 systemId，并返回 InputSource 对象。两个参数声明如下： publicId：被引用的外部实体的公共标识符，如果没有提供，则返回null systemId：被引用的外部实体的系统标识符 这两个参数的实际内容和具体的验证模式有关系。如下 XSD 验证模式 publicId：null systemId：http://www.springframework.org/schema/beans/spring-beans.xsd DTD 验证模式 publicId：-//SPRING//DTD BEAN 2.0//EN systemId：http://www.springframework.org/dtd/spring-beans.dtd 如下： )我们知道在 Spring 中使用 DelegatingEntityResolver 为 EntityResolver 的实现类，resolveEntity() 实现如下： public InputSource resolveEntity(String publicId, @Nullable String systemId) throws SAXException, IOException { if (systemId != null) { if (systemId.endsWith(DTD_SUFFIX)) { return this.dtdResolver.resolveEntity(publicId, systemId); } else if (systemId.endsWith(XSD_SUFFIX)) { return this.schemaResolver.resolveEntity(publicId, systemId); } } return null; } 不同的验证模式使用不同的解析器解析，如果是 DTD 验证模式则使用 BeansDtdResolver 来进行解析，如果是 XSD 则使用 PluggableSchemaResolver 来进行解析。 BeansDtdResolver 的解析过程如下: public InputSource resolveEntity(String publicId, @Nullable String systemId) throws IOException { if (logger.isTraceEnabled()) { logger.trace(\"Trying to resolve XML entity with public ID [\" + publicId + \"] and system ID [\" + systemId + \"]\"); } if (systemId != null &amp;&amp; systemId.endsWith(DTD_EXTENSION)) { int lastPathSeparator = systemId.lastIndexOf('/'); int dtdNameStart = systemId.indexOf(DTD_NAME, lastPathSeparator); if (dtdNameStart != -1) { String dtdFile = DTD_NAME + DTD_EXTENSION; if (logger.isTraceEnabled()) { logger.trace(\"Trying to locate [\" + dtdFile + \"] in Spring jar on classpath\"); } try { Resource resource = new ClassPathResource(dtdFile, getClass()); InputSource source = new InputSource(resource.getInputStream()); source.setPublicId(publicId); source.setSystemId(systemId); if (logger.isDebugEnabled()) { logger.debug(\"Found beans DTD [\" + systemId + \"] in classpath: \" + dtdFile); } return source; } catch (IOException ex) { if (logger.isDebugEnabled()) { logger.debug(\"Could not resolve beans DTD [\" + systemId + \"]: not found in classpath\", ex); } } } } or wherever. return null; } 从上面的代码中我们可以看到加载 DTD 类型的 BeansDtdResolver.resolveEntity() 只是对 systemId 进行了简单的校验（从最后一个 / 开始，内容中是否包含 spring-beans），然后构造一个 InputSource 并设置 publicId、systemId，然后返回。 PluggableSchemaResolver 的解析过程如下: public InputSource resolveEntity(String publicId, @Nullable String systemId) throws IOException { if (logger.isTraceEnabled()) { logger.trace(\"Trying to resolve XML entity with public id [\" + publicId + \"] and system id [\" + systemId + \"]\"); } if (systemId != null) { String resourceLocation = getSchemaMappings().get(systemId); if (resourceLocation != null) { Resource resource = new ClassPathResource(resourceLocation, this.classLoader); try { InputSource source = new InputSource(resource.getInputStream()); source.setPublicId(publicId); source.setSystemId(systemId); if (logger.isDebugEnabled()) { logger.debug(\"Found XML schema [\" + systemId + \"] in classpath: \" + resourceLocation); } return source; } catch (FileNotFoundException ex) { if (logger.isDebugEnabled()) { logger.debug(\"Couldn't find XML schema [\" + systemId + \"]: \" + resource, ex); } } } } return null; } 首先调用 getSchemaMappings() 获取一个映射表(systemId 与其在本地的对照关系)，然后根据传入的 systemId 获取该 systemId 在本地的路径 resourceLocation，最后根据 resourceLocation 构造 InputSource 对象。 映射表如下（部分）:","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之获取验证模型","date":"2020-01-04T06:21:04.000Z","path":"2020/01/04/4e0696ee.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=2658 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE 在上篇博客IOC 之 加载 BeanDefinition 中提到，在核心逻辑方法 doLoadBeanDefinitions()中主要是做三件事情。 调用 getValidationModeForResource() 获取 xml 文件的验证模式 调用 loadDocument() 根据 xml 文件获取相应的 Document 实例。 调用 registerBeanDefinitions() 注册 Bean 实例。 这篇博客主要分析获取 xml 文件的验证模式。 XML 文件的验证模式保证了 XML 文件的正确性 DTD 与 XSD 的区别DTD(Document Type Definition)，即文档类型定义，为 XML 文件的验证机制，属于 XML 文件中组成的一部分。DTD 是一种保证 XML 文档格式正确的有效验证方式，它定义了相关 XML 文档的元素、属性、排列方式、元素的内容类型以及元素的层次结构。其实 DTD 就相当于 XML 中的 “词汇”和“语法”，我们可以通过比较 XML 文件和 DTD 文件 来看文档是否符合规范，元素和标签使用是否正确。 要在 Spring 中使用 DTD，需要在 Spring XML 文件头部声明： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;!DOCTYPE beans PUBLIC \"-//SPRING//DTD BEAN//EN\" \"http://www.springframework.org/dtd/spring-beans.dtd\"> DTD 在一定的阶段推动了 XML 的发展，但是它本身存在着一些缺陷： 它没有使用 XML 格式，而是自己定义了一套格式，相对解析器的重用性较差；而且 DTD 的构建和访问没有标准的编程接口，因而解析器很难简单的解析 DTD 文档。 DTD 对元素的类型限制较少；同时其他的约束力也叫弱。 DTD 扩展能力较差。 基于正则表达式的 DTD 文档的描述能力有限。 针对 DTD 的缺陷，W3C 在 2001 年推出 XSD。XSD（XML Schemas Definition）即 XML Schema 语言。XML Schema 本身就是一个 XML文档，使用的是 XML 语法，因此可以很方便的解析 XSD 文档。 相对于 DTD，XSD 具有如下优势： XML Schema基于XML,没有专门的语法 XML Schema可以象其他XML文件一样解析和处理 XML Schema比DTD提供了更丰富的数据类型. XML Schema提供可扩充的数据模型。 XML Schema支持综合命名空间 XML Schema支持属性组。 getValidationModeForResource() 分析protected int getValidationModeForResource(Resource resource) { // 获取指定的验证模式 int validationModeToUse = getValidationMode(); // 如果手动指定，则直接返回 if (validationModeToUse != VALIDATION_AUTO) { return validationModeToUse; } // 通过程序检测 int detectedMode = detectValidationMode(resource); if (detectedMode != VALIDATION_AUTO) { return detectedMode; } // 出现异常，返回 XSD return VALIDATION_XSD; } 如果指定了 XML 文件的的验证模式（调用XmlBeanDefinitionReader.setValidating(boolean validating)）则直接返回指定的验证模式，否则调用 detectValidationMode() 获取相应的验证模式，如下： protected int detectValidationMode(Resource resource) { if (resource.isOpen()) { throw new BeanDefinitionStoreException( \"Passed-in Resource [\" + resource + \"] contains an open stream: \" + \"cannot determine validation mode automatically. Either pass in a Resource \" + \"that is able to create fresh streams, or explicitly specify the validationMode \" + \"on your XmlBeanDefinitionReader instance.\"); } InputStream inputStream; try { inputStream = resource.getInputStream(); } catch (IOException ex) { throw new BeanDefinitionStoreException( \"Unable to determine validation mode for [\" + resource + \"]: cannot open InputStream. \" + \"Did you attempt to load directly from a SAX InputSource without specifying the \" + \"validationMode on your XmlBeanDefinitionReader instance?\", ex); } try { // 核心方法 return this.validationModeDetector.detectValidationMode(inputStream); } catch (IOException ex) { throw new BeanDefinitionStoreException( \"Unable to determine validation mode for [\" + resource + \"]: an error occurred whilst reading from the InputStream.\", ex); } } 前面一大堆的代码，核心在于 this.validationModeDetector.detectValidationMode(inputStream)，validationModeDetector 定义为 XmlValidationModeDetector,所以验证模式的获取委托给 XmlValidationModeDetector 的 detectValidationMode() 方法。 public int detectValidationMode(InputStream inputStream) throws IOException { BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream)); try { boolean isDtdValidated = false; String content; // 一行一行读取 xml 文件的内容 while ((content = reader.readLine()) != null) { content = consumeCommentTokens(content); if (this.inComment || !StringUtils.hasText(content)) { continue; } // 包含 DOCTYPE 为 DTD 模式 if (hasDoctype(content)) { isDtdValidated = true; break; } // 读取 &lt; 开始符号，验证模式一定会在 &lt; 符号之前 if (hasOpeningTag(content)) { // End of meaningful data... break; } } // 为 true 返回 DTD，否则返回 XSD return (isDtdValidated ? VALIDATION_DTD : VALIDATION_XSD); } catch (CharConversionException ex) { // 出现异常，为 XSD return VALIDATION_AUTO; } finally { reader.close(); } } 从代码中看，主要是通过读取 XML 文件的内容，判断内容中是否包含有 DOCTYPE ，如果是 则为 DTD，否则为 XSD，当然只会读取到 第一个 “&lt;“ 处，因为 验证模式一定会在第一个 “&lt;” 之前。如果当中出现了 CharConversionException 异常，则为 XSD模式。 好了，XML 文件的验证模式分析完毕，下篇分析 doLoadBeanDefinitions() 的第二个步骤：获取 Document 实例。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IoC之加载BeanDefinition","date":"2020-01-02T23:14:45.000Z","path":"2020/01/03/a6d994a0.html","text":"本文作者：chenssy 出处：http://cmsblogs.com/?p=2658 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE 开局先看一段代码： ClassPathResource resource = new ClassPathResource(\"bean.xml\"); DefaultListableBeanFactory factory = new DefaultListableBeanFactory(); XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(factory); reader.loadBeanDefinitions(resource); 这段代码是 Spring 中编程式使用 IOC 容器，通过这四段简单的代码，我们可以初步判断 IOC 容器的使用过程。 获取资源 获取 BeanFactory 根据新建的 BeanFactory 创建一个BeanDefinitionReader对象，该Reader 对象为资源的解析器 装载资源 整个过程就分为三个步骤：资源定位、装载、注册，如下： 资源定位。我们一般用外部资源来描述 Bean 对象，所以在初始化 IOC 容器的第一步就是需要定位这个外部资源。在（ IOC 之 Spring 统一资源加载策略）已经详细说明了资源加载的过程。 装载。装载就是 BeanDefinition 的载入。BeanDefinitionReader 读取、解析 Resource 资源，也就是将用户定义的 Bean 表示成 IOC 容器的内部数据结构：BeanDefinition。在 IOC 容器内部维护着一个 BeanDefinition Map 的数据结构，在配置文件中每一个 都对应着一个BeanDefinition对象。 注册。向IOC容器注册在第二步解析好的 BeanDefinition，这个过程是通过 BeanDefinitionRegistry 接口来实现的。在 IOC 容器内部其实是将第二个过程解析得到的 BeanDefinition 注入到一个 HashMap 容器中，IOC 容器就是通过这个 HashMap 来维护这些 BeanDefinition 的。在这里需要注意的一点是这个过程并没有完成依赖注入，依赖注册是发生在应用第一次调用 getBean() 向容器索要 Bean 时。当然我们可以通过设置预处理，即对某个 Bean 设置 lazyinit 属性，那么这个 Bean 的依赖注入就会在容器初始化的时候完成。 XML Resource =&gt; XML Document =&gt; Bean Definition 。 资源定位在前面已经分析了，下面我们直接分析加载，上面提过reader.loadBeanDefinitions(resource) 才是加载资源的真正实现，所以我们直接从该方法入手。 public int loadBeanDefinitions(Resource resource) throws BeanDefinitionStoreException { return loadBeanDefinitions(new EncodedResource(resource)); } 从指定的 xml 文件加载 BeanDefinition，这里会先对 Resource 资源封装成 EncodedResource。这里为什么需要将 Resource 封装成 EncodedResource呢？主要是为了对 Resource 进行编码，保证内容读取的正确性。封装成 EncodedResource 后，调用loadBeanDefinitions()，这个方法才是真正的逻辑实现。如下： public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException { Assert.notNull(encodedResource, \"EncodedResource must not be null\"); if (logger.isInfoEnabled()) { logger.info(\"Loading XML bean definitions from \" + encodedResource.getResource()); } // 获取已经加载过的资源 Set&lt;EncodedResource> currentResources = this.resourcesCurrentlyBeingLoaded.get(); if (currentResources == null) { currentResources = new HashSet&lt;>(4); this.resourcesCurrentlyBeingLoaded.set(currentResources); } // 将当前资源加入记录中 if (!currentResources.add(encodedResource)) { throw new BeanDefinitionStoreException( \"Detected cyclic loading of \" + encodedResource + \" - check your import definitions!\"); } try { // 从 EncodedResource 获取封装的 Resource 并从 Resource 中获取其中的 InputStream InputStream inputStream = encodedResource.getResource().getInputStream(); try { InputSource inputSource = new InputSource(inputStream); // 设置编码 if (encodedResource.getEncoding() != null) { inputSource.setEncoding(encodedResource.getEncoding()); } // 核心逻辑部分 return doLoadBeanDefinitions(inputSource, encodedResource.getResource()); } finally { inputStream.close(); } } catch (IOException ex) { throw new BeanDefinitionStoreException( \"IOException parsing XML document from \" + encodedResource.getResource(), ex); } finally { // 从缓存中剔除该资源 currentResources.remove(encodedResource); if (currentResources.isEmpty()) { this.resourcesCurrentlyBeingLoaded.remove(); } } } 首先通过 resourcesCurrentlyBeingLoaded.get() 来获取已经加载过的资源，然后将 encodedResource 加入其中，如果 resourcesCurrentlyBeingLoaded 中已经存在该资源，则抛出 BeanDefinitionStoreException 异常。完成后从 encodedResource 获取封装的 Resource 资源并从 Resource 中获取相应的 InputStream ，最后将 InputStream 封装为 InputSource 调用 doLoadBeanDefinitions()。 方法 doLoadBeanDefinitions() 为从 xml 文件中加载 BeanDefinition 的真正逻辑，如下: protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException { try { // 获取 Document 实例 Document doc = doLoadDocument(inputSource, resource); // 根据 Document 实例****注册 Bean信息 return registerBeanDefinitions(doc, resource); } catch (BeanDefinitionStoreException ex) { throw ex; } catch (SAXParseException ex) { throw new XmlBeanDefinitionStoreException(resource.getDescription(), \"Line \" + ex.getLineNumber() + \" in XML document from \" + resource + \" is invalid\", ex); } catch (SAXException ex) { throw new XmlBeanDefinitionStoreException(resource.getDescription(), \"XML document from \" + resource + \" is invalid\", ex); } catch (ParserConfigurationException ex) { throw new BeanDefinitionStoreException(resource.getDescription(), \"Parser configuration exception parsing XML from \" + resource, ex); } catch (IOException ex) { throw new BeanDefinitionStoreException(resource.getDescription(), \"IOException parsing XML document from \" + resource, ex); } catch (Throwable ex) { throw new BeanDefinitionStoreException(resource.getDescription(), \"Unexpected exception parsing XML document from \" + resource, ex); } } 核心部分就是 try 块的两行代码。 调用 doLoadDocument() 方法，根据 xml 文件获取 Document 实例。 根据获取的 Document 实例注册 Bean 信息。 其实在 doLoadDocument()方法内部还获取了 xml 文件的验证模式。如下: protected Document doLoadDocument(InputSource inputSource, Resource resource) throws Exception { return this.documentLoader.loadDocument(inputSource, getEntityResolver(), this.errorHandler, getValidationModeForResource(resource), isNamespaceAware()); } 调用getValidationModeForResource() 获取指定资源（xml）的验证模式。 所以 doLoadBeanDefinitions()主要就是做了三件事情。 调用 getValidationModeForResource() 获取 xml 文件的验证模式 调用 loadDocument() 根据 xml 文件获取相应的 Document 实例。 调用 registerBeanDefinitions() 注册 Bean 实例。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之Spring统一资源加载策略","date":"2020-01-02T14:30:27.000Z","path":"2020/01/02/8f7aa5ac.html","text":"摘要 本文作者：chenssy 出处：http://cmsblogs.com/?p=2656 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE 资源加载策略需要满足如下要求： 职能划分清楚。资源的定义和资源的加载应该要有一个清晰的界限； 统一的抽象。统一的资源定义和资源加载策略。资源加载后要返回统一的抽象给客户端，客户端要对资源进行怎样的处理，应该由抽象资源接口来界定。 统一资源：Resourceorg.springframework.core.io.Resource 为 Spring 框架所有资源的抽象和访问接口，它继承 org.springframework.core.io.InputStreamSource接口。作为所有资源的统一抽象，Source 定义了一些通用的方法，由子类 AbstractResource 提供统一的默认实现。定义如下： public interface Resource extends InputStreamSource { /** * 资源是否存在 */ boolean exists(); /** * 资源是否可读 */ default boolean isReadable() { return true; } /** * 资源所代表的句柄是否被一个stream打开了 */ default boolean isOpen() { return false; } /** * 是否为 File */ default boolean isFile() { return false; } /** * 返回资源的URL的句柄 */ URL getURL() throws IOException; /** * 返回资源的URI的句柄 */ URI getURI() throws IOException; /** * 返回资源的File的句柄 */ File getFile() throws IOException; /** * 返回 ReadableByteChannel */ default ReadableByteChannel readableChannel() throws IOException { return Channels.newChannel(getInputStream()); } /** * 资源内容的长度 */ long contentLength() throws IOException; /** * 资源最后的修改时间 */ long lastModified() throws IOException; /** * 根据资源的相对路径创建新资源 */ Resource createRelative(String relativePath) throws IOException; /** * 资源的文件名 */ @Nullable String getFilename(); /** * 资源的描述 */ String getDescription(); } 类结构图如下： 从上图可以看到，Resource 根据资源的不同类型提供不同的具体实现，如下： FileSystemResource：对 java.io.File 类型资源的封装，只要是跟 File 打交道的，基本上与 FileSystemResource 也可以打交道。支持文件和 URL 的形式，实现 WritableResource 接口，且从 Spring Framework 5.0 开始，FileSystemResource 使用NIO.2 API进行读/写交互 ByteArrayResource：对字节数组提供的数据的封装。如果通过 InputStream 形式访问该类型的资源，该实现会根据字节数组的数据构造一个相应的 ByteArrayInputStream。 UrlResource：对 java.net.URL类型资源的封装。内部委派 URL 进行具体的资源操作。 ClassPathResource：class path 类型资源的实现。使用给定的 ClassLoader 或者给定的 Class 来加载资源。 InputStreamResource：将给定的 InputStream 作为一种资源的 Resource 的实现类。 AbstractResource 为 Resource 接口的默认实现，它实现了 Resource 接口的大部分的公共实现，作为 Resource 接口中的重中之重，其定义如下： public abstract class AbstractResource implements Resource { /** * 判断文件是否存在，若判断过程产生异常（因为会调用SecurityManager来判断），就关闭对应的流 */ @Override public boolean exists() { try { return getFile().exists(); } catch (IOException ex) { // Fall back to stream existence: can we open the stream? try { InputStream is = getInputStream(); is.close(); return true; } catch (Throwable isEx) { return false; } } } /** * 直接返回true，表示可读 */ @Override public boolean isReadable() { return true; } /** * 直接返回 false，表示未被打开 */ @Override public boolean isOpen() { return false; } /** * 直接返回false，表示不为 File */ @Override public boolean isFile() { return false; } /** * 抛出 FileNotFoundException 异常，交给子类实现 */ @Override public URL getURL() throws IOException { throw new FileNotFoundException(getDescription() + \" cannot be resolved to URL\"); } /** * 基于 getURL() 返回的 URL 构建 URI */ @Override public URI getURI() throws IOException { URL url = getURL(); try { return ResourceUtils.toURI(url); } catch (URISyntaxException ex) { throw new NestedIOException(\"Invalid URI [\" + url + \"]\", ex); } } /** * 抛出 FileNotFoundException 异常，交给子类实现 */ @Override public File getFile() throws IOException { throw new FileNotFoundException(getDescription() + \" cannot be resolved to absolute file path\"); } /** * 根据 getInputStream() 的返回结果构建 ReadableByteChannel */ @Override public ReadableByteChannel readableChannel() throws IOException { return Channels.newChannel(getInputStream()); } /** * 获取资源的长度 * * 这个资源内容长度实际就是资源的字节长度，通过全部读取一遍来判断 */ @Override public long contentLength() throws IOException { InputStream is = getInputStream(); try { long size = 0; byte[] buf = new byte[255]; int read; while ((read = is.read(buf)) != -1) { size += read; } return size; } finally { try { is.close(); } catch (IOException ex) { } } } /** * 返回资源最后的修改时间 */ @Override public long lastModified() throws IOException { long lastModified = getFileForLastModifiedCheck().lastModified(); if (lastModified == 0L) { throw new FileNotFoundException( getDescription() + \" cannot be resolved in the file system for resolving its last-modified timestamp\"); } return lastModified; } protected File getFileForLastModifiedCheck() throws IOException { return getFile(); } /** * 交给子类实现 */ @Override public Resource createRelative(String relativePath) throws IOException { throw new FileNotFoundException( \"Cannot create a relative resource for \" + getDescription()); } /** * 获取资源名称，默认返回 null */ @Override @Nullable public String getFilename() { return null; } /** * 返回资源的描述 */ @Override public String toString() { return getDescription(); } @Override public boolean equals(Object obj) { return (obj == this || (obj instanceof Resource &amp;&amp; ((Resource) obj) .getDescription().equals(getDescription()))); } @Override public int hashCode() { return getDescription().hashCode(); } } 如果我们想要实现自定义的 Resource，记住不要实现 Resource 接口，而应该继承 AbstractResource 抽象类，然后根据当前的具体资源特性覆盖相应的方法即可。 统一资源定位(ResourceLoader)一开始就说了 Spring 将资源的定义和资源的加载区分开了，Resource 定义了统一的资源，那资源的加载则由 ResourceLoader 来统一定义。 org.springframework.core.io.ResourceLoader 为 Spring 资源加载的统一抽象，具体的资源加载则由相应的实现类来完成，所以我们可以将 ResourceLoader 称作为统一资源定位器。其定义如下： public interface ResourceLoader { String CLASSPATH_URL_PREFIX = ResourceUtils.CLASSPATH_URL_PREFIX; Resource getResource(String location); ClassLoader getClassLoader(); } ResourceLoader 接口提供两个方法：getResource()、getClassLoader()。 getResource()根据所提供资源的路径 location 返回 Resource 实例，但是它不确保该 Resource 一定存在，需要调用 Resource.exist()方法判断。该方法支持以下模式的资源加载： URL位置资源，如”file:C:/test.dat” ClassPath位置资源，如”classpath:test.dat” 相对路径资源，如”WEB-INF/test.dat”，此时返回的Resource实例根据实现不同而不同 该方法的主要实现是在其子类 DefaultResourceLoader 中实现，具体过程我们在分析 DefaultResourceLoader 时做详细说明。 getClassLoader() 返回 ClassLoader 实例，对于想要获取 ResourceLoader 使用的 ClassLoader 用户来说，可以直接调用该方法来获取， 在分析 Resource 时，提到了一个类 ClassPathResource ，这个类是可以根据指定的 ClassLoader 来加载资源的。 作为 Spring 统一的资源加载器，它提供了统一的抽象，具体的实现则由相应的子类来负责实现，其类的类结构图如下： DefaultResourceLoaderDefaultResourceLoader 是 ResourceLoader 的默认实现，它接收 ClassLoader 作为构造函数的参数或者使用不带参数的构造函数，在使用不带参数的构造函数时，使用的 ClassLoader 为默认的 ClassLoader（一般为Thread.currentThread().getContextClassLoader()），可以通过 ClassUtils.getDefaultClassLoader()获取。当然也可以调用 setClassLoader()方法进行后续设置。如下： public DefaultResourceLoader() { this.classLoader = ClassUtils.getDefaultClassLoader(); } public DefaultResourceLoader(@Nullable ClassLoader classLoader) { this.classLoader = classLoader; } public void setClassLoader(@Nullable ClassLoader classLoader) { this.classLoader = classLoader; } @Override @Nullable public ClassLoader getClassLoader() { return (this.classLoader != null ? this.classLoader : ClassUtils.getDefaultClassLoader()); } ResourceLoader 中最核心的方法为 getResource(),它根据提供的 location 返回相应的 Resource，而 DefaultResourceLoader 对该方法提供了核心实现(它的两个子类都没有提供覆盖该方法，所以可以断定ResourceLoader 的资源加载策略就封装 DefaultResourceLoader中)，如下： public Resource getResource(String location) { Assert.notNull(location, \"Location must not be null\"); for (ProtocolResolver protocolResolver : this.protocolResolvers) { Resource resource = protocolResolver.resolve(location, this); if (resource != null) { return resource; } } if (location.startsWith(\"/\")) { return getResourceByPath(location); } else if (location.startsWith(CLASSPATH_URL_PREFIX)) { return new ClassPathResource(location.substring( CLASSPATH_URL_PREFIX.length()), getClassLoader()); } else { try { // Try to parse the location as a URL... URL url = new URL(location); return (ResourceUtils.isFileURL(url) ? new FileUrlResource(url) : new UrlResource(url)); } catch (MalformedURLException ex) { // No URL -> resolve as resource path. return getResourceByPath(location); } } } 首先通过 ProtocolResolver 来加载资源，成功返回 Resource，否则调用如下逻辑： 若 location 以 / 开头，则调用 getResourceByPath()构造 ClassPathContextResource 类型资源并返回。 若 location 以 classpath: 开头，则构造 ClassPathResource 类型资源并返回，在构造该资源时，通过 getClassLoader()获取当前的 ClassLoader。 构造 URL ，尝试通过它进行资源定位，若没有抛出 MalformedURLException 异常，则判断是否为 FileURL , 如果是则构造 FileUrlResource 类型资源，否则构造 UrlResource。若在加载过程中抛出 MalformedURLException 异常，则委派 getResourceByPath() 实现资源定位加载。 ProtocolResolver ，用户自定义协议资源解决策略，作为 DefaultResourceLoader 的 SPI，它允许用户自定义资源加载协议，而不需要继承 ResourceLoader 的子类。在介绍 Resource 时，提到如果要实现自定义 Resource，我们只需要继承 DefaultResource 即可，但是有了 ProtocolResolver 后，我们不需要直接继承 DefaultResourceLoader，改为实现 ProtocolResolver 接口也可以实现自定义的 ResourceLoader。 ProtocolResolver 接口，仅有一个方法 Resource resolve(String location, ResourceLoader resourceLoader)，该方法接收两个参数：资源路径location，指定的加载器 ResourceLoader，返回为相应的 Resource 。在 Spring 中你会发现该接口并没有实现类，它需要用户自定义，自定义的 Resolver 如何加入 Spring 体系呢？调用 DefaultResourceLoader.addProtocolResolver() 即可，如下： public void addProtocolResolver(ProtocolResolver resolver) { Assert.notNull(resolver, \"ProtocolResolver must not be null\"); this.protocolResolvers.add(resolver); } 下面示例是演示 DefaultResourceLoader 加载资源的具体策略，代码如下（该示例参考《Spring 解密》 P89）： ResourceLoader resourceLoader = new DefaultResourceLoader(); Resource fileResource1 = resourceLoader.getResource(\"D:/Users/chenming673/Documents/spark.txt\"); System.out.println(\"fileResource1 is FileSystemResource:\" + (fileResource1 instanceof FileSystemResource)); Resource fileResource2 = resourceLoader.getResource(\"/Users/chenming673/Documents/spark.txt\"); System.out.println(\"fileResource2 is ClassPathResource:\" + (fileResource2 instanceof ClassPathResource)); Resource urlResource1 = resourceLoader.getResource(\"file:/Users/chenming673/Documents/spark.txt\"); System.out.println(\"urlResource1 is UrlResource:\" + (urlResource1 instanceof UrlResource)); Resource urlResource2 = resourceLoader.getResource(\"http://www.baidu.com\"); System.out.println(\"urlResource1 is urlResource:\" + (urlResource2 instanceof UrlResource)); 运行结果： fileResource1 is FileSystemResource:false fileResource2 is ClassPathResource:true urlResource1 is UrlResource:true urlResource1 is urlResource:true 其实对于 fileResource1 我们更加希望是 FileSystemResource 资源类型，但是事与愿违，它是 ClassPathResource 类型。在getResource()资源加载策略中，我们知道 D:/Users/chenming673/Documents/spark.txt资源其实在该方法中没有相应的资源类型，那么它就会在抛出 MalformedURLException 异常时通过 getResourceByPath() 构造一个 ClassPathResource 类型的资源。而指定有协议前缀的资源路径，则通过 URL 就可以定义，所以返回的都是UrlResource类型。 FileSystemResourceLoader从上面的示例我们看到，其实 DefaultResourceLoader 对getResourceByPath(String)方法处理其实不是很恰当，这个时候我们可以使用 FileSystemResourceLoader ，它继承 DefaultResourceLoader 且覆写了 getResourceByPath(String)，使之从文件系统加载资源并以 FileSystemResource 类型返回，这样我们就可以得到想要的资源类型，如下： @Override protected Resource getResourceByPath(String path) { if (path.startsWith(\"/\")) { path = path.substring(1); } return new FileSystemContextResource(path); } FileSystemContextResource 为 FileSystemResourceLoader 的内部类，它继承 FileSystemResource。 private static class FileSystemContextResource extends FileSystemResource implements ContextResource { public FileSystemContextResource(String path) { super(path); } @Override public String getPathWithinContext() { return getPath(); } } 在构造器中也是调用 FileSystemResource 的构造方法来构造 FileSystemContextResource 的。 如果将上面的示例将 DefaultResourceLoader 改为 FileSystemContextResource ，则 fileResource1 则为 FileSystemResource。 ResourcePatternResolverResourceLoader 的 Resource getResource(String location) 每次只能根据 location 返回一个 Resource，当需要加载多个资源时，我们除了多次调用 getResource() 外别无他法。ResourcePatternResolver 是 ResourceLoader 的扩展，它支持根据指定的资源路径匹配模式每次返回多个 Resource 实例，其定义如下： public interface ResourcePatternResolver extends ResourceLoader { String CLASSPATH_ALL_URL_PREFIX = \"classpath*:\"; Resource[] getResources(String locationPattern) throws IOException; } ResourcePatternResolver 在 ResourceLoader 的基础上增加了 getResources(String locationPattern)，以支持根据路径匹配模式返回多个 Resource 实例，同时也新增了一种新的协议前缀 classpath*:，该协议前缀由其子类负责实现。 PathMatchingResourcePatternResolver 为 ResourcePatternResolver 最常用的子类，它除了支持 ResourceLoader 和 ResourcePatternResolver 新增的 classpath*: 前缀外，还支持 Ant 风格的路径匹配模式（类似于 **/*.xml）。 PathMatchingResourcePatternResolver 提供了三个构造方法，如下： public PathMatchingResourcePatternResolver() { this.resourceLoader = new DefaultResourceLoader(); } public PathMatchingResourcePatternResolver(ResourceLoader resourceLoader) { Assert.notNull(resourceLoader, \"ResourceLoader must not be null\"); this.resourceLoader = resourceLoader; } public PathMatchingResourcePatternResolver(@Nullable ClassLoader classLoader) { this.resourceLoader = new DefaultResourceLoader(classLoader); } PathMatchingResourcePatternResolver 在实例化的时候，可以指定一个 ResourceLoader，如果不指定的话，它会在内部构造一个 DefaultResourceLoader。 Resource getResource(String location)@Override public Resource getResource(String location) { return getResourceLoader().getResource(location); } getResource() 方法直接委托给相应的 ResourceLoader 来实现，所以如果我们在实例化的 PathMatchingResourcePatternResolver 的时候，如果不知道 ResourceLoader ，那么在加载资源时，其实就是 DefaultResourceLoader 的过程。其实在下面介绍的 Resource[] getResources(String locationPattern) 也相同，只不过返回的资源时多个而已。 Resource[] getResources(String locationPattern)public Resource[] getResources(String locationPattern) throws IOException { Assert.notNull(locationPattern, \"Location pattern must not be null\"); // 以 classpath*: 开头 if (locationPattern.startsWith(CLASSPATH_ALL_URL_PREFIX)) { // 路径包含通配符 if (getPathMatcher() .isPattern(locationPattern.substring(CLASSPATH_ALL_URL_PREFIX.length()))) { return findPathMatchingResources(locationPattern); } else { // 路径不包含通配符 return findAllClassPathResources( locationPattern.substring(CLASSPATH_ALL_URL_PREFIX.length())); } } else { int prefixEnd = ( locationPattern.startsWith(\"war:\") ? locationPattern.indexOf(\"*/\") + 1 : locationPattern.indexOf(':') + 1); // 路径包含通配符 if (getPathMatcher().isPattern(locationPattern.substring(prefixEnd))) { return findPathMatchingResources(locationPattern); } else { return new Resource[] {getResourceLoader().getResource(locationPattern)}; } } } 处理逻辑如下图： 下面就 findAllClassPathResources()做详细分析。 findAllClassPathResources()当 locationPattern 以 classpath*: 开头但是不包含通配符，则调用findAllClassPathResources() 方法加载资源。该方法返回 classes 路径下和所有 jar 包中的所有相匹配的资源。 protected Resource[] findAllClassPathResources(String location) throws IOException { String path = location; if (path.startsWith(\"/\")) { path = path.substring(1); } Set&lt;Resource> result = doFindAllClassPathResources(path); if (logger.isDebugEnabled()) { logger.debug(\"Resolved classpath location [\" + location + \"] to resources \" + result); } return result.toArray(new Resource[0]); } 真正执行加载的是在 doFindAllClassPathResources()方法，如下： protected Set&lt;Resource> doFindAllClassPathResources(String path) throws IOException { Set&lt;Resource> result = new LinkedHashSet&lt;>(16); ClassLoader cl = getClassLoader(); Enumeration&lt;URL> resourceUrls = (cl != null ? cl.getResources(path) : ClassLoader.getSystemResources(path)); while (resourceUrls.hasMoreElements()) { URL url = resourceUrls.nextElement(); result.add(convertClassLoaderURL(url)); } if (\"\".equals(path)) { addAllClassLoaderJarRoots(cl, result); } return result; } doFindAllClassPathResources() 根据 ClassLoader 加载路径下的所有资源。在加载资源过程中如果，在构造 PathMatchingResourcePatternResolver 实例的时候如果传入了 ClassLoader，则调用其 getResources()，否则调用ClassLoader.getSystemResources(path)。 ClassLoader.getResources()如下: public Enumeration&lt;URL> getResources(String name) throws IOException { @SuppressWarnings(\"unchecked\") Enumeration&lt;URL>[] tmp = (Enumeration&lt;URL>[]) new Enumeration&lt;?>[2]; if (parent != null) { tmp[0] = parent.getResources(name); } else { tmp[0] = getBootstrapResources(name); } tmp[1] = findResources(name); return new CompoundEnumeration&lt;>(tmp); } 看到这里是不是就已经一目了然了？如果当前父类加载器不为 null，则通过父类向上迭代获取资源，否则调用 getBootstrapResources()。这里是不是特别熟悉，(^▽^)。 若 path 为 空（“”）时，则调用 addAllClassLoaderJarRoots()方法。该方法主要是加载路径下得所有 jar 包，方法较长也没有什么实际意义就不贴出来了。 通过上面的分析，我们知道 findAllClassPathResources() 其实就是利用 ClassLoader 来加载指定路径下的资源，不管它是在 class 路径下还是在 jar 包中。如果我们传入的路径为空或者 /，则会调用 addAllClassLoaderJarRoots() 方法加载所有的 jar 包。 findAllClassPathResources()当 locationPattern 以 classpath*: 开头且当中包含了通配符，则调用该方法进行资源加载。如下： protected Resource[] findPathMatchingResources(String locationPattern) throws IOException { // 确定跟路径 String rootDirPath = determineRootDir(locationPattern); String subPattern = locationPattern.substring(rootDirPath.length()); // 获取根据路径下得资源 Resource[] rootDirResources = getResources(rootDirPath); Set&lt;Resource> result = new LinkedHashSet&lt;>(16); for (Resource rootDirResource : rootDirResources) { rootDirResource = resolveRootDirResource(rootDirResource); URL rootDirUrl = rootDirResource.getURL(); // bundle 资源类型 if (equinoxResolveMethod != null &amp;&amp; rootDirUrl.getProtocol().startsWith(\"bundle\")) { URL resolvedUrl = (URL) ReflectionUtils .invokeMethod(equinoxResolveMethod, null, rootDirUrl); if (resolvedUrl != null) { rootDirUrl = resolvedUrl; } rootDirResource = new UrlResource(rootDirUrl); } // VFS 资源 if (rootDirUrl.getProtocol().startsWith(ResourceUtils.URL_PROTOCOL_VFS)) { result.addAll(VfsResourceMatchingDelegate .findMatchingResources(rootDirUrl, subPattern, getPathMatcher())); } // Jar else if (ResourceUtils.isJarURL(rootDirUrl) || isJarResource(rootDirResource)) { result .addAll(doFindPathMatchingJarResources (rootDirResource, rootDirUrl, subPattern)); } else { result .addAll(doFindPathMatchingFileResources( rootDirResource, subPattern)); } } if (logger.isDebugEnabled()) { logger.debug(\"Resolved location pattern [\" + locationPattern + \"] to resources \" + result); } return result.toArray(new Resource[0]); } 方法有点儿长，但是思路还是很清晰的，主要分两步： 确定目录，获取该目录下得所有资源 在所获得的所有资源中进行迭代匹配获取我们想要的资源。 在这个方法里面我们要关注两个方法，一个是 determineRootDir(),一个是 doFindPathMatchingFileResources()。 determineRootDir()主要是用于确定根路径，如下： protected String determineRootDir(String location) { int prefixEnd = location.indexOf(':') + 1; int rootDirEnd = location.length(); while (rootDirEnd > prefixEnd &amp;&amp; getPathMatcher() .isPattern(location.substring(prefixEnd, rootDirEnd))) { rootDirEnd = location.lastIndexOf('/', rootDirEnd - 2) + 1; } if (rootDirEnd == 0) { rootDirEnd = prefixEnd; } return location.substring(0, rootDirEnd); } 该方法一定要给出一个确定的根目录。该根目录用于确定文件的匹配的起始点，将根目录位置的资源解析为 java.io.File 并将其传递到 retrieveMatchingFiles()，其余为知用于模式匹配，找出我们所需要的资源。 确定根路径如下: 原路径 确定根路径 classpath*:test/cc*/spring-*.xml classpath*:test/ classpath*:test/aa/spring-*.xml classpath*:test/aa/ 确定根路径后，则调用 getResources() 方法获取该路径下得所有资源，然后迭代资源获取符合条件的资源。 至此 Spring 整个资源记载过程已经分析完毕。下面简要总结下： Spring 提供了 Resource 和 ResourceLoader 来统一抽象整个资源及其定位。使得资源与资源的定位有了一个更加清晰的界限，并且提供了合适的 Default 类，使得自定义实现更加方便和清晰。 AbstractResource 为 Resource 的默认实现，它对 Resource 接口做了一个统一的实现，子类继承该类后只需要覆盖相应的方法即可，同时对于自定义的 Resource 我们也是继承该类。 DefaultResourceLoader 同样也是 ResourceLoader 的默认实现，在自定 ResourceLoader 的时候我们除了可以继承该类外还可以实现 ProtocolResolver 接口来实现自定资源加载协议。 DefaultResourceLoader 每次只能返回单一的资源，所以 Spring 针对这个提供了另外一个接口 ResourcePatternResolver ，该接口提供了根据指定的 locationPattern 返回多个资源的策略。其子类 PathMatchingResourcePatternResolver 是一个集大成者的 ResourceLoader ，因为它即实现了 Resource getResource(String location) 也实现了 Resource[] getResources(String locationPattern)。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"IOC之深入理解SpringIoC","date":"2020-01-01T15:41:06.000Z","path":"2020/01/01/a426e6ea.html","text":"摘要 本文作者：chenssy 出处：http://cmsblogs.com/?p=2652 在学习Spring源码的过程中发现的好站+好贴，感谢作者。Spring版本：Spring 5.0.6.RELEASE IOC 理论IoC 全称为 Inversion of Control，翻译为 “控制反转”，它还有一个别名为 DI（Dependency Injection）,即依赖注入。 如何理解“控制反转”好呢？理解好它的关键在于我们需要回答如下四个问题： 谁控制谁 控制什么 为何是反转 哪些方面反转了 在回答这四个问题之前，我们先看 IOC 的定义： 所谓 IOC ，就是由 Spring IOC 容器来负责对象的生命周期和对象之间的关系 上面这句话是整个 IoC 理论的核心。如何来理解这句话？我们引用一个例子来走阐述（看完该例子上面四个问题也就不是问题了）。 以找女朋友为例（对于程序猿来说这个值得探究的问题）。一般情况下我们是如何来找女朋友的呢？首先我们需要根据自己的需求（漂亮、身材好、性格好）找一个妹子，然后到处打听她的兴趣爱好、微信、电话号码，然后各种投其所好送其所要，最后追到手。如下： /** * 年轻小伙子 */ public class YoungMan { private BeautifulGirl beautifulGirl; YoungMan(){ // 可能你比较牛逼，指腹为婚 // beautifulGirl = new BeautifulGirl(); } public void setBeautifulGirl(BeautifulGirl beautifulGirl) { this.beautifulGirl = beautifulGirl; } public static void main(String[] args){ YoungMan you = new YoungMan(); BeautifulGirl beautifulGirl = new BeautifulGirl(\"你的各种条件\"); beautifulGirl.setxxx(\"各种投其所好\"); // 然后你有女票了 you.setBeautifulGirl(beautifulGirl); } } 这就是我们通常做事的方式，如果我们需要某个对象，一般都是采用这种直接创建的方式(new BeautifulGirl())，这个过程复杂而又繁琐，而且我们必须要面对每个环节，同时使用完成之后我们还要负责销毁它，在这种情况下我们的对象与它所依赖的对象耦合在一起。 其实我们需要思考一个问题？我们每次用到自己依赖的对象真的需要自己去创建吗？我们知道，我们依赖对象其实并不是依赖该对象本身，而是依赖它所提供的服务，只要在我们需要它的时候，它能够及时提供服务即可，至于它是我们主动去创建的还是别人送给我们的，其实并不是那么重要。再说了，相比于自己千辛万苦去创建它还要管理、善后而言，直接有人送过来是不是显得更加好呢？ 这个给我们送东西的“人” 就是 IoC，在上面的例子中，它就相当于一个婚介公司，作为一个婚介公司它管理着很多男男女女的资料，当我们需要一个女朋友的时候，直接跟婚介公司提出我们的需求，婚介公司则会根据我们的需求提供一个妹子给我们，我们只需要负责谈恋爱，生猴子就行了。你看，这样是不是很简单明了。 诚然，作为婚介公司的 IoC 帮我们省略了找女朋友的繁杂过程，将原来的主动寻找变成了现在的被动接受（符合我们的要求），更加简洁轻便。你想啊，原来你还得鞍马前后，各种巴结，什么东西都需要自己去亲力亲为，现在好了，直接有人把现成的送过来，多么美妙的事情啊。所以，简单点说，IoC 的理念就是让别人为你服务，如下图（摘自Spring揭秘）： 在没有引入 IoC 的时候，被注入的对象直接依赖于被依赖的对象，有了 IoC 后，两者及其他们的关系都是通过 Ioc Service Provider 来统一管理维护的。被注入的对象需要什么，直接跟 IoC Service Provider 打声招呼，后者就会把相应的被依赖对象注入到被注入的对象中，从而达到 IOC Service Provider 为被注入对象服务的目的。所以 IoC 就是这么简单！原来是需要什么东西自己去拿，现在是需要什么东西让别人（IOC Service Provider）送过来 现在在看上面那四个问题，答案就显得非常明显了: 谁控制谁：在传统的开发模式下，我们都是采用直接 new 一个对象的方式来创建对象，也就是说你依赖的对象直接由你自己控制，但是有了 IOC 容器后，则直接由 IoC 容器来控制。所以“谁控制谁”，当然是 IoC 容器控制对象。 控制什么：控制对象。 为何是反转：没有 IoC 的时候我们都是在自己对象中主动去创建被依赖的对象，这是正转。但是有了 IoC 后，所依赖的对象直接由 IoC 容器创建后注入到被注入的对象中，依赖的对象由原来的主动获取变成被动接受，所以是反转。 哪些方面反转了：所依赖对象的获取被反转了。 妹子有了，但是如何拥有妹子呢？这也是一门学问。 可能你比较牛逼，刚刚出生的时候就指腹为婚了。 大多数情况我们还是会考虑自己想要什么样的妹子，所以还是需要向婚介公司打招呼的。 还有一种情况就是，你根本就不知道自己想要什么样的妹子，直接跟婚介公司说，我就要一个这样的妹子。 所以，IOC Service Provider 为被注入对象提供被依赖对象也有如下几种方式：构造方法注入、setter方法注入、接口注入。 构造器注入构造器注入，顾名思义就是被注入的对象通过在其构造方法中声明依赖对象的参数列表，让外部知道它需要哪些依赖对象。 YoungMan(BeautifulGirl beautifulGirl){ this.beautifulGirl = beautifulGirl; } 构造器注入方式比较直观，对象构造完毕后就可以直接使用，这就好比你出生你家里就给你指定了你媳妇。 setter 方法注入对于 JavaBean 对象而言，我们一般都是通过 getter 和 setter 方法来访问和设置对象的属性。所以，当前对象只需要为其所依赖的对象提供相对应的 setter 方法，就可以通过该方法将相应的依赖对象设置到被注入对象中。如下： public class YoungMan { private BeautifulGirl beautifulGirl; public void setBeautifulGirl(BeautifulGirl beautifulGirl) { this.beautifulGirl = beautifulGirl; } } 相比于构造器注入，setter 方式注入会显得比较宽松灵活些，它可以在任何时候进行注入（当然是在使用依赖对象之前），这就好比你可以先把自己想要的妹子想好了，然后再跟婚介公司打招呼，你可以要林志玲款式的，赵丽颖款式的，甚至凤姐哪款的，随意性较强。 接口方式注入接口方式注入显得比较霸道，因为它需要被依赖的对象实现不必要的接口，带有侵入性。一般都不推荐这种方式。 关于 IOC 理论部分，笔者不在阐述，这里推荐几篇博客阅读： 谈谈对Spring IOC的理解：http://www.cnblogs.com/xdp-gacl/p/4249939.html Spring的IOC原理[通俗解释一下]：https://blog.csdn.net/m13666368773/article/details/7802126 spring ioc原理（看完后大家可以自己写一个spring）：https://blog.csdn.net/it_man/article/details/4402245 各个组件先看下图（摘自:http://singleant.iteye.com/blog/1177358） 该图为 ClassPathXmlApplicationContext 的类继承体系结构，虽然只有一部分，但是它基本上包含了 IOC 体系中大部分的核心类和接口。 下面我们就针对这个图进行简单的拆分和补充说明。 Resource体系Resource，对资源的抽象，它的每一个实现类都代表了一种资源的访问策略，如ClasspathResource 、 URLResource ，FileSystemResource 等。 [ 有了资源，就应该有资源加载，Spring 利用 ResourceLoader 来进行统一资源加载，类图如下： BeanFactory 体系BeanFactory 是一个非常纯粹的 bean 容器，它是 IOC 必备的数据结构，其中 BeanDefinition 是她的基本结构，它内部维护着一个 BeanDefinition map ，并可根据 BeanDefinition 的描述进行 bean 的创建和管理。 BeanFacoty 有三个直接子类 ListableBeanFactory、HierarchicalBeanFactory 和 AutowireCapableBeanFactory，DefaultListableBeanFactory 为最终默认实现，它实现了所有接口。 Beandefinition 体系BeanDefinition 用来描述 Spring 中的 Bean 对象。 BeandefinitionReader体系BeanDefinitionReader 的作用是读取 Spring 的配置文件的内容，并将其转换成 Ioc 容器内部的数据结构：BeanDefinition。 [ ApplicationContext体系这个就是大名鼎鼎的 Spring 容器，它叫做应用上下文，与我们应用息息相关，她继承 BeanFactory，所以它是 BeanFactory 的扩展升级版，如果BeanFactory 是屌丝的话，那么 ApplicationContext 则是名副其实的高富帅。由于 ApplicationContext 的结构就决定了它与 BeanFactory 的不同，其主要区别有： 继承 MessageSource，提供国际化的标准访问策略。 继承 ApplicationEventPublisher ，提供强大的事件机制。 扩展 ResourceLoader，可以用来加载多个 Resource，可以灵活访问不同的资源。 对 Web 应用的支持。 下图来源：https://blog.csdn.net/yujin753/article/details/47043143 上面五个体系可以说是Spring IoC中最核心的部分，后面博文也是针对这五个部分进行源码分析。其实 IoC 咋一看还是挺简单的，无非就是将配置文件（暂且认为是 xml 文件）进行解析（分析 xml 谁不会啊），然后放到一个 Map 里面就差不多了，初看有道理，其实要面临的问题还是有很多的，下面就劳烦各位看客跟着 LZ 博客来一步一步揭开 Spring IoC 的神秘面纱。 此系列博文为 LZ 学习、研究 Spring 机制和源码的学习笔记，会涉及参考别人的博文和书籍内容，如有雷同，纯属借鉴，当然 LZ 会标明参考来源。同时由于知识面和能力的问题，文章中难免会出现错误之处，如有，望各位大佬指出，不胜感激。 LZ 写此系列博客时，Spring 最新版本为 5.0.6.RELEASE ，所以此系列博客所有源码来源均为 5.0.6.RELEASE。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"}]},{"title":"基础支持层——缓存模块","date":"2019-10-31T01:09:42.000Z","path":"2019/10/31/fce458a9.html","text":"MyBatis基础支持层位于 Mybatis 整体架构的最底层，支撑着 Mybatis 的核心处理层，是整个框架的基石。基础支持层中封装了多个较为通用的、独立的模块，不仅仅为 Mybatis 提供基础支撑，也可以在合适的场景中直接复用。 这篇文章介绍MyBatis的缓存模块 MyBatis作为 一个 强大的持久层 框 架，缓 存是其必不可少的功能之一。MyBatis中的缓 存 是两 层 结 构 的，分为 一级 缓 存、二级 缓 存，但在本质 上是相同的，它 们 使用的都是Cache接 口的实 现 。 在 MyBatis缓 存模块 中涉及了装 饰 器模式的相关 知识 。 装饰器模式在实践生产中，新需求在软件的整个生命过程中总是不断出现的。当有新需求出现时，就需要为某些组件添加新的功能来满足这些需求。 添加新功能的方式有很多，我们可以直接修改己有组件的代码并添加相应的新功能，这显然会破坏己有组件的稳定性，修改完成后，整个组件需要重新进行测试，才能上线使用。这种方式显然违反了“开放-封闭”原则。 另一种方式是使用继承方式，我们可以创建子类并在子类中添加新功能实现扩展。*这种方法是静态的，用户不能控制增加行为的方式和时机。而且有些情况下继承是不可行的。 例如己有组件是被final关键字修饰的类。 另外，如果待添加的新功能存在多种组合，使用继承方式可能会导致大量子类的出现。 例如，有4个待添加的新功能，系统需要动态使用任意多个功能的组合，则需要添加15个子类才能满足全部需求。 装饰器模式能够帮助我们解决上述问题，装饰器可以动态地为对象添加功能，它是基于组合的方式实现该功能的。 在实践中，我们应该尽量使用组合的方式来扩展系统的功能，而非使用继承的方式。设计模式中常见的一句话:组合优于继承。 装饰器模式的类图，以及其中的核心角色： Component（组件） 组件接口定义了全部组件实现类以及所有装饰器实现的行为。 ConcreteComponent (具体 组 件实 现 类 ) 具体组件实现类实现了Component接口。 通常情况下，具体组件实现类就是被装饰器装饰的原始对象，该类提供了Component接口中定义的最基本的功能，其他高级功能或后续添加的新功能，都是通过装饰器的方式添加到该类的对象之上的。 Decorator(装饰器) 所有装饰器的父类，它是一个实现了Component接口的抽象类，并在其中封装了一个Component对象，也就是被装饰的对象。 而这个被装饰的对象只要是Component类型即可，这就实现了装饰器的组合和复用。 如下图，装饰器C(ConcreteDecoratorl类型)修饰了装饰器B(ConcreteDecorator2类型)并为其添加功能W，而装饰器B(ConcreteDecorator2类型)又修饰了组件A(ConcreteComponent类型)并为其添加功能V。 其中，组件对象A提供的是最基本的功能，装饰器B和装饰器C会为组件对象A添加新的功能。 ConcreteDecorator 具体的装饰器实现类，该实现类要向被装饰对象添加某些功能。如上图，装饰器B、C就是该角色，被装饰的对象只要是Component类型即可。在JavaIO包中，大量应用了装饰器模式，我们在使用JavaIO包读取文件时，经常会看到如下代码: BufferedlnputStream bis = new BufferedlnputStream( new FilelnputStream(new File(\"D:/test.txt\"))); FilelnputStream并没有缓冲功能，每次调用其read()方法时都会向操作系统发起相应的系统调用，当读取大量数据时，就会导致操作系统在用户态和内核态之间频繁切换，性能较低。 BufferedlnputStream是提供了缓冲功能的装饰器，每次调用其read()方法时，会预先从文件中获取一部分数据并缓存到BufferedlnputStream的缓冲区中，后面连续的几次读取可以直接从缓冲区中获取数据，直到缓冲区数据耗尽才会重新从文件中读取数据，这样就可以减少用户态和内核态的切换，提高了读取的性能。 在MyBatis的缓存模块中，使用了装饰器模式的变体，其中将Decorator接口和Component接口合并为一个Component接口 使用装饰器模式的优点： 相较于继承来说，装饰器模式的灵活性更强，可扩展性也强。正如前面所说，继承方式会导致大量子类的情况。而装饰者模式可以将复杂的功能切分成一个个独立的装饰器，通过多个独立装饰器的动态组合，创建不同功能的组件，从而满足多种不同需求。 当有新功能需要添加时，只需要添加新的装饰器实现类，然后通过组合方式添加这个新装饰器即可，无须修改己有类的代码，符合“开放-封闭”原则。 但是，随着添加的新需求越来越多，可能会创建出嵌套多层装饰器的对象，这增加了系统的复杂性，也增加了理解的难度和定位错误的难度。 Cache接口及其实现MyBatis的缓存模块在org.apache.ibatis.cache包下，其中Cache接口是缓存模块的中最核心的接口，它定义了所有缓存的基本行为。 Cache public interface Cache { /** * 返回该缓存对应的id * @return The identifier of this cache */ String getId(); /** * 向缓存中添加数据，一般情况下Key是CacheKey，value是查询结果 * @param key Can be any object but usually it is a {@link CacheKey} * @param value The result of a select. */ void putObject(Object key, Object value); /** * 从缓存中获取数据 * @param key The key * @return The object stored in the cache. */ Object getObject(Object key); /** * 删除Key对应的缓存 * As of 3.3.0 this method is only called during a rollback * for any previous value that was missing in the cache. * This lets any blocking cache to release the lock that * may have previously put on the key. * A blocking cache puts a lock when a value is null * and releases it when the value is back again. * This way other threads will wait for the value to be * available instead of hitting the database. * * * @param key The key * @return Not used */ Object removeObject(Object key); /** * 清空缓存 * Clears this cache instance */ void clear(); /** * 缓存项的个数，不会被MyBatis核心代码调用 * Optional. This method is not called by the core. * * @return The number of elements stored in the cache (not its capacity). */ int getSize(); /** * 获取读写锁，不会被MyBatis核心代码调用 * Optional. As of 3.2.6 this method is no longer called by the core. * * Any locking needed by the cache must be provided internally by the cache provider. * * @return A ReadWriteLock */ ReadWriteLock getReadWriteLock(); } Cache接口的实现类有多个，大部分都是装饰器，只有PerpetualCache提供了Cache接口的基本实现。 PerpetualCache**PerpetualCache在缓存模块中扮演着ConcreteComponent的角色**，其实现比较简单，底层使用HashMap记录缓存项，也是通过该HashMap对象的方法实现的Cache接口中定义的相应方法。 public class PerpetualCache implements Cache { private final String id; private Map&lt;Object, Object> cache = new HashMap&lt;Object, Object>(); public PerpetualCache(String id) { this.id = id; } @Override public String getId() { return id; } @Override public int getSize() { return cache.size(); } @Override public void putObject(Object key, Object value) { cache.put(key, value); } @Override public Object getObject(Object key) { return cache.get(key); } @Override public Object removeObject(Object key) { return cache.remove(key); } @Override public void clear() { cache.clear(); } @Override public ReadWriteLock getReadWriteLock() { return null; } @Override public boolean equals(Object o) { if (getId() == null) { throw new CacheException(\"Cache instances require an ID.\"); } if (this == o) { return true; } if (!(o instanceof Cache)) { return false; } Cache otherCache = (Cache) o; return getId().equals(otherCache.getId()); } @Override public int hashCode() { if (getId() == null) { throw new CacheException(\"Cache instances require an ID.\"); } return getId().hashCode(); } } 下面来介绍org.apache.ibatis.cache.decorators包下提供的装饰器，它们都直接实现了Cache接口，扮演着ConcreteDecorator的角色。 这些装饰器会在PerpetualCache的基础上提供一些额外的功能，通过多个组合后满足一个特定的需求，后面介绍二级缓存时，会见到这些装饰器是如何完成动态组合的。 BlockingCacheBlockingCache是阻塞版本的缓存装饰器，它会保证只有一个线程到数据库中查找指定key对应的数据。 // 阻塞超时时间 private long timeout; // 被装饰的底层Cache对象 private final Cache delegate; // 每个Key都有对应的ReentrantLock对象 private final ConcurrentHashMap&lt;Object, ReentrantLock> locks; 假设线程A在BlockingCache中未查找到keyA对应的缓存项时，线程A会获取keyA对应的锁，这样后续线程在查找keyA时会发生阻塞 BlockingCache.getObject(Object key) public Object getObject(Object key) { // 获取key对应的锁 acquireLock(key); Object value = delegate.getObject(key); if (value != null) { // 如果缓存有key对应的缓存项，则释放锁 releaseLock(key); } return value; } acquireLock(Object key) private void acquireLock(Object key) { // 获取ReentrantLock对象 Lock lock = getLockForKey(key); if (timeout > 0) { try { // 获取锁，带超时时间的那种 boolean acquired = lock.tryLock(timeout, TimeUnit.MILLISECONDS); if (!acquired) { // 如果超时，则抛出异常 throw new CacheException(\"...\"); } } catch (InterruptedException e) { throw new CacheException(\"...\"); } } else { lock.lock(); } } 再来看一下getLockForKey方法 private ReentrantLock getLockForKey(Object key) { ReentrantLock lock = new ReentrantLock(); // 创建ReentrantLock对象 // 试添加到locks集合中，如果locks集合中已经有了相应的ReentrantLock对象，则使用locks集合 // 中的ReentrantLock对象 ReentrantLock previous = locks.putIfAbsent(key, lock); return previous == null ? lock : previous; } 假设线程A从数据库中查找到keyA对应的结果对象后，将结果对象放入到BlockingCache中，此时线程A会释放keyA对应的锁，唤醒阻塞在该锁上的线程。 其他线程即可从BlockingCache中获取keyA对应的数据，而不是再次访问数据库。 BlockingCache.putObject() @Override public void putObject(Object key, Object value) { try { // 向缓存中添加缓存项 delegate.putObject(key, value); } finally { releaseLock(key);// 释放锁 } } BlockingCache.releaseLock(Object key) private void releaseLock(Object key) { ReentrantLock lock = locks.get(key); if (lock.isHeldByCurrentThread()) { // 判断锁是否被当前线程持有 // 释放锁 lock.unlock(); } } FifoCache&amp;LruCache在很多场景中，为了控制缓存的大小，系统需要按照一定的规则清理缓存。 FifoCache是先入先出版本的装饰器，当向缓存添加数据时，如果缓存项的个数己经达到上限，则会将缓存中最老(即最早进入缓存)的缓存项删除。 FifoCache中字段的含义： // 被装饰的底层Cache对象 private final Cache delegate; // 用于记录key进入缓存的先后顺序，使用的是LinkedList&lt;Object>类型的几个对象 private final Deque&lt;Object> keyList; // 记录缓存项的上限，如果超过，则清理最老的缓存 private int size; FifoCache.getObject()和removeObject()方法的实现都是直接调用底层Cache对象的对应方法。 在FifoCache.putObject()方法中会完成缓存项个数的检测以及缓存的清理操作。 public void putObject(Object key, Object value) { // 检测并清理缓存 cycleKeyList(key); // 添加缓存项 delegate.putObject(key, value); } private void cycleKeyList(Object key) { // 记录key keyList.addLast(key); if (keyList.size() > size) { // 如果达到缓存上限，则清理最老的缓存项 Object oldestKey = keyList.removeFirst(); delegate.removeObject(oldestKey); } } LruCache是按照近期最少使用算法(LeastRecentlyUsed，LRU)进行缓存清理的装饰器，在需要清理缓存时,它会清除最近最少使用的缓存项。 // 被装饰的底层Cache对象 private final Cache delegate; // LinkedHashMap&lt;Object,Object>类型对象，它是一个有序的HashMap，用于记录key最近的使用情况 private Map&lt;Object, Object> keyMap; // 记录最少被使用的缓存项的key private Object eldestKey; LruCache的构造函数中默认设置的缓存大小是1024,我们可以通过其setSize()方法重新设置缓存大小 public void setSize(final int size) { // 重新设置缓存大小的时候， 会充值keyMap字段 // LinkedHashMap构造函数的第三个参数，true表示该LinkedHashMap记录的顺序是 // access-order,也就是说LinkedHashMap.get()方法会改变其记录的顺序 keyMap = new LinkedHashMap&lt;Object, Object>(size, .75F, true) { private static final long serialVersionUID = 4267176411845948333L; // 当调用LinkedHashMap.put()方法时，会调用该方法 @Override protected boolean removeEldestEntry(Map.Entry&lt;Object, Object> eldest) { boolean tooBig = size() > size; if (tooBig) { // 如果已到达缓存上限，则更新eldestKey字段，后面会删除该项 eldestKey = eldest.getKey(); } return tooBig; } }; } LruCache.getObject()方法除了返回缓存项，还会调用keyMap.get()方法修改key的顺序，表示指定的key最近被使用。 LruCache.putObject()方法除了添加缓存项，还会将eldestKey字段指定的缓存项清除掉。 @Override public void putObject(Object key, Object value) { // 修改LinkedHashMap中记录的顺序 delegate.putObject(key, value); cycleKeyList(key); } @Override public Object getObject(Object key) { keyMap.get(key); //touch // 删除最久未使用的缓存项 return delegate.getObject(key); } private void cycleKeyList(Object key) { keyMap.put(key, key); if (eldestKey != null) { // eldestKey不为空，即缓存已达到上限 // 删除最久未使用的缓存 delegate.removeObject(eldestKey); eldestKey = null; } } SoftCache&amp;WeakCache先了解一下Java提供的4种引用类型。 SoftCache中各个字段的含义： // ReferenceQueue，引用队列，用于记录已经被GC回收的缓存项所对应的SoftEntry对象 private final Deque&lt;Object> hardLinksToAvoidGarbageCollection; // 在SoftCache中，最近使用的一部分缓存项不会被GC回收，这就是通过将其value添加到 // hardLinksToAvoidGarbageCollection集合中实现的(即有强引用指向其value) // hardLinksToAvoidGarbageCollection集合是LinkedList&lt;Object>类型 private final ReferenceQueue&lt;Object> queueOfGarbageCollectedEntries; // 底层被装饰的底层Cache对象 private final Cache delegate; // 强连接的个数，默认值是256 private int numberOfHardLinks; SoftCache中缓存项的value是SoftEntry对象，SoftEntry继承了SoftReference，其中指向key的引用是强引用，而指向value的引用是软引用。 private static class SoftEntry extends SoftReference&lt;Object> { private final Object key; SoftEntry(Object key, Object value, ReferenceQueue&lt;Object> garbageCollectionQueue) { super(value, garbageCollectionQueue); // 指向value的引用是软引用，且关联了引用队列 this.key = key; // 强引用 } } SoftCache.putObject()方法除了向缓存中添加缓存项，还会清除己经被GC回收的缓存项,其具体实现如下: public void putObject(Object key, Object value) { // 清除已被GC回收的缓存项 removeGarbageCollectedItems(); // 向缓存中添加缓存项 delegate.putObject(key, new SoftEntry(key, value, queueOfGarbageCollectedEntries)); } private void removeGarbageCollectedItems() { SoftEntry sv; // 遍历queueOfGarbageCollectedEntries集合 while ((sv = (SoftEntry) queueOfGarbageCollectedEntries.poll()) != null) { // 将已经被GC回收的value对象对应的缓存项清除 delegate.removeObject(sv.key); } } SoftCache.getObject()方法除了从缓存中查找对应的value,处理被GC回收的value对应的缓存项，还会更新hardLinksToAvoidGarbageCollection集合 public Object getObject(Object key) { Object result = null; @SuppressWarnings(\"unchecked\") // assumed delegate cache is totally managed by this cache // 从缓存中查找对应的缓存项 SoftReference&lt;Object> softReference = (SoftReference&lt;Object>) delegate.getObject(key); if (softReference != null) { // 检测缓存中是否有对应的缓存项 result = softReference.get(); // 获取SoftReference引用的value if (result == null) {// 已经被GC回收 delegate.removeObject(key); // 从缓存中清除对应的缓存项 } else { // 未被GC回收 // See #586 (and #335) modifications need more than a read lock synchronized (hardLinksToAvoidGarbageCollection) { // 缓存项的value添加到hardLinksToAvoidGarbageCollection集合中保存 hardLinksToAvoidGarbageCollection.addFirst(result); if (hardLinksToAvoidGarbageCollection.size() > numberOfHardLinks) { // 超过numberOfHardLinks，则将最老的缓存项从hardLinksToAvoidGarbageCollection集合中清除，有点类似于先进先出队列 hardLinksToAvoidGarbageCollection.removeLast(); } } } } return result; } SoftCache.removeObject()方法在清除缓存项之前，也会调用removeGarbageCollectedItems()方法清理被GC回收的缓存项。 SoftCache.clear()方法首先清理hardLinksToAvoidGarbageCollection集合，然后清理被GC回收的缓存项，最后清理底层delegate缓存中的缓存项。 public void clear() { synchronized (hardLinksToAvoidGarbageCollection) { hardLinksToAvoidGarbageCollection.clear(); // 清理强引用集合 } removeGarbageCollectedItems(); // 清理被GC回收的缓存项 delegate.clear(); // 清理底层delegate缓存中的缓存项 } WeakCache的实现与SoftCache基本类似，唯一的区别在于其中使用WeakEntry(继承自WeakReference)封装真正的value对象，其他实现完全一样。 othersScheduledCache是周期性清理缓存的装饰器，它的clearlnterval字段记录了两次缓存清理之间的时间间隔，默认是一小时，lastClear字段记录了最近一次清理的时间戳。 ScheduledCache的getObject()、putObject()、removeObject()等核心方法在执行时，都会根据这两个字段检测是否需要进行清理操作，清理操作会清空缓存中所有缓存项。 LoggingCache在Cache的基础上提供了日志功能，它通过hit字段和request字段记录了Cache的命中次数和访问次数。 在LoggingCache.getObject()方法中会统计命中次数和访问次数这两个指标，并按照指定的日志输出方式输出命中率。 SynchronizedCache通过在每个方法上添加synchronized关键字，为Cache添加了同步功能，有点类似于JDK中Collections中的SynchronizedCollection内部类的实现。 SerializedCache提供了将value对象序列化的功能。 SerializedCache在添加缓存项时，会将value对应的Java对象进行序列化，并将序列化后的byte[]数组作为value存入缓存。 SerializedCache在获取缓存项时，会将缓存项中的byte[]数组反序列化成Java对象。 使用前面介绍的Cache装饰器实现进行装饰之后，每次从缓存中获取同一key对应的对象时，得到的都是同一对象，任意一个线程修改该对象都会影响到其他线程以及缓存中的对象；而SerializedCache每次从缓存中获取数据时，都会通过反序列化得到一个全新的对象。SerializedCache使用的序列化方式是Java原生序列化。 CacheKey在Cache中唯一确定一个缓存项需要使用缓存项的key,MyBatis中因为涉及动态SQL等多方面因素，其缓存项的key不能仅仅通过一个String表示，所以MyBatis提供了CacheKey类来表示缓存项的key，在一个CacheKey对象中可以封装多个影响缓存项的因素。 CacheKey中可以添加多个对象，由这些对象共同确定两个CacheKey对象是否相同。 // 参与计算hashcode，默认值37 private final int multiplier; // CacheKey的hashcode，初始值是37 private int hashcode; // 校验和 private long checksum; // updateList集合的个数 private int count; // 由该集合中的所有对象共同决定两个CacheKey是否相同 private List&lt;Object> updateList; 在向CacheKey.updateList集合中添加对 象时 ，使用的是CacheKey.update()方法： public void update(Object object) { int baseHashCode = object == null ? 1 : ArrayUtil.hashCode(object); // 重新计算count、checksum和hashcode的值 count++; checksum += baseHashCode; baseHashCode *= count; hashcode = multiplier * hashcode + baseHashCode; // 将object添加到updateList集合中 updateList.add(object); } 参考 《MyBatis技术内幕》 部分图片来源——《MyBatis技术内幕》","tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://www.cayzlh.com/tags/MyBatis/"},{"name":"《MyBatis技术内幕》","slug":"《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/tags/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"},{"name":"基础支持层","slug":"基础支持层","permalink":"https://www.cayzlh.com/tags/%E5%9F%BA%E7%A1%80%E6%94%AF%E6%8C%81%E5%B1%82/"}],"categories":[{"name":"书籍","slug":"书籍","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/"},{"name":"《MyBatis技术内幕》","slug":"书籍/《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"}]},{"title":"基础支持层——binding模块","date":"2019-10-30T01:09:42.000Z","path":"2019/10/30/e275ec7f.html","text":"MyBatis基础支持层位于 Mybatis 整体架构的最底层，支撑着 Mybatis 的核心处理层，是整个框架的基石。基础支持层中封装了多个较为通用的、独立的模块，不仅仅为 Mybatis 提供基础支撑，也可以在合适的场景中直接复用。 这篇文章介绍MyBatis的binding模块 在 iBatis (MyBatis 的前身)中，查 询 一个 Blog 对 象时 需要调 用 SqlSession.queryForObject (&quot;selectBlog&quot;, blogld)方法。 其中，SqlSession.queryForObject()方法会 执 行指定的 SQL 语 句进 行 查 询 并 返回一个 结 果对 象，第一个 参 数 selectBlog指明了具体 执 行的SQL语 句的id,该 SQL 语 句定义 在相应 的映射配置文件中。 如果我们 错 将 selectBlog写 成了 selectBlogl，在初始 化过 程中，MyBatis是无法提示该 错 误 的，而在实 际 调 用queryForObject(selectBlog1，blogld) 方法时才会抛出异常，开发人员才能知道该错误。 MyBatis提供了 binding模块 用于解决 上述问 题 ，我们 可以定义 一个 Mapper接口，该 示例中为 BlogMapper接口，具体 代码 如下所示。 这 里的 BlogMapper接口并 不需要继 承任何其他接口，而且开 发 人员 不需要提供该 接口的实 现 。 public interface BlogMapper { // 在映射文件中存在一个&lt;select>接口，id为 selectById public Blog selectById(int id); } 该 Mapper接口中定义 了 SQL语 句对 应 的方法，这 些方法在MyBatis初始化过 程中会 与 映 射配置文件中定义 的SQL语 句相关 联 。如果存在无法关 联 的SQL语 句，在 MyBatis的初始化 节 点就会 抛出异 常。 我们可以调 用Mapper接口中的方法执 行相应 的SQL语 句，这样编译器就可以帮助我们提早发现上述问题 。 查询blog： blogMapper mapp = session.getMapper(BlogMapper.class); Blog blog = mapp.selectById(1); binding模块核心组件 MapperRegistry&amp;MapperProxyFactoryMapperRegistryMapperRegistry是 Mapper接口及其对 应 的代理对 象工厂 的注册 中心。Configuration是 MyBatis全局性的配置对 象，在 MyBatis初始化的过 程中，所有配置信息会 被解析成相应 的对 象并 记 录 到Configuration对 象中。这 里 关 注 Configuration.mapperRegistry字 段 ， 它 记 录 当 前 使 用 的 MapperRegistry对 象 。 MapperRegistry中字段及含义 // Configuration对象，MyBatis中全局唯一的配置对象，其中包含了所有配置信息 private final Configuration config; // 记录Mapper接口与对应MapperRegistry之间的关系 private final Map&lt;Class&lt;?>, MapperProxyFactory&lt;?>> knownMappers = new HashMap&lt;Class&lt;?>, MapperProxyFactory&lt;?>>(); 在 MyBatis初始化过程中读取映射配置文件以及Mapper接口中的注解信息，并 调 用 MapperRegistry.addMapper()方 法 填 充 MapperRegistry.knownMappers 集 合 ， 该 集 合 的 key 是 Mapper接口对 应 的Class对 象，value为 MapperProxyFactory工厂 对 象，可以为 Mapper接口创 建代理对 象。MapperRegistry.addMapper()方法的 部分实 现 如下: public &lt;T> void addMapper(Class&lt;T> type) { if (type.isInterface()) { // 检测type是否为接口 if (hasMapper(type)) { // 如果已经添加果该接口，则直接抛出异常 throw new BindingException(\"...\"); } boolean loadCompleted = false; try { // Mapper接口对应的Class对象和MapperProxyFactory对象添加到knownMappers集合 knownMappers.put(type, new MapperProxyFactory&lt;T>(type)); // It's important that the type is added before the parser is run // otherwise the binding may automatically be attempted by the // mapper parser. If the type is already known, it won't try. // XML解析和注解处理 MapperAnnotationBuilder parser = new MapperAnnotationBuilder(config, type); parser.parse(); loadCompleted = true; } finally { if (!loadCompleted) { knownMappers.remove(type); } } } } 在需要执 行某SQL语 句时 ，会 先调 用MapperRegistry.getMapper()方法获 取实 现 了 Mapper 接口的代理对 象，例如本节 开 始的示例中，session.getMapper(BlogMapper.class)方法得到的实 际 上 是 MyBatis通 过 JDK动 态 代 理 为 BlogMapper接 口 生 成 的 代 理 对 象 。MapperRegistry.getMapper() 方法的代码 如下。 public &lt;T> T getMapper(Class&lt;T> type, SqlSession sqlSession) { // 查找指定type的MapperProxyFactory对象 final MapperProxyFactory&lt;T> mapperProxyFactory = (MapperProxyFactory&lt;T>) knownMappers.get(type); if (mapperProxyFactory == null) { throw new BindingException(\"...\"); } try { // 创建实现了type接口的代理对象 return mapperProxyFactory.newInstance(sqlSession); } catch (Exception e) { throw new BindingException(\"Error getting mapper instance. Cause: \" + e, e); } } MapperProxyFactoryMapperProxyFactory主要负 责 创 建代理对 象，其中核心字段的含义 和功能如下 // 当前MapperProxyFactory对象可以创建实现了mapperlnterface接口的代理对象 private final Class&lt;T> mapperInterface; // 缓存，key是mapperlnterface接口中某方法对应的Method对象，value是对应的MapperMethod对象 private final Map&lt;Method, MapperMethod> methodCache = new ConcurrentHashMap&lt;Method, MapperMethod>(); MapperProxyFactory.newInstance()方法实现了创建实现了mapperlnterface 接口的代理对象的功能，具体代码如下: protected T newInstance(MapperProxy&lt;T> mapperProxy) { // 创建代理对象 return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] { mapperInterface }, mapperProxy); } public T newInstance(SqlSession sqlSession) { // 创建MapperProxy对象，每次调用都会创建新的MapperProxy对象 final MapperProxy&lt;T> mapperProxy = new MapperProxy&lt;T>(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy); } MapperProxyMapperProxy实现了InvocationHandler接口，InvocationHandler是实现JDK代理对象的核心逻辑。 MappProxy中核心字段含义和功能： // 记录了关联的SqlSession对象 private final SqlSession sqlSession; // mapper接口对应的class对象 private final Class&lt;T> mapperInterface; // 用于缓存MapperMethod对象，其中key是Mapper接口中方法对应的Method对象，value是对应的MapperMethod对象 // MapperMethod对象会完成参数转换以及SQL语句的执行功能 // MapperMethod中并不记录任何状态相关的信息，所以可以在多个代理对象之间共享 private final Map&lt;Method, MapperMethod> methodCache; MapperProxy.invoke()方法是代理对象执行的主要逻辑，实现如下: public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { try { // 如果目标方法继承自Object，则直接调用目标方法 if (Object.class.equals(method.getDeclaringClass())) { return method.invoke(this, args); } else if (isDefaultMethod(method)) { // 这里是针对java7以上版本动态类型语言的支持 return invokeDefaultMethod(proxy, method, args); } } catch (Throwable t) { throw ExceptionUtil.unwrapThrowable(t); } // 从缓存中获取MapperMethod对象，如果缓存中没有，则创建新的MapperMethod对象并添加到缓存中 final MapperMethod mapperMethod = cachedMapperMethod(method); // 执行SQL语句 return mapperMethod.execute(sqlSession, args); } MapperProxy.cachedMapperMethod()方法主要负责维护methodCache这个缓存集合： private MapperMethod cachedMapperMethod(Method method) { // 先从缓存中获取MapperMethod对象 MapperMethod mapperMethod = methodCache.get(method); if (mapperMethod == null) { // 缓存就爱你mapperMethod对象并放到缓存中 mapperMethod = new MapperMethod(mapperInterface, method, sqlSession.getConfiguration()); methodCache.put(method, mapperMethod); } return mapperMethod; } MapperMethodMapperMethod中封装了 Mapper接口中对应方法的信息，以及对应 SQL语句的信息。 可以将 MapperMethod看作连接 Mapper接口以及映射配置文件中定义的SQL语句的桥梁。 MapperMethod中各个字段的信息如下: // 记录SQL语句和类型 private final SqlCommand command; // Mapper接口对应方法的信息 private final MethodSignature method; SqlCommandSqlCommand是 MapperMethod中定义 的内 部类 ,它 使用name字段记 录 了 SQL语 句的名称 , 使用type字 段 (SqlCommandType类 型)记 录 了 SQL语 句的类 型。 SqlCommandType是枚举类型 ，有效取值为UNKNOWN、INSERT、UPDATE、DELETE、SELECT、FLUSH。 SqlCommand的构造方法会初始化name字段和type字段，代码如下: public SqlCommand(Configuration configuration, Class&lt;?> mapperInterface, Method method) { final String methodName = method.getName(); final Class&lt;?> declaringClass = method.getDeclaringClass(); MappedStatement ms = resolveMappedStatement(mapperInterface, methodName, declaringClass, configuration); if (ms == null) { if (method.getAnnotation(Flush.class) != null) { // @Flush处理 name = null; type = SqlCommandType.FLUSH; } else { throw new BindingException(\"...\"); } } else { name = ms.getId(); type = ms.getSqlCommandType(); if (type == SqlCommandType.UNKNOWN) { throw new BindingException(\"Unknown execution method for: \" + name); } } } private MappedStatement resolveMappedStatement( Class&lt;?> mapperInterface, String methodName, Class&lt;?> declaringClass, Configuration configuration) { // SQL语句的名称是由Mapper接口的名称与对应的方法名称组成的 String statementId = mapperInterface.getName() + \".\" + methodName; if (configuration.hasStatement(statementId)) { // 检测是否有该名称的SQL语句 // 从Configuration.mappedStatements集合中查找对应的MappedStatement对象， // MappedStatement对象中封装了SQL语句相关的信息，在MyBatis初始化时创建，后面详细描述 return configuration.getMappedStatement(statementId); } else if (mapperInterface.equals(declaringClass)) { return null; } for (Class&lt;?> superInterface : mapperInterface.getInterfaces()) { // 如果指定方法是在父接口中定义的，则在此进行继承结构的处理 if (declaringClass.isAssignableFrom(superInterface)) { // 递归处理 MappedStatement ms = resolveMappedStatement(superInterface,methodName,declaringClass, configuration); if (ms != null) { return ms; } } } return null; } } ParamNameResolver在 MethodSignature中 ，会 使 用 ParamNameResolver处 理 Mapper接 口 中 定 义 的 方 法 的 参 数 列 表 。 ParamNameResolver 使用 name 字 段 (SortedMap&lt;Integer, String&gt;类 型 )记 录 了 参 数 在 参 数 列表中的位置索引与 参 数 名称 之间 的对 应 关 系，其中key表示参 数 在参 数 列表中的索引位置， value表示参 数 名称 ，参 数 名称 可以通过 @Param注解指定，如果没 有指定@Param注解，则 使 用参 数 索引作为 其名称 。 如果参 数 列表中包含RowBounds类 型 或 ResultHandler类 型的参 数 ， 则 这 两 种 类 型的参 数 并 不会 被记 录 到name集合中，这 就会 导 致参 数 的索引与 名称 不一致。 ParamNameResolver的 hasParamAnnotation字 段 (boolean类 型 )记 录 对 应 方 法 的 参 数 列 表 中是否使用了 @Param注 解 。 在 ParamNameResolver的构 造方法中，会 通过 反射的方式读 取Mapper接口中对 应 方法的信息，并初始化以上字段： public ParamNameResolver(Configuration config, Method method) { // 获取参数列表中每个参数的类型 final Class&lt;?>[] paramTypes = method.getParameterTypes(); // 获取参数列表上的注解 final Annotation[][] paramAnnotations = method.getParameterAnnotations(); // 记录参数索引与参数名称的对应关系 final SortedMap&lt;Integer, String> map = new TreeMap&lt;Integer, String>(); int paramCount = paramAnnotations.length; // get names from @Param annotations for (int paramIndex = 0; paramIndex &lt; paramCount; paramIndex++) { if (isSpecialParameter(paramTypes[paramIndex])) { // skip special parameters // 如果参数是RowBounds类型或ResultHandler类型，则跳过对该参数的分析 continue; } String name = null; // 遍历参数对应的注解集合 for (Annotation annotation : paramAnnotations[paramIndex]) { if (annotation instanceof Param) { // 如果出现过@Param就把hasParamAnnotation初始化为true hasParamAnnotation = true; // 获取@Param注解指定的参数名称 name = ((Param) annotation).value(); break; } } if (name == null) { // @Param was not specified. if (config.isUseActualParamName()) { name = getActualParamName(method, paramIndex); } if (name == null) { // use the parameter index as the name (\"0\", \"1\", ...) // gcode issue #71 name = String.valueOf(map.size()); } } map.put(paramIndex, name); } names = Collections.unmodifiableSortedMap(map); } names集合主要在ParamNameResolver.getNamedParams()方法中使用，该 方法接收的参 数 是 用户传入的实参列表，并将实参与其对应名称进行关联，具体代码如下: public Object getNamedParams(Object[] args) { final int paramCount = names.size(); if (args == null || paramCount == 0) { return null; } else if (!hasParamAnnotation &amp;&amp; paramCount == 1) { return args[names.firstKey()]; } else { final Map&lt;String, Object> param = new ParamMap&lt;Object>(); int i = 0; for (Map.Entry&lt;Integer, String> entry : names.entrySet()) { param.put(entry.getValue(), args[entry.getKey()]); // add generic param names (param1, param2, ...) final String genericParamName = GENERIC_NAME_PREFIX + String.valueOf(i + 1); // ensure not to overwrite parameter named with @Param if (!names.containsValue(genericParamName)) { param.put(genericParamName, args[entry.getKey()]); } i++; } return param; } } MethodSignatureMethodSignature 也 是 MapperMethod中定义 的内 部类 ，其中封装 了 Mapper接口中定义 的方法的相关 信息， MethodSignature中核心字段的含义 如下: // 返回值类型是否为 Collection类型或是数组类型 private final boolean returnsMany; // 返回值类型是否为Map类型 private final boolean returnsMap; // 返回值类型是否为Void类型 private final boolean returnsVoid; // 返回类型是否为Cursor类型 private final boolean returnsCursor; // 返回值类型 private final Class&lt;?> returnType; // 如果返回值类型是Map，则该字段记录了作为key的列名 private final String mapKey; // 用来标记该方法参数列表中ResultHandler类型参数的位置 private final Integer resultHandlerIndex; // 用来标记该方法参数列表中RowBounds类型参数的位置 private final Integer rowBoundsIndex; // 方法对应的ParamNameResolver对象 private final ParamNameResolver paramNameResolver; 在 MethodSignature的构 造函数 中会 解析相应 的Method对 象，并 初始化上述字段，具体 代 码 如下: public MethodSignature (Configuration configuration, Class&lt;?> mapperInterface, Method method) { Type resolvedReturnType = TypeParameterResolver.resolveReturnType(method, mapperInterface); if (resolvedReturnType instanceof Class&lt;?>) { this.returnType = (Class&lt;?>) resolvedReturnType; } else if (resolvedReturnType instanceof ParameterizedType) { this.returnType = (Class&lt;?>) ((ParameterizedType) resolvedReturnType).getRawType(); } else { this.returnType = method.getReturnType(); } this.returnsVoid = void.class.equals(this.returnType); this.returnsMany = configuration.getObjectFactory().isCollection(this.returnType) || this.returnType.isArray(); this.returnsCursor = Cursor.class.equals(this.returnType); // 若MethodSignature对 应 方法的返回值 是Map且指定了@MapKey注解，则 使用getMapKey()方法处 理 this.mapKey = getMapKey(method); this.returnsMap = this.mapKey != null; this.rowBoundsIndex = getUniqueParamIndex(method, RowBounds.class); this.resultHandlerIndex = getUniqueParamIndex(method, ResultHandler.class); this.paramNameResolver = new ParamNameResolver(configuration, method); } getUniqueParamIndex()方法的主要功能是查找指定类型的参数在参数列表中的位置。 private Integer getUniqueParamIndex(Method method, Class&lt;?> paramType) { Integer index = null; final Class&lt;?>[] argTypes = method.getParameterTypes(); // 遍历MethodSignature对应方法的参数列表 for (int i = 0; i &lt; argTypes.length; i++) { if (paramType.isAssignableFrom(argTypes[i])) { if (index == null) { // 记录paramType类型参数在参数列表中的位置索引 index = i; } else { // RowBounds和ResultHandler类型的参数只能有一个，不能重复出现 throw new BindingException(\"...\"); } } } return index; } convertArgsToSqlCommandParam()辅助方法： // 负责将args[]数组(用户传入的实参列表)转换成SQL语句对应的参数列表，它是通过上面介绍的 public Object convertArgsToSqlCommandParam(Object[] args) { return paramNameResolver.getNamedParams(args); } MapperMethod.execute()MapperMethod中 最核心的方法是execute()方法，它 会 根据SQL语 句的类 型调 用SqlSession对 应 的方法完成数 据 库 操作： public Object execute(SqlSession sqlSession, Object[] args) { Object result; switch (command.getType()) {// 根据SQL语句的类型调用SqlSession对应的方法 case INSERT: { // 使用ParamNameResolver处理args[]数组(用户传入的实参列表)，将用户传入的实参与 // 指定参数名称关联起来 Object param = method.convertArgsToSqlCommandParam(args); // 用SqlSession.insert()方法，rowCountResult()方法会根据method字段中记录的方法的 result = rowCountResult(sqlSession.insert(command.getName(), param)); break; } case UPDATE: { Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.update(command.getName(), param)); break; } case DELETE: { Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.delete(command.getName(), param)); break; } case SELECT: // 处理返回值为Void且ResultSet通过ResultHandler处理的方法 if (method.returnsVoid() &amp;&amp; method.hasResultHandler()) { executeWithResultHandler(sqlSession, args); result = null; } else if (method.returnsMany()) { // 处理返回值为集合或数组的类型 result = executeForMany(sqlSession, args); } else if (method.returnsMap()) {// 处理返回值为Map的方法 result = executeForMap(sqlSession, args); } else if (method.returnsCursor()) { // ... result = executeForCursor(sqlSession, args); } else { // 处理返回值为单一对象的方法 Object param = method.convertArgsToSqlCommandParam(args); result = sqlSession.selectOne(command.getName(), param); } break; case FLUSH: result = sqlSession.flushStatements(); break; default: throw new BindingException(\"Unknown execution method for: \" + command.getName()); } if (result == null &amp;&amp; method.getReturnType().isPrimitive() &amp;&amp; !method.returnsVoid()) { throw new BindingException(\"...\"); } return result; } 执 行 INSERT、UPDATE、DELETE类 型 的 SQL语 句时 ，其执 行结 果都需要经 过MapperMethod.rowCountResult()方 法 处 理 。 SqlSession 中 的 insert()等 方 法 返 回 的 是 int 值 ， rowCountResult()方法会 将 该 int值 转 换 成Mapper接口中对 应 方法的返回值 ，具体 实 现 如下: private Object rowCountResult(int rowCount) { final Object result; if (method.returnsVoid()) { result = null; } else if (Integer.class.equals(method.getReturnType()) || Integer.TYPE.equals(method.getReturnType())) { result = rowCount; } else if (Long.class.equals(method.getReturnType()) || Long.TYPE.equals(method.getReturnType())) { result = (long)rowCount; } else if (Boolean.class.equals(method.getReturnType()) || Boolean.TYPE.equals(method.getReturnType())) { result = rowCount > 0; } else { throw new BindingException(\"...\"); } return result; } 如 果 Mapper接口中定义 的方法准备 使用ResultHandler处 理查 询 结 果集，则 通过 MapperMethod.executeWithResultHandler()方法处 理，具体 实 现 如下: private void executeWithResultHandler(SqlSession sqlSession, Object[] args) { // 获 取SQL语 句对 应 的MappedStatement对象 MappedStatement ms = sqlSession.getConfiguration().getMappedStatement(command.getName()); if (!StatementType.CALLABLE.equals(ms.getStatementType()) &amp;&amp; void.class.equals(ms.getResultMaps().get(0).getType())) { throw new BindingException(\"...\"); } Object param = method.convertArgsToSqlCommandParam(args); if (method.hasRowBounds()) { RowBounds rowBounds = method.extractRowBounds(args); sqlSession.select(command.getName(), param, rowBounds, method.extractResultHandler(args)); } else { // 调用SqlSession.select()方法，执行查询 ，并由指定的ResultHandler处理结果对象 sqlSession.select(command.getName(), param, method.extractResultHandler(args)); } } 如 果 Mapper接口中对 应 方法的返回值 为 数 组 或是Collection接口实 现 类 ，则 通过 MapperMethod.executeForMany()方 法 处 理 ，具 体 实 现 如 下 : private &lt;E> Object executeForMany(SqlSession sqlSession, Object[] args) { List&lt;E> result; Object param = method.convertArgsToSqlCommandParam(args); if (method.hasRowBounds()) { RowBounds rowBounds = method.extractRowBounds(args); // 调用SqlSession.selectList()方法完成查询 result = sqlSession.&lt;E>selectList(command.getName(), param, rowBounds); } else { result = sqlSession.&lt;E>selectList(command.getName(), param); } // issue #510 Collections &amp; arrays support if (!method.getReturnType().isAssignableFrom(result.getClass())) { if (method.getReturnType().isArray()) { return convertToArray(result); } else { return convertToDeclaredCollection(sqlSession.getConfiguration(), result); } } return result; } convertToDeclaredCollection()方 法 和 convertToArray()方 法 的 功 能 类 似 ，主 要 负 责 将 结 果 对 象转 换 成Collection集合对 象和数 组 对 象，具体 实 现 如下: private &lt;E> Object convertToDeclaredCollection(Configuration config, List&lt;E> list) { // 通过反射创建集合对象 Object collection = config.getObjectFactory().create(method.getReturnType()); // 创建MetaObject对象 MetaObject metaObject = config.newMetaObject(collection); metaObject.addAll(list); return collection; } @SuppressWarnings(\"unchecked\") private &lt;E> Object convertToArray(List&lt;E> list) { Class&lt;?> arrayComponentType = method.getReturnType().getComponentType(); Object array = Array.newInstance(arrayComponentType, list.size()); if (arrayComponentType.isPrimitive()) { for (int i = 0; i &lt; list.size(); i++) { Array.set(array, i, list.get(i)); } return array; } else { return list.toArray((E[])array); } } 如果Mapper接口中对 应 方法的返回值 为 Map类 型,则 通过 MapperMethod.executeForMap() 方法处理，具体实现如下: private &lt;K, V> Map&lt;K, V> executeForMap(SqlSession sqlSession, Object[] args) { Map&lt;K, V> result; Object param = method.convertArgsToSqlCommandParam(args); if (method.hasRowBounds()) { RowBounds rowBounds = method.extractRowBounds(args); result = sqlSession.&lt;K, V>selectMap( command.getName(), param, method.getMapKey(), rowBounds); } else { result = sqlSession.&lt;K, V>selectMap(command.getName(), param, method.getMapKey()); } return result; } executeForCursor()方法与 executeForMap()方法类似，唯一区别就是调 selectCursor()方法。 参考 《MyBatis技术内幕》 部分图片来源——《MyBatis技术内幕》","tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://www.cayzlh.com/tags/MyBatis/"},{"name":"《MyBatis技术内幕》","slug":"《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/tags/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"},{"name":"基础支持层","slug":"基础支持层","permalink":"https://www.cayzlh.com/tags/%E5%9F%BA%E7%A1%80%E6%94%AF%E6%8C%81%E5%B1%82/"}],"categories":[{"name":"书籍","slug":"书籍","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/"},{"name":"《MyBatis技术内幕》","slug":"书籍/《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"}]},{"title":"基础支持层——Transaction","date":"2019-10-29T01:09:42.000Z","path":"2019/10/29/e275ec7f.html","text":"MyBatis基础支持层位于 Mybatis 整体架构的最底层，支撑着 Mybatis 的核心处理层，是整个框架的基石。基础支持层中封装了多个较为通用的、独立的模块，不仅仅为 Mybatis 提供基础支撑，也可以在合适的场景中直接复用。 这篇文章介绍MyBatis的Transaction模块 在实 践 开 发 中，控制数 据库 事务 是一件非常重要的工作，MyBatis使 用 Transaction接口对数据库事务进 行了抽象，Transaction接口的定义 如下: public interface Transaction { /** * 获取对应的数据库连接 */ Connection getConnection() throws SQLException; /** * 提交事务 */ void commit() throws SQLException; /** * 回滚事务 */ void rollback() throws SQLException; /** * 关闭数据库连接 */ void close() throws SQLException; /** * 获取事务超时时间 */ Integer getTimeout() throws SQLException; } Transaction 接 口 有 JdbcTransaction、 ManagedTransaction 两 个 实 现 ， 其 对 象 分 别 由 JdbcTransactionFactory和 ManagedTransactionFactory负 责 创 建。这 里也使用 工厂 方法模式。 JdbcTransactionJdbcTransaction依赖于 JDBC Connection控制事务的提交和回 滚 。JdbcTransaction中 字 段 的 含义 如下: // 事务对应的数据库连接 protected Connection connection; // 数据库连接所属的DataSource protected DataSource dataSource; // 事务隔离级别 protected TransactionIsolationLevel level; // 是否自动提交 protected boolean autoCommmit; 在 JdbcTransaction的构 造函数 中会 初始化除connection字段之外的其他三个 字段，而 connection字段会 延迟 初始化，它 会 在调 用getConnection()方法时 通过 dataSource.getConnection() 方法初始化，并 且同时 设 置autoCommit和事务 隔离 级 别 。 JdbcTransaction的 commit()方法和 rollback()方法都会 调 用Connection对 应 方法实 现 的。 ManagedTransactionManagedTransaction的实 现 更加简 单 ，它 同样 依赖 其中的dataSource字段获 取连 接，但其 commit()、rollback()方法都是空实 现 ，事务 的提交和回滚 都是依靠 容器管理的。 ManagedTransaction中通过 closeConnection字段的值 控制数 据库 连 接的关 闭 行为 。 public void close() throws SQLException { if (this.closeConnection &amp;&amp; this.connection != null) { if (log.isDebugEnabled()) { log.debug(\"Closing JDBC Connection [\" + this.connection + \"]\"); } this.connection.close(); } } TransactionFactoryTransactionFactory接 口 定 义 了 配 置 新 建 TransactionFactory对 象 的 方 法 ， 以 及 创 建 Transaction对 象的方法，代码 如下: public interface TransactionFactory { /** * 配置TransactionFactory对 象，一般紧 跟 在创 建完成之后，完成对 TransactionFactory的自定义 配置 */ void setProperties(Properties props); /** * 在指定的连 接上创 建Transaction对 象 */ Transaction newTransaction(Connection conn); /** * 从 指定数 据源中获 取数 据库 连 接，并 在此连 接之上创 建Transaction对 象 */ Transaction newTransaction(DataSource dataSource, TransactionIsolationLevel level, boolean autoCommit); } JdbcTransactionFactory 和 ManagedTransactionFactory 负 责 创 建 JdbcTransaction 和 ManagedTransaction，这 一部分的代码 比较 简 单 。 参考 《MyBatis技术内幕》 部分图片来源——《MyBatis技术内幕》","tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://www.cayzlh.com/tags/MyBatis/"},{"name":"《MyBatis技术内幕》","slug":"《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/tags/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"},{"name":"基础支持层","slug":"基础支持层","permalink":"https://www.cayzlh.com/tags/%E5%9F%BA%E7%A1%80%E6%94%AF%E6%8C%81%E5%B1%82/"}],"categories":[{"name":"书籍","slug":"书籍","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/"},{"name":"《MyBatis技术内幕》","slug":"书籍/《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"}]},{"title":"基础支持层——DataSource","date":"2019-10-28T01:09:42.000Z","path":"2019/10/28/899df03d.html","text":"MyBatis基础支持层位于 Mybatis 整体架构的最底层，支撑着 Mybatis 的核心处理层，是整个框架的基石。基础支持层中封装了多个较为通用的、独立的模块，不仅仅为 Mybatis 提供基础支撑，也可以在合适的场景中直接复用。 这篇文章介绍MyBatis的DataSource模块 在数 据持久层 中，数 据源是一个 非常重要的组 件，其性能直接关 系到整个 数 据持久层 的性能。 在实 践 中比较 常见 的第三方数 据源组 件有ApacheCommonDBCP、C3P0、Proxool等，MyBatis不仅 可以集成第三方数 据源组 件，还 提供了自己的数 据源实 现 。 常见 的数 据源组 件都实 现 了 javax.sql.DataSource接口，MyBatis自身实 现 的数 据源实 现 也 不 例 外 。 MyBatis 提 供 了 两 个 javax.sql.DataSource 接 口 实 现 ， 分 别 是 PooledDataSource 和 UnpooledDataSource。 Mybatis使 用 不 同 的 DataSourceFactory接 口 实 现 创 建 不 同 类 型 的 DataSource,如图所示，这 是工厂 方法模式的一个 典型应 用。 工厂方法模式 在工厂 方法模式中，定义 了一个 用于创 建对 象的工厂 接口，并 根据工厂 接口的具体 实 现 类 决定具体实例化哪一个具体产品类。首先来看工厂方法模式的UML图，从整体上了解该模式 的结 构 。 工厂方法有四个角色构成： 工厂接口（Factory） 工厂 接口是工厂 方法模式的核心接口，调 用者会 直接与 工厂 接 口交互用于获取具体的产品实现类 具体工厂类（ConcreteFactory） 具体 工厂 类 是工厂 接口的实 现 类 ，用于实 例化产 品 对象，不同的具体工厂类会根据需求实例化不同的产品实现类。 产品接口（Product） 品接口用于定义 产 品类 的功能，具体 工厂 类 产 生的所有产 品对象都必须实现该接口。调用者一般会面向产品接口进行编程，所以产品接口会与调用者直接交互，也是调 用者最为 关 心的接口。 具体 产 品类 （ConcreteProduct） 现 产 品接口的实 现 类 ，具体 产 品类 中定义 了具体的业务逻辑 如果需要产 生新的产 品，例如对 于MyBatis的数 据源模块 来 说 ，就是添加新的第三方数 据 源组 件，只需要添加对 应 的工厂 实 现 类 ，新数 据源就可以被MyBatis使用，而不必修改己有的 代码 。显 然，工厂 方法模式符合“开 放-封闭 ”原则 。除此之外，工厂 方法会 向调 用者隐 藏具体 产 品类 的实 例化细 节 ，调 用者只需要了解工厂 接口和产 品接口，面向这 两 个 接口编 程即 可。 工厂 方法模式也是存在缺点的。在增加新产 品实 现 类 时 ，还 要提供一个 与 之对 应 的工厂 实 现 类 ，所以实 际 新增的类 是成对 出现 的，这 增加了系统 的复 杂 度。另 外，工厂 方法模式引入了 工厂 接口和产 品接口这 一层 抽象，调 用者面向该 抽象层 编 程,增加了程序的抽象性和理解难 度。 DataSourceFactory在数 据源模块 中，DataSourceFactory接口扮演工厂 接口的角色。 UnpooledDataSourceFactory 和 PooledDataSourceFactory则 扮演着具体 工厂 类 的角色。 我们 从 DataSourceFactory接口开 始分 析，其定义 如下: public interface DataSourceFactory { // 设置DataSource的相关属性，一般紧跟在初始化完成之后 void setProperties(Properties props); // 获取DataSource对象 DataSource getDataSource(); } 在 UnpooledDataSourceFactory的 构 造 函 数 中 会 直 接 创 建 UnpooledDataSource对 象 ，并 初始 化 UnpooledDataSourceFactory.dataSource 字 段 。UnpooledDataSourceFactory.setProperties()方法会 完成对 UnpooledDataSource对 象的配置，代码 如下: public void setProperties(Properties properties) { Properties driverProperties = new Properties(); // 创建DataSource对应的MetaObject MetaObject metaDataSource = SystemMetaObject.forObject(dataSource); // 遍历properties集合，该集合中配置了数据源需要的信息 for (Object key : properties.keySet()) { String propertyName = (String) key; // 以\"driver.\"开头的配置项是对DateSource的配置，记录到driverProperties中保存 if (propertyName.startsWith(DRIVER_PROPERTY_PREFIX)) { String value = properties.getProperty(propertyName); driverProperties.setProperty( propertyName.substring(DRIVER_PROPERTY_PREFIX_LENGTH), value); } else if (metaDataSource.hasSetter(propertyName)) { String value = (String) properties.get(propertyName); Object convertedValue = convertValue(metaDataSource, propertyName, value); metaDataSource.setValue(propertyName, convertedValue); } else { throw new DataSourceException(\"...\"); } } if (driverProperties.size() > 0) { metaDataSource.setValue(\"driverProperties\", driverProperties); } } UnpooledDataSourceFactory.getDataSource()方法实 现 比较 简 单 ，它 直接返回 dataSource字段 记 录 的 UnpooledDataSource 对 象 。 PooledDataSourceFactory 继 承 了 UnpooledDataSourceFactory, 但 并 没 有 覆 盖 setProperties() 方法和getDataSource()方法。两 者唯一的区 别 是PooledDataSourceFactory的构 造函数 会 将 其 dataSource 字 段 初 始 化 为 PooledDataSource 对 象 。 JndiDataSourceFactory是依赖 JNDI服务 从 容器中获 取用户 配置的DataSource，其逻 辑 并 不 复 杂 。 UnpooledDataSourcejavax.sql.DataSource接口在数 据源模块 中扮演了产 品接口的角色，MyBatis提供了两 个 DataSource接 口 的 实 现 类 ，分 别 是 UnpooledDataSource和 PooledDataSource，它 们 扮 演 着 具 体 产 品类 的角色。 UnpooledDataSource 实 现 了 javax.sql.DataSource 接 口 中 定 义 的 getConnection()方 法 及 其 重 载方法，用于获 取数 据库 连 接。 每次通过 UnpooledDataSource.getConnection()方法获 取数 据库 连 接 时 都会 创 建一个 新连 接。 UnpooledDataSource中的字段如下，每个 字段都有对 应 的getter/setter 方法: public class UnpooledDataSource implements DataSource { private ClassLoader driverClassLoader; private Properties driverProperties; private static Map&lt;String, Driver> registeredDrivers = new ConcurrentHashMap&lt;String, Driver>(); private String driver; private String url; private String username; private String password; private Boolean autoCommit; private Integer defaultTransactionIsolationLevel; static { Enumeration&lt;Driver> drivers = DriverManager.getDrivers(); while (drivers.hasMoreElements()) { Driver driver = drivers.nextElement(); registeredDrivers.put(driver.getClass().getName(), driver); } } // ... } Pooled DataSource了解JDBC编 程的读 者知道，数 据库 连 接的创 建过 程是非常耗时 的，数 据库 能够 建立的连 接数 也非常有限，所以在绝 大多数 系统 中，数 据库 连 接是非常珍贵 的资 源，使用数 据库 连 接池就显得尤为必要。 使用数据库连接池会带来很多好处，例如，可以实现数据库连接的重用、提高响 应 速度、防止数 据库 连 接过 多造成数 据库 假死、避免数 据库 连 接泄露等。 数据库连接池在初始化时，一般会创建一定数量的数据库连接并添加到连接池中备用。 当 程序需要使用数 据库 连 接时 ，从 池中请 求连 接;当 程序不再使用该 连 接时 ，会 将 其返回到池中 缓 存，等待下次使用，而不是直接关 闭 。 当 然，数 据库 连 接池会 控制连 接总 数 的上限以及空闲 连 接数 的上限，如果连 接池创 建的总 连 接数 己达 到上限，且都已被占用，则 后续 请 求连 接的线 程会 进 入阻塞队 列等待，直到有线 程释 放出可用的连 接。 如果连 接池中空闲 连 接数 较 多，达 到 其上限，则 后续 返回的空闲 连 接不会 放入池中，而是直接关 闭 ，这 样 可以减 少系统 维 护 多余数 据库连接的开销。 如果将总连接数的上限设置得过大，可能因连接数过多而导致数据库僵死，系统整体性能 下降; 如果总连接数上限过小，则无法完全发挥数据库的性能，浪费数据库资源。如果将空闲 连接的上限设置得过大，则会浪费系统资源来维护这些空闲连接; 如果空闲连接上限过小，当 出现 瞬间 的峰值 请 求时 ，系统 的快速响 应 能力就比较 弱。 所以在设 置数 据库 连 接池的这 两 个 值 时，需要进行性能测试、权衡以及一些经验。 PooledDataSource实 现 了简 易数 据库 连 接池的功能，它 依赖 的组 件如图 所示，其中需 要注意的是，PooledDataSource创 建新数 据库 连 接的功能是依赖 其中封装 的UnpooledDataSource 对象实现的。 PooledConnectionPooledDataSource并 不会 直接管理java.sql.Connection对 象，而是管理 PooledConnection对 象。 在 PooledConnection中封装 了真 正的数 据库 连 接对 象(java.sql.Connection) 以及其代理对 象，这 里的代理对 象是通过 JDK动 态 代理产 生的。PooledConnection继 承了 InvocationHandler 接口。 核心字段： // 记录当前PooledConnection对 象所在的 PooledDataSource对 象。 // 该 PooledConnection是从该 PooledDataSource中获 取的; // 当 调 用close() 方法时 会 将 PooledConnection放回该PooledDataSource 中 private final PooledDataSource dataSource; // 真正的数据库连接 private final Connection realConnection; // 数据库连接代理对象 private final Connection proxyConnection; // 从连接池中取出该连接的时间戳 private long checkoutTimestamp; // 创建该连接的时间戳 private long createdTimestamp; // 最后一次使用的时间戳 private long lastUsedTimestamp; // 由数据库URL、用户名和密码计算出来的hash值，可用于标识该连接所在的连接池 private int connectionTypeCode; // 检测当前PooledConnection是否有效，主要是为了防止程序通过close()方法将连接还给连接池之后 // 依然通过该连接操作数据库 private boolean valid; PooledConnection.invoke()方法的实 现 ，该 方法是proxyConnection这 个 连 接代理对 象的真 正代理 逻 辑 ，它 会 对 close()方法的调 用进 行代理，并 且在调 用真 正数 据库 连 接的方法之前进 行检 测 ， 代码 如下: public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { String methodName = method.getName(); // 如果调用close()方法，则将其重新放入连接池，而不是真正关闭数据库连接 if (CLOSE.hashCode() == methodName.hashCode() &amp;&amp; CLOSE.equals(methodName)) { dataSource.pushConnection(this); return null; } else { try { if (!Object.class.equals(method.getDeclaringClass())) { // issue #579 toString() should never fail // throw an SQLException instead of a Runtime // 通过valid字段检测连接是否有效 checkConnection(); } // 调用真正数据库连接对象对应的方法 return method.invoke(realConnection, args); } catch (Throwable t) { throw ExceptionUtil.unwrapThrowable(t); } } } PoolStatePoolState是 用 于 管 理 PooledConnection对 象 状 态 的 组 件 ，它 通 过 两 个 ArrayList &lt;PooledConnection&gt;集合分别 管理空闲 状 态 的连 接和活跃 状 态 的连 接，定义 如下: // 空闲的PooledConnection对象集合 protected final List&lt;PooledConnection> idleConnections = new ArrayList&lt;PooledConnection>(); // 活跃的PooledConnection集合 protected final List&lt;PooledConnection> activeConnections = new ArrayList&lt;PooledConnection>(); // 请求数据库连接的次数 protected long requestCount = 0; // 获取连接的累积时间 protected long accumulatedRequestTime = 0; // checkoutTime表示应用从连接池中取出连接，到归还的这段时长 // accumulatedCheckoutTime记录了所有连接累积的checkoutTime时长 protected long accumulatedCheckoutTime = 0; // 当连接长时间未归还给连接池的时候，会被认该连接超时 // claimedOverdueConnectionCount记录了超时连接个数 protected long claimedOverdueConnectionCount = 0; // 累积超时时间 protected long accumulatedCheckoutTimeOfOverdueConnections = 0; // 累积等待时间 protected long accumulatedWaitTime = 0; // 累积等待次数 protected long hadToWaitCount = 0; // 无效的连接数 protected long badConnectionCount = 0; PooledDataSourcePooledDataSource中 管 理 的 真 正 的 数 据 库 连 接 对 象 是 由 PooledDataSource中封装 的UnpooledDataSource对 象 创 建 的 ，并 由 PoolState管 理 所 有 连 接 的 状 态 。 PooledDataSource中核心字段的含义 和功能如下: // 通过 PoolState管理连接池的状态并记录统计信息 private final PoolState state = new PoolState(this); // 记录UnpooledDataSource对象，用于生成真实的数据库连接对象，构造函数中会初始化该字段 private final UnpooledDataSource dataSource; // 最大活跃连接数 protected int poolMaximumActiveConnections = 10; // 最大空闲连接数 protected int poolMaximumIdleConnections = 5; // 最大checkout时长 protected int poolMaximumCheckoutTime = 20000; // 最大等待时间 protected int poolTimeToWait = 20000; // 最大无效连接数量 protected int poolMaximumLocalBadConnectionTolerance = 3; // 在检测一个数据库连接是否可用的时候，会给数据库发送一个测试SQL语句 protected String poolPingQuery = \"NO PING QUERY SET\"; protected boolean poolPingEnabled; // 当连接超过 poolPingConnectionsNotUsedFor毫秒未使用时 ，会发送一次测试SQL语句，检测连接是否正常 protected int poolPingConnectionsNotUsedFor; // 根据数据库的URL、用户名和密码生成的一个hash值，该哈希值用于标志着当前的连接池，在构造函数中初始化 private int expectedConnectionTypeCode; PooledDataSource.getConnection()方 法 首 先 会 调 用 PooledDataSource.popConnection()方 法 获 取 PooledConnection 对 象，然后通过 PooledConnection.getProxyConnection()方法获 取数 据库 连 接的代理对 象。popConnection()方法是PooledDataSource的核心逻 辑 之一，其具体 逻 辑 如图。 PooledDataSource.popConnection()方法的具体实现： private PooledConnection popConnection(String username, String password) throws SQLException { boolean countedWait = false; PooledConnection conn = null; long t = System.currentTimeMillis(); int localBadConnectionCount = 0; while (conn == null) { synchronized (state) { if (!state.idleConnections.isEmpty()) { // Pool has available connection conn = state.idleConnections.remove(0); if (log.isDebugEnabled()) { log.debug(\"...\"); } } else { // Pool does not have available connection if (state.activeConnections.size() &lt; poolMaximumActiveConnections) { // Can create new connection conn = new PooledConnection(dataSource.getConnection(), this); if (log.isDebugEnabled()) { log.debug(\"...\"); } } else { // Cannot create new connection PooledConnection oldestActiveConnection = state.activeConnections.get(0); long longestCheckoutTime = oldestActiveConnection.getCheckoutTime(); if (longestCheckoutTime > poolMaximumCheckoutTime) { // Can claim overdue connection state.claimedOverdueConnectionCount++; state.accumulatedCheckoutTimeOfOverdueConnections += longestCheckoutTime; state.accumulatedCheckoutTime += longestCheckoutTime; state.activeConnections.remove(oldestActiveConnection); if (!oldestActiveConnection.getRealConnection().getAutoCommit()) { try { oldestActiveConnection.getRealConnection().rollback(); } catch (SQLException e) { log.debug(\"Bad connection. Could not roll back\"); } } conn = new PooledConnection(oldestActiveConnection.getRealConnection(), this); conn.setCreatedTimestamp(oldestActiveConnection.getCreatedTimestamp()); conn.setLastUsedTimestamp(oldestActiveConnection.getLastUsedTimestamp()); oldestActiveConnection.invalidate(); if (log.isDebugEnabled()) { log.debug(\"....\"); } } else { // Must wait try { if (!countedWait) { state.hadToWaitCount++; countedWait = true; } if (log.isDebugEnabled()) { log.debug(\"...\"); } long wt = System.currentTimeMillis(); state.wait(poolTimeToWait); state.accumulatedWaitTime += System.currentTimeMillis() - wt; } catch (InterruptedException e) { break; } } } } if (conn != null) { // ping to server and check the connection is valid or not if (conn.isValid()) { if (!conn.getRealConnection().getAutoCommit()) { conn.getRealConnection().rollback(); } conn.setConnectionTypeCode(assembleConnectionTypeCode(dataSource.getUrl(), username, password)); conn.setCheckoutTimestamp(System.currentTimeMillis()); conn.setLastUsedTimestamp(System.currentTimeMillis()); state.activeConnections.add(conn); state.requestCount++; state.accumulatedRequestTime += System.currentTimeMillis() - t; } else { if (log.isDebugEnabled()) { log.debug(\"...\"); } state.badConnectionCount++; localBadConnectionCount++; conn = null; if (localBadConnectionCount > (poolMaximumIdleConnections + poolMaximumLocalBadConnectionTolerance)) { if (log.isDebugEnabled()) { log.debug(\"...\"); } throw new SQLException(\"...\"); } } } } } if (conn == null) { if (log.isDebugEnabled()) { log.debug(\"...\"); } throw new SQLException(\"...\"); } return conn; } 通 过 前 面 对 PooledConnection.invoke()方法的分析我们 知道，当 调 用连 接的代理对 象的 close()方 法 时 ，并未关闭真正的数据连接 ，而是调用PooledDataSource.pushConnection()方法将 PooledConnection对 象归 还 给 连 接池，供之后重用。 PooledDataSource.pushConnection()方法也是 PooledDataSource的核心逻 辑 之一，其逻 辑 如图 PooledDataSource.pushConnection()代码如下： protected void pushConnection(PooledConnection conn) throws SQLException { synchronized (state) { state.activeConnections.remove(conn); if (conn.isValid()) { if (state.idleConnections.size() &lt; poolMaximumIdleConnections &amp;&amp; conn.getConnectionTypeCode() == expectedConnectionTypeCode) { state.accumulatedCheckoutTime += conn.getCheckoutTime(); if (!conn.getRealConnection().getAutoCommit()) { // 回滚未提交的事务 conn.getRealConnection().rollback(); } PooledConnection newConn = new PooledConnection(conn.getRealConnection(), this); state.idleConnections.add(newConn); newConn.setCreatedTimestamp(conn.getCreatedTimestamp()); newConn.setLastUsedTimestamp(conn.getLastUsedTimestamp()); conn.invalidate(); if (log.isDebugEnabled()) { log.debug(\"...\"); } state.notifyAll(); } else { // 空闲连接数已达到上限或PooledConnection对象并不属于该连接池 state.accumulatedCheckoutTime += conn.getCheckoutTime(); if (!conn.getRealConnection().getAutoCommit()) { conn.getRealConnection().rollback(); } conn.getRealConnection().close(); if (log.isDebugEnabled()) { log.debug(\"...\"); } conn.invalidate(); } } else { if (log.isDebugEnabled()) { log.debug(\"...\"); } // 统计无效PooledConnection对象个数 state.badConnectionCount++; } } } 这里需要注意的是，PooledDataSource.pushConnection()方法和popConnection()方法中都调 用了 PooledConnection.isValid()方 法 来 检 测 PooledConnection的 有 效 性 ， 该 方 法 除 了 检 测 PooledConnection.valid 字段的值 ，还 会 调 用 PooledDataSource.pingConnection()方法尝 试 让 数 据 库 执 行podPingQuery字段中记 录 的测 试 SQL语 句，从 而检 测 真 正的数 据库 连 接对 象是否依然 可以正常使用。 public boolean isValid() { return valid &amp;&amp; realConnection != null &amp;&amp; dataSource.pingConnection(this); } protected boolean pingConnection(PooledConnection conn) { boolean result = true; try { result = !conn.getRealConnection().isClosed(); } catch (SQLException e) { if (log.isDebugEnabled()) { log.debug(\"...\"); } result = false; } if (result) { if (poolPingEnabled) { // 检测poolPingEnabled设置，是否运行执行测试SQL语 句 // 长时间(超过 poolPingConnectionsNotUsedFor指定的时长)未使用的连接，才需要ping // 操作来检测数据库连接是否正常 if (poolPingConnectionsNotUsedFor >= 0 &amp;&amp; conn.getTimeElapsedSinceLastUse() > poolPingConnectionsNotUsedFor) { try { if (log.isDebugEnabled()) { log.debug(\"...\"); } Connection realConn = conn.getRealConnection(); Statement statement = realConn.createStatement(); ResultSet rs = statement.executeQuery(poolPingQuery); rs.close(); statement.close(); if (!realConn.getAutoCommit()) { realConn.rollback(); } result = true; if (log.isDebugEnabled()) { log.debug(\"...\"); } } catch (Exception e) { log.warn(\"...\"); try { conn.getRealConnection().close(); } catch (Exception e2) { //ignore } result = false; if (log.isDebugEnabled()) { log.debug(\"...\"); } } } } } return result; } 最后需要注意的是PooledDataSource.forceCloseAll()方法，当 修改PooledDataSource的字段 时 ，例如数 据库 URL、用户名、密码 、autoCommit配置等，都会 调 用forceCloseAll()方法将 所 有数 据库 连 接关 闭 ，同时 也会 将 所有相应 的PooledConnectiori对 象都设 置为 无效，清 空 activeConnections 集 合 和 idleConnections 集 合 。 应用系统之后通过PooledDataSource.getConnection()获取连接时，会按照新的配置重新配置新的数据库连接以及相应的PooledConnection对象。 public void forceCloseAll() { synchronized (state) { expectedConnectionTypeCode = assembleConnectionTypeCode( dataSource.getUrl(), dataSource.getUsername(), dataSource.getPassword()); for (int i = state.activeConnections.size(); i > 0; i--) { try { PooledConnection conn = state.activeConnections.remove(i - 1); conn.invalidate(); Connection realConn = conn.getRealConnection(); if (!realConn.getAutoCommit()) { realConn.rollback(); } realConn.close(); } catch (Exception e) { // ignore } } for (int i = state.idleConnections.size(); i > 0; i--) { try { PooledConnection conn = state.idleConnections.remove(i - 1); conn.invalidate(); Connection realConn = conn.getRealConnection(); if (!realConn.getAutoCommit()) { realConn.rollback(); } realConn.close(); } catch (Exception e) { // ignore } } } if (log.isDebugEnabled()) { log.debug(\"PooledDataSource forcefully closed/removed all connections.\"); } } 参考 《MyBatis技术内幕》 部分图片来源——《MyBatis技术内幕》","tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://www.cayzlh.com/tags/MyBatis/"},{"name":"《MyBatis技术内幕》","slug":"《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/tags/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"},{"name":"基础支持层","slug":"基础支持层","permalink":"https://www.cayzlh.com/tags/%E5%9F%BA%E7%A1%80%E6%94%AF%E6%8C%81%E5%B1%82/"}],"categories":[{"name":"书籍","slug":"书籍","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/"},{"name":"《MyBatis技术内幕》","slug":"书籍/《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"}]},{"title":"基础支持层——资源加载","date":"2019-10-27T01:09:42.000Z","path":"2019/10/27/899df03d.html","text":"MyBatis基础支持层位于 Mybatis 整体架构的最底层，支撑着 Mybatis 的核心处理层，是整个框架的基石。基础支持层中封装了多个较为通用的、独立的模块，不仅仅为 Mybatis 提供基础支撑，也可以在合适的场景中直接复用。 这篇文章介绍MyBatis的资源加载模块 类加载器Java虚 拟 机中的类 加载 器(ClassLoader)负 责 加载 来 自文件系统 、网 络 或其他来 源的类 文 件。Java虚 拟 机中的类 加载 器默认 使用的是双 亲 委派模式，如图所示，其中有三种 默认 使 用 的 类 加 载 器 ，分 别 是 Bootstrap ClassLoader、Extension ClassLoader 和 System ClassLoader (也 被称 为 ApplicationClassLoader)，每种 类 加载 器都己经 确 定从 哪 个 位置加载 类 文件。 BootstrapClassLoader负 责 加载 JDK自带 的rt.jar包中的类 文件，它 是所有类 加载 器的父加载 器，Bootstrap ClassLoader没 有任何父类 加载 器。Extension ClassLoader负 责 加 载 Java的扩 展类 库 ，也就是从 jre/lib/ext目录 下或者java.ext.dirs系统 属 性指定的目录 下加载 类 。 SystemClassLoader负 责 从 classpath环 境变 量中加载 类 文件，classpath环 境变 量通常由-classpath或 -cp命令行选 项 来 定义 ，或 是 由 JAR中 Manifest文 件 的 classpath属 性指定。System ClassLoader是ExtensionClassLoader的子加载 器。 根据双亲委派模式，在加载类文件时，子加载器首先会将加载请求委托给它的父加载器。 父加载器会检测自己是否已经加载过该类，如果己加载则加载过程结束;如果未加载则请求继 续 向上传 递 ，直到BootstrapClassLoader。 如果在请 求向上委托的过 程中，始终 未检 测 到该 类 己 加载 ，则 从 BootstrapClassLoader开 始尝 试 从 其对 应 路径 中加载 该 类 文件，如果加载 失败 则 由 子加载器继续尝试加载，直至发起加载请求的子加载器位为止。 双 亲 委派模式可以保证 两 点: 一是子加载 器可以使用父加载 器己加载 的类 ，而父加载 器无 法使用子加载 器已加载 的类 ; 二是父加载 器已加载 过 的类 无法被子加载 器再次加载 。 这 样 就可以保证 JVM的安全性和稳 定性。 ClassLoaderWrapper上上一小节中了解了类 加载 器的常见 使用方式。在 MyBatis的 IO 包中封装 了 ClassLoader以及读 取资 源文件的相关 API。 在 IO包 中 提 供 的 ClassLoaderWrapper是 一 个 ClassLoader的包装 器，其中包含了多个ClassLoader对 象。 通过 调 整多个 类 加载 器的使用顺 序，ClassLoaderWrapper可以确 保返回给 系 统 使用的是正确 的类 加载 器。 使 用 ClassLoaderWrapper就如同使用一个 ClassLoader对 象， ClassLoaderWrapper会 按照指定的顺 序依次检 测 其中封装 的ClassLoader对 象，并 从 中选 取第一 个 可用的ClassLoader完成相关 功能。 ClassLoaderWrapper的 主 要 功 能 可 以 分 为 三 类 ， 分 别 是 getResourceAsURL()方 法 、 classForName()方法、getResourceAsStream()方法，这 三个 方法都有多个 重载 ，这 三类 方法最终 都会 调 用参 数 为 String和ClassLoader[]的重载 。 getResourceAsURL()代码如下，其他的类似： public URL getResourceAsURL(String resource, ClassLoader classLoader) { return getResourceAsURL(resource, getClassLoaders(classLoader)); } // 返回ClassLoader[], 该方法指明类加载器的使用顺序 ClassLoader[] getClassLoaders(ClassLoader classLoader) { return new ClassLoader[]{ classLoader, defaultClassLoader, Thread.currentThread().getContextClassLoader(), getClass().getClassLoader(), systemClassLoader}; } URL getResourceAsURL(String resource, ClassLoader[] classLoader) { URL url; for (ClassLoader cl : classLoader) { if (null != cl) { // look for the resource as passed in... url = cl.getResource(resource); // ...but some class loaders want this leading \"/\", so we'll add it // and try again if we didn't find the resource if (null == url) { url = cl.getResource(\"/\" + resource); } // \"It's always in the last place I look for it!\" // ... because only an idiot would keep looking for it after finding it, so stop looking already. if (null != url) { return url; } } } // didn't find it anywhere. return null; } Resources是一个 提供了多个 静 态 方法的工具类 ，其中封装 了一个 ClassLoaderWrapper类 型 的静 态 字段，Resources提供的这 些静 态 工具都是通过 调 用该 ClassLoaderWrapper对 象的相应 方 法实 现 的。 ResolverUtilResolverUtil可以根据指定的条件查找指定包下的类 ，其中使用的条件由Test接口表示。 ResolverUtil中使用classLoader字 段 (ClassLoader类 型)记 录 了当 前使用的类 加载 器，默认 情 况 下，使用的是当 前线 程上下文绑 定的ClassLoader，我们 可以通过 setClassLoader()方法修改使 用类加载器。 MyBatis提供了两 个 常用的Test接口实 现 ，分别 是IsA和AnnotatedWith,如图 所示。 IsA用于检 测 类 是否继 承了指定的类 或接口，AnnotatedWith用于检 测 类 是否添加了指定的注解。 开 发 人员 也可以自己实 现 Test接口，实 现 指定条 件的检 测 。 Test接口中定义 了 matches()方法，它 用于检 测 指定类 是否符合条 件: public interface Test { /** * Will be called repeatedly with candidate classes. Must return True if a class * is to be included in the results, false otherwise. */ boolean matches(Class&lt;?> type); } IsA和 AnnotatedWith的具体 实 现 如下 public static class IsA implements Test { private Class&lt;?> parent; /** Constructs an IsA test using the supplied Class as the parent class/interface. */ public IsA(Class&lt;?> parentType) { this.parent = parentType; } /** Returns true if type is assignable to the parent type supplied in the constructor. */ @Override public boolean matches(Class&lt;?> type) { return type != null &amp;&amp; parent.isAssignableFrom(type); } @Override public String toString() { return \"is assignable to \" + parent.getSimpleName(); } } public static class AnnotatedWith implements Test { private Class&lt;? extends Annotation> annotation; /** Constructs an AnnotatedWith test for the specified annotation type. */ public AnnotatedWith(Class&lt;? extends Annotation> annotation) { this.annotation = annotation; } /** Returns true if the type is annotated with the class provided to the constructor. */ @Override public boolean matches(Class&lt;?> type) { return type != null &amp;&amp; type.isAnnotationPresent(annotation); } @Override public String toString() { return \"annotated with @\" + annotation.getSimpleName(); } } 默认 情况 下，使用Thread.currentThread().getContextClassLoader()这 个 类 加载 器加载 符合条 件的类 ，我们 可以在调 用find()方法之前，调 用 setClassLoader(ClassLoader)设 置需要使用的 ClassLoader，这 个 ClassLoader可 以 从 ClassLoaderWrapper中 获 取 合 适 的 类 加 载 器 。 ResolverUtil的使用案例： ResolverUtil&lt;ActionBean> resolver = new ResolverUtil&lt;ActionBean>(); // 在pkg1和pkg2这个包下查找实现了ActionBean这个接口的类 resolver.findImplementation(ActionBean.class, pkg1, pkg2); // 在pkg1包下查找符合CustomerTest条件的类 resolver.find(new CustomTest(), pkg1); // 在pkg2包下查找符合CustomerTest条件的类 resolver.find(new CustomTest(), pkg2); // 获取上面三次查找的结果 Collection&lt;ActionBean> beans = resolver.getClasses(); ResolverUtil.findImplementations()方法和ResolverUtil.findAnnotated()方法都是依赖RescolverUtil.find()方法实现的，findImplementations()方法会创建IsA对象作为检测条件，findAnnotated()方法会创建AnnotatedWith对象作为检测条件。 public ResolverUtil&lt;T> find(Test test, String packageName) { String path = getPackagePath(packageName); try { List&lt;String> children = VFS.getInstance().list(path); for (String child : children) { if (child.endsWith(\".class\")) { addIfMatching(test, child); } } } catch (IOException ioe) { log.error(\"Could not read package: \" + packageName, ioe); } return this; } protected void addIfMatching(Test test, String fqn) { try { // fqn是类所在完全限定名，即包括其所在包的包名 String externalName = fqn.substring(0, fqn.indexOf('.')).replace('/', '.'); ClassLoader loader = getClassLoader(); if (log.isDebugEnabled()) { log.debug(\"...\"); } Class&lt;?> type = loader.loadClass(externalName); if (test.matches(type)) { matches.add((Class&lt;T>) type); } } catch (Throwable t) { log.warn(\"...\"); } } VFSVFS表示虚 拟 文件系统 (VirtualFileSystem),它 用来 査找 指定路径 下的资 源。VFS是一个 抽象类 ，MyBatis中提供了 JBoss6VFS和 DefaultVFS两 个 VFS的实 现 ，如图所示。用户 也可以提供自定义 的VFS实 现 类 。 VFS采用单例模式实现 参考 《MyBatis技术内幕》 部分图片来源——《MyBatis技术内幕》","tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://www.cayzlh.com/tags/MyBatis/"},{"name":"《MyBatis技术内幕》","slug":"《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/tags/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"},{"name":"基础支持层","slug":"基础支持层","permalink":"https://www.cayzlh.com/tags/%E5%9F%BA%E7%A1%80%E6%94%AF%E6%8C%81%E5%B1%82/"}],"categories":[{"name":"书籍","slug":"书籍","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/"},{"name":"《MyBatis技术内幕》","slug":"书籍/《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"}]},{"title":"基础支持层——日志模块","date":"2019-10-26T01:09:42.000Z","path":"2019/10/26/899df03d.html","text":"MyBatis基础支持层位于 Mybatis 整体架构的最底层，支撑着 Mybatis 的核心处理层，是整个框架的基石。基础支持层中封装了多个较为通用的、独立的模块，不仅仅为 Mybatis 提供基础支撑，也可以在合适的场景中直接复用。 这篇文章介绍MyBatis的日志模块 在 Java 开 发 中常用的日志框 架有 Log4j、Log4j2、Apache Commons Log、java.util.logging、 slf4j等，这 些工具对 外的接口不尽 相同。 为 了统 一这 些工具的接口，MyBatis定义 了一套统 一 的日志接口供上层 使用，并 为 上述常用的日志框 架提供了相应 的适配器。 适配器模式先简单介绍一下设计模式中的六大原则 单一职责原则 不要存在多于一个导致类变更的原因，简单来说，一个类只负责唯一 项职责。 里氏替换原则 如果对 每一个 类 型为 T1的对 象tl，都有类 型为 T2的对 象使得以 T1定义 的所有程序P在所有的对 象tl都代换 成t2时 ，程序P 的行为 没 有发 生变 化， 那么 类 型T2是类 型T1的子类 型。遵守里氏替换 原则 ，可以帮 助我们 设 计 出更为 合 理的继 承体 系。 依赖倒置原则 系统的高层模块不应该依赖低层模块的具体实现，二者都应该依赖其 抽象类 或接口，抽象接口不应 该 依赖 具体 实 现 类 ，而具体 实 现 类 应 该 于依赖 抽象。简 单 来 说 ，我们 要面向接口编 程。当 需求发 生变 化时 对 外接口不变 ，只要提供新的实 现 类 即 可。 接口隔离原则 一个类对另一个类的依赖应该建立在最小的接口上。简单来说，我们 在设 计 接口时 ，不要设 计 出庞 大臃 肿 的接口，因为 实 现 这 种 接口时 需要实 现 很 多不必 要的方法。我们 要尽 量设 计 出功能单 一的接口，这 样 也能保证 实 现 类 的职 责 单 一。 迪米特法则 一个对象应该对其他对象保持最少的了解。简单来说，就是要求我们减 低类 间 耦 合。 开放-封闭原则 程序要对扩展开放，对修改关闭。简单来说，当需求发生变化时，我 们 可以通过 添加新的模块 满 足新需求，而不是通过 修改原来 的实 现 代码 来 满 足新需求。 在这 六条 原则 中，开 放-封闭 原则 是最基础 的原则 ，也是其他原则 以及后文介绍 的所有设 计 模式的最终 目标 。 适配器模式的主要目的是解决 由于接口不能兼容而导 致类 无 法使用的问 题 ，适配器模式会 将 需要适配的类 转 换 成调 用者能够 使用的目标 接口。这 里先介绍 适配器模式中涉及的几 个 角色，如下所述。 目标接口 用者能够 直接使用的接口。 需要适配的类（Adaptee） —般情况下，Adaptee类中有真正的业务逻辑，但是其接口 不能被调 用者直接使用。 适配器（Adapter） Adapter 实 现 了 Target 接口，并 包装 了一个 Adaptee 对 象。Adapter 在实 现 Target接口中的方法时 ，会 将 调 用委托给 Adaptee对 象的相关 方法，由Adaptee 完成具体 的业 务 。 适配器模式类图： 使用适配器模式的好处 就是复 用现 有组 件。 应 用程序需要复 用现 有的类 ，但接口不能被该 应 用程序兼容，则 无法直接使用。 这 种 场 景下就适合使用适配器模式实 现 接口的适配，从 而完 成组 件的复 用。 很 明显 ，适配器模式通过 提供Adapter的方式完成接口适配，实 现 了程序复 用 Adaptee的需求，避免了修改Adaptee实 现 接口，这 符合“开 放-封闭 ”原则 。 当 有新的Adaptee 需要被复 用时 ，只要添加新的Adapter即 可，这 也是符合“开 放-封闭 ”原则 的。 在 MyBatis的日志模块 中，就使用了适配器模式。 MyBatis内 部调 用其日志模块 时 ，使用 了其内 部接口(也就是后面要介绍 的org.apache.ibatis.loggingLog 接口)。但是 Log4j、Log4j2 等第三方日志组 件对 外提供的接口各不相同，MyBatis为 了集成和复 用这 些第三方日志组 件， 在其日志模块 中提供了多种 Adapter, 将 这 些第三方日志组 件对 外的接口适配成了 org.apache.ibatis.logging.Log 接口，这 样 MyBatis 内 部就可以统 一通过 org.apache.ibatis.logging.Log接口调 用第三方日志组 件的功能了。 日志适配器MyBatis 统 一提供了 trace、debug、 warn、error四个 级 别 用于对应上诉的各种第三方日志组件的级别，这 基本与 主流日志框 架的曰志级 别 类 似，可以满 足绝 大多数 场 景的日志 需求。 MyBatis的日志模块 位于org.apache.ibatis.logging包中，该 模块 中通过 Log接口定义 了日志 模块 的功能，当 然日志适配器也会 实 现 此接口。LogFactory工厂 类 负 责 创 建对 应 的日志组 件适 配器。 在LogFactory类 加载 时 会 执 行其静 态 代码 块 ，其逻 辑 是按序加载 并 实 例化对 应 日志组 件的 适配器，然后使用LogFactory. logConstructor这 个 静 态 字段，记 录 当 前使用的第三方日志组 件的 适配器，具体 代码 如下所示。 private static Constructor&lt;? extends Log> logConstructor; static { tryImplementation(new Runnable() { @Override public void run() { useSlf4jLogging(); } }); tryImplementation(new Runnable() { @Override public void run() { useCommonsLogging(); } }); tryImplementation(new Runnable() { @Override public void run() { useLog4J2Logging(); } }); tryImplementation(new Runnable() { @Override public void run() { useLog4JLogging(); } }); tryImplementation(new Runnable() { @Override public void run() { useJdkLogging(); } }); tryImplementation(new Runnable() { @Override public void run() { useNoLogging(); } }); } LogFactory.tryImplementation()方 法 首 先 会 检 测 logConstructor字 段 ， 若 为 空 则 调 用 Runnable.run()方法(注意，不是start()方法)，如上述代码 所示，其中会 调 用use*Logging()方法。 这 里以useJdkLogging()为 例进 行介绍 ，具体 代码 如下: public static synchronized void useJdkLogging() { setImplementation(org.apache.ibatis.logging.jdk14.Jdk14LoggingImpl.class); } private static void setImplementation(Class&lt;? extends Log> implClass) { try { // 获取指定适配器的构造方法 Constructor&lt;? extends Log> candidate = implClass.getConstructor(String.class); Log log = candidate.newInstance(LogFactory.class.getName()); if (log.isDebugEnabled()) { log.debug(\"Logging initialized using '\" + implClass + \"' adapter.\"); } // 初始化logConstructor字段 logConstructor = candidate; } catch (Throwable t) { throw new LogException(\"Error setting Log implementation. Cause: \" + t, t); } } 相应的实现类都在org.apache.ibatis.logging的子包下。且都实 现 了 org.apache.ibatis.logging.Log 接口，并 封装 了 java.util.logging. Logger 对 象 ，org.apache.ibatis.logging.Log 接口 的功能全部通过 调 用 java.util.logging.Logger 对 象 实 现 ，这 与 前面介绍 的适配器模式完全一致。 JDBC调试在MyBatis的日志模块 中有一个 Jdbc包，它 并 不是将 日志信息通过 JDBC保存到数 据库 中， 而是通过 JDK动 态 代理的方式，将 JDBC操作通过 指定的日志框 架打印出来 。这 个 功能通常在 开 发 阶 段使用，它 可以输 出SQL语 句、用户 传 入的绑 定参 数 、SQL语 句影响 行数 等等信息，对 调 试 程序来 说 是非常重要的。 BaseJdbcLogger是一个 抽象类 ，它 是Jdbc包下其他Logger类 的父类 ，继 承关 系如图所示。 参考 《MyBatis技术内幕》 部分图片来源——《MyBatis技术内幕》","tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://www.cayzlh.com/tags/MyBatis/"},{"name":"《MyBatis技术内幕》","slug":"《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/tags/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"},{"name":"基础支持层","slug":"基础支持层","permalink":"https://www.cayzlh.com/tags/%E5%9F%BA%E7%A1%80%E6%94%AF%E6%8C%81%E5%B1%82/"}],"categories":[{"name":"书籍","slug":"书籍","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/"},{"name":"《MyBatis技术内幕》","slug":"书籍/《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"}]},{"title":"基础支持层——反射模块","date":"2019-10-25T01:09:42.000Z","path":"2019/10/25/899df03d.html","text":"MyBatis基础支持层位于 Mybatis 整体架构的最底层，支撑着 Mybatis 的核心处理层，是整个框架的基石。基础支持层中封装了多个较为通用的、独立的模块，不仅仅为 Mybatis 提供基础支撑，也可以在合适的场景中直接复用。 这篇介绍MyBatis的反射模块 反射工具箱Mybatis 在进行参数处理、结果映射等操作时，会涉及大量的反射操作。Java 中的反射虽然功能强大，但是代码编写起来比较复杂且容易出错，为了简化反射操作的相关代码，Mybatis 提供了专门的反射模块，该模块位于 org.apache.ibatis.reflection 包中，它对常见的反射操作做了进一步封装，提供了更加简洁方便的反射 API。 Reflector &amp; ReflectorFactoryReflector是MyBatis中反射模块的基础，每隔Reflector对象都对应一个类，在Reflector中缓存了反射操作需要使用的累的元信息。 Reflector中各个字段的含义如下： Private Class &lt;?> type; //对应的 C1 ass 类型 //可读属性的名称集合，可读属性就是存在相应 getter 方法的属性，初始值为空数组 private String I readablepropertynames= EMPTY STRING ARRAY //可写属性的名称集合，可写属性就是存在相应 setter 方法的属性，初始值为空数组 private String [writeablepropertynames EMPTY STRING ARRAY; //记录了属性相应的 setter 方法，key 是属性名称，value 是 Invoker 对象，它是对 setter 方法对应 // Me thod 对象的封装，后面会详细介绍 private Map &lt;String, Invoker> setmethods =new Hashmap &lt;String, Invoker> (); //属性相应的 getter 方法集合，key 是属性名称，value 也是 Invoker 对象 private Map &lt;String, Invoker> getmethods =new Hashmap &lt;String, Invoker> (); //记录了属性相应的 setter 方法的参数值类型，key 是属性名称，value 是 setter 方法的参数类型 private Map &lt;String, Class &lt;?>> settypes =new Hashmap &lt;string, Class &lt;?>> (); //记录了属性相应的 getter 方法的返回值类型，key 是属性名称，value 是 getter 方法的返回值类型 private Map &lt;string, Class &lt;?>> gettypes=new Hashmap &lt;string, Class &lt;?>> (); private Constructor &lt;?> default Constructor; //记录了默认构造方法 //记录了所有属性名称的集合 private Map &lt;string, String> caseinsensitivepropertymap-new Hashmap &lt;String, String> (); 在Reflector的构造方法中会解析制定的Class对象，并填充上述集合。具体如下： public Reflector(Class&lt;?> clazz) { type = clazz; // 初始化type字段 // 查找clazz的默认构造方法，具体实现是通过反射遍历所有构造方法 addDefaultConstructor(clazz); addGetMethods(clazz); // 处理clazz中的getter方法，填充getMethods集合和getTypes集合 addSetMethods(clazz); // 处理clazz中的setter方法，填充setMethods集合和setTypes集合 addFields(clazz); // 处理没有getter/setter方法的字段 // 根据getMethods/setMethods集合，初始化可读/写属性的名称集合 readablePropertyNames = getMethods.keySet().toArray(new String[0]); writablePropertyNames = setMethods.keySet().toArray(new String[0]); // 初始化caseInsensitivePropertyMap集合，其中记录了所有大写格式的属性名称 for (String propName : readablePropertyNames) { caseInsensitivePropertyMap.put( propName.toUpperCase(Locale.ENGLISH), propName); } for (String propName : writablePropertyNames) { caseInsensitivePropertyMap.put( propName.toUpperCase(Locale.ENGLISH), propName); } } Reflector.Addgetmethodso()方法主要负责解析类中定义的 getter 方法，Reflector. addSetMethods()方法负责解析类中定义的 setter 方法，两者的逻辑类似。 Reflector. Addgetmethods() 方法有如下三个核心步骤。 首先，调用Reflector.getClassMethods()方法获取当前类及其父类中定义的所有方法的唯一签名以及响应的Method对象。 private Method[] getClassMethods(Class&lt;?> clazz) { // 用于记录制定类中定义的全部方法的唯一签名以及对应的Method对象 Map&lt;String, Method> uniqueMethods = new HashMap&lt;>(); Class&lt;?> currentClass = clazz; while (currentClass != null &amp;&amp; currentClass != Object.class) { // 记录currentClass这个类中定义的全部方法 addUniqueMethods(uniqueMethods, currentClass.getDeclaredMethods()); // we also need to look for interface methods - // because the class may be abstract // 记录接口中定义的方法 Class&lt;?>[] interfaces = currentClass.getInterfaces(); for (Class&lt;?> anInterface : interfaces) { addUniqueMethods(uniqueMethods, anInterface.getMethods()); } // 获取父类，继续while循环 currentClass = currentClass.getSuperclass(); } Collection&lt;Method> methods = uniqueMethods.values(); return methods.toArray(new Method[0]);// 转换成Methods数组返回 } 然后，按照JavaBean的规范，从Reflector.getClassMethods()方法返回的Method数组中查找该类中定义的getter方法，将其记录到conflictingGetters集合中。conflictingGetters集合的key为属性名称，value是该属性对应的getter方法的集合。 当子类覆盖了父类的getter方法且返回值发生变化时，在步骤1中就会产生两个签名不同的方法。 TypeParameterResolver在开 始介绍 TypeParameterResolver之前，先简 单 介绍 一下Type接口的基础 知识 。Type是所有类 型的父接口，它 有四个 子接口和一个 实 现 类 ，如图所示。 下面来 看这 些子接口和子类 所代表的类 型。 Class比较 常见 ，它 表示的是原始类 型。 Class类 的对 象表示JVM中的一个 类 或接口， 每个 Java类 在JVM里都表现 为 一个 Class对 象。 在程序中可以通过 “类名.class”、“对象.getClass()”或是“Class.forName(“类 名”)”等方式获 取Class对 象。 数 组 也被映射为 Class对 象，所有元素类 型相同且维 数 相同的数 组 都共享同一个 Class对 象。 ParameterizedType 表示的是参 数 化类 型，例如 List、 Map&lt;Integer，String&gt;、 Service这 种 带 有泛型的类 型。 ParameterizedType接口中常用的方法有三个 ，分别 是: Type getRawType()—–返回参 数 化类 型中的原始类 型，例如List的原始类 型为 List。 Type[] getActualTypeArguments()—–获 取参 数 化类 型的类 型变 量或是实 际 类 型列 表，例如Map&lt;Integer，String&gt;的实 际 泛型列表Integer和 String。需要注意的是， 该 列表的元素类 型都是Type,也就是说 ，可能存在多层 嵌套的情况 。 Type getOwnerType()—–返回是类 型所属 的类 型，例如存在A类 ，其中定义 了 内 部类 InnerA，则 InnerA属 的类 型为 A，如果是顶 层 类 型则 返回null。 这 种 关 系比较 常见 的示例是Map&lt;K，V&gt;接口与 Map.Entry&lt;K，V&gt;接口，Map&lt;K，V&gt; 接 口 是Map&lt;K,V&gt;接口的所有者。 TypeVariable表示的是类 型变 量，它 用来 反映在JVM编 译 该 泛型前的信息。 例如List 中的T就是类 型变 量，它 在编 译 时 需被转 换 为 一个 具体 的类 型后才能正常使用。 该 接口中常用的方法有三个 ，分别 是: Type[] getBounds()—–获 取类 型变 量的上边 界，如果未明确 声 明上边 界则 默认 为 Object。 例如 class Test中 K 的上界就是 Person。 D getGenericDeclaration()—–获 取声 明该 类 型变 量的原始类 型，例 如 class Test 中 的原始类 型是 Test。 String getName()— 获 取在源码 中定义 时 的名字，上例中为 K。 GenericArrayType 表示的是数 组 类 型且组 成元素是 ParameterizedType 或 TypeVariable。 例如 List或T[]。该 接口只有 Type getGenericComponentType()—个 方法，它 返回数 组 的组 成元素。 WildcardType 表示的是通配符泛型，例如? extends Number 和? uper Integer。 WildcardType接口有两 个 方法，分别 是: Type[] getUpperBounds()—-返回泛型变 量的上界。 Type[] getLowerBounds()—- 返回泛型变 量的下界。 回到对 TypeParameterResolve，它 是一个 工具类 ，提供了一系列静 态 方法来 解析指定类 中的字段、方法返回值 或方法参 数 的类 型。TypeParameterResolver中各个 静 态 方法之间 的调 用关 系大致如下图 所示，为 保持清 晰 ，其中递 归 调 用没 有表现 出来 ，在后面 的代码 分析过 程中会 进 行强调 。 TypeParameterResolver 中 通 过 resolveFieldType()方 法 、 resolveRetumType()方 法 、 resolveParamTypes()方法分别 解析字段类 型、方法返回值 类 型和方法参 数 列表中各个 参 数 的类 型。 这 三个 方法的逻 辑 基本类 似，这 里以resolveFieldType()方法为 例进 行介绍 ，TypeParameterResolver.resolveFieldType()方法的具体 实 现 如下: /** * @return The field type as {@link Type}. If it has type parameters in the declaration, * they will be resolved to the actual runtime {@link Type}s. */ public static Type resolveFieldType(Field field, Type srcType) { Type fieldType = field.getGenericType(); Class&lt;?> declaringClass = field.getDeclaringClass(); return resolveType(fieldType, srcType, declaringClass); } 上述三个 方法都会 调 用resolveType()方法，该 方法会 根据其第一个 参 数 的 类 型，即 字段、方法返回值 或方法参 数 的类 型，选 择 合适的方法进 行解析。resolveType()方法的 第二个 参 数 表示查 找 该 字段、返回值 或方法参 数 的起始位置。第三个 参 数 则 表示该 字段、方法 定义 所在的类 。TypeParameterResolver.resolveType()方法代码 如下： private static Type resolveType(Type type, Type srcType, Class&lt;?> declaringClass) { if (type instanceof TypeVariable) { // 解析TypeVariable类型 return resolveTypeVar((TypeVariable&lt;?>) type, srcType, declaringClass); } else if (type instanceof ParameterizedType) { // 解析ParameterizedType类型 return resolveParameterizedType((ParameterizedType) type, srcType, declaringClass); } else if (type instanceof GenericArrayType) { // 解析genericArrayType类型 return resolveGenericArrayType((GenericArrayType) type, srcType, declaringClass); } else { return type; // class类型 } // 字段、返回值 、参 数 不可能直接定义 成WildcardType类 型，但可以嵌套在别 的类 型中 } 为了便于理解，通过一个示例分析resolveType方法， 假设有三个类 ClassA、SubClassA、TestType，代码如下： ClassA public class ClassA &lt;K, V> { protected Map&lt;K, V> map; // ••• map 的 getter/setter 方 法 (略 ) } SubClassA public class SubClassA &lt;T> extends ClassA&lt;T,T> { // ...... } TestType public class TestType { SubClassA&lt;Long> sa = new SubClassA(); public static void main(String[] args) throws NoSuchFieldException { Field f = ClassA.class.getDeclaredField(\"map\"); System.out.println(f.getGenericType()); System.out.println(f.getGenericType() instanceof ParameterizedType); // 输出： // java.util.Map&lt;K, V> // true // 解析SubA&lt;Long>(ParameterizedType类 型)中的map字段，注意:ParameterizedTypelmpl是 // 在 sun.reflect.generics.reflectiveObjects 包下的 ParameterizedType接口实 现 Type type = TypeParameterResolver.resolveFieldType( f, ParameterizedTypelmpl.make(SubClassA.class, new Type[]{Long.class}, TestType.class)); //也可以使用下面的方式生成上述ParameterizedType对 象， // 并 调 用 TypeParameterResolver.resolveFieldType ()方 法 : // // TypeParameterResolver.resolveFieldType(f, // TestType.class.getDeclaredField(\"sa\").getGenericType()); System.out.println(type.getClass()); // 输 出 :class TypeParameterResolver$ParameterizedTypelmpl // 注意，TypeParameterResolver$ParameterizedTypeImpl是ParameterizedType接口的实 现 ParameterizedType p = (ParameterizedType) type; System.out.println(p.getRawType()); // 输 出 :interface java.util.Map System.out.println(p.getOwnerType()); // 输 出:null for (Type t : p .getActualTypeArguments()) { System.out.println(t); } //输 出: // class java.lang.Long // class java.lang.Long } } 根据前面的Type接口的介绍，上例中ClassA.map字段声明的类型Map&lt;K,V&gt;是ParamelerizedType类型，resolveType()方法回调用resolvParameterizedType()方法进行解析。 首先介绍resolveParameterizedType()方法的参数： 第一个参数是待解析的ParameterizedType类型 第二个参数是解析操作的起始类型 第三个参数为定义该字段或方法的类的Class对象 在该示例中第一个参数是Map&lt;K,V&gt;对应的ParameterizedType对象，第二个参数是TypeTest.SubA对应的ParameterizedType对象，第三个参数是ClassA（声明map字段的类）相应的Class对象。 继续分析scanSuperTypes()方法，该方法回递归整个继承结构并完成类型变量的解析。在该示例之中，第一个参数K对应的TypeVariable对象，第二个参数是TypeText.SubA对应的ParameterizedType对象，第三个参数是ClassA（声明map字段的类）对应的Class对象，第四个参数是SubClassA对应的Class对象，第五个参数是Class&lt;T,T&gt;对应的ParameterizedType对象。 scanSuperTypes()方法的具体实现如下： private static Type scanSuperTypes( TypeVariable&lt;?> typeVar, Type srcType, Class&lt;?> declaringClass, Class&lt;?> clazz, Type superclass) { Type result = null; if (superclass instanceof ParameterizedType) { ParameterizedType parentAsType = (ParameterizedType) superclass; Class&lt;?> parentAsClass = (Class&lt;?>) parentAsType.getRawType(); if (declaringClass == parentAsClass) { Type[] typeArgs = parentAsType.getActualTypeArguments(); TypeVariable&lt;?>[] declaredTypeVars = declaringClass.getTypeParameters(); for (int i = 0; i &lt; declaredTypeVars.length; i++) { if (declaredTypeVars[i] == typeVar) { if (typeArgs[i] instanceof TypeVariable) { TypeVariable&lt;?>[] typeParams = clazz.getTypeParameters(); for (int j = 0; j &lt; typeParams.length; j++) { if (typeParams[j] == typeArgs[i]) { if (srcType instanceof ParameterizedType) { result = ((ParameterizedType) srcType).getActualTypeArguments()[j]; } break; } } } else { result = typeArgs[i]; } } } } else if (declaringClass.isAssignableFrom(parentAsClass)) { result = resolveTypeVar(typeVar, parentAsType, declaringClass); } } else if (superclass instanceof Class) { if (declaringClass.isAssignableFrom((Class&lt;?>) superclass)) { result = resolveTypeVar(typeVar, superclass, declaringClass); } } return result; } 下图展示了scanSuperTypes()方法解析类型变量的核心逻辑。 ObjectFactoryMyBatis中很多模块会使用到ObjectFactory接口，该接口提供了多个create()方法的重载，通过这些create()方法可以创建指定类型的对象。ObjectFactory的定义如下： public interface ObjectFactory { /** * Sets configuration properties. * 设置配置信息 * @param properties configuration properties */ void setProperties(Properties properties); /** * Creates a new object with default constructor. * 通过无参构造器创建指定类的对象 * @param type Object type * @return */ &lt;T> T create(Class&lt;T> type); /** * Creates a new object with the specified constructor and params. * 根据参数列表，从指定类型中选择合适的构造器创建对象 * @param type Object type * @param constructorArgTypes Constructor argument types * @param constructorArgs Constructor argument values * @return */ &lt;T> T create(Class&lt;T> type, List&lt;Class&lt;?>> constructorArgTypes, List&lt;Object> constructorArgs); /** * Returns true if this object can have a set of other objects. * It's main purpose is to support non-java.util.Collection objects like Scala collections. * 检测指定类型是否为集合类型，主要处理java.util.Collectiopn及其子类 * * @param type Object type * @return whether it is a collection or not * @since 3.1.0 */ &lt;T> boolean isCollection(Class&lt;T> type); } DefaultObjectFactory是MyBatis提供的ObjectFactory接口的唯一实 现 ，它 是一个 反射工厂 ， 其 create()方法通过 调 用 instantiateClass()方法实 现 。 DefaultObjectFactory.instantiateClass()方法会 根据传 入的参 数 列表选 择 合适的构 造函数 实 例化对 象，具体 实 现 如下: private &lt;T> T instantiateClass(Class&lt;T> type, List&lt;Class&lt;?>> constructorArgTypes, List&lt;Object> constructorArgs) { try { Constructor&lt;T> constructor; if (constructorArgTypes == null || constructorArgs == null) { constructor = type.getDeclaredConstructor(); if (!constructor.isAccessible()) { constructor.setAccessible(true); } return constructor.newInstance(); } constructor = type.getDeclaredConstructor(constructorArgTypes.toArray(new Class[constructorArgTypes.size()])); if (!constructor.isAccessible()) { constructor.setAccessible(true); } return constructor.newInstance(constructorArgs.toArray(new Object[constructorArgs.size()])); } catch (Exception e) { StringBuilder argTypes = new StringBuilder(); if (constructorArgTypes != null &amp;&amp; !constructorArgTypes.isEmpty()) { for (Class&lt;?> argType : constructorArgTypes) { argTypes.append(argType.getSimpleName()); argTypes.append(\",\"); } argTypes.deleteCharAt(argTypes.length() - 1); // remove trailing , } StringBuilder argValues = new StringBuilder(); if (constructorArgs != null &amp;&amp; !constructorArgs.isEmpty()) { for (Object argValue : constructorArgs) { argValues.append(String.valueOf(argValue)); argValues.append(\",\"); } argValues.deleteCharAt(argValues.length() - 1); // remove trailing , } throw new ReflectionException(\"Error instantiating \" + type + \" with invalid types (\" + argTypes + \") or values (\" + argValues + \"). Cause: \" + e, e); } } 除了使用MyBatis提供的DefaultObjectFactory实现，还可以在mybatis-config.xml配置文件中指定自定义的ObjectFactory接口实现累， 从而实现功能上的扩展。 Property工具类org.apache.ibatis.reflection.property 包下，提供了 PropertyCopier、PropertyNamer、PropertyTokenizer 三个属性相关的工具类。 PropertyTokenizer 在使用MyBatis的过程中，经常会碰到一些属性表达式，例如，在查询用户（User）的订单（Order）的结果集如下表所示： user_name order item1 item2 … Mary 124640 iPhone 8 plus MacBook Pro … Lisa 46546 iPhone 11 Pro Mac Pro … … … … … … 对象模型如下： 假设现在需要将结果集中的item1列雨用户第一个订单（Order）的第一条目（Item）的名称映射，item2与用户第一个订单的（Order）的第二条目（Item）的名称映射（这里仅仅是一个示例，在实际生产中很少这样的设计），我们可以得到下面的映射规则： &lt;resultMap id=\"rm4testProTool\" type=\"User\"> &lt;id column=\"id\" property=\"id\" /> &lt;result property=\"orders[0].items[0].name\" column=\"iteml\" /> &lt;result property=\"orders[0].items[1].name\" column=\"item2\" /> &lt;/resultMap> 在上面的例子中，orders[0].items[0].name这种由.和[]组成的表达式是由PropertyTokenizer进行解析的。以下是此类的源码： public class PropertyTokenizer implements Iterator&lt;PropertyTokenizer> { // 当前表达式的名称 private String name; // 当前表达式的索引名 private final String indexedName; // 索引下标 private String index; // 子表达式 private final String children; public PropertyTokenizer(String fullname) { // 查找 . 的位置 int delim = fullname.indexOf('.'); if (delim > -1) { // 初始化 name name = fullname.substring(0, delim); // 初始化children children = fullname.substring(delim + 1); } else { name = fullname; children = null; } // 初始化indexname indexedName = name; delim = name.indexOf('['); if (delim > -1) { // 初始化index index = name.substring(delim + 1, name.length() - 1); name = name.substring(0, delim); } } public String getName() { return name; } public String getIndex() { return index; } public String getIndexedName() { return indexedName; } public String getChildren() { return children; } @Override public boolean hasNext() { return children != null; } // next方法中会创建PropertyTokenizer对象并解析children字段记录的子表达式 @Override public PropertyTokenizer next() { return new PropertyTokenizer(children); } @Override public void remove() { throw new UnsupportedOperationException(\"Remove is not supported, as it has no meaning in the context of properties.\"); } } PropertyTokenizer继承了Iterator接口，它可以迭代处理嵌套多层表达式。 next()方法中会创建PropertyTokenizer对象并解析children字段记录的子表达式。 继续使用订单示例进行说明，描述解析属性表达式orders[0].items[0].name的迭代过程： PropertyNamer PropertyNamer是另一个工具类，提供了下列静态方法帮助完成方法名到属性名的转换，以及多种检测操作。 public final class PropertyNamer { private PropertyNamer() { // Prevent Instantiation of Static Class } // 将方法名转换成属性名 public static String methodToProperty(String name) { if (name.startsWith(\"is\")) { name = name.substring(2); } else if (name.startsWith(\"get\") || name.startsWith(\"set\")) { name = name.substring(3); } else { throw new ReflectionException(\"Error parsing property name '\" + name + \"'. Didn't start with 'is', 'get' or 'set'.\"); } if (name.length() == 1 || (name.length() > 1 &amp;&amp; !Character.isUpperCase(name.charAt(1)))) { name = name.substring(0, 1).toLowerCase(Locale.ENGLISH) + name.substring(1); } return name; } public static boolean isProperty(String name) { return name.startsWith(\"get\") || name.startsWith(\"set\") || name.startsWith(\"is\"); } public static boolean isGetter(String name) { return name.startsWith(\"get\") || name.startsWith(\"is\"); } public static boolean isSetter(String name) { return name.startsWith(\"set\"); } } PropertyCopier PropertyCopier是一个属性拷贝的工具类，核心方法是copyBeanProperties()方法，主要实现相同类型的两个对象之间的属性值拷贝，具体如下： public final class PropertyCopier { private PropertyCopier() { // Prevent Instantiation of Static Class } public static void copyBeanProperties(Class&lt;?> type, Object sourceBean, Object destinationBean) { Class&lt;?> parent = type; while (parent != null) { final Field[] fields = parent.getDeclaredFields(); for(Field field : fields) { try { field.setAccessible(true); field.set(destinationBean, field.get(sourceBean)); } catch (Exception e) { // Nothing useful to do, will only fail on final fields, which will be ignored. } } // 继续拷贝父类中定义的字段 parent = parent.getSuperclass(); } } } MetaClassorg.apache.ibatis.reflection.MetaClass ，类的元数据，基于 Reflector 和 PropertyTokenizer ，提供对指定类的各种骚操作。实现了对复杂的属性表达式的解析，并实现了获取指定属性描述信息的功能。 代码： public class MetaClass { // 用于缓存Reflector对象 private final ReflectorFactory reflectorFactory; // 创建MetaClass时会指定一个类，该Reflector对象会用于记录该类相关的元信息 private final Reflector reflector; // MetaClass的构造方法是使用private修饰的 private MetaClass(Class&lt;?> type, ReflectorFactory reflectorFactory) { this.reflectorFactory = reflectorFactory; // 创建Reflector对象 this.reflector = reflectorFactory.findForClass(type); } // 使用静态方法创建MetaClass对象 public static MetaClass forClass(Class&lt;?> type, ReflectorFactory reflectorFactory) { return new MetaClass(type, reflectorFactory); } public MetaClass metaClassForProperty(String name) { Class&lt;?> propType = reflector.getGetterType(name); return MetaClass.forClass(propType, reflectorFactory); } public String findProperty(String name) { // 委托给buildProperty()方法实现 StringBuilder prop = buildProperty(name, new StringBuilder()); return prop.length() > 0 ? prop.toString() : null; } public String findProperty(String name, boolean useCamelCaseMapping) { if (useCamelCaseMapping) { name = name.replace(\"_\", \"\"); } return findProperty(name); } public String[] getGetterNames() { return reflector.getGetablePropertyNames(); } public String[] getSetterNames() { return reflector.getSetablePropertyNames(); } public Class&lt;?> getSetterType(String name) { PropertyTokenizer prop = new PropertyTokenizer(name); if (prop.hasNext()) { MetaClass metaProp = metaClassForProperty(prop.getName()); return metaProp.getSetterType(prop.getChildren()); } else { return reflector.getSetterType(prop.getName()); } } public Class&lt;?> getGetterType(String name) { PropertyTokenizer prop = new PropertyTokenizer(name); if (prop.hasNext()) { MetaClass metaProp = metaClassForProperty(prop); return metaProp.getGetterType(prop.getChildren()); } // issue #506. Resolve the type inside a Collection Object return getGetterType(prop); } private MetaClass metaClassForProperty(PropertyTokenizer prop) { Class&lt;?> propType = getGetterType(prop); return MetaClass.forClass(propType, reflectorFactory); } private Class&lt;?> getGetterType(PropertyTokenizer prop) { Class&lt;?> type = reflector.getGetterType(prop.getName()); if (prop.getIndex() != null &amp;&amp; Collection.class.isAssignableFrom(type)) { Type returnType = getGenericGetterType(prop.getName()); if (returnType instanceof ParameterizedType) { Type[] actualTypeArguments = ((ParameterizedType) returnType).getActualTypeArguments(); if (actualTypeArguments != null &amp;&amp; actualTypeArguments.length == 1) { returnType = actualTypeArguments[0]; if (returnType instanceof Class) { type = (Class&lt;?>) returnType; } else if (returnType instanceof ParameterizedType) { type = (Class&lt;?>) ((ParameterizedType) returnType).getRawType(); } } } } return type; } private Type getGenericGetterType(String propertyName) { try { Invoker invoker = reflector.getGetInvoker(propertyName); if (invoker instanceof MethodInvoker) { Field _method = MethodInvoker.class.getDeclaredField(\"method\"); _method.setAccessible(true); Method method = (Method) _method.get(invoker); return TypeParameterResolver.resolveReturnType(method, reflector.getType()); } else if (invoker instanceof GetFieldInvoker) { Field _field = GetFieldInvoker.class.getDeclaredField(\"field\"); _field.setAccessible(true); Field field = (Field) _field.get(invoker); return TypeParameterResolver.resolveFieldType(field, reflector.getType()); } } catch (NoSuchFieldException e) { } catch (IllegalAccessException e) { } return null; } public boolean hasSetter(String name) { PropertyTokenizer prop = new PropertyTokenizer(name); if (prop.hasNext()) { if (reflector.hasSetter(prop.getName())) { MetaClass metaProp = metaClassForProperty(prop.getName()); return metaProp.hasSetter(prop.getChildren()); } else { return false; } } else { return reflector.hasSetter(prop.getName()); } } // 判断指定属性是否有 getting 方法 public boolean hasGetter(String name) { PropertyTokenizer prop = new PropertyTokenizer(name); if (prop.hasNext()) { if (reflector.hasGetter(prop.getName())) { MetaClass metaProp = metaClassForProperty(prop); return metaProp.hasGetter(prop.getChildren()); } else { return false; } } else { return reflector.hasGetter(prop.getName()); } } public Invoker getGetInvoker(String name) { return reflector.getGetInvoker(name); } public Invoker getSetInvoker(String name) { return reflector.getSetInvoker(name); } private StringBuilder buildProperty(String name, StringBuilder builder) { // 解析属性表达式 PropertyTokenizer prop = new PropertyTokenizer(name); if (prop.hasNext()) { // 是否还有子表达式 // 查找Propertytokenizer.name对应的属性 String propertyName = reflector.findPropertyName(prop.getName()); if (propertyName != null) { builder.append(propertyName); builder.append(\".\"); // 为该属性创建对应的MetaClass对象 MetaClass metaProp = metaClassForProperty(propertyName); // 递归解析children字段，将解析结果添加到builder中保存 metaProp.buildProperty(prop.getChildren(), builder); } } else { // 递归出口 String propertyName = reflector.findPropertyName(name); if (propertyName != null) { builder.append(propertyName); } } return builder; } public boolean hasDefaultConstructor() { return reflector.hasDefaultConstructor(); } } MetaClass中比较重要的是findProperty()，它是通过调用MetaClass.buildProperty()方法实现的， 二buildProperty()方法会通过PropertyTokenizer解析复杂的属性表达式 ObjectWrapperMetaClass是Mybatis对类级别的元信息的封装和处理，下面来看MyBatis对对象级别的元信息的处理。ObjectWrapper接口是对对象的包装，抽象了对象的属性信息，它定义了一系列查询对象属性信息的方法，以及更新属性的方法。 public interface ObjectWrapper { // 如果ObjectWrapper中封装的是普通的Bean对象，则调用相应属性的相应getter方法， // 如果封装的是集合类，则获取指定key或下标对应的value值 Object get(PropertyTokenizer prop); // 如果ObjectWrapper中封装的是普通的Bean对象，则调用相应的setter方法 // 如果封装的是集合类，则设置指定key或下标对应的value值 void set(PropertyTokenizer prop, Object value); // 查找属性表达式指定的属性，第二个参数表示是否忽略属性表达式中的下划线 String findProperty(String name, boolean useCamelCaseMapping); String[] getGetterNames(); String[] getSetterNames(); Class&lt;?> getSetterType(String name); Class&lt;?> getGetterType(String name); boolean hasSetter(String name); boolean hasGetter(String name); // 为属性表达式的属性创建相应的MetaObject对象 MetaObject instantiatePropertyValue(String name, PropertyTokenizer prop, ObjectFactory objectFactory); boolean isCollection(); void add(Object element); &lt;E> void addAll(List&lt;E> element); } ObjectWrapperFactory负责创建ObjectWrapper对象。 DefaultObjectWrapperFactory实 现 了 ObjectWrapperFactory接口，但它 实 现 的 getWrapperFor() 方法始终 抛出异 常，hasWrapperFor()方法始终 返回false，所以该 实 现 实 际 上是不可用的。但是 与 ObjectFactory 类 似，我们 可以在 mybatis-config.xml 中配置自定义 的 ObjectWrapperFactory 实 现 类 进 行扩 展，在后面介绍 MyBatis初始化时 还 会 提到该 扩 展点。 BaseWrapper是一个实现了ObjectWrapper接口的抽象类，其中封装了MetaObject对象，并提供了三个方勇的方法提供其子类使用： BaseWrapper,resolveCollection()方法会 调 用 MetaObject.get Value()方法，它 会 解析属 性表达 式并 获 取指定的属 性。 BaseWrapper.getCollectionValue()方法和 setCollectionValue()方法会 解析属 性表达 式的索引 信息，然后获 取/设 置对 应 项 。 MetaObjectorg.apache.ibatis.reflection.MetaObject ，对象元数据，提供了对象的属性值的获得和设置等等方法。 可以理解成，对 BaseWrapper 操作的进一步增强。 ObjectWrapper提供了获取/设置对象中指定的属性值、检测getter/setter等常用功能，但是ObjectWrapper只是这些功能的最后一站，我们省略了对属性表达式解析过程的介绍，而该解析过程是在MetaObject中实现的。 MetaObject中字段的含义： // 原始JavaBean对象 private final Object originalObject; // 上文介绍的ObjectWrapper对象，其中封装了originalObject对象 private final ObjectWrapper objectWrapper; // 负责实例化originalObject的工厂对象 private final ObjectFactory objectFactory; // 负责创建ObjectWrapper的工厂对象 private final ObjectWrapperFactory objectWrapperFactory; // 用于创建并缓存Reflector对象的工厂对象 private final ReflectorFactory reflectorFactory; MetaObject的构造方法会根据传入的原始对象的类型以及ObjectFactory工厂的实现， 创建相应的ObjectWrapper对象： private MetaObject( Object object, ObjectFactory objectFactory, ObjectWrapperFactory objectWrapperFactory, ReflectorFactory reflectorFactory) { this.originalObject = object; this.objectFactory = objectFactory; this.objectWrapperFactory = objectWrapperFactory; this.reflectorFactory = reflectorFactory; if (object instanceof ObjectWrapper) { this.objectWrapper = (ObjectWrapper) object; } else if (objectWrapperFactory.hasWrapperFor(object)) { this.objectWrapper = objectWrapperFactory.getWrapperFor(this, object); } else if (object instanceof Map) { this.objectWrapper = new MapWrapper(this, (Map) object); } else if (object instanceof Collection) { this.objectWrapper = new CollectionWrapper(this, (Collection) object); } else { this.objectWrapper = new BeanWrapper(this, object); } } MetaObject和ObjectWrapper中关于类级别的方法，例如hasGetter()、hasSetter()、findProperty()等方法，都是直接调用MetaClass的对应方法实现的。 其他方法都是关于对象级别的方法，这些方法都是与ObjectWrapper配合实现，例如MetaObject.getValue()/setValue()方法。 以下是getValue()的代码： public Object getValue(String name) { PropertyTokenizer prop = new PropertyTokenizer(name); if (prop.hasNext()) { // 根据PropertyTokenizer解析后指定的属性，创建相应的MetaObject对象 MetaObject metaValue = metaObjectForProperty(prop.getIndexedName()); if (metaValue == SystemMetaObject.NULL_META_OBJECT) { return null; } else { return metaValue.getValue(prop.getChildren()); } } else { return objectWrapper.get(prop); } } 类型转换JDBC数据类型与Java语言中的数据类型并不是完全对应的，所以在PreparedStatement为SQL语句绑定参数时，需要从Java类型转换成JDBC类型，而从结果集获取数据的时候，则需要从JDBC类型转换成Java类型。 MyBatis使用类型转换处理器完车过了上述两种转换。 在 MyBatis中使用JdbcType这 个 枚举 类 型代表JDBC中的数 据类 型，该 枚举 类 型中定义 了 TYPE_CODE字段，记 录 了 JDBC类 型在java.sql.Types中相应 的常量 编 码 ，并 通过 一个 静 态 集合codeLookup (HashMap&lt;Integer，JdbcType&gt;类 型)维 护 了常量编 码 与JdbcType之间的对应关系。 TypeHandlerMyBatis中所有的类 型转 换 器都继 承了 TypeHandler接口，在 TypeHandler接口中定义 了如 下四个 方法，这 四个 方法分为 两 类 :setParameter()方法负 责 将 数 据由JdbcType类 型转 换 成Java 类 型:getResult()方法及其重载 负 责 将 数 据由Java类 型转 换 成JdbcType类 型。 public interface TypeHandler&lt;T> { //在通过 PreparedStatement为 SQL语 句绑 定参 数 时 ，会 将 数 据由JdbcType类 型转 换 成Java类 型 void setParameter(PreparedStatement ps, int i, T parameter, JdbcType jdbcType) throws SQLException; //从 ResultSet中获 取数 据时 会 调 用此方法，会 将 数 据由Java类 型转 换 成JdbcType类 型 T getResult(ResultSet rs, String columnName) throws SQLException; T getResult(ResultSet rs, int columnIndex) throws SQLException; T getResult(CallableStatement cs, int columnIndex) throws SQLException; } 为了方便用户自定义TypeHandler实现，MyBatis提供了BaseTypeHandler这个抽象类，它实现了TypeHandler接口，并继承了TypeReference抽象类，其继承结构如下： 在BaseTypeHandler中实现了TypeHandler.setParameter()方法和TypeHandler.getResult()方法，具体实现如下。需要注意的是，这两个方法对于非空数据的处理都交给了子类实现。 public abstract class BaseTypeHandler&lt;T> extends TypeReference&lt;T> implements TypeHandler&lt;T> { protected Configuration configuration; public void setConfiguration(Configuration c) { this.configuration = c; } @Override public void setParameter(PreparedStatement ps, int i, T parameter, JdbcType jdbcType) throws SQLException { if (parameter == null) { if (jdbcType == null) { throw new TypeException(\"JDBC requires that the JdbcType must be specified for all nullable parameters.\"); } try { ps.setNull(i, jdbcType.TYPE_CODE); } catch (SQLException e) { throw new TypeException(\"Error setting null for parameter #\" + i + \" with JdbcType \" + jdbcType + \" . \" + \"Try setting a different JdbcType for this parameter or a different jdbcTypeForNull configuration property. \" + \"Cause: \" + e, e); } } else { try { setNonNullParameter(ps, i, parameter, jdbcType); } catch (Exception e) { throw new TypeException(\"Error setting non null for parameter #\" + i + \" with JdbcType \" + jdbcType + \" . \" + \"Try setting a different JdbcType for this parameter or a different configuration property. \" + \"Cause: \" + e, e); } } } @Override public T getResult(ResultSet rs, String columnName) throws SQLException { T result; try { result = getNullableResult(rs, columnName); } catch (Exception e) { throw new ResultMapException(\"Error attempting to get column '\" + columnName + \"' from result set. Cause: \" + e, e); } if (rs.wasNull()) { return null; } else { return result; } } @Override public T getResult(ResultSet rs, int columnIndex) throws SQLException { T result; try { result = getNullableResult(rs, columnIndex); } catch (Exception e) { throw new ResultMapException(\"Error attempting to get column #\" + columnIndex+ \" from result set. Cause: \" + e, e); } if (rs.wasNull()) { return null; } else { return result; } } @Override public T getResult(CallableStatement cs, int columnIndex) throws SQLException { T result; try { result = getNullableResult(cs, columnIndex); } catch (Exception e) { throw new ResultMapException(\"Error attempting to get column #\" + columnIndex+ \" from callable statement. Cause: \" + e, e); } if (cs.wasNull()) { return null; } else { return result; } } public abstract void setNonNullParameter(PreparedStatement ps, int i, T parameter, JdbcType jdbcType) throws SQLException; public abstract T getNullableResult(ResultSet rs, String columnName) throws SQLException; public abstract T getNullableResult(ResultSet rs, int columnIndex) throws SQLException; public abstract T getNullableResult(CallableStatement cs, int columnIndex) throws SQLException; } 一般情况下， TypeHandler用于完成单个参数以及单个列值的类型转换， 如果存在多列值转换成一个Java对象的需求，应该优先考虑在使用映射文件中定义合适的映射规则（）完成映射。 TypeHandlerRegistry介绍完TypeHandler接口及其功能之后，MyBatis如何管理众多的TypeHanlder接口实现，如何知道何时使用哪个TypeHandler接口实现完成转换呢？ 这个工作是由TypeHandlerRegistry完成的，在MyBatis初始化过程中，会为所有已知的TypeHanlder创建对象，并实现注册到TypeHandlerRegistry中， 由TypeHandlerRegistry负责管理这些TypeHandler对象。 TypeHandlerRegistry中核心字段的含义： // 记录JdbcType与TypeHandler之间的对应关系，其中JdbcType是一个枚举类型，它定义对应的JDBC类型 // 该集合主要用于从结果集读取数据时，将数据从Jdbc类型转换成Java类型 private final Map&lt;JdbcType, TypeHandler&lt;?>> JDBC_TYPE_HANDLER_MAP = new EnumMap&lt;JdbcType, TypeHandler&lt;?>>(JdbcType.class); // 记录了Java类型向指定JdbcType转换时，需要使用的TypeHandler对象。 // 例如Java类型中的String可能转换成数据库的char、varchar等多种类型，所以存在一对多关系 private final Map&lt;Type, Map&lt;JdbcType, TypeHandler&lt;?>>> TYPE_HANDLER_MAP = new ConcurrentHashMap&lt;Type, Map&lt;JdbcType, TypeHandler&lt;?>>>(); // 记录了全部TypeHandler的类型以及该类型相应的TypeHandler对象 private final TypeHandler&lt;Object> UNKNOWN_TYPE_HANDLER = new UnknownTypeHandler(this); // 空TypeHandler集合的标识 private final Map&lt;Class&lt;?>, TypeHandler&lt;?>> ALL_TYPE_HANDLERS_MAP = new HashMap&lt;Class&lt;?>, TypeHandler&lt;?>>(); 1. 注册TypeHandler对象 TypeHandlerRegistry.register()方法实 现 了注册 TypeHandler对 象的功能，该 注册 过 程会 向上 述四个 集合中添加TypeHandler对 象。register()方法有多个 重载 ，这 些重载 之间 的调 用关 系如图 。 从 上图中可以看出，多数 register()方法最终 会 调 用重载(4) 完成注册 功能，先来看该方法的实现，其三个 参 数 分别 指定了 TypeHandler能够 处 理的Java类 型、Jdbc类 型以及 TypeHandler对 象。 重载(4) private void register(Type javaType, JdbcType jdbcType, TypeHandler&lt;?> handler) { if (javaType != null) {// 检测是否明确指定了TypeHanlder能够处理的Java类型 // 获取指定java类型在TYPE_HANDLER_MAP集合中对应TypeHanlder集合 Map&lt;JdbcType, TypeHandler&lt;?>> map = TYPE_HANDLER_MAP.get(javaType); if (map == null || map == NULL_TYPE_HANDLER_MAP) { // 创建新的TypeHandler集合，并添加到TYPE_HANDLER_MAP中 map = new HashMap&lt;JdbcType, TypeHandler&lt;?>>(); TYPE_HANDLER_MAP.put(javaType, map); } // 将TypeHandler对象注册到并添加到TYPE_HANDLER_MAP中 map.put(jdbcType, handler); } // 向ALL_TYPE_HANDLERS_MAP集合注册TypeHandler类型和对应的TypeHanlder对象 ALL_TYPE_HANDLERS_MAP.put(handler.getClass(), handler); } 在(1)〜(3)这 三个 register()方法重载 中会 尝 试 读 取TypeHandler类 中定义 的@MappedTypes 注解和@MappedJdbcTypes注解，@MappedTypes注解用于指明该 TypeHandler实 现 类 能够 处 理 的Java类 型的集合，@MappedJdbcTypes注解用于指明该 TypeHandler实 现 类 能够 处 理的JDBC 类 型集合。register()方法的重载(1)〜(3)的具体 实 现 如下: 重载(1) // Only handler type public void register(Class&lt;?> typeHandlerClass) { boolean mappedTypeFound = false; MappedTypes mappedTypes = typeHandlerClass.getAnnotation(MappedTypes.class); if (mappedTypes != null) { for (Class&lt;?> javaTypeClass : mappedTypes.value()) { register(javaTypeClass, typeHandlerClass); mappedTypeFound = true; } } if (!mappedTypeFound) { register(getInstance(null, typeHandlerClass)); } } 重载(2) public &lt;T> void register(TypeHandler&lt;T> typeHandler) { boolean mappedTypeFound = false; MappedTypes mappedTypes = typeHandler.getClass().getAnnotation(MappedTypes.class); if (mappedTypes != null) { for (Class&lt;?> handledType : mappedTypes.value()) { register(handledType, typeHandler); mappedTypeFound = true; } } // @since 3.1.0 - try to auto-discover the mapped type if (!mappedTypeFound &amp;&amp; typeHandler instanceof TypeReference) { try { TypeReference&lt;T> typeReference = (TypeReference&lt;T>) typeHandler; register(typeReference.getRawType(), typeHandler); mappedTypeFound = true; } catch (Throwable t) { // maybe users define the TypeReference with a different type and are not assignable, so just ignore it } } if (!mappedTypeFound) { register((Class&lt;T>) null, typeHandler); } } 重载(3) private &lt;T> void register(Type javaType, TypeHandler&lt;? extends T> typeHandler) { MappedJdbcTypes mappedJdbcTypes = typeHandler.getClass().getAnnotation(MappedJdbcTypes.class); if (mappedJdbcTypes != null) { for (JdbcType handledJdbcType : mappedJdbcTypes.value()) { register(javaType, handledJdbcType, typeHandler); } if (mappedJdbcTypes.includeNullJdbcType()) { register(javaType, null, typeHandler); } } else { register(javaType, null, typeHandler); } } 上 述 全 部 的 register()方 法 重 载 都 是 在 向 TYPE_HANDLER_MAP集 合 和 ALL_TYPE_HANDLERS_MAP 集合注册 TypeHandler 对 象，而重载(5)是向 JDBC_TYPE_HANDLER_MAP 集合注册 TypeHandler对 象，其具体 实 现 如下: 重载(5) public void register(JdbcType jdbcType, TypeHandler&lt;?> handler) { JDBC_TYPE_HANDLER_MAP.put(jdbcType, handler); } TypeHandlerRegistry除了提供注册 单 个 TypeHandler的register()重载 ，还 可以扫 描整个 包下 的TypeHandler接口实 现 类 ，并 将 完成这 些TypeHandler实 现 类 的注册 。 重载(6) public void register(String packageName) { ResolverUtil&lt;Class&lt;?>> resolverUtil = new ResolverUtil&lt;Class&lt;?>>(); // 查找指定包下的接口实现类 resolverUtil.find(new ResolverUtil.IsA(TypeHandler.class), packageName); Set&lt;Class&lt;? extends Class&lt;?>>> handlerSet = resolverUtil.getClasses(); for (Class&lt;?> type : handlerSet) { //Ignore inner classes and interfaces (including package-info.java) and abstract classes if (!type.isAnonymousClass() &amp;&amp; !type.isInterface() &amp;&amp; !Modifier.isAbstract(type.getModifiers())) { register(type); } } } 2. 查找TypeHandler TypeHandlerRegistry提供了查 找 TypeHandler对 象的功能。TypeHandlerRegistry.getTypeHandler()方法实 现 了从 上述四个 集合中获 取对 应 TypeHandler对 象的功能。TypeHandlerRegistry.getTypeHandler()方法有多个 重载 ，这 些重 载 之间 的关 系如下图所示。 经 过 一系列类 型转 换 之后，TypeHandlerRegistry.getTypeHandler()方法的多个 重载 都会 调 用 TypeHandlerRegistry.getTypeHandle(Type, JdbcType)这 个 重载 方法，它 会 根据指定的 Java 类 型和 JdbcType类 型查 找 相应 的TypeHandler对 象。 TypeAliasRegistry在编 写 SQL语 句时 ，使用别 名可以方便理解以及维 护 ，例如表名或列名很 长 时 ，我们 一般 会 为 其设 计 易懂 易维 护 的别 名。MyBatis将 SQL语 句中别 名的概 念进 行了延伸和扩 展，MyBatis 可以为 一个 类 添加一个 别 名，之后就可以通过 别 名引用该 类 。 MyBatis通过 TypeAliasRegistry类 完成别 名注册 和管理的功能，TypeAliasRegistry的结 构 比 较 简 单 ，它 通过 TYPE_ALIASES字段(Map&lt;String，Class&lt;?&gt;&gt;类 型)管理别 名与 Java类 型之间 的对 应 关 系，通过 TypeAHasRegistiy.registerAlias()方法完成注册 别 名，该 方法的具体 实 现 如下: public void registerAlias(String alias, Class&lt;?> value) { if (alias == null) { throw new TypeException(\"The parameter alias cannot be null\"); } // 将别名转换成小写 String key = alias.toLowerCase(Locale.ENGLISH); // 检测别名是否存在 if (TYPE_ALIASES.containsKey(key) &amp;&amp; TYPE_ALIASES.get(key) != null &amp;&amp; !TYPE_ALIASES.get(key).equals(value)) { throw new TypeException(\"...\"); } TYPE_ALIASES.put(key, value); } 在 TypeAliasRegistry的构 造方法中，默认 为 Java的基本类 型及其数 组 类 型、基本类 型的封 装 类 及其数组类型、Date、BigDecimal、Biglnteger、Map、HashMap、List、ArrayList、Collection、 Iterator、ResultSet等类 型添加了别名。 参考 《MyBatis技术内幕》 部分图片来源——《MyBatis技术内幕》","tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://www.cayzlh.com/tags/MyBatis/"},{"name":"《MyBatis技术内幕》","slug":"《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/tags/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"},{"name":"基础支持层","slug":"基础支持层","permalink":"https://www.cayzlh.com/tags/%E5%9F%BA%E7%A1%80%E6%94%AF%E6%8C%81%E5%B1%82/"}],"categories":[{"name":"书籍","slug":"书籍","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/"},{"name":"《MyBatis技术内幕》","slug":"书籍/《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"}]},{"title":"基础支持层——解析器模块","date":"2019-10-24T01:09:42.000Z","path":"2019/10/24/94150c5.html","text":"MyBatis基础支持层位于 Mybatis 整体架构的最底层，支撑着 Mybatis 的核心处理层，是整个框架的基石。基础支持层中封装了多个较为通用的、独立的模块，不仅仅为 Mybatis 提供基础支撑，也可以在合适的场景中直接复用。 这篇文章介绍MyBatis的解析器模块 Mybatis中涉及大量的XML配置文件，常见的XML解析方式：DOM、SAX和StAX。 XPath简介MyBatis在初始化过 程中处 理mybatis-config.xml配置文件以及映射文件时 ，使用的是DOM 解析方式，并 结 合使用XPath解析XML配置文件。 正如前文所述，DOM会将整个 XML文档 加载 到内 存中并 形成树状数据结构 ，而 XPath是一种 为 查 询 XML文档 而设 计 的语 言，它 可以 与 DOM解析方式配合使用，实 现 对 XML文档 的解析。 Xpath 之于 XML 就好比 SQL 语言之于数据库。 XPathParserMybatis 提供的 Xpathparser 类封装了Xpath、Document 和Entityresolver。 Xpathparser 中各个字段的含义和功能如下所示。 private Document document; // Document 对象 private boolean validation; //是否开启验证 private Entityresolver entityresolver; //用于加载本地 DTD 文件 private Properties variables; // mybatis- config. Xm1 中《propteries》标签定义的键值对集合 private Xpath xpath; // Xpath 对象 默认情况下，对 XML 文档进行验证时，会根据 XML 文档开始位置指定的网址加载对应的 DTD 文件或 XSD 文件。 如果解析 mybatis- config. Xml 配置文件，默认联网加载 http: / mybatis. Org, / dtd/mybatis-3- config. Dtd 这个 DTD 文档，当网络比较慢时会导致验证过程缓慢。 在实践中往往会提前设置 Entityresolver 接口对象加载本地的 DTD 文件，从而避免联网加载 DTD 文件。 Xmlmapperentity Resolver 是 Mybatis 提供的 Entity Resolver 接口的实现类。 EntityResolver 接口的核心是 resolveEntity()方法，XMLMapperEntityResolver 的实 现 如下 public class XMLMapperEntityResolver implements EntityResolver { private static final String IBATIS_CONFIG_SYSTEM = \"ibatis-3-config.dtd\"; private static final String IBATIS_MAPPER_SYSTEM = \"ibatis-3-mapper.dtd\"; private static final String MYBATIS_CONFIG_SYSTEM = \"mybatis-3-config.dtd\"; private static final String MYBATIS_MAPPER_SYSTEM = \"mybatis-3-mapper.dtd\"; private static final String MYBATIS_CONFIG_DTD = \"org/apache/ibatis/builder/xml/mybatis-3-config.dtd\"; private static final String MYBATIS_MAPPER_DTD = \"org/apache/ibatis/builder/xml/mybatis-3-mapper.dtd\"; @Override public InputSource resolveEntity(String publicId, String systemId) throws SAXException { try { if (systemId != null) { String lowerCaseSystemId = systemId.toLowerCase(Locale.ENGLISH); if (lowerCaseSystemId.contains(MYBATIS_CONFIG_SYSTEM) || lowerCaseSystemId.contains(IBATIS_CONFIG_SYSTEM)) { return getInputSource(MYBATIS_CONFIG_DTD, publicId, systemId); } else if (lowerCaseSystemId.contains(MYBATIS_MAPPER_SYSTEM) || lowerCaseSystemId.contains(IBATIS_MAPPER_SYSTEM)) { return getInputSource(MYBATIS_MAPPER_DTD, publicId, systemId); } } return null; } catch (Exception e) { throw new SAXException(e.toString()); } } private InputSource getInputSource(String path, String publicId, String systemId) { InputSource source = null; if (path != null) { try { InputStream in = Resources.getResourceAsStream(path); source = new InputSource(in); source.setPublicId(publicId); source.setSystemId(systemId); } catch (IOException e) { // ignore, null is ok } } return source; } } 回到对 XPathParser 的 分 析 ，在 XPathParser. createDocument()方法中封装 了前面介绍 的创 建Document对 象的过 程并 触 发 了加载 XML文档 的 过 程，具体 实 现 如下: private void commonConstructor(boolean validation, Properties variables, EntityResolver entityResolver) { this.validation = validation; this.entityResolver = entityResolver; this.variables = variables; XPathFactory factory = XPathFactory.newInstance(); this.xpath = factory.newXPath(); } private Document createDocument(InputSource inputSource) { // important: this must only be called AFTER common constructor try { DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance(); factory.setValidating(validation); factory.setNamespaceAware(false); factory.setIgnoringComments(true); factory.setIgnoringElementContentWhitespace(false); factory.setCoalescing(false); factory.setExpandEntityReferences(true); DocumentBuilder builder = factory.newDocumentBuilder(); builder.setEntityResolver(entityResolver); builder.setErrorHandler(new ErrorHandler() { @Override public void error(SAXParseException exception) throws SAXException { throw exception; } @Override public void fatalError(SAXParseException exception) throws SAXException { throw exception; } @Override public void warning(SAXParseException exception) throws SAXException { } }); return builder.parse(inputSource); } catch (Exception e) { throw new BuilderException(\"Error creating document instance. Cause: \" + e, e); } } Xpathparser 中提供了一系列的 eval*0 方法用于解析 boolean、shot、long、int、String、Node 等类型的信息，它通过调用前面介绍的 Xpath. Evaluate() 方法查找指定路径的节点或属性，并进行相应的类型装换。具体代码比较简单，就不贴出来了。这里需要注意的是 Xpathparser. Evalstring() 方法，其中会调用 Propertyparser. Parse() 方法处理节点中相应的默认值。 在 Propertyparser 中指定了是否开启使用默认值的功能以及默认的分隔符 PropertyParser.parse() 方法中会创建 Generic Tokenparser 解析器，并将默认值的处理委托给Generic Tokenparser.parse()方法。 Generic Tokenparser 是一个通用的字占位符解析器，其字段的含义如下： Private final String opentoken; //占位符的开始标记 private final String closetoken; //占位符的结東标记 private final Tokenhandler handler; // Tokenhandler 接口的实现会按照一定的逻辑解析占位符 GenericTokenparser.parse() 方法的逻辑并不复杂，它会顺序查找 openToken 和 closeToken，解析得到占位符的字面值，并将其交给 Tokenhandler 处理，然后将解析结果重新拼装成字符串并返回。 参考 《MyBatis技术内幕》 部分图片来源——《MyBatis技术内幕》","tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://www.cayzlh.com/tags/MyBatis/"},{"name":"《MyBatis技术内幕》","slug":"《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/tags/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"},{"name":"基础支持层","slug":"基础支持层","permalink":"https://www.cayzlh.com/tags/%E5%9F%BA%E7%A1%80%E6%94%AF%E6%8C%81%E5%B1%82/"}],"categories":[{"name":"书籍","slug":"书籍","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/"},{"name":"《MyBatis技术内幕》","slug":"书籍/《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"}]},{"title":"MyBatis快速入门","date":"2019-10-21T03:31:35.000Z","path":"2019/10/21/3f93d624.html","text":"心血来潮，搞了本《MyBatis技术内幕》，整理一些核心内容 思维导图： 整体架构： 基础支持层基础支持层包含整个 Mybatis 的基础模块，这些模块为核心处理层的功能提供了良好的支撑。 反射模块Java 中的反射虽然功能强大，但对大多数开发人员来说，写出高质量的反射代码还是 有一定难度的。Mybatis 中专门提供了反射模块，该模块对 Java 原生的反射进行了良好的封装，提供了更加简洁易用的 AP，方便上层使调用，并且对反射操作进行了系列优化，例如缓存了类的元数据，提高了反射操作的性能。 类型转换模块正如前面示例所示，Mybatis 为简化配置文件提供了别名机制，该机制是类型转换模块的主要功能之一。 类型转换模块的另一个功能是实现 JDBC 类型与 Java 类型之间的转换，该功能在为 SQL 语句绑定实参以及映射查询结果集时都会涉及。在为 SQL 语句绑定实参时，会将数据由 Java 类型转换成 JDBC 类型；而在映射结果集时，会将数据由 JDBC 类型转换成 Java 类型。 ###日志模块 无论在开发测试环境中，还是在线上生产环境中，日志在整个系统中的地位都是非常重要的。良好的日志功能可以帮助开发人员和测试人员快速定位 Bug 代码，也可以帮助运维人员快速定位性能瓶颈等问题。目前的 Java 世界中存在很多优秀的日志框架，例如 Log4j、Log4j2、slf4 等。Mybatis 作为一个设计优良的框架，除了提供详细的日志输出信息，还要能够集成多种日志框架，其日志模块的一个主要功能就是集成第三方日志框架。资源加载模块 资源加载模块主要是对类加载器进行封装，确定类加载器的使用顺序，并提供了加载类文件以及其他资源文件的功能。 解析器模块解析器模块的主要提供了两个功能：一个功能是对 Xpath 进行封装，为 Mybatis 初始化时解析 mybatis-config, xml 配置文件以及映射配置文件提供支持；另一个功能是为处理动态 SQL 语句中的占位符提供支持。数据源模块 数据源是实际开发中常用的组件之一。现在开源的数据源都提供了比较丰富的功能，例如，连接池功能、检测连接状态等，选择性能优秀的数据源组件对于提升 ORM 框架乃至整个应用的性能都是非常重要的。Mybatis 自身提供了相应的数据源实现，当然 Mybatis 也提供了与第三方数据源集成的接口，这些功能都位于数据源模块之中。 事务管理Mybatis 对数据库中的事务进行了抽象，其自身提供了相应的事务接口和简单实现。在很多场景中，My Batis 会与 Spring 框架集成，并由 Spring 框架管理事务，在第 4 章会介绍 Mybatis 如何与 Spring 集成开发，其中就会涉及 Spring 框架管理事务相关的配置。 缓存模块在优化系统性能时，优化数据库性能是非常重要的一个环节，而添加缓存则是优化数据库时最有效的手段之一。正确、合理地使用缓存可以将一部分数据库请求拦截在缓存这一层，这就能够减少相当一部分数据库的压力。 Mybatis 中提供了一级缓存和二级缓存，而这两级缓存都是依赖于基础支持层中的缓存模块实现的。这里需要读者注意的是，Mybatis 中自带的这两级缓存与 Mybatis 以及整个应用是运行在同一个 JM 中的，共享同一块堆内存。如果这两级缓存中的数据量较大，则可能影响系统中其他功能的运行，所以当需要缓存大量数据时，优先考虑使用 Redis、Memcache 等缓存产品。 Binding 模块通过前面的示例我们知道，在调用 Sqlsession 相应方法执行数据库操作时，需要指定映射文件中定义的 SQL 节点，如果出现拼写错误，我们只能在运行时才能发现相应的异常。为了尽早发现这种错误，Mybatis 通过 Binding 模块将用户自定义的 Mapper 1 接口与映射配置文件关联起来，系统可以通过调用自定义 Mapper 接口中的方法执行相应的 SQL 语句完成数据库操作，从而避免上述问题。 值得读者注意的是，开发人员无须编写自定义 Mapper 接口的实现，My Batis 会自动为其创建动态代理对象。在有些场景中，自定义 Mapper 接口可以完全代替映射配置文件，但有的映射规则和 SQL 语句的定义还是写在映射配置文件中比较方便，例如动态 SQL 语句的定义。 核心处理层配置解析在 Mybatis 初始化过程中，会加载 mybatis-config. Xml 配置文件、映射配置文件以及 Mapper 接口中的注解信息，解析后的配置信息会形成相应的对象并保存到 Configuration 对象中。例如，示例中定义的~ &lt;resultmap》节点（即 Resultset I 的映射规则）会被解析成 Resultmap 对象；示例中定义的《result 节点（即属性映射）会被解析成 Resultmapping 对象。之后，利用该 Configuration 对象创建 Sqlsessionfactory 对象。待 Mybatis 初始化之后，开发人员可以通过初始化得到 Sqlsessionfactory 创建 Sqlsession 对象并完成数据库操作。 SQL 解析与 scripting 模块拼凑 SQL 语句是一件烦琐且易出错的过程，为了将开发人员从这项枯燥无趣的工作中解脱出来，Mybatis 实现动态 SQL 语句的功能，提供了多种动态 SQL 语句对应的节点，例如，where节点、if节点、foreach节点等。通过这些节点的组合使用，开发人员可以写出几乎满足所有需求的动态 SQL 语句。 Mybatis 中的 scripting 模块会根据用户传入的实参，解析映射文件中定义的动态 SQL 节点，并形成数据库可执行的 SQL 语句。之后会处理 SQL 语句中的占位符，绑定用户传入的实参。 SQL 执行SQL 语句的执行涉及多个组件，其中比较重要的是 Executor、Statementhandler、Parameterhandler 和 Resultsethandler。Executor 主要负责维护一级缓存和二级缓存并提供事务管理的相关操作，它会将数据库相关操作委托给 Statementhandler 完成 Statementhandler 首先通过 Parameter Handler 完成 SQL 语句的实参绑定，然后通过 iava, sql Statement 对象执行 SQL 语句并得到结果集，最后通过 Resultset Handler 完成结果集的映射，得到结果对象并返回。 插件Mybatis 自身的功能虽然强大，但是并不能完美切合所有的应用场景，因此 Mybatis 提供了插件接口，我们可以通过添加用户自定义插件的方式对 Mybatis 进行扩展。用户自定义插件也可以改变 Mybatis 的默认行为，例如，我们可以拦截 SQL 语句并对其进行重写。由于用户自定义插件会影响 Mybatis 的核心行为，在使用自定义插件之前，开发人员需要了解 Mybatis 内部的原理，这样才能编写出安全、高效的插件 接口层接口层相对简单，其核心是 Sqlsession 接口，该接口中定义了 Mybatis 暴露给应用程序调用的 API，也就是上层应用与 MyBatis 交互的桥梁。接口层在接收到调用请求时，会调用核心处理层的相应模块来完成具体的数据库操作。","tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"https://www.cayzlh.com/tags/MyBatis/"},{"name":"《MyBatis技术内幕》","slug":"《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/tags/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"}],"categories":[{"name":"书籍","slug":"书籍","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/"},{"name":"《MyBatis技术内幕》","slug":"书籍/《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"}]},{"title":"关于Redis中的过期时间","date":"2019-10-11T11:28:16.000Z","path":"2019/10/11/dc5c5b71.html","text":"当使用Redis的时候，可以对Redis中的每个key设置一个过期时间，当到达过期时间的时候，这个key就会被自动删除。关于过期时间，还有一些可以关注的点。 DEL/SET/GETSET等命令会清除过期时间在使用DEL、SET、GETSET等会覆盖key对应value的命令操作一个设置了过期时间的key的时候，会导致对应的key的过期时间被清除。 //设置mykey的过期时间为300s 127.0.0.1:6379> set mykey hello ex 300 OK //查看过期时间 127.0.0.1:6379> ttl mykey (integer) 294 //使用set命令覆盖mykey的内容 127.0.0.1:6379> set mykey olleh OK //过期时间被清除 127.0.0.1:6379> ttl mykey (integer) -1 INCR/LPUSH/HSET等命令不会清除过期时间而在使用INCR/LPUSH/HSET这种只是修改一个key的value，而不是覆盖整个value的命令，则不会清除key的过期时间。INCR： //设置incr_key的过期时间为300s 127.0.0.1:6379> set incr_key 1 ex 300 OK 127.0.0.1:6379> ttl incr_key (integer) 291 //进行自增操作 127.0.0.1:6379> incr incr_key (integer) 2 127.0.0.1:6379> get incr_key \"2\" //查询过期时间，发现过期时间没有被清除 127.0.0.1:6379> ttl incr_key (integer) 277 LPUSH： //新增一个list类型的key，并添加一个为1的值 127.0.0.1:6379> LPUSH list 1 (integer) 1 //为list设置300s的过期时间 127.0.0.1:6379> expire list 300 (integer) 1 //查看过期时间 127.0.0.1:6379> ttl list (integer) 292 //往list里面添加值2 127.0.0.1:6379> lpush list 2 (integer) 2 //查看list的所有值 127.0.0.1:6379> lrange list 0 1 1) \"2\" 2) \"1\" //能看到往list里面添加值并没有使过期时间清除 127.0.0.1:6379> ttl list (integer) 252 PERSIST命令会清除过期时间当使用PERSIST命令将一个设置了过期时间的key转变成一个持久化的key的时候，也会清除过期时间。 127.0.0.1:6379> set persist_key haha ex 300 OK 127.0.0.1:6379> ttl persist_key (integer) 296 //将key变为持久化的 127.0.0.1:6379> persist persist_key (integer) 1 //过期时间被清除 127.0.0.1:6379> ttl persist_key (integer) -1 使用RENAME命令，老key的过期时间将会转到新key上在使用例如：RENAME KEY_A KEY_B命令将KEY_A重命名为KEY_B，不管KEY_B有没有设置过期时间，新的key KEY_B将会继承KEY_A的所有特性。 //设置key_a的过期时间为300s 127.0.0.1:6379> set key_a value_a ex 300 OK //设置key_b的过期时间为600s 127.0.0.1:6379> set key_b value_b ex 600 OK 127.0.0.1:6379> ttl key_a (integer) 279 127.0.0.1:6379> ttl key_b (integer) 591 //将key_a重命名为key_b 127.0.0.1:6379> rename key_a key_b OK //新的key_b继承了key_a的过期时间 127.0.0.1:6379> ttl key_b (integer) 248 使用EXPIRE/PEXPIRE设置的过期时间为负数或者使用EXPIREAT/PEXPIREAT设置过期时间戳为过去的时间会导致key被删除EXPIRE： 127.0.0.1:6379> set key_1 value_1 OK 127.0.0.1:6379> get key_1 \"value_1\" //设置过期时间为-1 127.0.0.1:6379> expire key_1 -1 (integer) 1 //发现key被删除 127.0.0.1:6379> get key_1 (nil) EXPIREAT： 127.0.0.1:6379> set key_2 value_2 OK 127.0.0.1:6379> get key_2 \"value_2\" //设置的时间戳为过去的时间 127.0.0.1:6379> expireat key_2 10000 (integer) 1 //key被删除 127.0.0.1:6379> get key_2 (nil) EXPIRE命令可以更新过期时间对一个已经设置了过期时间的key使用expire命令，可以更新其过期时间。 //设置key_1的过期时间为100s 127.0.0.1:6379> set key_1 value_1 ex 100 OK 127.0.0.1:6379> ttl key_1 (integer) 95 //更新key_1的过期时间为300s 127.0.0.1:6379> expire key_1 300 (integer) 1 127.0.0.1:6379> ttl key_1 (integer) 295 Redis的过期策略那你有没有想过一个问题，Redis里面如果有大量的key，怎样才能高效的找出过期的key并将其删除呢，难道是遍历每一个key吗？假如同一时期过期的key非常多，Redis会不会因为一直处理过期事件，而导致读写指令的卡顿。 这里说明一下，Redis是单线程的，所以一些耗时的操作会导致Redis卡顿，比如当Redis数据量特别大的时候，使用keys * 命令列出所有的key。 实际上Redis使用懒惰删除+定期删除相结合的方式处理过期的key。 懒惰删除所谓懒惰删除就是在客户端访问该key的时候，redis会对key的过期时间进行检查，如果过期了就立即删除。这种方式看似很完美，在访问的时候检查key的过期时间，不会占用太多的额外CPU资源。但是如果一个key已经过期了，如果长时间没有被访问，那么这个key就会一直存留在内存之中，严重消耗了内存资源。 定期删除定期删除的原理是，Redis会将所有设置了过期时间的key放入一个字典中，然后每隔一段时间从字典中随机一些key检查过期时间并删除已过期的key。 Redis默认每秒进行10次过期扫描： 从过期字典中随机20个key 删除这20个key中已过期的 如果超过25%的key过期，则重复第一步 同时，为了保证不出现循环过度的情况，Redis还设置了扫描的时间上限，默认不会超过25ms。 ^_^.","tags":[{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"Redis","slug":"Redis","permalink":"https://www.cayzlh.com/tags/Redis/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"},{"name":"Redis","slug":"运维/Redis","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/Redis/"}]},{"title":"正确访问redis中的海量数据，避免事故产生","date":"2019-10-10T01:06:53.000Z","path":"2019/10/10/1e34c708.html","text":"事故产生当我们使用usertoken:userid这样的格式的key来保存用户token值，这个时候想统计一下在线用户数量。 直接使用keys usertoken*方式进行查询，当用户数量巨大的时候，事故就产生了。导致redis不可用， 假死。 原因我们线上的登录用户有几百万，数据量比较多；keys算法是遍历算法，复杂度是O(n)，也就是数据越多，时间复杂度越高。 数据量达到几百万，keys这个指令就会导致 Redis 服务卡顿，因为 Redis 是单线程程序，顺序执行所有指令，其它指令必须等到当前的 keys 指令执行完了才可以继续。 解决方案们可以采用redis的另一个命令scan。我们看一下scan的特点 复杂度虽然也是 O(n)，但是它是通过游标分步进行的，不会阻塞线程 提供 count 参数，不是结果数量，是redis单次遍历字典槽位数量(约等于) 同 keys 一样，它也提供模式匹配功能; 服务器不需要为游标保存状态，游标的唯一状态就是 scan 返回给客户端的游标整数; 返回的结果可能会有重复，需要客户端去重复，这点非常重要; 单次返回的结果是空的并不意味着遍历结束，而要看返回的游标值是否为零 scan命令的格式SCAN cursor [MATCH pattern] [COUNT count] 命令解释scan 游标 MATCH &lt;返回和给定模式相匹配的元素&gt; count 每次迭代所返回的元素数量 SCAN命令是增量的循环，每次调用只会返回一小部分的元素。所以不会让redis假死 SCAN命令返回的是一个游标，从0开始遍历，到0结束遍历 例子redis > scan 0 match usertoken* count 5 1) \"6\" 2) 1) \"usertoken:100\" 2) \"usertoken:101\" 3) \"usertoken:102\" 4) \"usertoken:103\" 5) \"usertoken:104\" 从0开始遍历，返回了游标6，又返回了数据，继续scan遍历，就要从6开始 redis > scan 6 match usertoken* count 5 1) \"10\" 2) 1) \"usertoken:200\" 2) \"usertoken:201\" 3) \"usertoken:202\" 4) \"usertoken:203\" 5) \"usertoken:204\" 总结^_^.","tags":[{"name":"Redis","slug":"Redis","permalink":"https://www.cayzlh.com/tags/Redis/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"},{"name":"Redis","slug":"运维/Redis","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/Redis/"}]},{"title":"Docker Swarm","date":"2019-09-28T13:35:29.000Z","path":"2019/09/28/656e6847.html","text":"实践中会发现，生产环境中使用单个 Docker 节点是远远不够的，搭建 Docker 集群势在必行。然而，面对 Kubernetes, Mesos 以及 Swarm 等众多容器集群系统，我们该如何选择呢？它们之中，Swarm 是 Docker 原生的，同时也是最简单，最易学，最节省资源的，比较适合中小型公司使用。 Docker Swarm 介绍Swarm 在 Docker 1.12 版本之前属于一个独立的项目，在 Docker 1.12 版本发布之后，该项目合并到了 Docker 中，成为 Docker 的一个子命令。目前，Swarm 是 Docker 社区提供的唯一一个原生支持 Docker 集群管理的工具。它可以把多个 Docker 主机组成的系统转换为单一的虚拟 Docker 主机，使得容器可以组成跨主机的子网网络。 Docker Swarm 是一个为 IT 运维团队提供集群和调度能力的编排工具。用户可以把集群中所有 Docker Engine 整合进一个「虚拟 Engine」的资源池，通过执行命令与单一的主 Swarm 进行沟通，而不必分别和每个 Docker Engine 沟通。在灵活的调度策略下，IT 团队可以更好地管理可用的主机资源，保证应用容器的高效运行。 Docker Swarm 优点任何规模都有高性能表现对于企业级的 Docker Engine 集群和容器调度而言，可拓展性是关键。任何规模的公司——不论是拥有五个还是上千个服务器——都能在其环境下有效使用 Swarm。 经过测试，Swarm 可拓展性的极限是在 1000 个节点上运行 50000 个部署容器，每个容器的启动时间为亚秒级，同时性能无减损。 灵活的容器调度Swarm 帮助 IT 运维团队在有限条件下将性能表现和资源利用最优化。Swarm 的内置调度器（scheduler）支持多种过滤器，包括：节点标签，亲和性和多种容器部策略如 binpack、spread、random 等等。 服务的持续可用性Docker Swarm 由 Swarm Manager 提供高可用性，通过创建多个 Swarm master 节点和制定主 master 节点宕机时的备选策略。如果一个 master 节点宕机，那么一个 slave 节点就会被升格为 master 节点，直到原来的 master 节点恢复正常。 此外，如果某个节点无法加入集群，Swarm 会继续尝试加入，并提供错误警报和日志。在节点出错时，Swarm 现在可以尝试把容器重新调度到正常的节点上去。 和 Docker API 及整合支持的兼容性 Swarm 对 Docker API 完全支持，这意味着它能为使用不同 Docker 工具（如 Docker CLI，Compose，Trusted Registry，Hub 和 UCP）的用户提供无缝衔接的使用体验。 Docker Swarm 为 Docker 化应用的核心功能（诸如多主机网络和存储卷管理）提供原生支持。开发的 Compose 文件能（通过 docker-compose up ）轻易地部署到测试服务器或 Swarm 集群上。Docker Swarm 还可以从 Docker Trusted Registry 或 Hub 里 pull 并 run 镜像。 综上所述，Docker Swarm 提供了一套高可用 Docker 集群管理的解决方案，完全支持标准的 Docker API，方便管理调度集群 Docker 容器，合理充分利用集群主机资源。 并非所有服务都应该部署在Swarm集群内。数据库以及其它有状态服务就不适合部署在Swarm集群内。 相关概念节点运行 Docker 的主机可以主动初始化一个 Swarm 集群或者加入一个已存在的 Swarm 集群，这样这个运行 Docker 的主机就成为一个 Swarm 集群的节点 (node) 。节点分为管理 (manager) 节点和工作 (worker) 节点。 管理节点用于 Swarm 集群的管理，docker swarm 命令基本只能在管理节点执行（节点退出集群命令 docker swarm leave 可以在工作节点执行）。一个 Swarm 集群可以有多个管理节点，但只有一个管理节点可以成为 leader，leader 通过 raft 协议实现。 工作节点是任务执行节点，管理节点将服务 (service) 下发至工作节点执行。管理节点默认也作为工作节点。你也可以通过配置让服务只运行在管理节点。下图展示了集群中管理节点与工作节点的关系。 服务和任务任务 （Task）是 Swarm 中的最小的调度单位，目前来说就是一个单一的容器。 服务 （Services） 是指一组任务的集合，服务定义了任务的属性。服务有两种模式： replicated services 按照一定规则在各个工作节点上运行指定个数的任务。 global services 每个工作节点上运行一个任务 两种模式通过 docker service create 的 –mode 参数指定。下图展示了容器、任务、服务的关系。 最后 转自：Docker(六)：Docker 三剑客之 Docker Swarm 对这个Docker Swarm这部分不是很熟悉，主要是想了解其概念。转发这篇文章内容以免以后找不到。 实践之后再做补充","tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cayzlh.com/tags/Docker/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Docker","slug":"微服务/Docker","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/Docker/"}]},{"title":"使用Docker Compose","date":"2019-09-26T01:06:17.000Z","path":"2019/09/26/89c47277.html","text":"Docker-Compose 是 Docker 的一种编排服务，是一个用于在 Docker 上定义并运行复杂应用的工具，可以让用户在集群中部署分布式应用。 使用一个 Dockerfile 模板文件可以定义一个单独的应用容器，如果需要定义多个容器就需要服务编排。Docker Compose是其中的一种服务编排技术方案，是Docker的官方产品。 Dockerfile 可以让用户管理一个单独的应用容器；而 Compose 则允许用户在一个模板（YAML 格式）中定义一组相关联的应用容器（被称为一个 project，即项目），例如一个 Web 服务容器再加上后端的数据库服务容器等。 参考：Docker 三剑客之 Docker Compose Docker Compose 介绍通过 Docker-Compose 用户可以很容易地用一个配置文件定义一个多容器的应用，然后使用一条指令安装这个应用的所有依赖，完成构建。Docker-Compose 解决了容器与容器之间如何管理编排的问题。 Compose 中有两个重要的概念： 服务 (service) ：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。 项目 (project) ：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。 一个项目可以由多个服务（容器）关联而成，Compose 面向项目进行管理，通过子命令对项目中的一组容器进行便捷地生命周期管理。 Compose 项目由 Python 编写，实现上调用了 Docker 服务提供的 API 来对容器进行管理。因此，只要所操作的平台支持 Docker API，就可以在其上利用 Compose 来进行编排管理。 Docker Compose 安装Docker Compose 是 Docker 的独立产品，因此需要安装 Docker 之后在单独安装 Docker Compose . macOSmacOS下使用homebrew安装之后默认安装好了Docker Compose。 brew cask install docker Centos方法一： #下载 sudo curl -L https://github.com/docker/compose/releases/download/1.20.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose #安装 chmod +x /usr/local/bin/docker-compose #查看版本 docker-compose version 方法二： #安装pip yum -y install epel-release yum -y install python-pip #确认版本 pip --version #更新pip pip install --upgrade pip #安装docker-compose pip install docker-compose #查看版本 docker-compose version 安装完成后执行docker-compose version，输出以下信息，说明安装完成。 docker-compose version 1.24.1, build 4667896b docker-py version: 3.7.3 CPython version: 3.6.8 OpenSSL version: OpenSSL 1.1.0j 20 Nov 2018 一个小例子 源码地址：https://github.com/cayzlh/springboot-docker-demo 创建一个SpringBoot应用创建于SpringBoot应用，配合Redis记录访问次数。 pom&lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-data-redis&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>redis.clients&lt;/groupId> &lt;artifactId>jedis&lt;/artifactId> &lt;/dependency> DockerController@RestController public class DockerController { @Autowired @Lazy private StringRedisTemplate redisTemplate; @GetMapping(\"/\") public String index() { redisTemplate.opsForValue().increment(\"request_key\", 1); String times = redisTemplate.opsForValue().get(\"request_key\"); return \"Hello Docker! you had request \"+times+\" times!!!!!!!!!\"; } } Dockerfile在src/main/docker路径中创建Dockerfile文件. FROM openjdk:8-jdk-alpine MAINTAINER chenanyu antchenanyu@163.com VOLUME /tmp ADD target/springboot-docker-demo-0.0.3.jar app.jar ENTRYPOINT [\"java\",\"-Djava.security.egd=file:/dev/./urandom\",\"-jar\",\"/app.jar\"] docker-compose在根目录创建docker-compose.yml文件。 version: '3' services: app: container_name: v-app restart: always build: . working_dir: /app volumes: - ./:/app - ~/.m2:/root/.m2 expose: - \"8080\" depends_on: - nginx - redisserver command: mvn clean spring-boot:run -Dspring-boot.run.profiles=docker redisserver: restart: always container_name: v-redis image: \"redis:alpine\" ports: - 6379:6379 nginx: container_name: v-nginx image: nginx:1.13 restart: always ports: - 8081:80 - 443:443 volumes: - ./nginx:/etc/nginx/conf.d 使用docker-compose命令运行docker-compose up 这个时候浏览器访问http://youipaddress:8081，就能看到效果了，访问次数会不断的叠加。 Hello Docker! you had request 5 times!!!!!!!!! 在macOS中，非root用户是无法使用小于1024的常用端口的。如果开发中需要用到80端口, 就要设置端口转发。这里就不想麻烦了，使用8081来做测试。 Docker Compose常用命令 使用docker-compose up -d在后台启动服务 [root@localhost composetest]# docker-compose up -d Starting composetest_web_1 ... Starting composetest_web_1 ... done 使用docker-compose ps命令查看启动的服务 [root@localhost composetest]# docker-compose ps Name Command State Ports ------------------------------------------------------------------------------------- composetest_redis_1 docker-entrypoint.sh redis ... Up 6379/tcp composetest_web_1 python app.py Up 0.0.0.0:5000->5000/tcp 使用docker-compose stop停止服务。 [root@localhost composetest]# docker-compose stop Stopping composetest_web_1 ... done Stopping composetest_redis_1 ... done 其他 #查看帮助 docker-compose -h # -f 指定使用的 Compose 模板文件，默认为 docker-compose.yml，可以多次指定。 docker-compose -f docker-compose.yml up -d #启动所有容器，-d 将会在后台启动并运行所有的容器 docker-compose up -d #停用移除所有容器以及网络相关 docker-compose down #查看服务容器的输出 docker-compose logs #列出项目中目前的所有容器 docker-compose ps #构建（重新构建）项目中的服务容器。服务容器一旦构建后，将会带上一个标记名，例如对于 web 项目中的一个 db 容器，可能是 web_db。可以随时在项目目录下运行 docker-compose build 来重新构建服务 docker-compose build #拉取服务依赖的镜像 docker-compose pull #重启项目中的服务 docker-compose restart #删除所有（停止状态的）服务容器。推荐先执行 docker-compose stop 命令来停止容器。 docker-compose rm #在指定服务上执行一个命令。 docker-compose run ubuntu ping docker.com #设置指定服务运行的容器个数。通过 service=num 的参数来设置数量 docker-compose scale web=3 db=2 #启动已经存在的服务容器。 docker-compose start #停止已经处于运行状态的容器，但不删除它。通过 docker-compose start 可以再次启动这些容器。 docker-compose stop 参考 Docker 三剑客之 Docker Compose","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"Docker","slug":"Docker","permalink":"https://www.cayzlh.com/tags/Docker/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Docker","slug":"微服务/Docker","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/Docker/"}]},{"title":"使用Docker部署SpringBoot项目","date":"2019-09-25T08:34:06.000Z","path":"2019/09/25/2a4c017c.html","text":"Docker 技术发展为微服务落地提供了更加便利的环境，使用 Docker 部署 Spring Boot 其实非常简单。 创建SpringBoot项目使用SpringBoot2.0创建一个SpringBoot项目。 &lt;parent> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-parent&lt;/artifactId> &lt;version>2.0.0.RELEASE&lt;/version> &lt;/parent> 添加 web 和测试依赖 &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;/dependency> &lt;/dependencies> 创建一个 DockerController，在其中有一个index()方法，访问时返回：Hello Docker! @RestController public class DockerController { @RequestMapping(\"/\") public String index() { return \"Hello Docker!\"; } } 启动类 @SpringBootApplication public class DockerApplication { public static void main(String[] args) { SpringApplication.run(DockerApplication.class, args); } } 添加完毕后启动项目，启动成功后浏览器放问：http://localhost:8080/，页面返回：Hello Docker!，说明 Spring Boot 项目配置正常。 为SpringBoot项目添加Docker支持在 pom.xml的properties节点中添加 Docker 镜像名称 &lt;properties> &lt;docker.image.prefix>springboot&lt;/docker.image.prefix> &lt;/properties> plugins 中添加 Docker 构建插件： &lt;build> &lt;plugins> &lt;plugin> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-maven-plugin&lt;/artifactId> &lt;/plugin> &lt;!-- Docker maven plugin --> &lt;plugin> &lt;groupId>com.spotify&lt;/groupId> &lt;artifactId>docker-maven-plugin&lt;/artifactId> &lt;version>1.0.0&lt;/version> &lt;configuration> &lt;imageName>${docker.image.prefix}/${project.artifactId}&lt;/imageName> &lt;dockerDirectory>src/main/docker&lt;/dockerDirectory> &lt;resources> &lt;resource> &lt;targetPath>/&lt;/targetPath> &lt;directory>${project.build.directory}&lt;/directory> &lt;include>${project.build.finalName}.jar&lt;/include> &lt;/resource> &lt;/resources> &lt;/configuration> &lt;/plugin> &lt;!-- Docker maven plugin --> &lt;/plugins> &lt;/build> 在目录src/main/docker下创建 Dockerfile 文件，Dockerfile 文件用来说明如何来构建镜像。 FROM openjdk:8-jdk-alpine VOLUME /tmp ADD spring-boot-docker-1.0.jar app.jar ENTRYPOINT [\"java\",\"-Djava.security.egd=file:/dev/./urandom\",\"-jar\",\"/app.jar\"] 这个 Dockerfile 文件很简单，构建 Jdk 基础环境，添加 Spring Boot Jar 到镜像中，简单解释一下: FROM ，表示使用 Jdk8 环境 为基础镜像，如果镜像不是本地的会从 DockerHub 进行下载 VOLUME ，VOLUME 指向了一个/tmp的目录，由于 Spring Boot 使用内置的Tomcat容器，Tomcat 默认使用/tmp作为工作目录。这个命令的效果是：在宿主机的/var/lib/docker目录下创建一个临时文件并把它链接到容器中的/tmp目录 ADD ，拷贝文件并且重命名 ENTRYPOINT ，为了缩短 Tomcat 的启动时间，添加java.security.egd的系统属性指向/dev/urandom作为 ENTRYPOINT SpringBoot项目的Docker依赖就配置完成了 使用dockerfile打包镜像mvn package docker:build 当看到BUILD SUCCESS的时候，说明构建成功了。 使用docker images命令查看构建好的镜像： docker images REPOSITORY TAG IMAGE ID CREATED SIZE springboot/spring-boot-docker latest 99ce9468da74 6 seconds ago 117.5 MB springboot/spring-boot-docker 就是我们构建好的镜像，下一步就是运行该镜像 docker run -p 8080:8080 -t springboot/spring-boot-docker 可以看到我们构建的容器正在在运行，访问浏览器：http://192.168.0.x:8080/,返回 Hello Docker! ^_^。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"Docker","slug":"Docker","permalink":"https://www.cayzlh.com/tags/Docker/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cayzlh.com/tags/SpringBoot/"}],"categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Docker","slug":"微服务/Docker","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/Docker/"}]},{"title":"RocketMQ相关流程图/原理图","date":"2019-09-19T01:51:47.000Z","path":"2019/09/19/bade4616.html","text":"转自：后端程序员必备：RocketMQ相关流程图/原理图，怕以后找不到。 RocketMQ是什么 是一个队列模型的消息中间件，具有高性能、高可靠、高实时、分布式特点。 Producer、Consumer、队列都可以分布式。 Producer 向一些队列轮流发送消息，队列集合称为 Topic，Consumer 如果做广播消费，则一个 consumer 实例消费这个 Topic 对应的所有队列，如果做集群消费，则多个 Consumer 实例平均消费这个 topic 对应的队列集合。 能够保证严格的消息顺序 提供丰富的消息拉取模式 高效的订阅者水平扩展能力 实时的消息订阅机制 亿级消息堆积能力 较少的依赖 RocketMQ 核心组件图RocketMQ是开源的消息中间件，它主要由NameServer，Producer，Broker，Consumer四部分构成。 NameServerNameServer主要负责Topic和路由信息的管理，功能类似Dubbo的zookeeper。 Producer消息生产者，负责产生消息，一般由业务系统负责产生消息。 Broker消息中转角色，负责存储消息，转发消息。 Consumer消息消费者，负责消息消费，一般是后台系统负责异步消费。 RokcetMQ 物理部署图 NameServerNameServer是一个几乎无状态节点，可集群部署，节点之间无任何信息同步。 BrokerBroker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave的对应关系通过指定相同的BrokerName，不同的BrokerId来定义，BrokerId为0表示Master，非0表示Slave。Master也可以部署多个。每个Broker与Name Server集群中的所有节点建立长连接，定时注册Topic信息到所有Name Server。 ProducerProducer与Name Server集群中的其中一个节点（随机选择）建立长连接，定期从Name Server取Topic路由信息，并向提供Topic服务的Master建立长连接，且定时向Master发送心跳。Producer完全无状态，可集群部署。 ConsumerConsumer与Name Server集群中的其中一个节点（随机选择）建立长连接，定期从Name Server取Topic路由信息，并向提供Topic服务的Master、Slave建立长连接，且定时向Master、Slave发送心跳。Consumer既可以从Master订阅消息，也可以从Slave订阅消息，订阅规则由Broker配置决定。 RocketMQ 逻辑部署结构 Producer Group用来表示一个发送消息应用，一个 Producer Group 下包含多个 Producer 实例，可以是多台机器，也可以 是一台机器的多个进程，或者一个进程的多个 Producer 对象。一个 Producer Group 可以发送多个 Topic 消息，Producer Group 作用如下： 标识一类 Producer 可以通过运维工具查询这个发送消息应用下有多个 Producer 实例 发送分布式事务消息时，如果 Producer 中途意外宕机，Broker 会主动回调 Producer Group 内的任意 一台机器来确认事务状态。 Consumer Group用来表示一个消费消息应用，一个 Consumer Group 下包含多个 Consumer 实例，可以是多台机器，也可 以是多个进程，或者是一个进程的多个 Consumer 对象。一个 Consumer Group 下的多个 Consumer 以均摊 方式消费消息，如果设置为广播方式，那么这个 Consumer Group 下的每个实例都消费全量数据。 NameServer 路由注册、删除机制 Broker每30秒向NameServer发送心跳包，心跳包中包含topic的路由信息 NarneServer 收到 Broker 心跳包后 更新 brokerLiveTable 中的信息， 特别记录心跳时间 lastUpdateTime NarneServer 每隔 10s 扫描 brokerLiveTable， 检 测表中上次收到心跳包的时间，比较当前时间 与上一次时间，如果超过120s，则认为 broker 不可用，移除路由表中与该 broker相关的所有 信息 消息生产者拉取主题的路由信息，即消息生产者并不会立即感知 Broker 服务器的新增与删除。 RocketMQ的消息领域模型图 Topic Topic表示消息的第一级类型，比如一个电商系统的消息可以分为：交易消息、物流消息等。一条消息必须有一个Topic。 最细粒度的订阅单位，一个Group可以订阅多个Topic的消息。 TagTag表示消息的第二级类型，比如交易消息又可以分为：交易创建消息，交易完成消息等。RocketMQ提供2级消息分类，方便灵活控制。 Group组，一个组可以订阅多个Topic。 Message Queue消息的物理管理单位。一个Topic下可以有多个Queue，Queue的引入使得消息的存储可以分布式集群化，具有了水平扩展能力。 在 RocketMQ 中，所有消息队列都是持久化，长度无限的数据结构，所谓长度无限是指队列中的每个存储单元都是定长，访问其中的存储单元使用 Offset 来访问，offset 为 java long 类型，64 位，理论上在 100年内不会溢出，所以认为是长度无限。 也可以认为 Message Queue 是一个长度无限的数组，Offset 就是下标。 顺序消息原理图 消费消息的顺序要同发送消息的顺序一致，在 RocketMQ 中，主要的是局部顺序，即一类消息为满足顺 序性，必须 Producer 单线程顺序发送，且发送到同一个队列，这样 Consumer 就可以按照 Producer 收送 的顺序去消费消息。 RocketMQ 消息存储设计原理图 CommitLog消息存储文件，所有消息主题的消息都存储在 CommitLog 文件中。 Commitlog 文件存储的逻辑视图如图所示 ConsumeQueue消息消费队列，消息到达 CommitLog 文件后，将异步转发到消息 消费队列，供消息消费者消费。ConsumeQueue存储格式如下： 单个 ConsumeQueue 文件中默认包含 30 万个条目，单个文件的长度为 30w × 20 字节， 单个 ConsumeQueue 文件可以看出是一个 ConsumeQueue 条目的数组，其下标为 ConsumeQueue 的逻辑偏移量，消息消费进度存储的偏移量 即逻辑偏移量。 ConsumeQueue 即为 Commitlog 文件的索引文件， 其构建机制是当消息到达 Commitlog 文件后， 由专门的线程 产生消息转发任务，从而构建消息消费队列文件与下文提到的索引文件。 IndexFile消息索引文件，主要存储消息 Key 与 Offset 的对应关系。 消息消费队列是RocketMQ专门为消息订阅构建的索引文件，提高根据主题与消息队 列检索消息的速度 ，另外 RocketMQ 引入了 Hash 索引机制为消息建立索引， HashMap 的设 计包含两个基本点 ： Hash 槽与 Hash 冲突的链表结构。 RocketMQ 索引文件布局如图所示 lndexFile 总共包含 lndexHeader、 Hash 槽、 Hash 条目 事务状态服务存储每条消息的事务状态。 定时消息服务每一个延迟级别对应一个消息消费队列，存储延迟队列的消息拉取进度。 RMQ文件存储模型层 RocketMQ业务处理器层Broker端对消息进行读取和写入的业务逻辑入口，这一层主要包含了业务逻辑相关处理操作（根据解析RemotingCommand中的RequestCode来区分具体的业务操作类型，进而执行不同的业务处理流程），比如前置的检查和校验步骤、构造MessageExtBrokerInner对象、decode反序列化、构造Response返回对象等。 RocketMQ数据存储组件层 该层主要是RocketMQ的存储核心类—DefaultMessageStore，其为RocketMQ消息数据文件的访问入口，通过该类的“putMessage()”和“getMessage()”方法完成对CommitLog消息存储的日志数据文件进行读写操作（具体的读写访问操作还是依赖下一层中CommitLog对象模型提供的方法）； 另外，在该组件初始化时候，还会启动很多存储相关的后台服务线程，包括AllocateMappedFileService（MappedFile预分配服务线程）、ReputMessageService（回放存储消息服务线程）、HAService（Broker主从同步高可用服务线程）、StoreStatsService（消息存储统计服务线程）、IndexService（索引文件服务线程）等。 RocketMQ存储逻辑对象层 该层主要包含了RocketMQ数据文件存储直接相关的三个模型类IndexFile、ConsumerQueue和CommitLog。 IndexFile为索引数据文件提供访问服务，ConsumerQueue为逻辑消息队列提供访问服务，CommitLog则为消息存储的日志数据文件提供访问服务。 这三个模型类也是构成了RocketMQ存储层的整体结构。 封装的文件内存映射层 RocketMQ主要采用JDK NIO中的MappedByteBuffer和FileChannel两种方式完成数据文件的读写。 其中，采用MappedByteBuffer这种内存映射磁盘文件的方式完成对大文件的读写，在RocketMQ中将该类封装成MappedFile类。 这里，每一种类的单个文件均由MappedFile类提供读写操作服务（其中，MappedFile类提供了顺序写/随机读、内存数据刷盘、内存清理等和文件相关的服务）。 磁盘存储层主要指的是部署RocketMQ服务器所用的磁盘。这里，需要考虑不同磁盘类型（如SSD或者普通的HDD）特性以及磁盘的性能参数（如IOPS、吞吐量和访问时延等指标）对顺序写/随机读操作带来的影响。 RocketMQ中消息刷盘在RocketMQ中消息刷盘主要可以分为同步刷盘和异步刷盘两种。 同步刷盘 在返回写成功状态时，消息已经被写入磁盘。 具体流程是，消息写入内存的PAGECACHE后，立刻通知刷盘线程刷盘，然后等待刷盘完成，刷盘线程执行完成后唤醒等待的线程，返回消息写成功的状态。 一般只用于金融场景。 异步刷盘 在返回写成功状态时，消息可能只是被写入了内存的PAGECACHE，写操作的返回快，吞吐量大；当内存里的消息量积累到一定程度时，统一触发写磁盘操作，快速写入。 消息在系统中流转图 1、Producer 发送消息，消息从 socket 进入 java 堆。 2、Producer 发送消息，消息从 java 堆转入 PAGACACHE，物理内存。 3、Producer 发送消息，由异步线程刷盘，消息从 PAGECACHE 刷入磁盘。 4、Consumer 拉消息（正常消费），消息直接从 PAGECACHE（数据在物理内存）转入 socket，到达 consumer， 不经过 java 堆。这种消费场景最多，线上 96G 物理内存，按照 1K 消息算，可以在物理内存缓存 1 亿条消 息。 5、Consumer 拉消息（异常消费），消息直接从 PAGECACHE（数据在虚拟内存）转入 socket。 6、Consumer 拉消息（异常消费），由于 Socket 访问了虚拟内存，产生缺页中断，此时会产生磁盘 IO，从磁 盘 Load 消息到 PAGECACHE，然后直接从 socket 发出去。 7、同 5 一致。 8、同 6 一致。 ^_^.","tags":[{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"消息队列","slug":"消息队列","permalink":"https://www.cayzlh.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}],"categories":[{"name":"笔记本","slug":"笔记本","permalink":"https://www.cayzlh.com/categories/%E7%AC%94%E8%AE%B0%E6%9C%AC/"}]},{"title":"Gson简易指南","date":"2019-09-18T12:32:30.000Z","path":"2019/09/18/9fc188b6.html","text":"Gson简介在正式介绍 Gson 之前，我们可以先从官方的wiki看下 Gson 的描述，了解它是什么？ Gson is a Java library that can be used to convert Java Objects into their JSON representation. It can also be used to convert a JSON string to an equivalent Java object。 从描述可以看出，Gson 是用于将 Java 对象与 JSON格式字符串数据相互转换的 Java 库。它起初在Google 内部广泛使用在 Android 平台 和 Java 服务端上。2008 年开源之后，成为了谷歌又一个被广泛使用的开源框架，截止目前(2019.09.08) 在GitHub 上已有1W6 多星，相同作用的类库还有 Spring Framework 中集成的 Jackson，以及阿里开源的 fastjson等。 在特性方面，Gson 提供简易的API fromJson/toJson 来实现 Java 与 JSON 之间的转换，并且能生成紧凑，可读的 JSON 字符串输出，还支持复杂对象转换和丰富的自定义表示，足以满足在日常开发中我们绝大部分的 JSON 数据处理需求。 通常将对象与JSON字符串间的转换称之为序列化和反序列化(Serialization/Deserialization)。将 对象转化成 JSON字符串的过程称为序列化，将JSON 字符串转化成对象的过程称为反序列化。 Gson基本使用使用 Gson 框架进行序列化与反序列操作，都离不开 com.google.gson.Gson 对象，它也是 Gson 框架的关键对象，提供的公共 API 具备了多种序列化和反序列方式。 Gson 对象的创建主要有两种方式： 使用 new 关键字直接创建：Gson gson = new Gson() 由 GsonBuilder 对象构建：Gson gson = new GsonBuilder().create() 通常情况下，上面两种方式创建的 Gson 对象在进行序列化与反序列操作时行为都是一样的，但是第二种方式构建 Gson 对象时，允许进行额外的行为定制，比如格式化 JSON 字符串的输出内容，是否序列化 null 值等等。 Java序列化简单对象的序列化通过下面的例子来看下通过上述两种方式序列化 Java 对象的不同效果： public class ResultTest { @Test void test_serialization() { Gson gson = new Gson(); Result result = new Result(200, \"成功\", null); String json = gson.toJson(result); System.out.println(\"json is \" + json); Gson buildedGson = new GsonBuilder().setPrettyPrinting().serializeNulls().create(); String buildedJson = buildedGson.toJson(result); System.out.println(\"buildedJson is \" + buildedJson); } class Result { private int code; private String message; private Object data; public Result(int code, String message, Object data) { this.code = code; this.message = message; this.data = data; } } } 从结果可以看出，默认的 Gson 对象行为序列化对象时会将 null 值的字段忽略，而 com.google.gson.GsonBuilder#serializeNulls 方法将允许 Gson 对象序列化 null 字段；并且正常序列化后的 JSON 字符串是紧凑格式，节省字符串内存，使用 com.google.gson.GsonBuilder#setPrettyPrinting 方法之后最终输出的 JSON 字符串是更易读的格式。当然除了这两个方法，GsonBuilder 还提供了许多定制序列化和反序列化行为的API。 JosnObject 生成 JSON除了上述将自定义类的对象转换成 JSON 的方式之外，还可以使用 Gson 框架提供的 JsonObject 构建普通对象，然后使用 toJson 方法生成 JSON 字符串，在原测试类中补充下方测试类： @Test void test_jsonObject_serialization() { Gson gson = new Gson(); JsonObject jsonObject = new JsonObject(); jsonObject.addProperty(\"code\", 400); jsonObject.addProperty(\"message\", \"参数错误\"); String toJson = gson.toJson(jsonObject); String exceptedJson = \"{\\\"code\\\":400,\\\"message\\\":\\\"参数错误\\\"}\"; Assertions.assertEquals(exceptedJson, toJson); //true } JsonObject 使用 addProperty(property,value) 方法只能用来添加 String，Number，Boolean，Character这四类数据， 因为内部是调用 com.google.gson.JsonObject#add, 将 value 封装成了 JsonPrimitive 对象，然后保存到了内部自定义的 LinkedTreeMap 集合变量 members 中；如果需要在 JsonObject 对象上添加其他对象时，就需要直接使用 add(String property, JsonElement value) 方法添加一个 JsonElement 对象。这里的 JsonElement 是一个抽象类，JsonObject 和 JsonPrimitive 都继承了JsonElement，所以我们最终通过另外的 JsonObject 对象来作为原 JsonObject 上的属性对象： Gson gson = new Gson(); JsonObject jsonObject = new JsonObject(); //... JsonObject nestJsonObject = new JsonObject(); nestJsonObject.addProperty(\"username\", \"one\"); nestJsonObject.addProperty(\"score\", 99); jsonObject.add(\"data\", nestJsonObject); String toJson2 = gson.toJson(jsonObject); System.out.println(toJson2); // {\"code\":400,\"message\":\"参数错误\",\"data\":{\"username\":\"one\",\"score\":99}} JSON 反序列化简单对象的反序列化现在我们再来看下 JSON 反序列化成 Java 对象用法，这里主要使用方法是 com.google.gson.Gson#fromJson，它最基础的用法就是 fromJson(String json, Class&lt;T&gt; classOfT)，尝试将 JSON 字符串转为指定 Class 的对象，如果转换失败，就会抛出 JsonSyntaxException 异常。我们可以在原来代码上新增一个测试用例，运行看下效果： @Test void test_deserialization() { String json = \"{\\\"code\\\":400,\\\"message\\\":\\\"参数错误\\\"}\"; Result result = new Gson().fromJson(json, Result.class); Assertions.assertEquals(400, result.code); // true Assertions.assertEquals(\"参数错误\", result.message); // true } 反序列化 Map除了将JSON 字符串序列化为自定义的Java 对象之外，我们还可以转为 Map 集合，Gson 提供了对 Map 集合的转换，使用起来也十分简单： @Test void test_map() { String jsonString = \"{'employee.name':'one','employee.salary':10}\"; Gson gson = new Gson(); Map map = gson.fromJson(jsonString, Map.class); assertEquals(2, map.size()); assertEquals(\"one\", map.get(\"employee.name\")); assertEquals(Double.class, map.get(\"employee.name\").getClass()); } 需要注意的是转换后的 Map 对象真实类型并不是我们经常用的 HashMap，而是 Gson 自定义集合LinkedTreeMap ，它实现Map 接口来存储键值对，在新增和删除上实现上进行了优化，并且将存储键值对的顺序作为遍历顺序，也就是先存入的先被遍历到。除此之外，JSON 字符串里的数值型数据都会转转换为 Double 类型，而 true/false 数据被会被转换成 Boolean 类型，具体判断依据可以参考 com.google.gson.internal.bind.ObjectTypeAdapter#read 方法的实现。 ### JSON 与 Array，List 转换 JSON 转换 Array当我们正对 JSON 数据进行数组转换时，类似普通对象转换的方式即可， toJson 方法直接使用转为 JSON 数据，fromJson 指定数组类型转换为对应类型的数组。 @Test void test_array() { Gson gson = new Gson(); int[] ints = {1, 2, 3, 4, 5}; String[] strings = {\"abc\", \"def\", \"ghi\"}; String s = gson.toJson(ints);// [1,2,3,4,5] assertEquals(\"[1,2,3,4,5]\", s); // true String s1 = gson.toJson(strings);// [\"abc\", \"def\", \"ghi\"] assertEquals(\"[\\\"abc\\\",\\\"def\\\",\\\"ghi\\\"]\", s1); String[] strings1 = gson.fromJson(s1, String[].class); assertEquals(strings.length, strings1.length); // true assertEquals(strings[0], strings1[0]); // true int[] ints2 = gson.fromJson(\"[1,2,3,4,5]\", int[].class); assertEquals(1, ints2[0]); // true assertEquals(5, ints2[4]); // true } JSON 转换 List要将 List 数据转换为 JSON数据，使用 Gson 的方式与处理 Array 数据一样；这里主要讲的是将JSON 数据转为 List 对象的操作略有不同，要将一个 JSON 数组数据转换为一个自定义类的List 时，我们按照原来的写法如下： @Test public void givenJsonString_whenIncorrectDeserializing() { Gson gson = new Gson(); String inputString = \"[{\\\"id\\\":1,\\\"name\\\":\\\"one\\\"},{\\\"id\\\":2,\\\"name\\\":\\\"two\\\"}]\"; List&lt;Person> outputList = gson.fromJson(inputString, List.class); outputList.get(0).getId(); } 但是不幸的是，运行这段代码后会抛出 ClassCastException 异常，具体描述如下： java.lang.ClassCastException: com.google.gson.internal.LinkedTreeMap cannot be cast to com.one.learn.Person 从上述描述中我们可以知道执行 fromJson 之后，反序列化后得到的 List 元素类型为 LinkedTreeMap，而不是 Person，所以以 Person 对象方式访问 id 属性时就会抛出 ClassCastException 异常。那又该如何处理呢, 我们需要调用 Gson 的 另外一个 fromJson 方法：fromJson(String json, Type typeOfT) ，先看下使用方式 @Test public void givenJsonString_whenCorrectDeserializing_() { Gson gson = new Gson(); String inputString = \"[{\\\"id\\\":1,\\\"name\\\":\\\"one\\\"},{\\\"id\\\":2,\\\"name\\\":\\\"two\\\"}]\"; Type type = new TypeToken&lt;List&lt;Person>>(){}.getType(); List&lt;Person> outputList = gson.fromJson(inputString, type); int id = outputList.get(0).getId(); assertEquals(1, id); // true assertEquals(\"one\", outputList.get(0).getName()); // true } 这个方法中的 Type 对象通过 TypeToken 对象的 getType 方法获取到，就是 TypeToken 对象所关联的泛型类型。而这里 TypeToken 是 Gson 为了支持泛型而引入的类，来解决 Java 无法提供泛型类型表示的问题，由于 TypeToken 的构造方法是protected修饰的，无法直接构造，使用就需要写成new TypeToken&lt;List&lt;String&gt;&gt;() {}.getType() 形式。 Gson进阶用法接触了 Gson 基本的使用之后，我们接着进一步学习 Gson 的其他用法。 泛型对象反序列化简单接触了 Gson 对泛型的支持，接下来用代码来展示下它的强大之处，首先我们将上文的 Result 类调整下接受泛型参数： class Result&lt;T> { private int code; private String message; private T data; public Result(int code, String message, T data) { this.code = code; this.message = message; this.data = data; } } 然后对一个有内嵌对象的 JSON字符串进行解析成 Result 对象，示例代码如下： @Test void test_genric_object() { String json = \"{\\\"code\\\":200,\\\"message\\\":\\\"操作成功\\\",\\\"data\\\":{\\\"username\\\": \\\"one\\\",\\\"avater\\\": \\\"image.jpg\\\"\" + \"}}\"; Type type = new TypeToken&lt;Result&lt;User>>(){}.getType(); Result&lt;User> result = new Gson().fromJson(json, type); Assertions.assertEquals(200, result.code); Assertions.assertEquals(\"one\", result.data.getUsername()); Assertions.assertEquals(\"image.jpg\", result.data.getAvater()); } class User { private String username; private String avater; public String getUsername() { return username; } public String getAvater() { return avater; } } 利用 TypeToken 对象获取具体泛型类型 Result , 然后在 fromJson 方法中传入就会根据对应类型的执行反序列化操作。 自定义序列化要对Java 对象的某些字段进行特殊处理，比如隐藏某些字段的序列化，对字段的数据格式化处理等，我们可以通过实现 JsonSerializer 接口，对序列化逻辑进行自定义。例如，我们需要对 Date 类型属性进行特定格式的处理，可以声明 DateSerializer 类实现如下： class DateSerializer implements JsonSerializer&lt;Date> { SimpleDateFormat dateTime = new SimpleDateFormat(\"yyyy-MM-dd\"); @Override public JsonElement serialize(Date src, Type typeOfSrc, JsonSerializationContext context) { return new JsonPrimitive(dateTime.format(src)); } } 然后在构建 Gson 对象前，利用 GsonBuilder 将 DateSerializer 实例进行注册，使用方式如下： Gson gson = new GsonBuilder() .registerTypeAdapter(Date.class, new DateSerializer()) .create(); 这样一来，一旦遇到要序列化 Date 类型的字段时，都会通过自定义的 serialize 方法将日期以 yyyy-MM-dd 格式进行输出，如下方的示例代码： @Test void test_dateSerializer() { MyObject myObject = new MyObject(new Date(), \"one\"); Gson gson = new GsonBuilder().registerTypeAdapter(Date.class, new DateSerializer()).create(); String json = gson.toJson(myObject); String exceptedJson = \"{\\\"date\\\":\\\"2019-09-08\\\",\\\"name\\\":\\\"one\\\"}\"; Assertions.assertEquals(exceptedJson, json); // true } class MyObject { private Date date; private String name; public MyObject(Date date, String name) { this.date = date; this.name = name; } public MyObject() { } } 自定义反序列化与自定义序列化实现方式类似，想要自定义反序列化逻辑，就需要同样要实现一个叫 JsonDeserializer 的接口，进行自定义反序列化逻辑的实现。比如现在有个 JSON 字符串内容为 {&quot;CODE&quot;: 400, &quot;MESSAGE&quot;: &quot;参数错误&quot;}，需要被反序列化为前文提到的 Result 对象，由于字段名不一样，为了实现对应的转换，就需要自定义 ResultDeserializer 类，具体实现如下： class ResultDeserializer implements JsonDeserializer&lt;Result> { @Override public Result deserialize(JsonElement json, Type typeOfT, JsonDeserializationContext context) throws JsonParseException { JsonObject object = json.getAsJsonObject(); Result&lt;Object> result = new Result&lt;>(object.getAsJsonPrimitive(\"CODE\") .getAsInt(), object.getAsJsonPrimitive(\"MESSAGE\") .getAsString(), null); return result; } } 接下来就是利用 GsonBuilder 注册 ResultDeserializer 实例，生成对应的 Gson 对象，并进行反序列化操作： @Test void test_resultDeserializer() { //language=JSON String json = \"{\\\"CODE\\\": 400,\\\"MESSAGE\\\": \\\"参数错误\\\"}\"; Gson gson = new GsonBuilder().registerTypeAdapter(Result.class, new ResultDeserializer()) .create(); Result result = gson.fromJson(json, Result.class); Assertions.assertEquals(400, result.code); // true Assertions.assertEquals(\"参数错误\", result.message); // true } Gson常用注解Gson 除了提供一些 API 供开发者使用之外，还有一些具有特性的注解可以使用，接下来就介绍在 Gson 中最常用的注解。 @Expose这个注解只能用在字段上，作用就是注明对应的字段是否将在序列化或者反序列化时暴露出来，有两个属性 serialize 和 deserialize ，默认都为 true。当给一个字段加上 注解@Expose(serialize = true, deserialize = false)，则表示了该字段尽在序列化时可见，在反序列化时会忽略赋值。需要额外注意的一点是，@Expose 注解只有在用 GsonBuilder 方式构建 Gson 时有限，并且构建前必须调用 excludeFieldsWithoutExposeAnnotation 方法，下面是具体的使用示例： @Test void test_expose() { MySubClass subclass = new MySubClass(42L, \"the answer\", \"Verbose field not to serialize\"); MyClass source = new MyClass(1L, \"foo\", \"bar\", subclass); Gson gson = new GsonBuilder().excludeFieldsWithoutExposeAnnotation().create(); String s = gson.toJson(source); System.out.println(s); // {\"id\":1,\"name\":\"foo\",\"subclass\":{\"id\":42,\"description\":\"the answer\",\"otherVerboseInfo\":\"Verbose field not to serialize\"}} } @Data @AllArgsConstructor class MyClass { private long id; @Expose(serialize = false, deserialize = true) private String name; private transient String other; @Expose private MySubClass subclass; } @Data @AllArgsConstructor class MySubClass { @Expose private long id; @Expose private String description; @Expose private String otherVerboseInfo; } 在 Gson 中 transient 关键字修饰的字段默认不会被序列化和反序列化，这个行为是与 Java 原生的序列化和反序列化操作一致的。 @Since该注解用于标记对应字段或者类型的版本，让 Gson 可以指定版本号进行序列化和反序列化操作。当Web服务上的 JSON 数据对应的类存在多个版本的字段时，这个注解就十分有用。 同样地，该注解只针对使用 GsonBuilder 方式构建的 Gson 对象，并且使用 setVersion 方法指明版本号时有效，只解析对象中对应版本的字段，下面为具体示例： public class VersioningSupportTest { @Test void test() { VersionedClass versionedObject = new VersionedClass(); Gson gson = new GsonBuilder().setVersion(1.0).create(); String jsonOutput = gson.toJson(versionedObject); System.out.println(jsonOutput); // {\"newField\":\"new\",\"field\":\"old\"} } } class VersionedClass { @Since(1.1) private final String newerField; @Since(1.0) private final String newField; private final String field; public VersionedClass() { this.newerField = \"newer\"; this.newField = \"new\"; this.field = \"old\"; } } @SerializedName这个注解使用起来比较简单，也很有用。@SerializedName 指定了成员字段被序列化和反序列化时所采用的名称下面是具体使用方式： public class JSONFieldNamingSupportTest { private class SomeObject { @SerializedName(\"custom_naming\") private final String someField; private final String someOtherField; public SomeObject(String a, String b) { this.someField = a; this.someOtherField = b; } } @Test void test() { SomeObject someObject = new SomeObject(\"first\", \"second\"); String jsonRepresentation = gson.toJson(someObject); System.out.println(jsonRepresentation); // {\"custom_naming\":\"first\",\"someOtherField\":\"second\"} SomeObject someObject1 = gson.fromJson(jsonRepresentation, SomeObject.class); System.out.println(someObject1); // SomeObject{someField='first', someOtherField='second'} } } @JsonAdapter@JsonAdapter 主要作用就是代替 GsonBuilder.registerTypeAdapter 方法的执行，直接通过 @JsonAdapter(aClass.class) 方式指定 JsonDeserializer 对象或者 JsonSerializer 对象，可以起到相同的作用，并且优先级比GsonBuilder.registerTypeAdapter的优先级更高，由于只是将 registerTypeAdapter方法执行简化成了注解方法，这里就不再演示，直接在前文自定义反序列化一节的 Result 类上使用就可以看到效果。 结语^_^. 参考 除了FastJson,你还有选择: Gson简易指南","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"Gson","slug":"Gson","permalink":"https://www.cayzlh.com/tags/Gson/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"}]},{"title":"SonarQube的安装与使用","date":"2019-08-27T06:30:57.000Z","path":"2019/08/27/f372f498.html","text":"前言随着代码量的越来越多，同时对代码质量的要求也越来越高，对于代码review的需求越来越多。因此，引入SonarQube这个工具对Java代码进行质量管控。 SonarQube（曾用名Sonar（声纳））是一个开源的代码质量管理系统。 安装前置条件 系统环境：Centos 7 Java环境：1.8 SonarQube版本：6.7.7 由于最新版的SonarQube7.9要求Java环境必须是Java11以上，我们目前开发使用的是1.8，所以选用较低版本的6.7.7 创建sonar用户由于sonar用到了es，不允许直接使用root用户运行，因此，需要在linux下，创建sonar用户，专门用来运行sonar程序。 假设当前使用的是root用户登录： useradd sonar passwd sonar su sonar 安装mysql数据库，创建sonar库1、mysql的安装步骤：记录Linux安装Mysql全过程 2、创建sonar库 ​ 创建sonar数据库，用于保存soanrqube的扫描数据 安装sonarqube1、将sonar6.7.7安装包拉到/opt/SonarQube目录 2、解压 unzip sonarqube-6.7.7.zip 3、修改配置 vi ./sonarqube-6.7.7/conf/sonar.properties 添加mysql配置： #-------------------------------------------------------------------------------------------------- # DATABASE # User credentials. # Permissions to create tables, indices and triggers must be granted to JDBC user. # The schema must be created first. sonar.jdbc.username=sonar sonar.jdbc.password=******* #----- MySQL 5.6 or greater # Only InnoDB storage engine is supported (not myISAM). # Only the bundled driver is supported. It can not be changed. sonar.jdbc.url=jdbc:mysql://localhost:3306/sonar?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;useConfigs=maxPerformance&amp;useSSL=false 省略了不需要展示的部分 创建软连接ln -s /opt/SonarQube/sonarqube-6.7.7/bin/linux-x86-64/sonar.sh /usr/bin/sonar 运行sonarsonar start 重启 sonar restart 停止 sonar stop 查看状态 sonar status 可能遇到的问题 没有目录权限： 将目录授权给sonar用户: su root chown -R sonar /opt/SonarQube 没有操作权限 chmod a+x /opt/SonarQube/sonarqube-6.7.7/bin/linux-x86-64/sonar.sh chmod a+x /opt/SonarQube/sonarqube-6.7.7/bin/linux-x86-64/wrapper chmod a+x /opt/SonarQube/sonarqube-6.7.7/elasticsearch/bin/elasticsearch 数据库问题 录数据库后执行： SET GLOBAL max_allowed_packet = 4*1024*1024*16 使用Java扫描Java的maven项目，首先要在pom.xml中添加配置： &lt;plugin> &lt;groupId>org.sonarsource.scanner.maven&lt;/groupId> &lt;artifactId>sonar-maven-plugin&lt;/artifactId> &lt;version>3.3.0.603&lt;/version> &lt;/plugin> 使用logintoken扫描mvn sonar:sonar \\ -Dsonar.host.url=http://10.0.2.91:9000 \\ -Dsonar.login=youtoken 其中youtoken可以在登录sonar后台后找到：我的账号 - 安全 设置settings.xml扫描 修改本地maven的settings.xml文件，添加配置： &lt;pluginGroups> &lt;pluginGroup>org.sonarsource.scanner.maven&lt;/pluginGroup> &lt;/pluginGroups> &lt;profiles> &lt;profile> &lt;id>sonar&lt;/id> &lt;activation> &lt;activeByDefault>true&lt;/activeByDefault> &lt;/activation> &lt;properties> &lt;!-- 配置 Sonar Host地址，默认：http://localhost:9000 --> &lt;sonar.host.url> http://10.0.2.91:9000 &lt;/sonar.host.url> &lt;/properties> &lt;/profile> &lt;/profiles> 然后执行： mvn clean verify sonar:sonar 或 mvn clean install sonar:sonar 或 mvn clean -Dmaven.test.skip=true verify sonar:sonar 或在IDEA中执行maven插件： 分析扫描完成后，登录sonar后台，将可以看到本次扫描的项目，和相应的分析： over ^_^. 参考 SonarQube 的安装、配置及 Maven 项目的使用 SonarQube官网","tags":[{"name":"SonarQube","slug":"SonarQube","permalink":"https://www.cayzlh.com/tags/SonarQube/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"}]},{"title":"使用Spring读取文件的几种方式","date":"2019-08-23T02:00:37.000Z","path":"2019/08/23/536e3362.html","text":"概述在业务开发中经常有可能读取一些自定义配置或者文件。比如说公私钥文件、一些固定的词典文件之类的，这一类统称为资源（Resource）。Spring自带有资源加载功能，甚至还有非常便利的方法将读取的内容注入Spring bean。 整理网络上相关方法与自身实践的实践 通过Resource接口读取文件我们可以使用org.springframework.core.io.Resource接口简化资源文件的定位。Spring帮助我们使用资源加载器查找和读取资源，资源加载器根据提供的路径决定选择哪个Resource实现。 使用Resource的实现类 org.springframework.core.io.Resource接口常用的有两个实现类： org.springframework.core.io.ClassPathResource 用来加载classpath下的资源，直接读取springboot 配置文件 application.properties,其中已经写入了一个配置 server.port=8080 @Test public void classPathResourceTest() throws IOException { Resource resource = new ClassPathResource(\"application.properties\"); InputStream inputStream = resource.getInputStream(); Properties properties = new Properties(); properties.load(inputStream); properties.forEach((o, o2) -> { Assertions.assertThat(o).isEqualTo(\"server.address\"); Assertions.assertThat(o2).isEqualTo(\"8080\"); }); } org.springframework.core.io.FileSystemResource 用来加载系统文件，通常通过文件的绝对值或者相对路径来读取。需要文件的路径。 @Test public void fileResourceTest() throws IOException { String path = \"/workspaces/springboot-demo/src/main/resources/application.properties\"; FileSystemResource resource = new FileSystemResource(path); InputStream inputStream = resource.getInputStream(); Properties properties = new Properties(); properties.load(inputStream); properties.forEach((o,o2) -> { Assertions.assertThat(o).isEqualTo(\"server.adderss\"); Assertions.assertThat(o2).isEqualTo(\"8080\"); }); } 使用ResourceLoader使用ResourceLoader可以实现延迟加载： @Test public void resourceLoaderTest() throws IOException { ResourceLoader resourceLoader = new DefaultResourceLoader(); String location = \"application.properties\"; Resource resource = resourceLoader.getResource(location); InputStream is = resource.getInputStream(); Properties properties = new Properties(); properties.load(is); properties.forEach((o,o2) -> { Assertions.assertThat(o).isEqualTo(\"server.adderss\"); Assertions.assertThat(o2).isEqualTo(\"8080\"); }); } 可以使用@Autowired将ResourceLoader注入为bean. 使用@Value注解@Value(\"classpath:application.properties\") private Resource resource; @Test public void resourceLoader() throws IOException { InputStream inputStream = resource.getInputStream; Properties properties = new Properties(); properties.load(inputStream); properties.forEach((o,o2) -> { Assertions.assertThat(o).isEqualTo(\"server.adderss\"); Assertions.assertThat(o2).isEqualTo(\"8080\"); }); } 总结^_^.","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"}]},{"title":"Maven中Scope的分类","date":"2019-05-04T10:52:02.000Z","path":"2019/05/04/375e8475.html","text":"Scope的分类compile默认就是compile，什么都不配置也就是意味着compile。compile表示被依赖项目需要参与当前项目的编译，当然后续的测试，运行周期也参与其中，是一个比较强的依赖。打包的时候通常需要包含进去。 testscope为test表示依赖项目仅仅参与测试相关的工作，包括测试代码的编译，执行。比较典型的如junit。 runntimerunntime表示被依赖项目无需参与项目的编译，不过后期的测试和运行周期需要其参与。与compile相比，跳过编译而已，说实话在终端的项目（非开源，企业内部系统）中，和compile区别不是很大。比较常见的如JSR×××的实现，对应的API jar是compile的，具体实现是runtime的，compile只需要知道接口就足够了。oracle jdbc驱动架包就是一个很好的例子，一般scope为runntime。另外runntime的依赖通常和optional搭配使用，optional为true。我可以用A实现，也可以用B实现。 providedprovided意味着打包的时候可以不用包进去，别的设施(Web Container)会提供。事实上该依赖理论上可以参与编译，测试，运行等周期。相当于compile，但是在打包阶段做了exclude的动作。 system从参与度来说，也provided相同，不过被依赖项不会从maven仓库抓，而是从本地文件系统拿，一定需要配合systemPath属性使用。 scope的依赖传递A–&gt;B–&gt;C。当前项目为A，A依赖于B，B依赖于C。知道B在A项目中的scope，那么怎么知道C在A中的scope呢？答案是： 当C是test或者provided时，C直接被丢弃，A不依赖C； 否则A依赖C，C的scope继承于B的scope。 import在做SpringBoot应用的时候，都会有如下代码： &lt;parent> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-parent&lt;/artifactId> &lt;version>1.3.3.RELEASE&lt;/version> &lt;/parent> 继承一个父模块，然后再引入相应的依赖。 但是一般来说，自己的项目不会用springboot作为父maven；Maven的继承和Java的继承一样，是无法实现多重继承的，如果10个、20个甚至更多模块继承自同一个模块，那么按照我们之前的做法，这个父模块的dependencyManagement会包含大量的依赖。如果你想把这些依赖分类以更清晰的管理，那就不可能了，import scope依赖能解决这个问题。你可以把dependencyManagement放到单独的专门用来管理依赖的pom中，然后在需要使用依赖的模块中通过import scope依赖，就可以引入dependencyManagement。例如可以写这样一个用于依赖管理的pom： &lt;project> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;groupId>com.test.sample&lt;/groupId> &lt;artifactId>base-parent1&lt;/artifactId> &lt;packaging>pom&lt;/packaging> &lt;version>1.0.0-SNAPSHOT&lt;/version> &lt;dependencyManagement> &lt;dependencies> &lt;dependency> &lt;groupId>junit&lt;/groupId> &lt;artifactid>junit&lt;/artifactId> &lt;version>4.8.2&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>log4j&lt;/groupId> &lt;artifactid>log4j&lt;/artifactId> &lt;version>1.2.16&lt;/version> &lt;/dependency> &lt;/dependencies> &lt;/dependencyManagement> &lt;/project> 然后我就可以通过非继承的方式来引入这段依赖管理配置 &lt;dependencyManagement> &lt;dependencies> &lt;dependency> &lt;groupId>com.test.sample&lt;/groupId> &lt;artifactid>base-parent1&lt;/artifactId> &lt;version>1.0.0-SNAPSHOT&lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> &lt;/dependencies> &lt;/dependencyManagement> &lt;dependency> &lt;groupId>junit&lt;/groupId> &lt;artifactid>junit&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>log4j&lt;/groupId> &lt;artifactid>log4j&lt;/artifactId> &lt;/dependency> 注意：import scope只能用在dependencyManagement里面 父模块的pom就会非常干净，由专门的packaging为pom来管理依赖，也契合的面向对象设计中的单一职责原则。此外，还能够创建多个这样的依赖管理pom，以更细化的方式管理依赖。这种做法与面向对象设计中使用组合而非继承也有点相似的味道。 用这个方法来解决SpringBoot的那个继承问题： &lt;dependencyManagement> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-dependencies&lt;/artifactId> &lt;version>1.3.3.RELEASE&lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> &lt;/dependencies> &lt;/dependencyManagement> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;/dependencies> 这样配置的话，自己的项目里面就不需要继承SpringBoot的module了，而可以继承自己项目的module了。","tags":[{"name":"Maven","slug":"Maven","permalink":"https://www.cayzlh.com/tags/Maven/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"},{"name":"Maven","slug":"Java/Maven","permalink":"https://www.cayzlh.com/categories/Java/Maven/"}]},{"title":"Springboot集成Shiro（前后端分离）","date":"2019-04-30T13:01:28.000Z","path":"2019/04/30/18d925c2.html","text":"思维导图 什么是Shiroshiro是apache的一个开源框架，是一个权限管理的框架，实现 用户认证、用户授权。 spring中有spring security (原名Acegi)，是一个权限框架，它和spring依赖过于紧密，没有shiro使用简单。 shiro不依赖于spring，shiro不仅可以实现 web应用的权限管理，还可以实现c/s系统，分布式系统权限管理，shiro属于轻量框架，越来越多企业项目开始使用shiro。 使用shiro实现系统的权限管理，有效提高开发效率，从而降低开发成本。 用户通过subject登陆，形成一个UsernamePasswordToken，令牌，在域realm里完成认证、授权，成功后加入缓存。（realm可以写、也可以用默认的，也可以写很多个域） Shiro架构 subject：主体，可以是用户也可以是程序，主体要访问系统，系统需要对主体进行认证、授权。 securityManager：安全管理器，主体进行认证和授权都是通过securityManager进行。 authenticator：认证器，主体进行认证最终通过authenticator进行的。 authorizer：授权器，主体进行授权最终通过authorizer进行的。 sessionManager：web应用中一般是用web容器对session进行管理，shiro也提供一套session管理的方式。 SessionDao： 通过SessionDao管理session数据，针对个性化的session数据存储需要使用sessionDao。 cache Manager：缓存管理器，主要对session和授权数据进行缓存，比如将授权数据通过cacheManager进行缓存管理，和ehcache整合对缓存数据进行管理。 realm：域，领域，相当于数据源，通过realm存取认证、授权相关数据。 在realm中存储授权和认证的逻辑。 认证过程 认证执行流程1、通过ini配置文件创建securityManager 2、调用subject.login方法主体提交认证，提交的token 3、securityManager进行认证，securityManager最终由ModularRealmAuthenticator进行认证。 4、ModularRealmAuthenticator调用IniRealm(给realm传入token) 去ini配置文件中查询用户信息 5、IniRealm根据输入的token（UsernamePasswordToken）从 shiro.ini查询用户信息，根据账号查询用户信息（账号和密码） 如果查询到用户信息，就给ModularRealmAuthenticator返回用户信息（账号和密码） 如果查询不到，就给ModularRealmAuthenticator返回null6、ModularRealmAuthenticator接收IniRealm返回Authentication认证信息 如果返回的认证信息是null，ModularRealmAuthenticator抛出异常（org.apache.shiro.authc.UnknownAccountException） 如果返回的认证信息不是null（说明inirealm找到了用户），对IniRealm返回用户密码 （在ini文件中存在）和 token中的密码 进行对比，如果不一致抛出异常（org.apache.shiro.authc.IncorrectCredentialsException） 授权流程 1、对subject进行授权，调用方法isPermitted（”permission串”） 2、SecurityManager执行授权，通过ModularRealmAuthorizer执行授权 3、ModularRealmAuthorizer执行realm（自定义的Realm）从数据库查询权限数据 调用realm的授权方法：doGetAuthorizationInfo 4、realm从数据库查询权限数据，返回ModularRealmAuthorizer 5、ModularRealmAuthorizer调用PermissionResolver进行权限串比对 6、如果比对后，isPermitted中”permission串”在realm查询到权限数据中，说明用户访问permission串有权限，否则 没有权限，抛出异常。 实现 代码地址：https://github.com/cayzlh/spring-boot-shiro-demo 自定义RealmCustRealm： public class CustomRealm extends AuthorizingRealm { @Autowired @Lazy private AuthorizingService authorizingService; /** * Shiro 的权限授权是通过继承AuthorizingRealm抽象类，重载doGetAuthorizationInfo(); * 当访问到页面的时候，链接配置了相应的权限或者 Shiro 标签才会执行此方法否则不会执行， * 所以如果只是简单的身份认证没有权限的控制的话，那么这个方法可以不进行实现，直接返回 null 即可。 * * @param principalCollection * @return */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principalCollection) { String username = (String) super.getAvailablePrincipal(principalCollection); SimpleAuthorizationInfo authorizationInfo = new SimpleAuthorizationInfo(); Set&lt;String> roles = authorizingService.findRoleListByUsername(username); authorizationInfo.setRoles(roles); roles.forEach(role -> { Set&lt;String> permissions = authorizingService.findPermissionsByRole(roles); authorizationInfo.addStringPermissions(permissions); }); return authorizationInfo; } /** * 在认证、授权内部实现机制中都有提到，最终处理都将交给Real进行处理。 * 因为在 Shiro 中，最终是通过 Realm 来获取应用程序中的用户、角色及权限信息的。 * 通常情况下，在 Realm 中会直接从我们的数据源中获取 Shiro 需要的验证信息。 * 可以说，Realm 是专用于安全框架的 DAO. Shiro 的认证过程最终会交由 Realm 执行， * 这时会调用 Realm 的getAuthenticationInfo(token)方法。 * * 该方法主要执行以下操作: * * 1、检查提交的进行认证的令牌信息 * 2、根据令牌信息从数据源(通常为数据库)中获取用户信息 * 3、对用户信息进行匹配验证。 * 4、验证通过将返回一个封装了用户信息的AuthenticationInfo实例。 * 5、验证失败则抛出AuthenticationException异常信息。 * * @param authenticationToken * @return * @throws AuthenticationException */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken authenticationToken) throws AuthenticationException { UsernamePasswordToken token = (UsernamePasswordToken) authenticationToken; String username = token.getUsername(); UserInfo user = authorizingService.selectByUserName(username); if (null == user) { throw new UnknownAccountException(\"doGetAuthenticationInfo() has an UnknownAccountException: \"+username); } String passwordInToken = new String(token.getPassword()); String passwordInDb = user.getPassword(); if (!StringUtils.equals(passwordInDb, passwordInToken)) { throw new IncorrectCredentialsException(\"doGetAuthenticationInfo() has an IncorrectCredentialsException: \"+username); } return new SimpleAuthenticationInfo(username, passwordInToken, ByteSource.Util.bytes(user.getSalt()), getName()); } } 自定义SessionManager在我们项目中， 由于使用前后端分离的架构，所以要自定义Shiro的session管理： public class CustomSessionManager extends DefaultWebSessionManager { private static final String HEADER_TOKEN = \"token\"; private static final String REFERENCED_SESSION_ID_SOURCE = \"Stateless request\"; public CustomSessionManager() { super(); } @Override protected Serializable getSessionId(ServletRequest request, ServletResponse response) { String id = WebUtils.toHttp(request).getHeader(HEADER_TOKEN); if (!StringUtils.isEmpty(id)) { request.setAttribute(ShiroHttpServletRequest.REFERENCED_SESSION_ID_SOURCE, REFERENCED_SESSION_ID_SOURCE); request.setAttribute(ShiroHttpServletRequest.REFERENCED_SESSION_ID, id); request.setAttribute(ShiroHttpServletRequest.REFERENCED_SESSION_ID_IS_VALID, Boolean.TRUE); return id; } else { return super.getSessionId(request, response); } } } 通过监听请求Header里的token字段，如果有值，则作为shiro的sessionid。 配置Shiro@Configuration public class ShiroConfig { @Bean(name = \"customRealm\") public CustomRealm customRealm() { return new CustomRealm(); } @Bean(name = \"sessionManager\") public SessionManager sessionManager() { return new CustomSessionManager(); } @Bean(name = \"securityManager\") public DefaultWebSecurityManager defaultWebSecurityManager() { DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); securityManager.setRealm(customRealm()); securityManager.setSessionManager(sessionManager()); return securityManager; } @Bean(name = \"lifecycleBeanPostProcessor\") public LifecycleBeanPostProcessor lifecycleBeanPostProcessor() { return new LifecycleBeanPostProcessor(); } @Bean(name = \"shiroFilter\") public ShiroFilterFactoryBean shiroFilterFactoryBean(DefaultWebSecurityManager securityManager) { ShiroFilterFactoryBean shiroFilterFactoryBean = new ShiroFilterFactoryBean(); shiroFilterFactoryBean.setSecurityManager(securityManager); return shiroFilterFactoryBean; } @Bean public DefaultAdvisorAutoProxyCreator advisorAutoProxyCreator(){ DefaultAdvisorAutoProxyCreator advisorAutoProxyCreator = new DefaultAdvisorAutoProxyCreator(); advisorAutoProxyCreator.setProxyTargetClass(true); return advisorAutoProxyCreator; } @Bean public AuthorizationAttributeSourceAdvisor authorizationAttributeSourceAdvisor(DefaultWebSecurityManager securityManager) { AuthorizationAttributeSourceAdvisor authorizationAttributeSourceAdvisor = new AuthorizationAttributeSourceAdvisor(); authorizationAttributeSourceAdvisor.setSecurityManager(securityManager); return authorizationAttributeSourceAdvisor; } } 其中： @Bean public DefaultAdvisorAutoProxyCreator advisorAutoProxyCreator(){ DefaultAdvisorAutoProxyCreator advisorAutoProxyCreator = new DefaultAdvisorAutoProxyCreator(); advisorAutoProxyCreator.setProxyTargetClass(true); return advisorAutoProxyCreator; } @Bean public AuthorizationAttributeSourceAdvisor authorizationAttributeSourceAdvisor(DefaultWebSecurityManager securityManager) { AuthorizationAttributeSourceAdvisor authorizationAttributeSourceAdvisor = new AuthorizationAttributeSourceAdvisor(); authorizationAttributeSourceAdvisor.setSecurityManager(securityManager); return authorizationAttributeSourceAdvisor; } 在spring boot中， shiro使用@RequiresRoles,@RequiresPermissions注解无效时，需要添加这两个配置。 其他代码AuthorizingService： @Service public class AuthorizingService { @Autowired private UserDao userDao; @Autowired private RoleDao roleDao; @Autowired private PermissionDao permissionDao; public UserInfo selectByUserName(String username) { return userDao.selectByUsername(username); } public Set&lt;String> findRoleListByUsername(String username) { return roleDao.selectByUsername(username); } public Set&lt;String> findPermissionsByRole(Set&lt;String> roles) { HashSet&lt;String> permissions = Sets.newHashSet(); roles.forEach(role -> permissions.addAll(permissionDao.selectByRole(role))); return permissions; } public String login(String username, String password) { UsernamePasswordToken token = new UsernamePasswordToken(username, password); Subject currentUser = SecurityUtils.getSubject(); currentUser.login(token); currentUser.getSession().setTimeout(60 * 60 * 1000); return currentUser.getSession().getId().toString(); } public void logout() { Subject currentUser = SecurityUtils.getSubject(); currentUser.logout(); } } PermissionDao： @Repository public class PermissionDao { public Set&lt;String> selectByRole(String role) { switch (role) { case \"admin\": return Sets.newHashSet(\"Idea\", \"navicat\", \"notepad\", \"webstorm\", \"chrome\"); case \"java\": return Sets.newHashSet(\"Idea\"); case \"mysql\": return Sets.newHashSet(\"navicat\"); case \"html\": return Sets.newHashSet(\"notepad\"); case \"javascript\": return Sets.newHashSet(\"webstorm\"); case \"guest\": return Sets.newHashSet(\"chrome\"); default: return Sets.newHashSet(); } } } RoleDao： @Repository public class RoleDao { public Set&lt;String> selectByUsername(String username) { switch (username) { case \"zhangsan\": return Sets.newHashSet(\"admin\"); case \"lisi\": return Sets.newHashSet(\"java\", \"mysql\"); case \"wangwu\": return Sets.newHashSet(\"html\", \"javascript\"); default: return Sets.newHashSet(\"guest\"); } } } UserDao： @Repository public class UserDao { public UserInfo selectByUsername(String username) { switch (username) { case \"zhangsan\": return UserInfo.builder() .userName(\"zhangsan\").password(\"123456\").salt(\"123456\") .build(); case \"lisi\": return UserInfo.builder() .userName(\"lisi\").password(\"123456\").salt(\"123456\") .build(); case \"wangwu\": return UserInfo.builder() .userName(\"wangwu\").password(\"123456\").salt(\"123456\") .build(); default: return null; } } } 这里没有使用数据库， 直接模拟数据库操作。 集群 在实际项目运行中，为了达到高可用的目的，通常要把应用部署在多台服务器上，这个时候就要对session进行集群的管理 添加redis支持pom.xml &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-data-redis&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>redis.clients&lt;/groupId> &lt;artifactId>jedis&lt;/artifactId> &lt;/dependency> 配置文件spring: application: name: shiro-demo redis: host: redistest.xxxx.com port: 6379 database: 10 password: test@2018 timeout: 180000 jedis: pool: max-active: 100 max-wait: 360000 min-idle: 0 max-idle: 100 my: shiro: session: expireTime: 1800 prefix: you-shiro-session 新增Java类：ShiroCacheManagerpublic class ShiroCacheManager implements CacheManager { private RedisTemplate redisTemplate; private int expireTime; @Override public &lt;K, V> Cache&lt;K, V> getCache(String name) throws CacheException { return new ShiroRedisCache&lt;>(name, redisTemplate, expireTime); } public ShiroCacheManager(RedisTemplate redisTemplate, int expireTime) { this.redisTemplate = redisTemplate; this.expireTime = expireTime; } public class ShiroRedisCache&lt;K, V> implements Cache&lt;K, V> { private String cacheKey; private RedisTemplate redisTemplate; private int expireTime; private ShiroRedisCache(String cacheKey, RedisTemplate redisTemplate, int expireTime) { this.cacheKey = cacheKey; this.redisTemplate = redisTemplate; this.expireTime = expireTime; } private Object hashKey(K key) { if (key instanceof PrincipalCollection) { PrincipalCollection principalCollection = (PrincipalCollection) key; return principalCollection.getPrimaryPrincipal().toString(); } return key; } @Override public V get(K key) throws CacheException { BoundHashOperations&lt;String, K, V> boundHashOperations = redisTemplate.boundHashOps(cacheKey); Object realKey = hashKey(key); return boundHashOperations.get(realKey); } @Override public V put(K key, V value) throws CacheException { BoundHashOperations&lt;String, K, V> boundHashOperations = redisTemplate.boundHashOps(cacheKey); Object realKey = hashKey(key); boundHashOperations.put((K) realKey, value); boundHashOperations.expire(expireTime, TimeUnit.SECONDS); return value; } @Override public V remove(K key) throws CacheException { BoundHashOperations&lt;String, K, V> boundHashOperations = redisTemplate.boundHashOps(cacheKey); Object realKey = hashKey(key); V value = boundHashOperations.get(realKey); boundHashOperations.delete(realKey); return value; } @Override public void clear() throws CacheException { redisTemplate.delete(cacheKey); } @Override public int size() { BoundHashOperations&lt;String, K, V> boundHashOperations = redisTemplate.boundHashOps(cacheKey); return boundHashOperations.size().intValue(); } @Override public Set&lt;K> keys() { BoundHashOperations&lt;String, K, V> boundHashOperations = redisTemplate.boundHashOps(cacheKey); return boundHashOperations.keys(); } @Override public Collection&lt;V> values() { BoundHashOperations&lt;String, K, V> boundHashOperations = redisTemplate.boundHashOps(cacheKey); return boundHashOperations.values(); } } } 新增java类：RedisSessionDAO，继承EnterpriseCacheSessionDAOpublic class RedisSessionDAO extends EnterpriseCacheSessionDAO { private int expireTime; private String prefix; private RedisTemplate redisTemplate; public RedisSessionDAO(RedisTemplate redisTemplate, int expireTime, String prefix) { this.redisTemplate = redisTemplate; this.expireTime = expireTime; this.prefix = prefix; } @Override protected Serializable doCreate(Session session) { log.info(\"doCreate({})\", session.getId()); Serializable sessionId = super.doCreate(session); redisTemplate.opsForValue().set(prefix + \":\" + sessionId.toString(), session); return sessionId; } @Override protected Session doReadSession(Serializable sessionId) { log.info(\"doReadSession({})\", sessionId); Session session = super.doReadSession(sessionId); if (session == null) { session = (Session) redisTemplate.opsForValue().get(prefix + \":\" + sessionId.toString()); } return session; } @Override protected void doUpdate(Session session) { super.doUpdate(session); String key = prefix + \":\" + session.getId().toString(); if (!redisTemplate.hasKey(key)) { redisTemplate.opsForValue().set(key, session); } redisTemplate.expire(key, expireTime, TimeUnit.SECONDS); } @Override protected void doDelete(Session session) { log.info(\"doDelete({})\", session.getId()); super.doDelete(session); redisTemplate.delete(prefix + \":\" + session.getId().toString()); } } 新增Java类：RedisObjectSerializer implements RedisSerializerpublic class RedisObjectSerializer implements RedisSerializer&lt;Object> { private Converter&lt;Object, byte[]> serializer = new SerializingConverter(); private Converter&lt;byte[], Object> deserializer = new DeserializingConverter(); static final byte[] EMPTY_ARRAY = new byte[0]; @Override public Object deserialize(byte[] bytes) { if (isEmpty(bytes)) { return null; } try { return deserializer.convert(bytes); } catch (Exception ex) { throw new SerializationException(\"Cannot deserialize\", ex); } } @Override public byte[] serialize(Object object) { if (object == null) { return EMPTY_ARRAY; } try { return serializer.convert(object); } catch (Exception ex) { return EMPTY_ARRAY; } } private boolean isEmpty(byte[] data) { return (data == null || data.length == 0); } } 修改ShiroConfig@Configuration public class ShiroConfig implements InitializingBean { @Value(\"${my.shiro.session.expireTime:1800}\") private int expireTime; @Value(\"${my.shiro.session.prefix:you-shiro-session}\") private String prefix; @Autowired private RedisTemplate redisTemplate; @Override public void afterPropertiesSet() { ParserConfig.getGlobalInstance().setAutoTypeSupport(true); redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setValueSerializer(new RedisObjectSerializer()); redisTemplate.afterPropertiesSet(); } @Bean public RedisTemplate redisTemplate() { return new RedisTemplate(); } @Bean(name = \"shiroCacheManager\") public ShiroCacheManager shiroCacheManager() { return new ShiroCacheManager(redisTemplate, expireTime); } @Bean(name = \"redisSessionDAO\") public RedisSessionDAO redisSessionDAO() { return new RedisSessionDAO(redisTemplate, expireTime, prefix); } @Bean(name = \"customRealm\") public CustomRealm customRealm() { return new CustomRealm(); } @Bean(name = \"sessionManager\") public SessionManager sessionManager() { CustomSessionManager sessionManager = new CustomSessionManager(); sessionManager.setSessionDAO(redisSessionDAO()); return sessionManager; } @Bean(name = \"securityManager\") public DefaultWebSecurityManager defaultWebSecurityManager() { DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); securityManager.setRealm(customRealm()); securityManager.setCacheManager(shiroCacheManager()); securityManager.setSessionManager(sessionManager()); return securityManager; } @Bean(name = \"lifecycleBeanPostProcessor\") public LifecycleBeanPostProcessor lifecycleBeanPostProcessor() { return new LifecycleBeanPostProcessor(); } @Bean(name = \"shiroFilter\") public ShiroFilterFactoryBean shiroFilterFactoryBean(DefaultWebSecurityManager securityManager) { ShiroFilterFactoryBean shiroFilterFactoryBean = new ShiroFilterFactoryBean(); shiroFilterFactoryBean.setSecurityManager(securityManager); return shiroFilterFactoryBean; } @Bean public DefaultAdvisorAutoProxyCreator advisorAutoProxyCreator(){ DefaultAdvisorAutoProxyCreator advisorAutoProxyCreator = new DefaultAdvisorAutoProxyCreator(); advisorAutoProxyCreator.setProxyTargetClass(true); return advisorAutoProxyCreator; } @Bean public AuthorizationAttributeSourceAdvisor authorizationAttributeSourceAdvisor(DefaultWebSecurityManager securityManager) { AuthorizationAttributeSourceAdvisor authorizationAttributeSourceAdvisor = new AuthorizationAttributeSourceAdvisor(); authorizationAttributeSourceAdvisor.setSecurityManager(securityManager); return authorizationAttributeSourceAdvisor; } } 集群完成^_^. 经过以上改造，shiro就可以在分布式应用中集群使用。 项目代码，在 with-redis 分支中。 测试运行Demo，测试登录和请求其他接口： –","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cayzlh.com/tags/SpringBoot/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"https://www.cayzlh.com/categories/Spring/SpringBoot/"}]},{"title":"Java设计模式之代理模式","date":"2019-04-02T12:14:47.000Z","path":"2019/04/02/ae152a83.html","text":"以下文章内容来源：微信公众号（Java知音）文章，设计模式是什么鬼（代理） 生活中还有很多其他实例不胜枚举，但对于做技术的我们，以网络代理举例相信是最合适不过了。 首先，我们上网前得去网络服务提供商（ISP）申请互联网宽带业务，于是顺理成章光纤入户，并拿到一个调制解调器，也就是我们俗称的“猫”。好，“猫”实现了互联网访问接口，看代码。 public interface Internet {//互联网访问接口 public void access(String url); } public class Modem implements Internet {//调制解调器 @Override public void access(String url){//实现互联网访问接口 System.out.println(\"正在访问：\" + url); } } 作为调制解调器，一定有上网功能了，用户的电脑只需要用网线连接这只“猫”便接入互联网了。就这么简单么？然而某天我们发现孩子学习时总是偷偷上网看电影玩游戏，于是我们决定对某些网站进行过滤，拒绝黄赌毒侵害未成年。那么，我们需要在客户终端电脑与猫之间加一层代理，用于过滤某些不良网站，最终我们决定购买一款有过滤功能的路由器。 public class RouterProxy implements Internet {//路由器代理类 private Internet modem;//持有被代理类引用 private List&lt;String> blackList = Arrays.asList(\"电影\", \"游戏\", \"音乐\", \"小说\"); public RouterProxy() { this.modem = new Modem();//实例化被代理类 System.out.println(\"拨号上网...连接成功！\"); } @Override public void access(String url) {//同样实现互联网访问接口方法 for (String keyword : blackList) {//循环黑名单 if (url.contains(keyword)) {//是否包含黑名单字眼 System.out.println(\"禁止访问：\" + url); return; } } modem.access(url);//正常访问互联网 } } 注意看，在这里路由器代理主要充当代理的角色，和之前的“猫”一样，它同样实现了互联网接口，看似也是有上网功能的，其实不然。第12行代码对于互联网访问功能的实现一开始就做了个过滤，如果地址中带有黑名单中的敏感字眼则禁止访问并直接退出，反之则于第19行调用“猫”的互联网访问方法，看到了吧，最终还是调用“猫”的上网功能。注意此处为了对“猫”进行控制，代理专为此而生，我们直接于第7行实例化它而不是需要别人把它注入进来。好了，孩子现在来上网了，迫不及待运行之。 public class Client { public static void main(String[] args) { Internet proxy = new RouterProxy();//实例化的是代理 proxy.access(\"http://www.电影.com\"); proxy.access(\"http://www.游戏.com\"); proxy.access(\"ftp://www.学习.com/java\"); proxy.access(\"http://www.工作.com\"); /* 运行结果 拨号上网...连接成功！ 禁止访问：http://www.电影.com 禁止访问：http://www.游戏.com 正在访问：ftp://www.学习.com/java 正在访问：http://www.工作.com */ } } 在第3行处，孩子实例化的不再是“猫”，而是被偷梁换柱的替换为路由器代理了，也就是说大家上网都连接路由器了，而不是直接去连“猫”，这样不但省去了我们拨号的麻烦（路由器帮助拨号）而且孩子再也访问不到乱七八糟的网站了。而这个代理自身其实并不具备访问互联网的能力，它只是简单的调用“猫”上网功能，其存在目的只是为了控制对”猫“的互联访问，对其进行代理而已。 代理模式更强调的是对被代理对象的控制，而不是仅限于去装饰目标对象并增强其原有的功能。就像明星的例子一样，如果钱没给够，合同未达成，则不让明星随意作秀。 相信大家已经理解地很通透了吧，这也是我们最常用的代理模式了。其实还有一种叫动态代理，不同之处在于其实例化过程是在运行时完成的，也就是说我们不需要专门针对某个接口去写这么一个代理类，而是根据接口动态生成。 举个例子，让我们先忘掉之前的路由器代理，当我们内网中的上网设备越来越多，路由器的Lan口已被占满不够用了，于是我们决定换成交换机，看代码。 public interface Intranet {//局域网访问接口 public void fileAccess(String path); } 为了保持简单，我们假设这个交换机Switch实现了局域网访问接口Intranet，请注意这里不是互联网接口Internet。 public class Switch implements Intranet { @Override public void fileAccess(String path){ System.out.println(\"访问内网：\" + path); } } 这里进行的是局域网文件访问，比如说是拷贝另一台内网机器上的共享文件，并且我们想保证与之前一样的关键字过滤控制功能，也就是说不管是什么地址都要先通过过滤。 到这里让我们思考一下，猫实现的是互联网访问接口，交换机实现的是局域网访问接口，那我们的过滤器代理类到底该怎么写？是实现Internet接口呢还是实现Intranet接口呢？要么两个都实现？再加进来新的类接口又要不停地改实现类吗？这显然行不通，过滤器无非就是一段过滤逻辑不必来回改动，这违反了设计模式开闭原则。动态代理应时而生，我们来看代码。 public class KeywordFilter implements InvocationHandler { private List&lt;String> blackList = Arrays.asList(\"电影\", \"游戏\", \"音乐\", \"小说\"); // 被代理的真实对象,猫、交换机、或是别的什么都是。 private Object origin; public KeywordFilter(Object origin) { this.origin = origin;//注入被代理对象 System.out.println(\"开启关键字过滤模式...\"); } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { //要被切入方法面之前的业务逻辑 String arg = args[0].toString(); for (String keyword : blackList) { if (arg.toString().contains(keyword)) { System.out.println(\"禁止访问：\" + arg); return null; } } //调用真实的被代理对象方法 return method.invoke(origin, arg); } } 对于这个关键字过滤功能我们不再写到代理类里面了，而是另外写个类并实现JDK反射包中提供的InvocationHandler接口，于第9行注入即将被代理的对象，不管是猫还是交换机什么的它总归是个Object，然后在第14行实现这个invoke调用方法，之后生成的动态代理将来会调进来跑这块的逻辑，很显然我们这里依然保持不变的逻辑，在真实对象方法被执行之前运行了过滤逻辑加以控制。由于传入的参数是被代理对象的方法method，以及一堆参数args，所以注意这里第24行我们要用反射去调用被代理对象origin了，最后来看我们如何运行。 public class Client { public static void main(String[] args) { //访问外网（互联网）,生成猫代理。 Internet internet = (Internet) Proxy.newProxyInstance( Modem.class.getClassLoader(), Modem.class.getInterfaces(), new KeywordFilter(new Modem())); internet.access(\"http://www.电影.com\"); internet.access(\"http://www.游戏.com\"); internet.access(\"http://www.学习.com\"); internet.access(\"http://www.工作.com\"); //访问内网（局域网），生成交换机代理。 Intranet intranet = (Intranet) Proxy.newProxyInstance( Switch.class.getClassLoader(), Switch.class.getInterfaces(), new KeywordFilter(new Switch())); intranet.fileAccess(\"\\\\\\\\192.68.1.2\\\\共享\\\\电影\\\\IronHuman.mp4\"); intranet.fileAccess(\"\\\\\\\\192.68.1.2\\\\共享\\\\游戏\\\\Hero.exe\"); intranet.fileAccess(\"\\\\\\\\192.68.1.4\\\\shared\\\\Java学习资料.zip\"); intranet.fileAccess(\"\\\\\\\\192.68.1.6\\\\Java知音\\\\设计模式是什么鬼.doc\"); /* 开启关键字过滤模式... 禁止访问：http://www.电影.com 禁止访问：http://www.游戏.com 正在访问：http://www.学习.com 正在访问：http://www.工作.com 开启关键字过滤模式... 禁止访问：\\\\192.68.1.2\\共享\\电影\\IronHuman.mp4 禁止访问：\\\\192.68.1.2\\共享\\游戏\\Hero.exe 访问内网：\\\\192.68.1.4\\shared\\Java学习资料.zip 访问内网：\\\\192.68.1.6\\Java知音\\设计模式是什么鬼.doc */ } } 可以看到，我们不管是访问互联网还是局域网，只需要分别生成相应的代理并调用即可，相同的过滤器逻辑被执行了。如此一来，我们并不需要再写任何的代理类了，只需要实现一次InvocationHandler就一劳永逸了，在运行时去动态地生成代理，达到兼容任何接口的目的。 其实在很多框架中大量应用到了动态代理模式，比如Spring的面向切面AOP，我们只需要定义好一个切面类@Aspect，声明其切入点@Pointcut（被代理的哪些对象的哪些方法，也就是这里的猫和交换机的access以及accessFile），以及被切入的代码块（要增加上去的逻辑，比如这里的过滤功能代码，可分为前置执行@Before，后置执行@After，以及异常处理@AfterThrowing等），于是框架自动帮我们生成代理并切入目标执行。正如给每给方法前后加入日志的例子，或者更经典的事务控制的例子，在所有业务代码之前先切入“事务开始”，执行过后再切入“事务提交”，如果抛异常被捕获则执行“事务回滚”，如此就不必要在每个业务类中去写这些重复代码了，一劳永逸，冗余代码大量减少，开发效率惊人提升。","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"设计模式","slug":"设计模式","permalink":"https://www.cayzlh.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"},{"name":"Java设计模式","slug":"Java/Java设计模式","permalink":"https://www.cayzlh.com/categories/Java/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Java设计模式之享元模式","date":"2019-03-23T12:02:33.000Z","path":"2019/03/23/34d98dd9.html","text":"以下文章内容来源：微信公众号（Java知音）文章，设计模式是什么鬼（享元） 首先来看一个实例，比如我们要开发一款RPG游戏，游戏地图通常非常大，而且有各种各样，有草地、沙漠、荒原，水路等等，在写代码之前，我们先思考下应该怎样去建模。 对于这种地图，我们加载一整张图片来做地图？如果地图太大，图片加载相当卡顿吧？而且大片地图上其实都是重复的图片素材，整图加载设计也有失灵活性。再仔细观察下，这地图无非就是很多小图片（元）拼起来的哦，这不就是类似于我们装修时贴马赛克嘛？ 简单的实现方法，我们有个砖块类，持有“图片”，“位置”等属性信息，然后实例化这些砖块再调用其“绘制”方法把图片显示在地图某位置上即可。 public class Tile { private String image;//地砖所用的图片材质 private int x, y;//地砖所在坐标 public Tile(String image, int x, int y) { this.image = image; System.out.print(\"从磁盘加载[\" + image + \"]图片，耗时半秒。。。\"); this.x = x; this.y = y; } public void draw() { System.out.println(\"在位置[\" + x + \":\" + y + \"]上绘制图片：[\" + image + \"]\"); } } 代码看起来非常简单，第3行的地砖材质图片我们用String来模拟代替，第7行初始化时我们把图片加载到内存，比如说这个IO操作要耗费半秒时间，好了我们先测试绘制第一行砖块，运行一下。 public class Client { public static void main(String[] args) { //以绘制第一行为例 new Tile(\"河流\", 10, 10).draw(); new Tile(\"河流\", 10, 20).draw(); new Tile(\"石路\", 10, 30).draw(); new Tile(\"草坪\", 10, 40).draw(); new Tile(\"草坪\", 10, 50).draw(); new Tile(\"草坪\", 10, 60).draw(); new Tile(\"草坪\", 10, 70).draw(); new Tile(\"草坪\", 10, 80).draw(); /* 运行结果 从磁盘加载[河流]图片，耗时半秒。。。在位置[10:10]上绘制图片：[河流] 从磁盘加载[河流]图片，耗时半秒。。。在位置[10:20]上绘制图片：[河流] 从磁盘加载[石路]图片，耗时半秒。。。在位置[10:30]上绘制图片：[石路] 从磁盘加载[草坪]图片，耗时半秒。。。在位置[10:40]上绘制图片：[草坪] 从磁盘加载[草坪]图片，耗时半秒。。。在位置[10:50]上绘制图片：[草坪] 从磁盘加载[草坪]图片，耗时半秒。。。在位置[10:60]上绘制图片：[草坪] 从磁盘加载[草坪]图片，耗时半秒。。。在位置[10:70]上绘制图片：[草坪] 从磁盘加载[草坪]图片，耗时半秒。。。在位置[10:80]上绘制图片：[草坪] */ } } 有没有发现问题？每加载一张图都要耗费掉半秒钟，才画了8张地砖图就4秒钟流逝了，如果构建整张地图得多少时间？这就像是在慢性自杀，如此效率严重影响了游戏的用户体验，光卡顿在地图加载这给漫长的过程就已经让玩家失去兴趣了。 这个场景很容易想到用原型模式来实现，把相同的图共享出来，用克隆的方式代替物件图实例化的过程，从而加快初始化速度。共享元貌似没什么问题，速度也加快了，但对象数量貌似还是个严重问题，每一个小物件图都要对应一个对象，这么个小游戏用得着那么大的内存开销么，搞不好甚至会造成内存溢出，所以，设计模式一定还是有问题。 沿着共享的思路我们再看下到底需不需要这么多对象？这些对象不同的地方在于其坐标的不同，再就是材质的不同，也就是图的不同了，能不能从这些对象里抽取出来一些共同点呢？首先每个图的坐标都不一样，是没办法共享的，但是材质图是重复出现的，是可以共享的，同样的材质图会在不同的坐标位置上重复出现，那么这个材质图是可以做成共享元的。 既然坐标不能共享，那就不做为材质类的共享元属性，由客户端维护这些坐标并作为参数传入好了，而且这些材质都有绘制能力，那就先定义一个接口吧。 public interface Drawable { void draw(int x, int y);//绘制方法，接收地图坐标。 } 也可以用抽象类抽出更多的属性和方法代替接口，使子类变得简单，这里为了清晰说明问题就用接口。接下来是材质类们，统统实现这个绘制接口。 public class Water implements Drawable { private String image;//河流图片材质 public Water() { this.image = \"河流\"; System.out.print(\"从磁盘加载[\" + image + \"]图片，耗时半秒。。。\"); } @Override public void draw(int x, int y) { System.out.println(\"在位置[\" + x + \":\" + y + \"]上绘制图片：[\" + image + \"]\"); } } 注意第6行因为是河流材质类，所以初始化我们直接加载河流图片素材，这就是类内部即将做共享的“元”数据了，也叫做“内蕴状态”，至于“外蕴状态”就是坐标了，只作为参数从外部传入不做共享。接下来是草地、石子路等等。 public class Grass implements Drawable { private String image;//草坪图片材质 public Grass() { this.image = \"草坪\"; System.out.print(\"从磁盘加载[\" + image + \"]图片，耗时半秒。。。\"); } @Override public void draw(int x, int y) { System.out.println(\"在位置[\" + x + \":\" + y + \"]上绘制图片：[\" + image + \"]\"); } } public class Stone implements Drawable { private String image;//石路图片材质 public Stone() { this.image = \"石路\"; System.out.print(\"从磁盘加载[\" + image + \"]图片，耗时半秒。。。\"); } @Override public void draw(int x, int y) { System.out.println(\"在位置[\" + x + \":\" + y + \"]上绘制图片：[\" + image + \"]\"); } } public class House implements Drawable { private String image;//房子图片材质 public House() { this.image = \"房子\"; System.out.print(\"从磁盘加载[\" + image + \"]图片，耗时一秒。。。\"); } @Override public void draw(int x, int y) { System.out.println(\"将图层切到最上层。。。\");//房子盖在地上，所以切换到顶层图层。 System.out.println(\"在位置[\" + x + \":\" + y + \"]上绘制图片：[\" + image + \"]\"); } } 注意上面这个的房子类有所不同，它有自己特有的绘制行为方法，也就是在地板图层之上绘制房子，覆盖掉下面的地板，使其变得更加立体。这也就是为什么我们非要用接口或抽象类来做引用，使实现类可以有自己独特的行为方式，多态的好处立竿见影。接下来就是实现“元之共享”的关键了，我们来做一个简单工厂类，看代码。 public class Factory {//图件工厂 private Map&lt;String, Drawable> images;//图库 public Factory() { images = new HashMap&lt;String, Drawable>(); } public Drawable getDrawable(String image) { //缓存里如果没有图件，则实例化并放入缓存。 if(!images.containsKey(image)){ switch (image) { case \"河流\": images.put(image, new Water()); break; case \"草坪\": images.put(image, new Grass()); break; case \"石路\": images.put(image, new Stone()); } } //缓存里必然有图，直接取得并返回。 return images.get(image); } } 这个图件工厂维护着所有元对象的图库，构造方法于第5行会初始化一个哈希图的缓存”池“，当客户端于第8行需要实例化图件的时候，我们先观察这个图库池里存在不存在已实例化过的图件，也就是看有无已做共享的图元，如果没有则实例化并加入图库共享池供下次使用，这便是”元之共享“的秘密了。巧夺天工的设计一气呵成，已经迫不及待去运行了。 public class Client { public static void main(String[] args) { //先实例化图件工厂 Factory factory = new Factory(); //以第一行为例 factory.getDrawable(\"河流\").draw(10, 10); factory.getDrawable(\"河流\").draw(10, 20); factory.getDrawable(\"石路\").draw(10, 30); factory.getDrawable(\"草坪\").draw(10, 40); factory.getDrawable(\"草坪\").draw(10, 50); factory.getDrawable(\"草坪\").draw(10, 60); factory.getDrawable(\"草坪\").draw(10, 70); factory.getDrawable(\"草坪\").draw(10, 80); /*运行结果 从磁盘加载[河流]图片，耗时半秒。。。在位置[10:10]上绘制图片：[河流] 在位置[10:20]上绘制图片：[河流] 从磁盘加载[石路]图片，耗时半秒。。。在位置[10:30]上绘制图片：[石路] 从磁盘加载[草坪]图片，耗时半秒。。。在位置[10:40]上绘制图片：[草坪] 在位置[10:50]上绘制图片：[草坪] 在位置[10:60]上绘制图片：[草坪] 在位置[10:70]上绘制图片：[草坪] 在位置[10:80]上绘制图片：[草坪] */ } } 可以看到，我们抛弃了利用new关键字肆意妄为地制造对象，而是改用这个图件工厂去帮我们把元构建并共享起来。显而易见，我们看到运行结果中每次实例化对象会耗费半秒时间，再次请求对象时就不再会加载图片耗费时间了，也就是从共享图池直接拿到了，不再造次。更妙的是，如果画完整个地图只需要实例化需要用到的某些元素材而已，即使是那个大房子图件也只需要实例化一次就够了。至此，CPU速度，内存轻量化同时做到了优化，整个游戏用户体验得到了极大的提升。 享元的精髓当然重点不止于”享“，更重要的是对于元的辨识，例如那个从外部客户端传入的坐标参数，如果我们依然把坐标也当作共享对象元数据（内蕴状态）的话，那么这个结构将无元可享，大量的对象就如同世界上没有相同的两片树叶一样多不胜数，最终会导致图库池被撑爆，享元将变得毫无意义。所以，对于整个系统数据结构的分析、设计、规划显得尤为重要。","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"设计模式","slug":"设计模式","permalink":"https://www.cayzlh.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"},{"name":"Java设计模式","slug":"Java/Java设计模式","permalink":"https://www.cayzlh.com/categories/Java/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Java设计模式之中介者模式","date":"2019-03-18T09:55:37.000Z","path":"2019/03/18/af3a654f.html","text":"以下文章内容来源：微信公众号（Java知音）文章，设计模式是什么鬼（中介） 中介，作用于多个事物之间充当交互沟通的媒介。我们的生活中有各种各样的媒介，比如一些传统媒体，书刊杂志，报纸，把信息传递给读者。再比如利用电子信息技术的互联网，作为一种新媒体，不单可以更高效地把信息传递给用户，而且可以反向地获得用户反馈评论，用户与用户之间亦可以进行沟通，这种全终端双向互通是传统媒体所不能及的。 除此之外，再如婚介所、房产中介、交换机组网、现代电子商务、C2C购物平台、手机、即时通软件等等，这些都与我们的生活息息相关，离开它们我们将举步维艰。其实不管是任何中介，其本质都是相同的，都是充当中间媒介的角色，并达成多方业务互通的目的。 首先我们以最简单的模型来解决问题，以两个人交谈为例，其实他们之间并不需要任何第三方媒介，而是一对一直接沟通，看代码。 public class People { private String name;//用名字来区别人。 private People other;//持有对方的引用。 public String getName() { return this.name; } public People(String name) { this.name = name;//初始化必须起名。 } public void connect(People other) { this.other = other;//连接方法中注入对方引用。 } public void talk(String msg) { other.listen(msg);//我方说话时，对方聆听。 } public void listen(String msg) { //聆听来自对方的声音 System.out.println( other.getName() + \" 对 \" + this.name + \" 说：\" + msg ); } } 一切就绪，两人开始沟通。 public class Main { public static void main(String args[]) { People p3 = new People(\"张三\"); People p4 = new People(\"李四\"); p3.connect(p4); p4.connect(p3); p3.talk(\"你好。\"); p4.talk(\"早上好，三哥。\"); } /**************************** 输出结果： 张三 对 李四 说：你好。 李四 对 张三 说：早上好，三哥。 *****************************/ } 从People类中我们可以看到，沟通只只能在两人之间进行，而且各自都持有对方对象的引用，以便把消息传递给对方的监听方法。这种模式虽然简单，但耦合性太强，你中有我，我中有你，谁也离不开谁。试想如果再有多个人加入交谈，那每个人都要持有其他所有人的引用了，这时会陷入一种多对多的关联陷阱，对象关系变得复杂不堪，如蛛网般难以维护。 我们就拿群聊天室举例，每当有人加入或离开，都要把每个人持有的其他人的引用关系更新一遍，发消息时更是繁琐不堪，重复工作显得非常多余。那么如何解决这个问题呢？我们开始进行思考，为何不把重复的部分抽离出来呢，也就是把对方的引用放在一个中介类里面去统一维护起来，于是设计更改如下。 可以看到，每个用户不再所持有其他所有用户的引用了，取而代之的是聊天室的引用，这样引用关系瞬间变得明朗起来，开始我们的代码重构。 public class User { private String name;//名字 private ChatRoom chatRoom;//聊天室引用 public User(String name) { this.name = name;//初始化必须起名字 } public String getName() { return this.name; } public void login(ChatRoom chatRoom) {//用户登陆 chatRoom.connect(this);//调用聊天室连接方法 this.chatRoom = chatRoom;//注入聊天室引用 } public void talk(String msg) {//用户发言 chatRoom.sendMsg(this, msg);//给聊天室发消息 } public void listen(User fromWhom, String msg) {//且听风吟 System.out.print(\"【\"+this.name+\"的对话框】\"); System.out.println(fromWhom.getName() + \" 说： \" + msg); } } 可以看到第14行，用户登陆聊天室时不再是连接对方了，而是连接通知聊天室并告知：“有人进来了请进行注册”，然后记录下来用户当前所在聊天室的引用。第19行，用户发言时也不是直接找对方了，而是把消息扔给聊天室处理。第23行，聆听方法同样也是，将来会接受来自聊天室的声音。很显然，一切沟通都与是中介聊天室进行，这样用户之间就实现了解耦的目的。接着写聊天室中介类： public class ChatRoom { private String name;//聊天室命名 public ChatRoom(String name) { this.name = name;//初始化必须命名聊天室 } List&lt;User> users = new ArrayList&lt;>();//聊天室里的用户们 public void connect(User user) { this.users.add(user);//用户进入聊天室加入列表。 System.out.print(\"欢迎【\"); System.out.print(user.getName()); System.out.println(\"】加入聊天室【\" + this.name + \"】\"); } public void sendMsg(User fromWhom, String msg) { // 循环所有用户，只发消息给非发送方fromWhom。 users.stream() .filter(user -> !user.equals(fromWhom))//过滤掉发送方fromWhom .forEach(toWhom -> toWhom.listen(fromWhom, msg));//发送消息给剩下的所有人 } } 这里我们新建一个聊天室作为中介类，所有参与者登陆时调用第10行的connect方法进入聊天室，并记录其引用到users列表中。第17行，当用户发消息到平台我们再转发给其他人，这里利用Java8的流和Lambda表达式进行过滤（User类的equals方法请自行加入），并循环调用所有接收方的listen方法即可。 为了说明问题，我们这里只是保持最简单的方式，如果某天情况变得复杂，有了不同的用户，或是聊天室也各不相同并加入了各自的特性，那我们就需要继续重构，抽象聊天室类，抽象用户类，读者可以灵活运用，这里就不做赘述了。 其实中介模式不止是在生活中广泛应用，在软件架构中也非常常见，当下流行的微服务分布式软件架构所用到的注册中心，例如最常用到的云组件Eureka Server，其作用就是为众多分布式服务提供注册发现服务，它正是充当像中介一样的角色。 中介模式更像是网络拓扑中的星型结构，它描述了众节点与中心点的关系。 对像之间显式地互相引用越多，意味着依赖性越强，独立性越差，不利于代码维护与扩展，同时多方沟通的任务也应交由中间平台来完成，每个类应只具备各自该有的功能，这便是高内聚低耦合的设计标准。中介模式符合迪米特法则，它解决了对象间过度耦合、复杂频繁交互的问题，打破了你中有我，我中有你的相互依赖，第三方的介入有助于双方调停，打破如胶似漆、纠缠不休的关系，让他们之间变得松散、自由、独立。","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"设计模式","slug":"设计模式","permalink":"https://www.cayzlh.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"},{"name":"Java设计模式","slug":"Java/Java设计模式","permalink":"https://www.cayzlh.com/categories/Java/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Java设计模式之装饰器模式","date":"2019-03-15T09:36:20.000Z","path":"2019/03/15/e4d55155.html","text":"以下文章内容来源：微信公众号（Java知音）文章，设计模式是什么鬼（装饰） 装饰，在某物件基础上加以修饰，装点，使得原本的朴素变得华丽，达到化腐朽为神奇的效果。比如我们从开发商买来的毛坯房，必然要进行室内装潢这么一项工程，什么简约风啊，北欧风啊，地中海，美式中式等等，当然萝卜青菜各有所爱，每个人装出的房子都各有差异，但不管何种风格，这都是对原本毛坯房的装饰，留给业主按照自己的喜好进行二次加工，这也是为什么有时候毛坯二手房比装修过的要好卖，有成品就一定得有半成品，这样才能把更多的选择留给用户，使得装饰成为可能。 人靠衣装马靠鞍，当然不止是装修有这么神奇的效果，对于女生化妆来说我们也是深有体会，每当女友回家卸妆后素面朝天的时候我们的内心是崩溃的，有种当初相亲被骗的感觉。 显而易见，女友每天出门之前进行的那场洗礼是多么的神圣，多么的不可或缺。诚然，化妆的过程对于男人来说充满了神秘色彩，但对于女人来说更像是一场洗礼，怀揣着信仰与敬畏感进行的一场仪式，最终会像魔法一般把自己的脸变得完美无瑕，更有甚者浓妆艳抹地连毛孔都看不到。 作为研发人员，我们一定不能放过对于这项神秘工程的拆解分析，开始我们的工作。首先每个人要展示自己那必然有一个标准行为show()，我们将它抽象出来作为接口Showable。 public interface Showable { public void show();//定义展示行为 } 当然，女友会这门功夫了，所以实现了此行为并施展其“美丽的脸庞”了，但此时只是原生态的素颜。 public class Girl implements Showable{ @Override public void show() { System.out.print(\"女孩的素颜\"); } } 没什么复杂的，直接调用的话会是素面朝天直面惨淡的人生，这样当然达不到美颜效果了，何以登上人生巅峰。那么接下来要进行化妆了，这里必须依靠一种神秘而又昂贵的东西，化妆品登场了，它同样实现了Showable接口。 public class Decorator implements Showable{//化妆品粉饰器 Showable showable;//持有某个善于展示的家伙 public Decorator(Showable showable) {//构造时注入这个家伙 this.showable = showable; } @Override public void show() { System.out.print(\"粉饰(\");//化妆品粉饰 showable.show();//这家伙素面朝天的秀 System.out.print(\")\");//粉饰打完收工 } } 我们可以发现，在构造化妆品类的时候可以把女孩给注入进来，目的在于调用女孩的show方法，但对于其原本的具体行为装饰器一无所知，并且没有加入任何逻辑限制，它所做的无非是“画龙点睛”，“锦上添花”。接下来我们来运行一下看结果。 public class Client { public static void main(String[] args) { //用装饰器包裹女孩show出来 new Decorator(new Girl()).show(); //结果：粉饰(女孩的素颜) } } 我们可以看到，只需要新建装饰器的时候把女孩给包装进去就得到了粉饰过的美颜，是不是非常简单？然而此时有女朋友会嫌弃了，“只是打粉底这么简单吗？眼霜呢？口红呢……”。 好吧，为了满足女友的要求，我们得再多一些设计。想想看这些化妆品，不管是什么都有共同的特性，也就是说他们统统都可以装饰原生态的素颜展示方法show，那我们何不把这些特性抽象出来呢？开始行动，修改我们的装饰类。 public abstract class Decorator implements Showable{ protected Showable showable; public Decorator(Showable showable) { this.showable = showable; } @Override public void show() { showable.show();//直接调用不做加任何粉饰。 } } 我们把化妆品类给改成抽象类，重写show方法，但不做任何粉饰了，这里我们留给子类具体的某个化妆品去做装饰吧。化妆首先第一步一定要打底了，这里我们首先加入一个粉底类。 public class FoundationMakeup extends Decorator{ public FoundationMakeup(Showable showable) { super(showable);//调用化妆品父类注入 } @Override public void show() { System.out.print(\"打粉底(\"); showable.show(); System.out.print(\")\"); } } 我们可以看到粉底类继承了化妆品类，当然这个粉底的show方法一定要加以修饰了，在原生态的前后都进行了打粉底操作。同样地，打完粉底后再画个口红吧。 public class Lipstick extends Decorator{ public Lipstick(Showable showable) { super(showable); } @Override public void show() { System.out.print(\"涂口红(\"); showable.show(); System.out.print(\")\"); } } 最后，我们把女友、粉底、口红层层包裹起来并运行，结果如愿以偿。 public class Client { public static void main(String[] args) { //口红包裹粉底，再包裹女友。 Showable madeupGirl = new Lipstick(new FoundationMakeup(new Girl())); madeupGirl.show(); //运行结果：涂口红(打粉底(女孩的脸庞)) } } 如果女友对这种淡妆效果还是不满意，我们可以继续添加化妆品类，睫毛膏、眼线、眉笔、腮红等等等等，只需要层层包裹起来，最终实现女友浓妆艳抹的梦想。 我们观察这种装饰器模式结构，是不是似曾相识呢？没错，其实装饰器模式在JDK里就有很多应用，比如Java IO包里的众多流处理类。 new BufferedReader(new InputStreamReader(new FileInputStream(filePath))); 当然，流处理类当然要比我们的例子复杂的多，但其基本思想和我们去繁就简的例子异途同归，这些对象就好像是俄罗斯套娃一样层层包裹，层层装饰，每套一层就会多出一些功能出来，我们更可以自由搭配，实现不同的组合功能。 所以，不管是女生化妆还是程序员写代码，我们都不可能弄出一个巨大的类然后去搞定所有事情，如此代码会越堆积越多，难于维护，功能扩展更是举步维艰。我们都需要有这种设计思想，每个化妆品部件各司其职，不做和自己不相关的事，然后把部件层层叠加，并根据需求组装成型，以达最终的装饰目的。","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"设计模式","slug":"设计模式","permalink":"https://www.cayzlh.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"},{"name":"Java设计模式","slug":"Java/Java设计模式","permalink":"https://www.cayzlh.com/categories/Java/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Java设计模式之门面模式","date":"2019-03-12T09:18:38.000Z","path":"2019/03/12/2ce91e46.html","text":"以下文章内容来源：微信公众号（Java知音）文章，设计模式是什么鬼（门面） 开门见山，门，建筑物的入口，面，脸也。门面（Facade），通常指店铺的门头外表部分，当然一定要临街才是好的商铺，在人流量大的地方营造更好的视觉冲击，这样会有更多等等机会暴露给潜在顾客，否则只能是靠“酒香不怕巷子深”，靠味道来吸引人了。 当然除了光鲜亮丽的外表，更重要的是门店提供的服务了。就拿餐饮来举例吧，如果没有这些门店我们都怎样吃饭呢？我们自己做又不会，算了还是找女友下厨吧。很简单分三步走，首先找菜贩买菜，其次女友下厨，最后吃完洗碗，打完收工代码如下。 public class VegVendor {//菜贩子 public void sell(){ System.out.println(\"菜贩子卖菜。。。\"); } } public class GirlFriend {//女友 public void cook(){ System.out.println(\"女友烹饪。。。\"); } } public class Me { public void eat(){ System.out.println(\"我只会吃。。。\"); } public static void main(String[] args) { //找菜贩子买菜 VegVendor vv = new VegVendor(); vv.sell(); //找女友做饭 GirlFriend gf = new GirlFriend(); gf.cook(); //我只会吃 Me me = new Me(); me.eat(); //谁洗碗呢？一场战场一触即发…… } } 其实我们不该找女友做饭的，而是应该雇一个专业厨师，可这下来得多大花费啊，太划不来了，也许还得我们自己洗碗……哎。其实我们也不想麻烦，还是找门店来解决吧，至于那些买菜啊，烹饪啊，洗碗收拾桌子啊我们统统都不用管了，门店可以进行资源整合与调度，这样我们吃饭就变得如此简单了，只需要付钱就行了，毕竟我们只会吃。 public class Facade { private VegVendor vv; private Chef chef; private Waiter waiter; private Cleaner cleaner; public Facade() { this.vv = new VegVendor(); //开门前就找菜贩子准备好蔬菜 vv.sell(); //当然还得雇佣好各类饭店服务人员 this.chef = new Chef(); this.waiter = new Waiter(); this.cleaner = new Cleaner(); } public void provideService(){ //接待，入座，点菜 waiter.order(); //找厨师做饭 chef.cook(); //上菜 waiter.serve(); //收拾桌子，洗碗，以及其他工序…… cleaner.clean(); cleaner.wash(); } } 这下可爽了，我们再也不用去花费时间去调动那么多资源，又是出门买菜，又是找女友做菜，洗碗擦桌什么的。所以我们急需一个门面来解决这些问题，如果没有门面的话，试想每家每户每顿都做饭的话，于是我们放弃我们的专业优势，整天花很长时间做饭才能不饿肚子，如此劳动分工不明确，社会生产率低下，国家经济生产不景气，最后造成GDP下滑，这就是亚当斯密的劳动分工理论。 总结： 其实这就是门面模式的用法了，门面就是一个大系统，里面封装了很多的子部件（或子系统），部件之间也许有复杂的逻辑关系，对于我们旁观者来说，直接使用这些子部件是非常麻烦的一件事情，所以门面就充当了一个包装类的角色，并且对外暴露一个接口，达到简化客户操作的目的，同时也是对客户端与子系统之间的解耦。","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"设计模式","slug":"设计模式","permalink":"https://www.cayzlh.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"},{"name":"Java设计模式","slug":"Java/Java设计模式","permalink":"https://www.cayzlh.com/categories/Java/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Java设计模式之模板方法","date":"2019-03-08T06:54:47.000Z","path":"2019/03/08/334a0583.html","text":"设计模式`相关文章，用于整理网络中对应的设计模式的一些解读。 面向对象，是对事物属性与行为的封装，方法，指的就是行为。模板方法，显而易见是说某个方法充当了模板的作用，其充分利用了抽象类虚实结合的特性，虚部抽象预留，实部固定延续，以达到将某种固有行为延续至子类的目的。反观接口，则达不到这种目的。要搞明白模板方法，首先我们从接口与抽象类的区别切入。 以下文章内容来源：微信公众号（Java知音）文章，设计模式是什么鬼（模板方法） 模板方法汽车上的接口最常见的就是这几个了：点烟器，USB，AUX等等，很明显这些都是接口，它们都预留了某种标准，暴露在系统外部，并与外设对接。就拿点烟器接口来说吧，它原本是专门用于给点烟器供电的，后来由于这个接口在汽车上的通用性，于是衍生出了各种外部设备，只要是符合这个标准size的，带正负极簧片的，直流12V的，那就可以使用，比如导航、行车记录仪、吸尘器什么的，以及其他各种车载电子设备。 点烟器接口public interface CigarLighterInterface {//点烟器接口 //供电方法，16V直流电 public void electrifyDC16V(); } GPSpublic class GPS implements CigarLighterInterface { //导航的实现 @Override public void electrifyDC16V() { System.out.println(\"连接卫星\"); System.out.println(\"定位。。。\"); } } CigarLighterpublic class CigarLighter implements CigarLighterInterface { //点烟器的实现 @Override public void electrifyDC16V() { int time = 1000; while(--time>0){ System.out.println(\"加热电炉丝\"); } System.out.println(\"点烟器弹出\"); } } 对于点烟器接口来说，它根本不在乎也不知道对接的外设是什么鬼，它只是定义了一种规范，一种标准，只要符合的都可以对接。再比如USB接口的应用更加广泛，外设更是应有尽有。 当然大部分情况我们使用接口会多于抽象类，因为接口灵活啊，抽象类不允许多继承啊等等，其实我们还是要看应用场景，在某种无规矩不成方圆，或者规范比较明确，的情况下抽象类的应用是有必要的，世间万物没有最好的，只有最合适的。","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"设计模式","slug":"设计模式","permalink":"https://www.cayzlh.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"},{"name":"Java设计模式","slug":"Java/Java设计模式","permalink":"https://www.cayzlh.com/categories/Java/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Java设计模式之状态模式","date":"2019-03-01T06:22:45.000Z","path":"2019/03/01/5f8f3de5.html","text":"设计模式`相关文章，用于整理网络中对应的设计模式的一些解读。 举例 以下文字来源于微信公众号（Java知音）文章，设计模式是什么鬼（状态） 状态State，指某事物所处的状况或形态，比如水的三态，零下会变成固态冰，常温会是液态水，100℃会蒸发成气态的水蒸气。 在这个地球生态系统中，水的总量并不会增加，也不会减少，只是随着温度的变化其分子间发生了稀松紧密的变化罢了，于是便有了不同的行为，比如流动、凝固、或是蒸腾，但对于其本质H2O分子对象并没有任何变化，变化的，只是其形态。 当然，事物的状态都是不同的，有的多有的少。物质基本三态，人的精神状态更是非常复杂多变的，喜怒哀乐，五味杂陈。更有趣的是，对于某些患有严重的精神分裂的病人来说，其精神状态更是变化无常，有些竟可以扮演几十种角色，随时间或境遇切换，一会变成精明聪颖的律师，一会是懦弱的失败者总是要自杀，一个境遇触发又是愤怒的杀人暴徒，这人格切换速度，丧心病狂到令人发指。 实例 以下实例来源于微信公众号（Java知音）文章，设计模式是什么鬼（适配器） 开关实现一个开关类，暴露出两个UI可操作接口（对接你的手指）：开、关。 定义一个类吧，就叫它：Switcher好了，对外暴露两个方法：switchOn()以及switchOff()，以便用户调用。 public class Switcher { //false代表关，true代表开 private boolean state = false;//初始状态是关 public void switchOn(){ state = !state; System.out.println(\"OK...灯亮\"); } public void switchOff(){ state = !state; System.out.println(\"OK...灯灭\"); } } 接口设计完成，没有问题了！！当然说这个没问题是在前端UI壳子设计精妙的前提下，但这并不能代表我们的程序设计没问题。如果UI可以重复调用开或者关会出现什么情况？状态乱套了！这个设计是非常不可靠的，我们不能因为表面设计上的完美就忽略了后端代码功能的逻辑正确性，表里不一。这就是为什么我们做应用时不但要做好前端校验（用户体验），更要保证后端校验（功能正确性）不可缺失。 改一下我们之前的设计，这里一定要加入针对当前状态的条件判断，也就是说，开的状态不能再开，关的状态不能再关！ public class Switcher { //false代表关，true代表开 boolean state = false;//初始状态是关 public void switchOn(){ if(state == false){//当前是关状态 state = true; System.out.println(\"OK...灯亮\"); }else{//当前是开状态 System.out.println(\"WARN!!!通电状态无需再开\"); } } public void switchOff(){ if(state == true){//当前是开状态 state = false; System.out.println(\"OK...灯灭\"); }else{//当前是关状态 System.out.println(\"WARN!!!断电状态无需再关\"); } } } 这里加入了逻辑判断，如果重复开或者重复关的话是会告警的，当然这里也可以抛异常出去，我们就不搞那么复杂化了。那对于这样的设计没有问题吧？很显然，逻辑上是跑的通的，写个Client类测试一下。 public class Client { public static void main(String[] args) { Switcher s = new Switcher(); s.switchOff();//WARN!!!断电状态无需再关 s.switchOn();//OK...灯亮 s.switchOff();//OK...灯灭 s.switchOn();//OK...灯亮 s.switchOn();//WARN!!!通电状态无需再开 } } So far，不管熊孩子怎么开开关关都不会有问题了。 自动挡 这样的设计仍然是糟糕的。试想，如果状态不止一种，并且状态切换有及其复杂的逻辑，例如：汽车的自动挡。 汽车的自动挡，按照上面的逻辑来设计，就像如下代码： public class Car { //0：Park驻车档，1：Reverse倒退挡， //2：Neutral空挡，3：Drive前进档。 String state = \"P\";//初始状态是P档 public void push(){//向上推档杆 switch (state) { case \"P\"://驻车档状态 System.out.println(\"WARN!!!到头了推不动了！\"); break; case \"R\"://倒挡状态 state = \"P\"; System.out.println(\"OK...切P档\"); break; case \"N\"://空档状态 System.out.println(\"OK...切R档\"); break; case \"D\"://前进档状态 System.out.println(\"OK...切N档\"); break; default: break; } } public void pull(){//向下拉档杆 //这里省略，逻辑同上类似 } } 这个是在作死了，那一大堆逻辑判断写在宿主类里会越来越像蜘蛛网！我们必须想方设法把这个设计给模块化，把状态模块给独立出来！可以使用策略模式，将算法策略被抽离出来，这里举一反三，把状态也给抽离出来，好了办法有了，我们忘掉自动挡，继续用我们大道至简的开关例子。 public interface State { public void switchOn(Switcher switcher);//开 public void switchOff(Switcher switcher);//关 } 以上我们首先了定义一个状态State接口，两个方法开与关，注意这里与策略模式不同的是，我们为了与宿主Switcher对接所以把它作为参数传入。然后是开状态与关状态的实现。 public class On implements State { @Override public void switchOn(Switcher switcher) { System.out.println(\"WARN!!!通电状态无需再开\"); return; } @Override public void switchOff(Switcher switcher) { switcher.setState(new Off()); System.out.println(\"OK...灯灭\"); } } public class Off implements State { @Override public void switchOn(Switcher switcher) { switcher.setState(new On()); System.out.println(\"OK...灯亮\"); } @Override public void switchOff(Switcher switcher) { System.out.println(\"WARN!!!断电状态无需再关\"); return; } } 显而易见，注意看第10行代码，开状态不能做开行为，只告警并返回，关状态反之亦然。而第4行代码则是合法的行为，所以可以进行状态切换并实施相应行为，也就是说，开状态可关，关状态可开。注意这里是把宿主对象传入进来用于切换其当前状态，亦或是调用宿主的具体功能方法（这里省略用打印输出代替），比如宿主里的一盏灯提供的方法。 至此，一切看起来非常优雅，我们已经成功的将状态从宿主中抽离了，最后再来看宿主开关类是什么样子。 public class Switcher { //开关的初始状态设置为“关” private State state = new Off(); public State getState() { return state; } public void setState(State state) { this.state = state; } public void switchOn(){ state.switchOn(this);//这里调用的是当前状态的开方法 } public void switchOff(){ state.switchOff(this);//这里调用的是当前状态的关方法 } } 甚至我们还可以给里面加一盏灯，像之前我们提到的那样，在State状态接口实现里去调用。 public class Switcher { //...之上代码略... private Lamp lamp; public void lampOn(){ lamp.on(); } public void lampOff(){ lamp.off(); } } 其实它就是策略的一个变种，只不过状态模式会更好的根据当前的状态去实施不同的行为，并且自主切换到另一个正确的状态，开变关，关变开。就好似电梯（虽然是嵌入式面向过程，这里只是举例），用户根本无法随意强制更改其状态以及行为，你让它上，它不一定马上就能上，否则会造成事故。电梯内部封装了多个状态以及对应的逻辑产生不同的行为，它会根据当前状态去自我调整并实施最优方案，以达到安全、高效的目的，这才是可靠的设计。 注意事项：在行为受状态约束的时候使用状态模式，而且状态不超过 5 个。","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"设计模式","slug":"设计模式","permalink":"https://www.cayzlh.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"},{"name":"Java设计模式","slug":"Java/Java设计模式","permalink":"https://www.cayzlh.com/categories/Java/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Java设计模式之策略模式","date":"2019-02-26T05:53:55.000Z","path":"2019/02/26/a7a792e2.html","text":"设计模式相关文章，用于整理网络中对应的设计模式的一些解读。 策略模式在策略模式（Strategy Pattern）中，一个类的行为或其算法可以在运行时更改。这种类型的设计模式属于行为型模式。 在策略模式中，我们创建表示各种策略的对象和一个行为随着策略对象改变而改变的 context 对象。策略对象改变 context 对象的执行算法。 实例 以下实例来源于微信公众号（Java知音）文章，设计模式是什么鬼（策略） 计算器实现一个最简单的计算器，假设只能进行加减法，代码如下： public class Calculator {//违反设计模式原则的做法 public int add(int a, int b){//加法 return a + b; } public int sub(int a, int b){//减法 return a - b; } } 这样写能实现我们的加减法功能，但是往拓展方面想，如果随着我们的算法不断增加，如乘法、除法、次方、开方等等，那么这个计算器类就得不断的改啊改啊，改到最后这个类的代码将会非常庞大。。 抽象既然不能把算法给写死在这里面，那一定要把这个算法给抽象一下，把实现细节从这个类里抽离出来，独立出来成为n个策略，就当下来讲我们一共有俩个策略，一个是加法策略，一个是减法策略，他们实现的都是同一个算法接口，接收参数为操作数a，以及被操作数b。 public interface Strategy {//算法标准 public int calculate(int a, int b);//操作数，被操作数 } 实现加法public class Addition implements Strategy{//实现算法接口 @Override public int calculate(int a, int b) {//加数与被加数 return a + b;//这里我们做加法运算 } } 减法public class Subtraction implements Strategy{//实现算法接口 @Override public int calculate(int a, int b) {//减数与被减数 return a - b;//这里我们做减法运算 } } 实现计算器public class Calculator {//计算器类 private Strategy strategy;//拥有某种算法策略 public void setStrategy(Strategy strategy) {//接入算法策略 this.strategy = strategy; } public int getResult(int a, int b){ return this.strategy.calculate(a, b);//返回具体策略的结果 } } 可以看到，计算器类里已经把之前的具体加减算法实现代码给剥离出去了，要用哪个算法，只需要注入进来，然后获得计算结果getResult实际上调用的是具体算法的calculate。 使用计算器public class Client { public static void main(String[] args) { Calculator calculator = new Calculator();//实例化计算器 calculator.setStrategy(new Addition());//接入加法实现 int result = calculator.getResult(1, 1);//计算！ System.out.println(result);//得到的是加法结果2 calculator.setStrategy(new Subtraction());//再次接入减法实现 result = calculator.getResult(1, 1);//计算！ System.out.println(result);//得到的是减法结果0 } } 这个计算器可以说是具有算法策略扩展性的，以后要有新的算法是不需要再更改任何现有代码的，只需要新写一个算法比如乘法Multiplication，并实现calculate方法，接下来要做的只是组装上去便可以使用了。 总结策略实现类已经成为独立于宿主之外的模块，即插即用。可以组合成为一个整体，又可以分拆独立，可以发生关联，但绝不耦合，既对立又统一，这是唯物辩证法的绝佳体现。","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"设计模式","slug":"设计模式","permalink":"https://www.cayzlh.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"},{"name":"Java设计模式","slug":"Java/Java设计模式","permalink":"https://www.cayzlh.com/categories/Java/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Java设计模式之适配器模式","date":"2019-02-25T02:03:23.000Z","path":"2019/02/25/8ac957b9.html","text":"设计模式相关文章，用于整理网络中对应的设计模式的一些解读。 实例 以下实例来源于微信公众号（Java知音）文章，设计模式是什么鬼（适配器） 顾名思义，适配器，得适应当前的不同配置，解决兼容性问题。我们生活中充满了各种各样的适配器，上网用的调制解调器(modem)就是一种数模转换的适配器，俗称“猫”，不过现在都是光猫了，也就是光信号和电信号的互相转化，其实道理是一样的，还有各种变压器也属于电压转换的适配器。 如果觉得还不够形象可以看一下家里的电器，比如你的电视是两项插头，墙上的插孔是三项插孔怎么办？哦，有人说把插头掰弯强行插入！那如果是三项插头接两项插孔呢？把零线插针拔了！呃，我只能说这是暴力破解！违反设计模式原则。言归正传，我们还是不要随便破坏现有的类，那我们需要的是一个转换器，用优雅微妙的方式化解这种不兼容情况。 举个例子，我们开始代码部分，先写墙上的三项插孔接口，命名TriplePin： public interface TriplePin { //参数分别为火线live，零线null，地线earth public void electrify(int l, int n, int e); } 我们只定义三插孔标准electrify（通电）方法，三个参数分别是火线、零线、地线，很简单吧，同样地接下来是两项插孔接口，只是少了地线，命名DualPin： public interface DualPin { public void electrify(int l, int n);//这里没有地线 } 请注意，这个并不是我们的墙上的目标接口，而是电视机的两插标准。好了继续，我们的TV登场了，用的是两项插头，当然它实现的是DualPin的标准，Let&#39;s keep it simple，命名TV： public class TV implements DualPin { @Override//既然是两项插头，当然实现两项插标准 public void electrify(int l, int n) { System.out.println(\"火线通电：\" + l); System.out.println(\"零线通电：\" + n); } } 那么问题来了，墙上的接口是三插标准，电视实现的是两插标准，无法通电。怎么办？把电视拆了重新修改实现三插标准么？暴力份子你又来？答案显然是否定的，既然是设计模式，果断转换插头啊！好，写个Adapter解决他们之间不可调和的矛盾。 public class Adapter implements TriplePin { private DualPin dualPinDevice; //创建适配器地时候，需要把双插设备接入进来 public Adapter(DualPin dualPinDevice) { this.dualPinDevice = dualPinDevice; } //适配器实现的是目标接口 @Override public void electrify(int l, int n, int e) { //实际上调用了被适配设备的双插通电，地线e被丢弃了。 dualPinDevice.electrify(l, n); } } 注意了最关键最精华的部分来了，private DualPin dualPinDevice;代码意味着这个适配器内部是有一个双插接口的，对于任何双插标准的设备都是可以兼容的OK吗？不明白赶紧看看你家里的适配器。public Adapter(DualPin dualPinDevice) {...}方法的代码完成的过程实际就是你把电视插头接入Adapter了，其实适配器并不在意是什么设备，洗衣机冰箱都可以的，只要是双插标准就可以接入（第一节讲过的多态概念）。electrify()通电方法实现的是三插标准，但方法体内部dualPinDevice.electrify(l, n);实际上是在给“某个设备”（是什么设备就看你接什么了）的双插供电，地线e那个参数是用不上的，所以就没有接通，很清晰透彻吧？ 当然，除了以上的注入插头的方式（对象适配），还有另一种更简单的方式叫做“类适配器”我们来看下： public class ClassAdapter extends TV implements TriplePin{ @Override public void electrify(int l, int n, int e) { super.electrify(l, n); } } 看出来区别没有？这里并没有注入插头（对象组合），而是把电视机给继承了，这样就可以直接调用父类（TV）的双插通电而不是注入进来去调用，缺点大家也看到了，这适配器继承为TV儿子专用了，洗衣机是用不了啦，作死？其实也不是完全不好，要看具体应用场景哈。 至此，我们的Adapter就差不多完成了，以后再也不用破坏插头了，因为这样重写接口或者修改类的代价太大，如果其他类还有依赖的话，那统统要修改，引入了没有必要的重构，总之暴力修改是违反设计模式的基本原则的，开闭原则，指的就是对扩展开放，而对修改关闭，也就是说不要去改动原始类，而是扩展现有功能，提供另一种机制让整个系统实现想要的功能。 最后说下那些概念，归类，名字，什么“类适配器”，“对象适配器”啊，其实，理解不了就算了无所谓，真正的意义在于怎么样在实际工作中灵活运用，实现方式是无穷无尽的，道不清说不尽的，没必要太纠结它到底叫什么，归于哪一类，掌控其背后的道才是最根本的，正如李耳君所言：“道可道，非常道。名可名，非常名。”","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"设计模式","slug":"设计模式","permalink":"https://www.cayzlh.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"},{"name":"Java设计模式","slug":"Java/Java设计模式","permalink":"https://www.cayzlh.com/categories/Java/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Java设计模式之单例模式","date":"2019-02-20T07:37:39.000Z","path":"2019/02/20/242438ad.html","text":"设计模式相关文章，用于整理网络中对应的设计模式的一些解读。 单例模式单例模式（Singleton Pattern）是 Java 中最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。 注意 1、单例类只能有一个实例。 2、单例类必须自己创建自己的唯一实例。 3、单例类必须给所有其他对象提供这一实例。 介绍意图：保证一个类仅有一个实例，并提供一个访问它的全局访问点。 主要解决：一个全局使用的类频繁地创建与销毁。 何时使用：当您想控制实例数目，节省系统资源的时候。 如何解决：判断系统是否已经有这个单例，如果有则返回，如果没有则创建。 关键代码：构造函数是私有的。 实例应用 以下实例来源于微信公众号（Java知音）文章，设计模式是什么鬼（单例） 单例，顾名思义，整个系统其实就只有一个实例存在，不能再多，否则就不叫单例。那我们把整个宇宙看做是一个庞大的系统，这宇宙里有各种对象存在，人啊，动物啊，植物啊不胜枚举，这些都是实例，丰富多彩的世界是美好的。然而，持续几千年的战争给世界带来了巨大灾难，尤其是宗教战争最为残忍，各个信仰间存在极大的世界观价值观冲突。 单印度一个国家就有几百个神，人们各信各的，风俗各异，各邦文化冲突不断，语言不通，办事效率极低。 为了让幸福美好洒满人间，那我们就定义一位神吧，独一无二的神。 我们先写一个God类吧，类中空空如也，世界如此清净，虚无缥缈。 public class God { } 首先我们得保证任何人都不能去创建神的实例，否则如：new God()，这样世界又要陷入战争的灾难，各种造神运动，或是某天又出来个什么神棍先知告诉信徒说他们肚子里有个轮子。那就不写构造方法吧？不行，因为有默认的无参构造器！那就把构造方法改成private吧，也就是神可以自己创造自己，但别人不能。 public class God { private God(){}//构造方法私有化 } God类里面封装一个God自己，对，一切都是神创造的，包括我们人类。有人开始质疑，那神是谁？神自己是谁造的？这是个哲学问题。神说“I am who I am.” 我是我所是，我就是我，自有永有，超越时空。很逆天吧？ 好吧，谁也不能造上帝，神自己造自己。 public class God { private static final God god = new God();//自有永有的神单例 private God(){}//构造方法私有化 } 以上private关键字保证了上帝的私有性，不可见性，不可访问性，我想没有活人见过上帝吧？static关键字保证上帝的静态性，他与类同在，不依赖于类的实例化就自有永有，他将在内存中永生，GC垃圾回收器也回收不了他。final关键字则保证这位神是和常量，衡量，他是终极上帝，不能再改。 正如同静态方法main()，不需要实例化类就能运行的入口，同样我们需要一个静态方法getInstance()来请神，方法体内我们就返回这个在唯一的真神，当然方法它必须是public公开的，不然谁都访问不了。 public class God { private static final God god = new God();//自有永有的神单例 private God(){}//构造方法私有化 public static God getInstance(){//请神方法公开化 return god; } } 以上的神类雏形已经写好了，当然你还可以加其他的功能方法，比如说创世纪神造了光，造了世界、动物、人、亚当夏娃等等功能，我们这里就不在赘述了。那对于外部来说只要调用God.getInstance();就可以拿到神了，而且不管谁拿，拿几次，都是同一个神，这样就保证了整个系统中神的唯一性，不可伪造性，至于其他先知那也只是神的代理人，只能帮请神而已。 好了，其实我们已经学会了单例模式的“痴汉模式（Eager load）”，代码第一行一开始就造出了神（new God那一句），已经准备好了随时给你请神，这样就有了一个问题，如果没人请神那不是白造了？提前备货如果价格跌了不是很惨？反应在系统中的问题就是占用了内存空间。于是又有了“懒汉模式（Lazy load）” public class God { private static God god;//这里不进行实例化 private God(){} public static God getInstance() { if (god == null) {//如果无神才造神 god = new God(); } return god; } } 这我们看到一开始就没有造神，只有某人第一次求神时才实例化，之后再求的就直接返回了。这样的好处是省了一段时间的内存（无求神期间），坏处是第一次请神的时候速度相较之前的痴汉模式会慢，因为要消耗CPU去造神。 其实这么写是在多线程模式下是有陷阱的，试想多人同时并发请神的话，依然会造成多神，好吧我们再来改良一下，把请神方法加上synchronized，声明为同步方法，某线程调用前必须获取同步锁，调用完后会释放锁给其他线程用，也就是请神的必须排队，大家一个一个按顺序来。 public class God { private static God god;//这里不进行实例化 private God(){} public static synchronized God getInstance() {//此处加入同步 if (god == null) {//如果无神才造神 god = new God(); } return god; } } 然而，这样做是要付出代价的，还没进庙呢不管三七二十一请神的直接给加锁排队，结果队伍从北边的庙排到了南天门，人们都要来一个一个拜佛求神，这造成了巨大时间浪费，没有充分利用CPU资源并发优势（特别是多核情况）。好吧，那还是让人们抢好了，但依然得保证单例神的情况下。 这里我们去掉方法上的同步关键字，换到方法体内部做同步，整个方法开放并发大家都可以同时入庙，当然起早贪黑的虔诚信徒们要抢头香是必须要入堂排队的。一旦头香诞生，那其他抢香的都白早起，白排队了。再之后的事情我们都可以预见了，头注香被抢后堂内排队再无必要来了，大家可以在堂外同时并发拜佛求神，这就极大的利用了CPU资源。简而言之：只有第一批抢头香的在排队，之后大家都不必排队了，代码如下。 public class God { private volatile static God god; private God(){} public static God getInstance() {//庙是开放的不用排队进入 if (god == null) {//如果头柱香未产生，这批抢香人进入堂内排队。 synchronized(God.class){ if (god == null) {//只有头香造了神，其他抢香的白排队了 god = new God(); } } } //此处头柱香产生后不必再排队 return god; } } 其实在这之上还发展出了各种各样的单例模式变种，我们这里只讲了最基础的两种，其实他们都各有优缺，我们要做到灵活运用，各取所需。对于我个人来讲倾向于痴汉模式，现在内存成本根本不算问题，况且迟早要被实例化占用内存，加锁解锁更是一种浪费，还有同步效率低等问题，如果上帝不是很占空间那就没必要去懒汉延迟加载，越复杂问题越多，风险越大。 单例模式的几种实现方式懒汉式，线程不安全是否 Lazy 初始化：是 是否多线程安全：否 实现难度：易 描述：这种方式是最基本的实现方式，这种实现最大的问题就是不支持多线程。因为没有加锁 synchronized，所以严格意义上它并不算单例模式。这种方式 lazy loading 很明显，不要求线程安全，在多线程不能正常工作。 实例： public class Singleton { private static Singleton instance; private Singleton (){} public static Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } } 懒汉式，线程安全是否 Lazy 初始化：是 是否多线程安全：是 实现难度：易 描述：这种方式具备很好的 lazy loading，能够在多线程中很好的工作，但是，效率很低，99% 情况下不需要同步。优点：第一次调用才初始化，避免内存浪费。缺点：必须加锁 synchronized 才能保证单例，但加锁会影响效率。getInstance() 的性能对应用程序不是很关键（该方法使用不太频繁）。 实例： public class Singleton { private static Singleton instance; private Singleton (){} public static synchronized Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } } 饿汉式是否 Lazy 初始化：否 是否多线程安全：是 实现难度：易 描述：这种方式比较常用，但容易产生垃圾对象。优点：没有加锁，执行效率会提高。缺点：类加载时就初始化，浪费内存。它基于 classloader 机制避免了多线程的同步问题，不过，instance 在类装载时就实例化，虽然导致类装载的原因有很多种，在单例模式中大多数都是调用 getInstance 方法， 但是也不能确定有其他的方式（或者其他的静态方法）导致类装载，这时候初始化 instance 显然没有达到 lazy loading 的效果。 实例： public class Singleton { private static Singleton instance = new Singleton(); private Singleton (){} public static Singleton getInstance() { return instance; } } 双检锁/双重校验锁（DCL，即 double-checked locking）JDK 版本：JDK1.5 起 是否 Lazy 初始化：是 是否多线程安全：是 实现难度：较复杂 描述：这种方式采用双锁机制，安全且在多线程情况下能保持高性能。getInstance() 的性能对应用程序很关键。 实例： public class Singleton { private volatile static Singleton singleton; private Singleton (){} public static Singleton getSingleton() { if (singleton == null) { synchronized (Singleton.class) { if (singleton == null) { singleton = new Singleton(); } } } return singleton; } } 登记式/静态内部类是否 Lazy 初始化：是 是否多线程安全：是 实现难度：一般 描述：这种方式能达到双检锁方式一样的功效，但实现更简单。对静态域使用延迟初始化，应使用这种方式而不是双检锁方式。这种方式只适用于静态域的情况，双检锁方式可在实例域需要延迟初始化时使用。这种方式同样利用了 classloader 机制来保证初始化 instance 时只有一个线程，它跟第 3 种方式不同的是：第 3 种方式只要 Singleton 类被装载了，那么 instance 就会被实例化（没有达到 lazy loading 效果），而这种方式是 Singleton 类被装载了，instance 不一定被初始化。因为 SingletonHolder 类没有被主动使用，只有通过显式调用 getInstance 方法时，才会显式装载 SingletonHolder 类，从而实例化 instance。想象一下，如果实例化 instance 很消耗资源，所以想让它延迟加载，另外一方面，又不希望在 Singleton 类加载时就实例化，因为不能确保 Singleton 类还可能在其他的地方被主动使用从而被加载，那么这个时候实例化 instance 显然是不合适的。这个时候，这种方式相比第 3 种方式就显得很合理。 实例： public class Singleton { private static class SingletonHolder { private static final Singleton INSTANCE = new Singleton(); } private Singleton (){} public static final Singleton getInstance() { return SingletonHolder.INSTANCE; } } 枚举JDK 版本：JDK1.5 起 是否 Lazy 初始化：否 是否多线程安全：是 实现难度：易 描述：这种实现方式还没有被广泛采用，但这是实现单例模式的最佳方法。它更简洁，自动支持序列化机制，绝对防止多次实例化。这种方式是 Effective Java 作者 Josh Bloch 提倡的方式，它不仅能避免多线程同步问题，而且还自动支持序列化机制，防止反序列化重新创建新的对象，绝对防止多次实例化。不过，由于 JDK1.5 之后才加入 enum 特性，用这种方式写不免让人感觉生疏，在实际工作中，也很少用。不能通过 reflection attack 来调用私有构造方法。 实例： public enum Singleton { INSTANCE; public void whateverMethod() { } } 经验之谈：一般情况下，不建议使用第 1 种和第 2 种懒汉方式，建议使用第 3 种饿汉方式。只有在要明确实现 lazy loading 效果时，才会使用第 5 种登记方式。如果涉及到反序列化创建对象时，可以尝试使用第 6 种枚举方式。如果有其他特殊的需求，可以考虑使用第 4 种双检锁方式。","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"设计模式","slug":"设计模式","permalink":"https://www.cayzlh.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"},{"name":"Java设计模式","slug":"Java/Java设计模式","permalink":"https://www.cayzlh.com/categories/Java/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Java设计模式之原型模式","date":"2019-02-14T07:33:50.000Z","path":"2019/02/14/44e9b870.html","text":"设计模式相关文章，用于整理网络中对应的设计模式的一些解读。 原型模式原型模式（Prototype Pattern）是用于创建重复的对象，同时又能保证性能。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 这种模式是实现了一个原型接口，该接口用于创建当前对象的克隆。当直接创建对象的代价比较大时，则采用这种模式。例如，一个对象需要在一个高代价的数据库操作之后被创建。我们可以缓存该对象，在下一个请求时返回它的克隆，在需要的时候更新数据库，以此来减少数据库调用。 介绍意图：用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。 主要解决：在运行期建立和删除原型。 何时使用： 1、当一个系统应该独立于它的产品创建，构成和表示时。 2、当要实例化的类是在运行时刻指定时，例如，通过动态装载。 3、为了避免创建一个与产品类层次平行的工厂类层次时。 4、当一个类的实例只能有几个不同状态组合中的一种时。建立相应数目的原型并克隆它们可能比每次用合适的状态手工实例化该类更方便一些。 如何解决：利用已有的一个原型对象，快速地生成和原型对象一样的实例。 关键代码： 1、实现克隆操作，在 JAVA 继承 Cloneable，重写 clone()，在 .NET 中可以使用 Object 类的 MemberwiseClone() 方法来实现对象的浅拷贝或通过序列化的方式来实现深拷贝。 2、原型模式同样用于隔离类对象的使用者和具体类型（易变类）之间的耦合关系，它同样要求这些”易变类”拥有稳定的接口。 应用实例： 1、细胞分裂。 2、JAVA 中的 Object clone() 方法。 优点： 1、性能提高。 2、逃避构造函数的约束。 缺点： 1、配备克隆方法需要对类的功能进行通盘考虑，这对于全新的类不是很难，但对于已有的类不一定很容易，特别当一个类引用不支持串行化的间接对象，或者引用含有循环结构的时候。 2、必须实现 Cloneable 接口。 使用场景： 1、资源优化场景。 2、类初始化需要消化非常多的资源，这个资源包括数据、硬件资源等。 3、性能和安全要求的场景。 4、通过 new 产生一个对象需要非常繁琐的数据准备或访问权限，则可以使用原型模式。 5、一个对象多个修改者的场景。 6、一个对象需要提供给其他对象访问，而且各个调用者可能都需要修改其值时，可以考虑使用原型模式拷贝多个对象供调用者使用。 7、在实际项目中，原型模式很少单独出现，一般是和工厂方法模式一起出现，通过 clone 的方法创建一个对象，然后由工厂方法提供给调用者。原型模式已经与 Java 融为浑然一体，大家可以随手拿来使用。 注意事项：与通过对一个类进行实例化来构造新对象不同的是，原型模式是通过拷贝一个现有对象生成新对象的。浅拷贝实现 Cloneable，重写，深拷贝是通过实现 Serializable 读取二进制流。 实例 以下实例来源于微信公众号（Java知音）文章，设计模式是什么鬼（原型） 假设我们要做一个打飞机游戏，游戏设定位纵版移动，单打。 既然是单打，那我们的主角飞机当然只有一架，于是我们写一个单例模式，此处我们省略主角代码。那么敌机呢？当然有很多架了，好，为了说明问题我们去繁就简，先写一个敌机类。 public class EnemyPlane { private int x;//敌机横坐标 private int y = 0;//敌机纵坐标 public EnemyPlane(int x) {//构造器 this.x = x; } public int getX() { return x; } public int getY() { return y; } public void fly(){//让敌机飞 y++;//每调用一次，敌机飞行时纵坐标＋1 } } 代码public EnemyPlane(int x) {//构造器....开始，初始化只接收x坐标，因为敌机一开始是从顶部出来所以纵坐标y必然是0。此类只提供getter而没有setter，也就是说只能在初始化时确定敌机的横坐标x，后续是不需要更改坐标了，只要连续调用第17行的fly方法即可让飞机跟雨点一样往下砸。 好了，我们开始绘制敌机动画了，先实例化出50架吧。 public class Client { public static void main(String[] args) { List&lt;EnemyPlane> enemyPlanes = new ArrayList&lt;EnemyPlane>(); for (int i = 0; i &lt; 50; i++) { //此处随机位置产生敌机 EnemyPlane ep = new EnemyPlane(new Random().nextInt(200)); enemyPlanes.add(ep); } } } 注意代码EnemyPlane ep = new EnemyPlane(new Random().nextInt(200));，觉不觉得每个迭代都实例化new出一个对象存在性能问题呢？答案是肯定的，这个实例化的过程是得不偿失的，构造方法会被调用50次，cpu被极大浪费了，内存被极大浪费了，尤其对于游戏来说性能瓶颈绝对是大忌，这会造成用户体验问题，谁也不希望玩游戏会卡帧吧。 那到底什么时候去new？游戏场景初始化就new敌机（如以上代码）？这关会出现500个敌机那我们一次都new出来吧？浪费内存！那我们实时的去new，每到一个地方才new出来一个！浪费CPU！如果敌机线程过多造成CPU资源耗尽，每出一个敌机游戏会卡一下，试想一下这种极端情况下，游戏对象实例很多的话就是在作死。 解决方案到底是什么呢？好，原型模式Prototype！上代码！我们把上面的敌机类改造一下，让它支持原型拷贝。 public class EnemyPlane implements Cloneable{//此处实现克隆接口 private int x;//敌机横坐标 private int y = 0;//敌机纵坐标 public EnemyPlane(int x) {//构造器 this.x = x; } public int getX() { return x; } public int getY() { return y; } public void fly(){//让敌机飞 y++;//每调用一次，敌机飞行时纵坐标＋1 } //此处开放setX，为了让克隆后的实例重新修改x坐标 public void setX(int x) { this.x = x; } //为了保证飞机飞行的连贯性 //这里我们关闭setY方法，不支持随意更改Y纵坐标 // public void setY(int y) { // this.y = y; // } //重写克隆方法 @Override public EnemyPlane clone() throws CloneNotSupportedException { return (EnemyPlane)super.clone(); } } setX()方法为了保证克隆飞机的个性化，因为它们出现的位置是不同的。克隆方法重写我们调用了父类Object的克隆方法，这里JVM会进行内存操作直接拷贝原始数据流，简单粗暴，不会有其他更多的复杂操作（类加载，实例化，初始化等等），速度远远快于实例化操作。OK，我们看怎么克隆这些敌机，做一个造飞机的工厂吧。 public class EnemyPlaneFactory { //此处用痴汉模式造一个敌机原型 private static EnemyPlane protoType = new EnemyPlane(200); //获取敌机克隆实例 public static EnemyPlane getInstance(int x){ EnemyPlane clone = protoType.clone();//复制原型机 clone.setX(x);//重新设置克隆机的x坐标 return clone; } } 此处我们省去抓异常，随后的事情就非常简单了，我们只需要很简单地调用EnemyPlaneFactory.getInstance(int x)并声明x坐标位置，一架敌机很快地就做好了，并且我们保证是在敌机出现的时候再去克隆，确保不要一开局就全部克隆出来，如此一来，既保证了实时性节省了内存空间，又保证了敌机实例化的速度，游戏绝不会卡帧！ 最后，还要强调一点就是浅拷贝和深拷贝的问题。假如我们的敌机类里有一颗子弹bullet可以射击我们的主角，如下。 public class EnemyPlane implements Cloneable{ private Bullet bullet = new Bullet(); private int x;//敌机横坐标 private int y = 0;//敌机纵坐标 //之后代码省略…… } 我们都知道Java中的变量分为原始类型和引用类型，所谓浅拷贝只是拷贝原始类型的指，比如坐标x, y的指会被拷贝到克隆对象中，对于对象bullet也会被拷贝，但是请注意拷贝的只是地址而已，那么多个地址其实真正指向的对象还是同一个bullet。 由于我们调用父类Object的clone方法进行的是浅拷贝，所以此处的bullet并没有被克隆成功，比如我们每架敌机必须携带的子弹是不同的实例，那么我们就必须进行深拷贝，于是我们的代码就得做这样的改动。 public class EnemyPlane implements Cloneable{ private Bullet bullet = new Bullet(); public void setBullet(Bullet bullet) { this.bullet = bullet; } @Override protected EnemyPlane clone() throws CloneNotSupportedException { // 先克隆出敌机，其中子弹还未进行克隆。 EnemyPlane clonePlane = (EnemyPlane) super.clone(); // 对子弹进行深拷贝 clonePlane.setBullet(this.bullet.clone()); return clonePlane; } //之后代码省略…… } 相信大家看注释就能懂了，这里就不做过多解释，当然对于Bullet类也同样实现了克隆接口，代码不用再写了吧？相信大家都学会了举一反三。至此，我们的每个敌机携带的弹药也同样被克隆完毕了，再也不必担心游戏的流畅性了。","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"设计模式","slug":"设计模式","permalink":"https://www.cayzlh.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"},{"name":"Java设计模式","slug":"Java/Java设计模式","permalink":"https://www.cayzlh.com/categories/Java/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Docker私有仓库的搭建与使用","date":"2019-01-30T01:34:46.000Z","path":"2019/01/30/aacd52c7.html","text":"转载自：spring-cloud-book 和Maven一样，Docker不仅提供了一个中央仓库，同时也允许我们搭建私有仓库。如果读者对Maven有所了解，将会很容易理解私有仓库的优势： 节省带宽，镜像无需从中央仓库下载，只需从私有仓库中下载即可 对于私有仓库中已有的镜像，提升了下载速度 便于内部镜像的统一管理 下面我们来讲解一下如何搭建、使用私有仓库 准备工作准备两台安装有Docker的CentOS7的机器，主机规划如下（仅供参考）： 主机 IP 角色 node0 192.168.11.143 Docker开发机 node1 192.168.11.144 Docker私有仓库 安装、使用私有仓库网上有很多docker-registry 的教程，但是docker-registry 已经过时，并且已经2年不维护了。详见https://github.com/docker/docker-registry ，故而本文不做探讨，对docker-registry 有兴趣的童鞋可以查阅本节的参考文档。 本节讲解registry V2，registry V2需要Docker版本高于1.6.0。registry V2要求使用https访问，那么我们先做一些准备，为了方便，这边模拟以域名reg.itmuch.com 进行讲解。 使用域名搭建https的私有仓库 首先修改两台机器的hosts，配置192.168.11.144 到reg.itmuch.com 的映射 echo '192.168.11.144 reg.itmuch.com'>> /etc/hosts 既然使用https，那么我们需要生成证书，本文讲解的是使用openssl自签名证书，当然也可以使用诸如Let’s Encrypt 等工具生成证书，首先在node1机器上生成key： mkdir -p ~/certs cd ~/certs openssl genrsa -out reg.itmuch.com.key 2048 再生成密钥文件： openssl req -newkey rsa:4096 -nodes -sha256 -keyout reg.itmuch.com.key -x509 -days 365 -out reg.itmuch.com.crt 会有一些信息需要填写： Country Name (2 letter code) [XX]:CN # 你的国家名称 State or Province Name (full name) []:JS # 省份 Locality Name (eg, city) [Default City]:NJ # 所在城市 Organization Name (eg, company) [Default Company Ltd]:ITMUCH # 组织名称 Organizational Unit Name (eg, section) []:ITMUCH # 组织单元名称 Common Name (eg, your name or your server's hostname) []:reg.itmuch.com # 域名 Email Address []:eacdy0000@126.com # 邮箱 这样自签名证书就制作完成了。 由于是自签名证书，默认是不受Docker信任的，故而需要将证书添加到Docker的根证书中，Docker在CentOS 7中，证书存放路径是/etc/docker/certs.d/域名： node1 端： mkdir -p /etc/docker/certs.d/reg.itmuch.com cp ~/certs/reg.itmuch.com.crt /etc/docker/certs.d/reg.itmuch.com/ node0 端：将生成的证书下载到根证书路径 mkdir -p /etc/docker/certs.d/reg.itmuch.com scp root@192.168.11.144:/root/certs/reg.itmuch.com.crt /etc/docker/certs.d/reg.itmuch.com/ 重新启动node0 和 node1 的Docker service docker restart 在node1 上启动私有仓库 首先切换到家目录中，这一步不能少，原因是下面的-v 挂载了证书，如果不切换，将会引用不到证书文件。 cd ~启动Docker私有仓库（注意：如果直接粘贴运行，请删除掉注释）： docker run -d -p 443:5000 --restart=always --name registry \\ -v `pwd`/certs:/certs \\ # 将“当前目录/certs”挂载到容器的“/certs” -v /opt/docker-image:/opt/docker-image \\ -e STORAGE_PATH=/opt/docker-image \\ # 指定容器内存储镜像的路径 -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/reg.itmuch.com.crt \\ # 指定证书文件 -e REGISTRY_HTTP_TLS_KEY=/certs/reg.itmuch.com.key \\ # 指定key文件 registry:2 其中，之所以挂载/opt/docker-image目录，是为了防止私有仓库容器被删除，私有仓库中的镜像也会丢失。 在node0 上测试，将镜像push到私服 docker pull kitematic/hello-world-nginx docker tag kitematic/hello-world-nginx reg.itmuch.com/kitematic/hello-world-nginx # 为本地镜像打标签 docker push reg.itmuch.com/kitematic/hello-world-nginx # 将镜像push到私服 会发现如下内容： The push refers to a repository [reg.itmuch.com/kitematic/hello-world-nginx] 5f70bf18a086: Pushed b51acdd3ef48: Pushed 3f47ff454588: Pushed .... latest: digest: sha256:d3e1883b703c39556f2f09da14cc3b820f69a43436655c882c0c0ded0dda6a4b size: 3226 说明已经push成功。 从私服中下载镜像： docker pull reg.itmuch.com/kitematic/hello-world-nginx 配置登录认证在很多场景下，我们需要用户登录后才能访问私有仓库，那么我们可以如下操作： 建立在上文生成证书，同时重启过Docker服务的前提下，我们讲解一下如何配置： 为防止端口冲突，我们首先删除或停止之前启动好的私有仓库： docker kill registry 在node1机器上安装httpd-tools ： yum install httpd-tools 在node机器上创建密码文件，并添加一个用户testuser ，密码是testpassword ： cd ~ mkdir auth htpasswd -Bbn testuser testpassword > auth/htpasswd 在node1机器上切换到~ 目录，并启动私有仓库（注意：如果直接粘贴运行，请删除掉注释）： docker run -d -p 443:5000 --restart=always --name registry2 \\ -v /opt/docker-image:/var/lib/registry \\ # 挂载容器内存储镜像路径到宿主机 -v `pwd`/certs:/certs \\ -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/reg.itmuch.com.crt \\ -e REGISTRY_HTTP_TLS_KEY=/certs/reg.itmuch.com.key \\ -v `pwd`/auth:/auth \\ -e \"REGISTRY_AUTH=htpasswd\" \\ -e \"REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm\" \\ -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd \\ registry:2 测试： docker push reg.itmuch.com/kitematic/hello-world-nginx 提示： 461f75075df2: Image push failed no basic auth credentials 说明需要认证。 我们登陆一下，执行： docker login reg.imuch.com 再次执行 docker push reg.itmuch.com/kitematic/hello-world-nginx 就可以正常push镜像到私有仓库了。 注意：如果想要从私有仓库上下载镜像，同样需要登录。","tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cayzlh.com/tags/Docker/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"}]},{"title":"Dockerfile常用指令","date":"2019-01-30T00:23:45.000Z","path":"2019/01/30/9d9fc4e1.html","text":"转载自：Docker(三)：Dockerfile 命令详解，怕以后找不到 Dockerfile 指令详解1 FROM 指定基础镜像FROM 指令用于指定其后构建新镜像所使用的基础镜像。FROM 指令必是 Dockerfile 文件中的首条命令，启动构建流程后，Docker 将会基于该镜像构建新镜像，FROM 后的命令也会基于这个基础镜像。 FROM语法格式为： FROM 或 FROM : 或 FROM : 通过 FROM 指定的镜像，可以是任何有效的基础镜像。FROM 有以下限制： FROM 必须 是 Dockerfile 中第一条非注释命令 在一个 Dockerfile 文件中创建多个镜像时，FROM 可以多次出现。只需在每个新命令 FROM 之前，记录提交上次的镜像 ID。 tag 或 digest 是可选的，如果不使用这两个值时，会使用 latest 版本的基础镜像 2 RUN 执行命令在镜像的构建过程中执行特定的命令，并生成一个中间镜像。格式: #shell格式 RUN #exec格式 RUN [\"executable\", \"param1\", \"param2\"] RUN 命令将在当前 image 中执行任意合法命令并提交执行结果。命令执行提交后，就会自动执行 Dockerfile 中的下一个指令。 层级 RUN 指令和生成提交是符合 Docker 核心理念的做法。它允许像版本控制那样，在任意一个点，对 image 镜像进行定制化构建。 RUN 指令创建的中间镜像会被缓存，并会在下次构建中使用。如果不想使用这些缓存镜像，可以在构建时指定 --no-cache 参数，如：docker build --no-cache。 3 COPY 复制文件格式： COPY ... COPY [\"\",... \"\"] 和 RUN 指令一样，也有两种格式，一种类似于命令行，一种类似于函数调用。COPY 指令将从构建上下文目录中 &lt;源路径&gt; 的文件/目录复制到新的一层的镜像内的&lt;目标路径&gt;位置。比如： COPY package.json /usr/src/app/ &lt;源路径&gt;可以是多个，甚至可以是通配符，其通配符规则要满足 Go 的 filepath.Match 规则，如： COPY hom* /mydir/ COPY hom?.txt /mydir/ &lt;目标路径&gt;可以是容器内的绝对路径，也可以是相对于工作目录的相对路径（工作目录可以用 WORKDIR 指令来指定）。目标路径不需要事先创建，如果目录不存在会在复制文件前先行创建缺失目录。 此外，还需要注意一点，使用 COPY 指令，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。这个特性对于镜像定制很有用。特别是构建相关文件都在使用 Git 进行管理的时候。 4 ADD 更高级的复制文件ADD 指令和 COPY 的格式和性质基本一致。但是在 COPY 基础上增加了一些功能。比如&lt;源路径&gt;可以是一个 URL，这种情况下，Docker 引擎会试图去下载这个链接的文件放到&lt;目标路径&gt;去。 在构建镜像时，复制上下文中的文件到镜像内，格式： ADD ... ADD [\"\",... \"\"] 注意如果 docker 发现文件内容被改变，则接下来的指令都不会再使用缓存。关于复制文件时需要处理的/，基本跟正常的 copy 一致 5 ENV 设置环境变量格式有两种： ENV ENV = =... 这个指令很简单，就是设置环境变量而已，无论是后面的其它指令，如 RUN，还是运行时的应用，都可以直接使用这里定义的环境变量。 ENV VERSION=1.0 DEBUG=on \\ NAME=\"Happy Feet\" 这个例子中演示了如何换行，以及对含有空格的值用双引号括起来的办法，这和 Shell 下的行为是一致的。 6 EXPOSE为构建的镜像设置监听端口，使容器在运行时监听。格式： EXPOSE [...] EXPOSE 指令并不会让容器监听 host 的端口，如果需要，需要在 docker run 时使用 -p、-P 参数来发布容器端口到 host 的某个端口上。 7 VOLUME 定义匿名卷VOLUME用于创建挂载点，即向基于所构建镜像创始的容器添加卷： VOLUME [\"/data\"] 一个卷可以存在于一个或多个容器的指定目录，该目录可以绕过联合文件系统，并具有以下功能： 卷可以容器间共享和重用 容器并不一定要和其它容器共享卷 修改卷后会立即生效 对卷的修改不会对镜像产生影响 卷会一直存在，直到没有任何容器在使用它 VOLUME 让我们可以将源代码、数据或其它内容添加到镜像中，而又不并提交到镜像中，并使我们可以多个容器间共享这些内容。 8 WORKDIR 指定工作目录WORKDIR用于在容器内设置一个工作目录： WORKDIR /path/to/workdir 通过WORKDIR设置工作目录后，Dockerfile 中其后的命令 RUN、CMD、ENTRYPOINT、ADD、COPY 等命令都会在该目录下执行。 如，使用WORKDIR设置工作目录： WORKDIR /a WORKDIR b WORKDIR c RUN pwd 在以上示例中，pwd 最终将会在 /a/b/c 目录中执行。在使用 docker run 运行容器时，可以通过-w参数覆盖构建时所设置的工作目录。 9 USER 指定当前用户USER 用于指定运行镜像所使用的用户： USER daemon 使用USER指定用户时，可以使用用户名、UID 或 GID，或是两者的组合。以下都是合法的指定试： USER user USER user:group USER uid USER uid:gid USER user:gid USER uid:group 使用USER指定用户后，Dockerfile 中其后的命令 RUN、CMD、ENTRYPOINT 都将使用该用户。镜像构建完成后，通过 docker run 运行容器时，可以通过 -u 参数来覆盖所指定的用户。 10 CMDCMD用于指定在容器启动时所要执行的命令。CMD 有以下三种格式： CMD [\"executable\",\"param1\",\"param2\"] CMD [\"param1\",\"param2\"] CMD command param1 param2 省略可执行文件的 exec 格式，这种写法使 CMD 中的参数当做 ENTRYPOINT 的默认参数，此时 ENTRYPOINT 也应该是 exec 格式，具体与 ENTRYPOINT 的组合使用，参考 ENTRYPOINT。 注意与 RUN 指令的区别：RUN 在构建的时候执行，并生成一个新的镜像，CMD 在容器运行的时候执行，在构建时不进行任何操作。 11 ENTRYPOINTENTRYPOINT 用于给容器配置一个可执行程序。也就是说，每次使用镜像创建容器时，通过 ENTRYPOINT 指定的程序都会被设置为默认程序。ENTRYPOINT 有以下两种形式： ENTRYPOINT [\"executable\", \"param1\", \"param2\"] ENTRYPOINT command param1 param2 ENTRYPOINT 与 CMD 非常类似，不同的是通过docker run执行的命令不会覆盖 ENTRYPOINT，而docker run命令中指定的任何参数，都会被当做参数再次传递给 ENTRYPOINT。Dockerfile 中只允许有一个 ENTRYPOINT 命令，多指定时会覆盖前面的设置，而只执行最后的 ENTRYPOINT 指令。 docker run运行容器时指定的参数都会被传递给 ENTRYPOINT ，且会覆盖 CMD 命令指定的参数。如，执行docker run &lt;image&gt; -d时，-d 参数将被传递给入口点。 也可以通过docker run --entrypoint重写 ENTRYPOINT 入口点。如：可以像下面这样指定一个容器执行程序： ENTRYPOINT [\"/usr/bin/nginx\"] 完整构建代码： # Version: 0.0.3 FROM ubuntu:16.04 MAINTAINER 何民三 \"cn.liuht@gmail.com\" RUN apt-get update RUN apt-get install -y nginx RUN echo 'Hello World, 我是个容器' \\ > /var/www/html/index.html ENTRYPOINT [\"/usr/sbin/nginx\"] EXPOSE 80 使用docker build构建镜像，并将镜像指定为 itbilu/test： docker build -t=\"itbilu/test\" . 构建完成后，使用itbilu/test启动一个容器： docker run -i -t itbilu/test -g \"daemon off;\" 在运行容器时，我们使用了 -g &quot;daemon off;&quot;，这个参数将会被传递给 ENTRYPOINT，最终在容器中执行的命令为 /usr/sbin/nginx -g &quot;daemon off;&quot;。 12 LABELLABEL用于为镜像添加元数据，元数以键值对的形式指定： LABEL = = = ... 使用LABEL指定元数据时，一条LABEL指定可以指定一或多条元数据，指定多条元数据时不同元数据之间通过空格分隔。推荐将所有的元数据通过一条LABEL指令指定，以免生成过多的中间镜像。 如，通过LABEL指定一些元数据： LABEL version=\"1.0\" description=\"这是一个Web服务器\" by=\"IT笔录\" 指定后可以通过docker inspect查看： docker inspect itbilu/test \"Labels\": { \"version\": \"1.0\", \"description\": \"这是一个Web服务器\", \"by\": \"IT笔录\" }, 13 ARGARG用于指定传递给构建运行时的变量： ARG [=] 如，通过ARG指定两个变量： ARG site ARG build_user=IT笔录 以上我们指定了 site 和 build_user 两个变量，其中 build_user 指定了默认值。在使用 docker build 构建镜像时，可以通过 --build-arg &lt;varname&gt;=&lt;value&gt; 参数来指定或重设置这些变量的值。 docker build --build-arg site=itiblu.com -t itbilu/test . 这样我们构建了 itbilu/test 镜像，其中site会被设置为 itbilu.com，由于没有指定 build_user，其值将是默认值 IT 笔录。 14 ONBUILDONBUILD用于设置镜像触发器： ONBUILD [INSTRUCTION] 当所构建的镜像被用做其它镜像的基础镜像，该镜像中的触发器将会被钥触发。 如，当镜像被使用时，可能需要做一些处理： [...] ONBUILD ADD . /app/src ONBUILD RUN /usr/local/bin/python-build --dir /app/src [...] 15 STOPSIGNALSTOPSIGNAL用于设置停止容器所要发送的系统调用信号： STOPSIGNAL signal 所使用的信号必须是内核系统调用表中的合法的值，如：SIGKILL。 16 SHELLSHELL用于设置执行命令（shell式）所使用的的默认 shell 类型： SHELL [\"executable\", \"parameters\"] SHELL在Windows环境下比较有用，Windows 下通常会有 cmd 和 powershell 两种 shell，可能还会有 sh。这时就可以通过 SHELL 来指定所使用的 shell 类型： FROM microsoft/windowsservercore # Executed as cmd /S /C echo default RUN echo default # Executed as cmd /S /C powershell -command Write-Host default RUN powershell -command Write-Host default # Executed as powershell -command Write-Host hello SHELL [\"powershell\", \"-command\"] RUN Write-Host hello # Executed as cmd /S /C echo hello SHELL [\"cmd\", \"/S\"\", \"/C\"] RUN echo hello Dockerfile 使用经验Dockerfile 示例构建Nginx运行环境 # 指定基础镜像 FROM sameersbn/ubuntu:14.04.20161014 # 维护者信息 MAINTAINER sameer@damagehead.com # 设置环境 ENV RTMP_VERSION=1.1.10 \\ NPS_VERSION=1.11.33.4 \\ LIBAV_VERSION=11.8 \\ NGINX_VERSION=1.10.1 \\ NGINX_USER=www-data \\ NGINX_SITECONF_DIR=/etc/nginx/sites-enabled \\ NGINX_LOG_DIR=/var/log/nginx \\ NGINX_TEMP_DIR=/var/lib/nginx \\ NGINX_SETUP_DIR=/var/cache/nginx # 设置构建时变量，镜像建立完成后就失效 ARG BUILD_LIBAV=false ARG WITH_DEBUG=false ARG WITH_PAGESPEED=true ARG WITH_RTMP=true # 复制本地文件到容器目录中 COPY setup/ ${NGINX_SETUP_DIR}/ RUN bash ${NGINX_SETUP_DIR}/install.sh # 复制本地配置文件到容器目录中 COPY nginx.conf /etc/nginx/nginx.conf COPY entrypoint.sh /sbin/entrypoint.sh # 运行指令 RUN chmod 755 /sbin/entrypoint.sh # 允许指定的端口 EXPOSE 80/tcp 443/tcp 1935/tcp # 指定网站目录挂载点 VOLUME [\"${NGINX_SITECONF_DIR}\"] ENTRYPOINT [\"/sbin/entrypoint.sh\"] CMD [\"/usr/sbin/nginx\"] 构建tomcat 环境 Dockerfile文件 # 指定基于的基础镜像 FROM ubuntu:13.10 # 维护者信息 MAINTAINER zhangjiayang \"zhangjiayang@sczq.com.cn\" # 镜像的指令操作 # 获取APT更新的资源列表 RUN echo \"deb http://archive.ubuntu.com/ubuntu precise main universe\"> /etc/apt/sources.list # 更新软件 RUN apt-get update # Install curl RUN apt-get -y install curl # Install JDK 7 RUN cd /tmp && curl -L 'http://download.oracle.com/otn-pub/java/jdk/7u65-b17/jdk-7u65-linux-x64.tar.gz' -H 'Cookie: oraclelicense=accept-securebackup-cookie; gpw_e24=Dockerfile' | tar -xz RUN mkdir -p /usr/lib/jvm RUN mv /tmp/jdk1.7.0_65/ /usr/lib/jvm/java-7-oracle/ # Set Oracle JDK 7 as default Java RUN update-alternatives --install /usr/bin/java java /usr/lib/jvm/java-7-oracle/bin/java 300 RUN update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/java-7-oracle/bin/javac 300 # 设置系统环境 ENV JAVA_HOME /usr/lib/jvm/java-7-oracle/ # Install tomcat7 RUN cd /tmp && curl -L 'http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.8/bin/apache-tomcat-7.0.8.tar.gz' | tar -xz RUN mv /tmp/apache-tomcat-7.0.8/ /opt/tomcat7/ ENV CATALINA_HOME /opt/tomcat7 ENV PATH $PATH:$CATALINA_HOME/bin # 复件tomcat7.sh到容器中的目录 ADD tomcat7.sh /etc/init.d/tomcat7 RUN chmod 755 /etc/init.d/tomcat7 # Expose ports. 指定暴露的端口 EXPOSE 8080 # Define default command. ENTRYPOINT service tomcat7 start && tail -f /opt/tomcat7/logs/catalina.out tomcat7.sh命令文件 export JAVA_HOME=/usr/lib/jvm/java-7-oracle/ export TOMCAT_HOME=/opt/tomcat7 case $1 in start) sh $TOMCAT_HOME/bin/startup.sh ;; stop) sh $TOMCAT_HOME/bin/shutdown.sh ;; restart) sh $TOMCAT_HOME/bin/shutdown.sh sh $TOMCAT_HOME/bin/startup.sh ;; esac exit 0 原则与建议 容器轻量化。从镜像中产生的容器应该尽量轻量化，能在足够短的时间内停止、销毁、重新生成并替换原来的容器。 使用 .gitignore。在大部分情况下，Dockerfile 会和构建所需的文件放在同一个目录中，为了提高构建的性能，应该使用 .gitignore 来过滤掉不需要的文件和目录。 为了减少镜像的大小，减少依赖，仅安装需要的软件包。 一个容器只做一件事。解耦复杂的应用，分成多个容器，而不是所有东西都放在一个容器内运行。如一个 Python Web 应用，可能需要 Server、DB、Cache、MQ、Log 等几个容器。一个更加极端的说法：One process per container。 减少镜像的图层。不要多个 Label、ENV 等标签。 对续行的参数按照字母表排序，特别是使用apt-get install -y安装包的时候。 使用构建缓存。如果不想使用缓存，可以在构建的时候使用参数--no-cache=true来强制重新生成中间镜像。","tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cayzlh.com/tags/Docker/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Docker","slug":"微服务/Docker","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/Docker/"}]},{"title":"Dockerfile使用介绍","date":"2019-01-30T00:23:30.000Z","path":"2019/01/30/c15a63a5.html","text":"转自：Docker(二)：Dockerfile 使用介绍， 怕以后找不到 Dockerfile 概念Docker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。 镜像的定制实际上就是定制每一层所添加的配置、文件。如果我们可以把每一层修改、安装、构建、操作的命令都写入一个脚本，用这个脚本来构建、定制镜像，那么之前提及的无法重复的问题、镜像构建透明性的问题、体积的问题就都会解决。这个脚本就是 Dockerfile。 Dockerfile 是一个文本文件，其内包含了一条条的指令(Instruction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。有了 Dockerfile，当我们需要定制自己额外的需求时，只需在 Dockerfile 上添加或者修改指令，重新生成 image 即可，省去了敲命令的麻烦。 Dockerfile 文件格式Dockerfile文件格式如下： ## Dockerfile文件格式 # This dockerfile uses the ubuntu image # VERSION 2 - EDITION 1 # Author: docker_user # Command format: Instruction [arguments / command] .. # 1、第一行必须指定 基础镜像信息 FROM ubuntu # 2、维护者信息 MAINTAINER docker_user docker_user@email.com # 3、镜像操作指令 RUN echo \"deb http://archive.ubuntu.com/ubuntu/ raring main universe\" >> /etc/apt/sources.list RUN apt-get update && apt-get install -y nginx RUN echo \"\\ndaemon off;\" >> /etc/nginx/nginx.conf # 4、容器启动执行指令 CMD /usr/sbin/nginx Dockerfile 分为四部分：基础镜像信息、维护者信息、镜像操作指令、容器启动执行指令。一开始必须要指明所基于的镜像名称，接下来一般会说明维护者信息；后面则是镜像操作指令，例如 RUN 指令。每执行一条RUN 指令，镜像添加新的一层，并提交；最后是 CMD 指令，来指明运行容器时的操作命令。 构建镜像docker build 命令会根据 Dockerfile 文件及上下文构建新 Docker 镜像。构建上下文是指 Dockerfile 所在的本地路径或一个URL（Git仓库地址）。构建上下文环境会被递归处理，所以构建所指定的路径还包括了子目录，而URL还包括了其中指定的子模块。 将当前目录做为构建上下文时，可以像下面这样使用docker build命令构建镜像： docker build . Sending build context to Docker daemon 6.51 MB ... 说明：构建会在 Docker 后台守护进程（daemon）中执行，而不是CLI中。构建前，构建进程会将全部内容（递归）发送到守护进程。大多情况下，应该将一个空目录作为构建上下文环境，并将 Dockerfile 文件放在该目录下。 在构建上下文中使用的 Dockerfile 文件，是一个构建指令文件。为了提高构建性能，可以通过.dockerignore文件排除上下文目录下不需要的文件和目录。 在 Docker 构建镜像的第一步，docker CLI 会先在上下文目录中寻找.dockerignore文件，根据.dockerignore 文件排除上下文目录中的部分文件和目录，然后把剩下的文件和目录传递给 Docker 服务。 Dockerfile 一般位于构建上下文的根目录下，也可以通过-f指定该文件的位置： docker build -f /path/to/a/Dockerfile . 构建时，还可以通过-t参数指定构建成镜像的仓库、标签。 镜像标签docker build -t nginx/v3 . 如果存在多个仓库下，或使用多个镜像标签，就可以使用多个-t参数： docker build -t nginx/v3:1.0.2 -t nginx/v3:latest . 在 Docker 守护进程执行 Dockerfile 中的指令前，首先会对 Dockerfile 进行语法检查，有语法错误时会返回： docker build -t nginx/v3 . Sending build context to Docker daemon 2.048 kB Error response from daemon: Unknown instruction: RUNCMD 缓存Docker 守护进程会一条一条的执行 Dockerfile 中的指令，而且会在每一步提交并生成一个新镜像，最后会输出最终镜像的ID。生成完成后，Docker 守护进程会自动清理你发送的上下文。 Dockerfile文件中的每条指令会被独立执行，并会创建一个新镜像，RUN cd /tmp等命令不会对下条指令产生影响。 Docker 会重用已生成的中间镜像，以加速docker build的构建速度。以下是一个使用了缓存镜像的执行过程： $ docker build -t svendowideit/ambassador . Sending build context to Docker daemon 15.36 kB Step 1/4 : FROM alpine:3.2 ---> 31f630c65071 Step 2/4 : MAINTAINER SvenDowideit@home.org.au ---> Using cache ---> 2a1c91448f5f Step 3/4 : RUN apk update &amp;&amp; apk add socat &amp;&amp; rm -r /var/cache/ ---> Using cache ---> 21ed6e7fbb73 Step 4/4 : CMD env | grep _TCP= | (sed 's/.*_PORT_\\([0-9]*\\)_TCP=tcp:\\/\\/\\(.*\\):\\(.*\\)/socat -t 100000000 TCP4-LISTEN:\\1,fork,reuseaddr TCP4:\\2:\\3 \\&amp;/' &amp;&amp; echo wait) | sh ---> Using cache ---> 7ea8aef582cc Successfully built 7ea8aef582cc 构建缓存仅会使用本地父生成链上的镜像，如果不想使用本地缓存的镜像，也可以通过--cache-from指定缓存。指定后将不再使用本地生成的镜像链，而是从镜像仓库中下载。 寻找缓存的逻辑Docker 寻找缓存的逻辑其实就是树型结构根据 Dockerfile 指令遍历子节点的过程。下图可以说明这个逻辑。 FROM base_image:version Dockerfile: +----------+ FROM base_image:version |base image| RUN cmd1 --> use cache because we found base image +-----X----+ RUN cmd11 --> use cache because we found cmd1 / \\ / \\ RUN cmd1 RUN cmd2 Dockerfile: +------+ +------+ FROM base_image:version |image1| |image2| RUN cmd2 --> use cache because we found base image +---X--+ +------+ RUN cmd21 --> not use cache because there's no child node / \\ running cmd21, so we build a new image here / \\ RUN cmd11 RUN cmd12 +-------+ +-------+ |image11| |image12| +-------+ +-------+ 大部分指令可以根据上述逻辑去寻找缓存，除了 ADD 和 COPY 。这两个指令会复制文件内容到镜像内，除了指令相同以外，Docker 还会检查每个文件内容校验(不包括最后修改时间和最后访问时间)，如果校验不一致，则不会使用缓存。 除了这两个命令，Docker 并不会去检查容器内的文件内容，比如 RUN apt-get -y update，每次执行时文件可能都不一样，但是 Docker 认为命令一致，会继续使用缓存。这样一来，以后构建时都不会再重新运行apt-get -y update。 如果 Docker 没有找到当前指令的缓存，则会构建一个新的镜像，并且之后的所有指令都不会再去寻找缓存。 简单示例接下来用一个简单的示例来感受一下 Dockerfile 是如何用来构建镜像启动容器。我们以定制 nginx 镜像为例，在一个空白目录中，建立一个文本文件，并命名为 Dockerfile： mkdir mynginx cd mynginx vi Dockerfile 构建一个 Dockerfile 文件内容为： FROM nginx RUN echo 'Hello, Docker!' > /usr/share/nginx/html/index.html vi Dockerfile 这个 Dockerfile 很简单，一共就两行涉及到了两条指令：FROM 和 RUN，FROM 表示获取指定基础镜像，RUN 执行命令，在执行的过程中重写了 nginx 的默认页面信息，将信息替换为：Hello, Docker!。 在 Dockerfile 文件所在目录执行： docker build -t nginx:v1 . 命令最后有一个. 表示当前目录 构建完成之后，使用 docker images 命令查看所有镜像，如果存在 REPOSITORY 为 nginx 和 TAG 是 v1 的信息，就表示构建成功。 docker images REPOSITORY TAG IMAGE ID CREATED SIZE nginx v1 8c92471de2cc 6 minutes ago 108.6 MB 接下来使用 docker run 命令来启动容器 docker run --name docker_nginx_v1 -d -p 80:80 nginx:v1 这条命令会用 nginx 镜像启动一个容器，命名为docker_nginx_v1，并且映射了 80 端口，这样我们可以用浏览器去访问这个 nginx 服务器：http://192.168.0.54/，页面返回信息： 这样一个简单使用 Dockerfile 构建镜像，运行容器的示例就完成了！ 修改容器内容容器启动后，需要对容器内的文件进行进一步的完善，可以使用docker exec -it xx bash命令再次进行修改，以上面的示例为基础，修改 nginx 启动页面内容： docker exec -it docker_nginx_v1 bash root@3729b97e8226:/# echo &#39;&lt;h1&gt;Hello, Docker neo!&lt;/h1&gt;&#39; &gt; /usr/share/nginx/html/index.html root@3729b97e8226:/# exit exit以交互式终端方式进入 docker_nginx_v1 容器，并执行了 bash 命令，也就是获得一个可操作的 Shell。然后，我们用&lt;h1&gt;Hello, Docker neo!&lt;/h1&gt;覆盖了 /usr/share/nginx/html/index.html 的内容。 再次刷新浏览器，会发现内容被改变。 修改了容器的文件，也就是改动了容器的存储层，可以通过 docker diff 命令看到具体的改动。 docker diff docker_nginx_v1 ...","tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cayzlh.com/tags/Docker/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Docker","slug":"微服务/Docker","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/Docker/"}]},{"title":"Redis的使用场景","date":"2019-01-29T01:48:53.000Z","path":"2019/01/29/c7bd1b6d.html","text":"转自：使用过Redis，我竟然还不知道Rdb 整理Redis的使用场景 字符串缓存$redis->set(); $redis->get(); $redis->hset(); $redis->hget(); 队列$redis->rpush(); $redis->lpop(); $redis->lrange(); 发布订阅$redis->publish(); $redis->subscribe(); 计数器$redis->set(); $redis->incr(); 排行榜$redis->zadd(); $redis->zrevrange(); $redis->zrange(); 集合间操作$redis->sadd(); $redis->spop(); $redis->sinter(); $redis->sunion(); $redis->sdiff(); 悲观锁解释：悲观锁(Pessimistic Lock), 顾名思义，就是很悲观。 每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁。 场景：如果项目中使用了缓存且对缓存设置了超时时间。 当并发量比较大的时候，如果没有锁机制，那么缓存过期的瞬间， 大量并发请求会穿透缓存直接查询数据库，造成雪崩效应。 /** * 获取锁 * @param String $key 锁标识 * @param Int $expire 锁过期时间 * @return Boolean */ public function lock($key = '', $expire = 5) { $is_lock = $this->_redis->setnx($key, time()+$expire); //不能获取锁 if(!$is_lock){ //判断锁是否过期 $lock_time = $this->_redis->get($key); //锁已过期，删除锁，重新获取 if (time() > $lock_time) { unlock($key); $is_lock = $this->_redis->setnx($key, time() + $expire); } } return $is_lock? true : false; } /** * 释放锁 * @param String $key 锁标识 * @return Boolean */ public function unlock($key = ''){ return $this->_redis->del($key); } // 定义锁标识 $key = 'test_lock'; // 获取锁 $is_lock = lock($key, 10); if ($is_lock) { echo 'get lock success'; echo 'do sth..'; sleep(5); echo 'success'; unlock($key); } else { //获取锁失败 echo 'request too frequently'; } 乐观锁解释：乐观锁(Optimistic Lock), 顾名思义，就是很乐观。 每次去拿数据的时候都认为别人不会修改，所以不会上锁。 watch命令会监视给定的key，当exec时候如果监视的key从调用watch后发生过变化，则整个事务会失败。 也可以调用watch多次监视多个key。这样就可以对指定的key加乐观锁了。 注意watch的key是对整个连接有效的，事务也一样。 如果连接断开，监视和事务都会被自动清除。 当然了exec，discard，unwatch命令都会清除连接中的所有监视。 $strKey = 'test_age'; $redis->set($strKey,10); $age = $redis->get($strKey); echo \"---- Current Age:{$age} ---- \"; $redis->watch($strKey); # 开启事务 $redis->multi(); # 在这个时候新开了一个新会话执行 $redis->set($strKey,30); #新会话 echo \"---- Current Age:{$age} ---- \"; # 30 $redis->set($strKey,20); $redis->exec(); $age = $redis->get($strKey); echo \"---- Current Age:{$age} ---- \"; # 30 # 当exec时候如果监视的key从调用watch后发生过变化，则整个事务会失败","tags":[{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"Redis","slug":"Redis","permalink":"https://www.cayzlh.com/tags/Redis/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"},{"name":"Redis","slug":"运维/Redis","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/Redis/"}]},{"title":"JDK8特性一览","date":"2019-01-22T08:02:21.000Z","path":"2019/01/22/1abc3648.html","text":"转自：https://github.com/winterbe/java8-tutorial 转自：Java8 新特性指导手册 接口内允许添加默认实现的方法Java 8 允许我们通过 default 关键字对接口中定义的抽象方法提供一个默认的实现。 请看下面示例代码： // 定义一个公式接口 interface Formula { // 计算 double calculate(int a); // 求平方根 default double sqrt(int a) { return Math.sqrt(a); } } 在上面这个接口中，我们除了定义了一个抽象方法 calculate，还定义了一个带有默认实现的方法 sqrt。 我们在实现这个接口时，可以只需要实现 calculate 方法，默认方法 sqrt 可以直接调用即可，也就是说我们可以不必强制实现 sqrt 方法。 补充：通过 default 关键字这个新特性，可以非常方便地对之前的接口做拓展，而此接口的实现类不必做任何改动。 Formula formula = new Formula() { @Override public double calculate(int a) { return sqrt(a * 100); } }; formula.calculate(100); // 100.0 formula.sqrt(16); // 4.0 上面通过匿名对象实现了 Formula 接口。但是即使是这样，我们为了完成一个 sqrt(a * 100)简单计算，就写了 6 行代码，很是冗余。 Lamdba表达式在学习 Lambda 表达式之前，我们先来看一段老版本的示例代码，其对一个含有字符串的集合进行排序： List&lt;String> names = Arrays.asList(\"peter\", \"anna\", \"mike\", \"xenia\"); Collections.sort(names, new Comparator&lt;String>() { @Override public int compare(String a, String b) { return b.compareTo(a); } }); Collections 工具类提供了静态方法 sort 方法，入参是一个 List 集合，和一个 Comparator 比较器，以便对给定的 List 集合进行 排序。上面的示例代码创建了一个匿名内部类作为入参，这种类似的操作在我们日常的工作中随处可见。 Java 8 中不再推荐这种写法，而是推荐使用 Lambda 表达： Collections.sort(names, (String a, String b) -> { return b.compareTo(a); }); 正如你看到的，上面这段代码变得简短很多而且易于阅读。但是我们还可以再精炼一点： Collections.sort(names, (String a, String b) -> b.compareTo(a)); List 集合现在已经添加了 sort 方法。而且 Java 编译器能够根据类型推断机制判断出参数类型，这样，连入参的类型都可以省略了！ 函数式接口 Functional Interface抛出一个疑问：在我们书写一段 Lambda 表达式后（比如上一章节中匿名内部类的 Lambda 表达式缩写形式），Java 编译器是如何进行类型推断的，它又是怎么知道重写的哪个方法的？ 需要说明的是，不是每个接口都可以缩写成 Lambda 表达式。只有那些函数式接口（Functional Interface）才能缩写成 Lambda 表示式。 那么什么是函数式接口（Functional Interface）呢？ 所谓函数式接口（Functional Interface）就是只包含一个抽象方法的声明。针对该接口类型的所有 Lambda 表达式都会与这个抽象方法匹配。 注意：你可能会有疑问，Java 8 中不是允许通过 defualt 关键字来为接口添加默认方法吗？那它算不算抽象方法呢？答案是：不算。因此，你可以毫无顾忌的添加默认方法，它并不违反函数式接口（Functional Interface）的定义。 总结一下：只要接口中仅仅包含一个抽象方法，我们就可以将其改写为 Lambda 表达式。为了保证一个接口明确的被定义为一个函数式接口（Functional Interface），我们需要为该接口添加注解：@FunctionalInterface。这样，一旦你添加了第二个抽象方法，编译器会立刻抛出错误提示。 示例代码： @FunctionalInterface interface Converter&lt;F, T> { T convert(F from); } 示例代码2： Converter&lt;String, Integer> converter = (from) -> Integer.valueOf(from); Integer converted = converter.convert(\"123\"); System.out.println(converted); // 123 注意：上面的示例代码，即使去掉 @FunctionalInterface 也是好使的，它仅仅是一种约束而已。 便捷的引用类的构造器及方法小伙伴们，还记得上一个章节这段示例代码么： @FunctionalInterface interface Converter&lt;F, T> { T convert(F from); } Converter&lt;String, Integer> converter = (from) -> Integer.valueOf(from); Integer converted = converter.convert(\"123\"); System.out.println(converted); // 123 上面这段代码，通过 Java 8 的新特性，进一步简化上面的代码： Converter&lt;String, Integer> converter = Integer::valueOf; Integer converted = converter.convert(\"123\"); System.out.println(converted); // 123 Java 8 中允许你通过 :: 关键字来引用类的方法或构造器。上面的代码简单的示例了如何引用静态方法，当然，除了静态方法，我们还可以引用普通方法： class Something { String startsWith(String s) { return String.valueOf(s.charAt(0)); } } Something something = new Something(); Converter&lt;String, String> converter = something::startsWith; String converted = converter.convert(\"Java\"); System.out.println(converted); // \"J\" 接下来，我们再来看看如何通过 :: 关键字来引用类的构造器。首先，我们先来定义一个示例类，在类中声明两个构造器： class Person { String firstName; String lastName; Person() {} Person(String firstName, String lastName) { this.firstName = firstName; this.lastName = lastName; } } 然后，我们再定义一个工厂接口，用来生成 Person 类： // Person 工厂 interface PersonFactory&lt;P extends Person> { P create(String firstName, String lastName); } 我们可以通过 :: 关键字来引用 Person 类的构造器，来代替手动去实现这个工厂接口： // 直接引用 Person 构造器 PersonFactory&lt;Person> personFactory = Person::new; Person person = personFactory.create(\"Peter\", \"Parker\"); Person::new 这段代码，能够直接引用 Person 类的构造器。然后 Java 编译器能够根据上下文选中正确的构造器去实现 PersonFactory.create 方法。 Lamdba访问外部变量及接口默认方法在本章节中，我们将会讨论如何在 lambda 表达式中访问外部变量（包括：局部变量，成员变量，静态变量，接口的默认方法.），它与匿名内部类访问外部变量很相似。 访问局部变量在 Lambda 表达式中，我们可以访问外部的 final 类型变量，如下面的示例代码： // 转换器 @FunctionalInterface interface Converter&lt;F, T> { T convert(F from); } 复制代码 final int num = 1; Converter&lt;Integer, String> stringConverter = (from) -> String.valueOf(from + num); stringConverter.convert(2); // 3 复制代码 与匿名内部类不同的是，我们不必显式声明 num 变量为 final 类型，下面这段代码同样有效： int num = 1; Converter&lt;Integer, String> stringConverter = (from) -> String.valueOf(from + num); stringConverter.convert(2); // 3 但是 num 变量必须为隐式的 final 类型，何为隐式的 final 呢？就是说到编译期为止，num 对象是不能被改变的，如下面这段代码，就不能被编译通过： int num = 1; Converter&lt;Integer, String> stringConverter = (from) -> String.valueOf(from + num); num = 3; 在 lambda 表达式内部改变 num 值同样编译不通过，需要注意, 比如下面的示例代码： int num = 1; Converter&lt;Integer, String> converter = (from) -> { String value = String.valueOf(from + num); num = 3; return value; }; 访问成员变量和静态变量上一章节中，了解了如何在 Lambda 表达式中访问局部变量。与局部变量相比，在 Lambda 表达式中对成员变量和静态变量拥有读写权限： @FunctionalInterface interface Converter&lt;F, T> { T convert(F from); } class Lambda4 { // 静态变量 static int outerStaticNum; // 成员变量 int outerNum; void testScopes() { Converter&lt;Integer, String> stringConverter1 = (from) -> { // 对成员变量赋值 outerNum = 23; return String.valueOf(from); }; Converter&lt;Integer, String> stringConverter2 = (from) -> { // 对静态变量赋值 outerStaticNum = 72; return String.valueOf(from); }; } } 访问接口的默认方法还记得第一章节中定义的那个 Formula (公式) 接口吗？ @FunctionalInterface interface Formula { // 计算 double calculate(int a); // 求平方根 default double sqrt(int a) { return Math.sqrt(a); } } 当时，我们在接口中定义了一个带有默认实现的 sqrt 求平方根方法，在匿名内部类中我们可以很方便的访问此方法： Formula formula = new Formula() { @Override public double calculate(int a) { return sqrt(a * 100); } }; 但是在 lambda 表达式中可不行： Formula formula = (a) -> sqrt(a * 100); 带有默认实现的接口方法，是不能在 lambda 表达式中访问的，上面这段代码将无法被编译通过。 内置的函数式接口JDK 1.8 API 包含了很多内置的函数式接口。其中就包括我们在老版本中经常见到的 Comparator 和 Runnable，Java 8 为他们都添加了 @FunctionalInterface 注解，以用来支持 Lambda 表达式。 值得一提的是，除了 Comparator 和 Runnable 外，还有一些新的函数式接口，它们很多都借鉴于知名的 Google Guava 库。 Predicate断言Predicate 是一个可以指定入参类型，并返回 boolean 值的函数式接口。它内部提供了一些带有默认实现的方法，可以 被用来组合一个复杂的逻辑判断（and, or, negate）： Predicate&lt;String> predicate = (s) -> s.length() > 0; predicate.test(\"foo\"); // true predicate.negate().test(\"foo\"); // false Predicate&lt;Boolean> nonNull = Objects::nonNull; Predicate&lt;Boolean> isNull = Objects::isNull; Predicate&lt;String> isEmpty = String::isEmpty; Predicate&lt;String> isNotEmpty = isEmpty.negate(); FunctionFunction 函数式接口的作用是，我们可以为其提供一个原料，他给生产一个最终的产品。通过它提供的默认方法，组合,链行处理(compose, andThen)： Function&lt;String, Integer> toInteger = Integer::valueOf; Function&lt;String, String> backToString = toInteger.andThen(String::valueOf); backToString.apply(\"123\"); // \"123\" Supplier生产者Supplier 与 Function 不同，它不接受入参，直接为我们生产一个指定的结果，有点像生产者模式： class Person { String firstName; String lastName; Person() {} Person(String firstName, String lastName) { this.firstName = firstName; this.lastName = lastName; } } Supplier&lt;Person> personSupplier = Person::new; personSupplier.get(); // new Person ###Consumer消费者 对于 Consumer，我们需要提供入参，用来被消费，如下面这段示例代码： class Person { String firstName; String lastName; Person() {} Person(String firstName, String lastName) { this.firstName = firstName; this.lastName = lastName; } } Consumer&lt;Person> greeter = (p) -> System.out.println(\"Hello, \" + p.firstName); greeter.accept(new Person(\"Luke\", \"Skywalker\")); ComparatorComparator 在 Java 8 之前是使用比较普遍的。Java 8 中除了将其升级成了函数式接口，还为它拓展了一些默认方法： Comparator&lt;Person> comparator = (p1, p2) -> p1.firstName.compareTo(p2.firstName); Person p1 = new Person(\"John\", \"Doe\"); Person p2 = new Person(\"Alice\", \"Wonderland\"); comparator.compare(p1, p2); // > 0 comparator.reversed().compare(p1, p2); // &lt; 0 Optional首先，Optional 它不是一个函数式接口，设计它的目的是为了防止空指针异常（NullPointerException），要知道在 Java 编程中， 空指针异常可是臭名昭著的。 让我们来快速了解一下 Optional 要如何使用！你可以将 Optional 看做是包装对象（可能是 null, 也有可能非 null）的容器。当你定义了 一个方法，这个方法返回的对象可能是空，也有可能非空的时候，你就可以考虑用 Optional 来包装它，这也是在 Java 8 被推荐使用的做法。 Optional&lt;String> optional = Optional.of(\"bam\"); optional.isPresent(); // true optional.get(); // \"bam\" optional.orElse(\"fallback\"); // \"bam\" optional.ifPresent((s) -> System.out.println(s.charAt(0))); // \"b\" Stream流什么是 Stream 流？ 简单来说，我们可以使用 java.util.Stream 对一个包含一个或多个元素的集合做各种操作。这些操作可能是 中间操作 亦或是 终端操作。 终端操作会返回一个结果，而中间操作会返回一个 Stream 流。 需要注意的是，你只能对实现了 java.util.Collection 接口的类做流的操作。 Map 不支持 Stream 流。 Stream 流支持同步执行，也支持并发执行。 Filter过滤首先，我们创建一个 List 集合： List&lt;String> stringCollection = new ArrayList&lt;>(); stringCollection.add(\"ddd2\"); stringCollection.add(\"aaa2\"); stringCollection.add(\"bbb1\"); stringCollection.add(\"aaa1\"); stringCollection.add(\"bbb3\"); stringCollection.add(\"ccc\"); stringCollection.add(\"bbb2\"); stringCollection.add(\"ddd1\"); Filter 的入参是一个 Predicate, 上面已经说到，Predicate 是一个断言的中间操作，它能够帮我们筛选出我们需要的集合元素。它的返参同样 是一个 Stream 流，我们可以通过 foreach终端操作，来打印被筛选的元素： stringCollection .stream() .filter((s) -> s.startsWith(\"a\")) .forEach(System.out::println); // \"aaa2\", \"aaa1\" 注意：foreach 是一个终端操作，它的返参是 void, 我们无法对其再次进行流操作。 Sorted排序Sorted 同样是一个中间操作，它的返参是一个 Stream 流。另外，我们可以传入一个 Comparator 用来自定义排序，如果不传，则使用默认的排序规则。 stringCollection .stream() .sorted() .filter((s) -> s.startsWith(\"a\")) .forEach(System.out::println); // \"aaa1\", \"aaa2\" 需要注意，sorted 不会对 stringCollection 做出任何改变，stringCollection 还是原有的那些个元素，且顺序不变： System.out.println(stringCollection); // ddd2, aaa2, bbb1, aaa1, bbb3, ccc, bbb2, ddd1 Map转换中间操作 Map 能够帮助我们将 List 中的每一个元素做功能处理。例如下面的示例，通过 map我们将每一个 string 转成大写： stringCollection .stream() .map(String::toUpperCase) .sorted((a, b) -> b.compareTo(a)) .forEach(System.out::println); // \"DDD2\", \"DDD1\", \"CCC\", \"BBB3\", \"BBB2\", \"AAA2\", \"AAA1\" 另外，我们还可以做对象之间的转换，业务中比较常用的是将 DO（数据库对象） 转换成 BO（业务对象） 。 Match匹配顾名思义，match 用来做匹配操作，它的返回值是一个 boolean 类型。通过 match, 我们可以方便的验证一个 list 中是否存在某个类型的元素。 // 验证 list 中 string 是否有以 a 开头的, 匹配到第一个，即返回 true boolean anyStartsWithA = stringCollection .stream() .anyMatch((s) -> s.startsWith(\"a\")); System.out.println(anyStartsWithA); // true // 验证 list 中 string 是否都是以 a 开头的 boolean allStartsWithA = stringCollection .stream() .allMatch((s) -> s.startsWith(\"a\")); System.out.println(allStartsWithA); // false // 验证 list 中 string 是否都不是以 z 开头的, boolean noneStartsWithZ = stringCollection .stream() .noneMatch((s) -> s.startsWith(\"z\")); System.out.println(noneStartsWithZ); // true Count计数count 是一个终端操作，它能够统计 stream 流中的元素总数，返回值是 long 类型。 // 先对 list 中字符串开头为 b 进行过滤，让后统计数量 long startsWithB = stringCollection .stream() .filter((s) -> s.startsWith(\"b\")) .count(); System.out.println(startsWithB); // 3 Reduce汇聚Reduce 中文翻译为：减少、缩小。通过入参的 Function，我们能够将 list 归约成一个值。它的返回类型是 Optional 类型。 Optional&lt;String> reduced = stringCollection .stream() .sorted() .reduce((s1, s2) -> s1 + \"#\" + s2); reduced.ifPresent(System.out::println); // \"aaa1#aaa2#bbb1#bbb2#bbb3#ccc#ddd1#ddd2\" ##Parallel Streams并行流 前面章节我们说过，stream 流是支持顺序和并行的。顺序流操作是单线程操作，而并行流是通过多线程来处理的，能够充分利用物理机 多核 CPU 的优势，同时处理速度更快。 首先，我们创建一个包含 1000000 UUID list 集合。 int max = 1000000; List&lt;String> values = new ArrayList&lt;>(max); for (int i = 0; i &lt; max; i++) { UUID uuid = UUID.randomUUID(); values.add(uuid.toString()); } 分别通过顺序流和并行流，对这个 list 进行排序，测算耗时: 顺序流排序// 纳秒 long t0 = System.nanoTime(); long count = values.stream().sorted().count(); System.out.println(count); long t1 = System.nanoTime(); // 纳秒转微秒 long millis = TimeUnit.NANOSECONDS.toMillis(t1 - t0); System.out.println(String.format(\"顺序流排序耗时: %d ms\", millis)); // 顺序流排序耗时: 899 ms 并行流排序// 纳秒 long t0 = System.nanoTime(); long count = values.parallelStream().sorted().count(); System.out.println(count); long t1 = System.nanoTime(); // 纳秒转微秒 long millis = TimeUnit.NANOSECONDS.toMillis(t1 - t0); System.out.println(String.format(\"并行流排序耗时: %d ms\", millis)); // 并行流排序耗时: 472 ms 正如你所见，同样的逻辑处理，通过并行流，我们的性能提升了近 50%。完成这一切，我们需要做的仅仅是将 stream 改成了 parallelStream。 Map集合前面已经提到过 Map 是不支持 Stream 流的，因为 Map 接口并没有像 Collection 接口那样，定义了 stream() 方法。但是，我们可以对其 key, values, entry 使用 流操作，如 map.keySet().stream(), map.values().stream() 和 map.entrySet().stream(). 另外, JDK 8 中对 map 提供了一些其他新特性: Map&lt;Integer, String> map = new HashMap&lt;>(); for (int i = 0; i &lt; 10; i++) { // 与老版不同的是，putIfAbent() 方法在 put 之前， // 会判断 key 是否已经存在，存在则直接返回 value, 否则 put, 再返回 value map.putIfAbsent(i, \"val\" + i); } // forEach 可以很方便地对 map 进行遍历操作 map.forEach((key, value) -> System.out.println(value)); 除了上面的 putIfAbsent() 和 forEach() 外，我们还可以很方便地对某个 key 的值做相关操作： // computeIfPresent(), 当 key 存在时，才会做相关处理 // 如下：对 key 为 3 的值，内部会先判断值是否存在，存在，则做 value + key 的拼接操作 map.computeIfPresent(3, (num, val) -> val + num); map.get(3); // val33 // 先判断 key 为 9 的元素是否存在，存在，则做删除操作 map.computeIfPresent(9, (num, val) -> null); map.containsKey(9); // false // computeIfAbsent(), 当 key 不存在时，才会做相关处理 // 如下：先判断 key 为 23 的元素是否存在，不存在，则添加 map.computeIfAbsent(23, num -> \"val\" + num); map.containsKey(23); // true // 先判断 key 为 3 的元素是否存在，存在，则不做任何处理 map.computeIfAbsent(3, num -> \"bam\"); map.get(3); // val33 关于删除操作，JDK 8 中提供了能够新的 remove() API: map.remove(3, \"val3\"); map.get(3); // val33 map.remove(3, \"val33\"); map.get(3); // null 如上代码，只有当给定的 key 和 value 完全匹配时，才会执行删除操作。 关于添加方法，JDK 8 中提供了带有默认值的 getOrDefault() 方法： // 若 key 42 不存在，则返回 not found map.getOrDefault(42, \"not found\"); // not found 对于 value 的合并操作也变得更加简单： // merge 方法，会先判断进行合并的 key 是否存在，不存在，则会添加元素 map.merge(9, \"val9\", (value, newValue) -> value.concat(newValue)); map.get(9); // val9 // 若 key 的元素存在，则对 value 执行拼接操作 map.merge(9, \"concat\", (value, newValue) -> value.concat(newValue)); map.get(9); // val9concat 新的日期APIJava 8 中在包 java.time 下添加了新的日期 API. 它和 Joda-Time 库相似，但又不完全相同。 ClockClock 提供对当前日期和时间的访问。我们可以利用它来替代 System.currentTimeMillis() 方法。另外，通过 clock.instant() 能够获取一个 instant 实例， 此实例能够方便地转换成老版本中的 java.util.Date 对象。 Clock clock = Clock.systemDefaultZone(); long millis = clock.millis(); Instant instant = clock.instant(); Date legacyDate = Date.from(instant); // 老版本 java.util.Date Timezones时区ZoneId 代表时区类。通过静态工厂方法方便地获取它，入参我们可以传入某个时区编码。另外，时区类还定义了一个偏移量，用来在当前时刻或某时间 与目标时区时间之间进行转换。 System.out.println(ZoneId.getAvailableZoneIds()); // prints all available timezone ids ZoneId zone1 = ZoneId.of(\"Europe/Berlin\"); ZoneId zone2 = ZoneId.of(\"Brazil/East\"); System.out.println(zone1.getRules()); System.out.println(zone2.getRules()); // ZoneRules[currentStandardOffset=+01:00] // ZoneRules[currentStandardOffset=-03:00] LocalTimeLocalTime 表示一个没有指定时区的时间类，例如，10 p.m.或者 17：30:15，下面示例代码中，将会使用上面创建的 时区对象创建两个 LocalTime。然后我们会比较两个时间，并计算它们之间的小时和分钟的不同。 LocalTime now1 = LocalTime.now(zone1); LocalTime now2 = LocalTime.now(zone2); System.out.println(now1.isBefore(now2)); // false long hoursBetween = ChronoUnit.HOURS.between(now1, now2); long minutesBetween = ChronoUnit.MINUTES.between(now1, now2); System.out.println(hoursBetween); // -3 System.out.println(minutesBetween); // -239 LocalTime 提供多个静态工厂方法，目的是为了简化对时间对象实例的创建和操作，包括对时间字符串进行解析的操作等。 LocalTime late = LocalTime.of(23, 59, 59); System.out.println(late); // 23:59:59 DateTimeFormatter germanFormatter = DateTimeFormatter .ofLocalizedTime(FormatStyle.SHORT) .withLocale(Locale.GERMAN); LocalTime leetTime = LocalTime.parse(\"13:37\", germanFormatter); System.out.println(leetTime); // 13:37 LocalDateLocalDate 是一个日期对象，例如：2014-03-11。它和 LocalTime 一样是个 final 类型对象。下面的例子演示了如何通过加减日，月，年等来计算一个新的日期。 LocalDate, LocalTime, 因为是 final 类型的对象，每一次操作都会返回一个新的时间对象。 LocalDate today = LocalDate.now(); // 今天加一天 LocalDate tomorrow = today.plus(1, ChronoUnit.DAYS); // 明天减两天 LocalDate yesterday = tomorrow.minusDays(2); // 2014 年七月的第四天 LocalDate independenceDay = LocalDate.of(2014, Month.JULY, 4); DayOfWeek dayOfWeek = independenceDay.getDayOfWeek(); System.out.println(dayOfWeek); // 星期五 也可以直接解析日期字符串，生成 LocalDate 实例。（和 LocalTime 操作一样简单） DateTimeFormatter germanFormatter = DateTimeFormatter .ofLocalizedDate(FormatStyle.MEDIUM) .withLocale(Locale.GERMAN); LocalDate xmas = LocalDate.parse(\"24.12.2014\", germanFormatter); System.out.println(xmas); // 2014-12-24 LocalDateTimeLocalDateTime 是一个日期-时间对象。你也可以将其看成是 LocalDate 和 LocalTime 的结合体。操作上，也大致相同。 LocalDateTime 同样是一个 final 类型对象。 LocalDateTime sylvester = LocalDateTime.of(2014, Month.DECEMBER, 31, 23, 59, 59); DayOfWeek dayOfWeek = sylvester.getDayOfWeek(); System.out.println(dayOfWeek); // 星期三 Month month = sylvester.getMonth(); System.out.println(month); // 十二月 // 获取改时间是该天中的第几分钟 long minuteOfDay = sylvester.getLong(ChronoField.MINUTE_OF_DAY); System.out.println(minuteOfDay); // 1439 如果再加上的时区信息，LocalDateTime 还能够被转换成 Instance 实例。Instance 能够被转换成老版本中 java.util.Date 对象。 Instant instant = sylvester .atZone(ZoneId.systemDefault()) .toInstant(); Date legacyDate = Date.from(instant); System.out.println(legacyDate); // Wed Dec 31 23:59:59 CET 2014 格式化 LocalDateTime 对象就和格式化 LocalDate 或者 LocalTime 一样。除了使用预定义的格式以外，也可以自定义格式化输出。 DateTimeFormatter formatter = DateTimeFormatter .ofPattern(\"MMM dd, yyyy - HH:mm\"); LocalDateTime parsed = LocalDateTime.parse(\"Nov 03, 2014 - 07:13\", formatter); String string = formatter.format(parsed); System.out.println(string); // Nov 03, 2014 - 07:13 注意：和 java.text.NumberFormat 不同，新的 DateTimeFormatter 类是 final 类型的，同时也是线程安全的。 Annotations注解在 Java 8 中，注解是可以重复的。让我通过下面的示例代码，来看看到底是咋回事。 首先，我们定义一个包装注解，里面包含了一个有着实际注解的数组： @interface Hints { Hint[] value(); } @Repeatable(Hints.class) @interface Hint { String value(); } Java 8 中，通过 @Repeatable，允许我们对同一个类使用多重注解： 第一种形态：使用注解容器（老方法） @Hints({@Hint(\"hint1\"), @Hint(\"hint2\")}) class Person {} 第二种形态：使用可重复注解（新方法） @Hint(\"hint1\") @Hint(\"hint2\") class Person {} 使用第二种形态，Java 编译器能够在内部自动对 @Hint 进行设置。这对于需要通过反射来读取注解信息时，是非常重要的。 Hint hint = Person.class.getAnnotation(Hint.class); System.out.println(hint); // null Hints hints1 = Person.class.getAnnotation(Hints.class); System.out.println(hints1.value().length); // 2 Hint[] hints2 = Person.class.getAnnotationsByType(Hint.class); System.out.println(hints2.length); // 2 尽管我们绝对不会在 Person 类上声明 @Hints 注解，但是它的信息仍然是可以通过 getAnnotation(Hints.class) 来读取的。 并且，getAnnotationsByType 方法会更方便，因为它赋予了所有 @Hints 注解标注的方法直接的访问权限。 @Target({ElementType.TYPE_PARAMETER, ElementType.TYPE_USE}) @interface MyAnnotation {}","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"}]},{"title":"Java阻塞队列之BlockingQueue","date":"2019-01-18T09:24:44.000Z","path":"2019/01/18/d419173e.html","text":"阻塞队列是一种队列，一种可以在多线程环境下使用，并且支持阻塞等待的队列。也就是说，阻塞队列和一般的队列的区别就在于： 多线程环境支持，多个线程可以安全的访问队列 支持生产和消费等待，多个线程之间互相配合，当队列为空的时候，消费线程会阻塞等待队列不为空；当队列满了的时候，生产线 程就会阻塞直到队列不满。 阻塞队列阻塞队列在Java中的一种典型使用场景是线程池，在线程池中，当提交的任务不能立即 得到执行的时候，线程池就会将提交的任务放到一个阻塞队列中来。比如下面的代码： public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable>()); } newFixedThreadPool使用可LinkedBlockingQueue这种阻塞队列。 public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable>()); } newCachedThreadPool使用了SynchronousQueue这种队列，这种队列的特点是不缓存数据，而是缓存线程，线程分为生产者线程和消费者线程，一个生产者线程和一个消费者线程是互补的，当一个生产者线程遇到一个消费者线程的时候就会直接进行数据交换，所以这种队列的技术点比较高，理解起来难度较大。一个线程只能缓存一个数据，当一个线程插入数据之后就会被阻塞，直到另外一个线程消费了其中的数据。 阻塞队列还提供了其他类型的队列，包括双端阻塞队列，延时阻塞队列，延时阻塞队列的使用可以在newScheduledThreadPool中找到，newScheduledThreadPool里面使用延时阻塞队列来调度周期性任务执行。 下面展示的是BlockingQueue提供的一些方法： BlockingQueue的使用BlockingQueue通常用于在线程上生成另一个线程消耗的对象。下图展示这个过程： 生成线程将继续生成新对象并将它们插入队列，直到队列达到它可以包含的内容的某个上限。换句话说，这是限制。如果阻塞队列达到其上限，则在尝试插入新对象时会阻止生成线程。它一直被阻塞，直到消费线程将一个对象从队列中取出。 消费线程不断将对象从阻塞队列中取出并处理它们。如果消费线程试图将对象从空队列中取出，则消耗线程将被阻塞，直到生成线程将对象放入队列。 BlockingQueue的方法BlockingQueue有4组不同的方法用于插入，删除和检查队列中的元素。如果不能立即执行所请求的操作，则每组方法的行为都不同。 操作类型 Throws Exception Special Value Blocks Times Out 插入 add(o) offer(o) put(o) offer(o, timeout, timeunit) 取出（删除） remove(o) poll() take() poll(timeout, timeunit) 检查 element() peek() 四种操作的含义： Throws Exception： 如果无法立即尝试操作，则抛出异常。 Special Value： 如果无法立即尝试操作，则返回特殊值（通常为true / false）。 Blocks： 如果无法立即执行尝试的操作，则方法调用将阻塞直到它为止。 Times Out： 如果无法立即执行尝试的操作，则方法调用将阻塞直到它，但等待不超过给定的超时。返回一个特殊值，告知操作是否成功（通常为true / false）。 无法在BlockingQueue中插入null。如果您尝试插入null，则BlockingQueue将抛出NullPointerException。 可以访问BlockingQueue中的所有元素，而不仅仅是开头和结尾的元素。例如，假设您已排队对象进行处理，但您的应用程序决定取消它。然后可以调用remove(o)删除队列中的特定对象。但是，这不是非常有效，所以除非你真的需要，否则你不应该使用这些Collection方法。 BlockingQueue实现类BlockingQueue是一个接口，需要通过它的实现类来使用它，BlockingQueue有以下实现类： ArrayBlockingQueueArrayBlockingQueue是一个有界的阻塞队列，它将元素存储在数组内部。它有界意味着它无法存储无限量的元素。它可以同时存储的元素数量有一个上限。在实例化时设置上限，之后无法更改。 ArrayBlockingQueue以FIFO（先进先出）顺序在内部存储元素。队列的头部是队列中最长时间的元素，队列的尾部是队列中最短时间的元素。 以下是如何实例化和使用ArrayBlockingQueue： BlockingQueue queue = new ArrayBlockingQueue(1024); queue.put(\"1\"); Object object = queue.take(); DelayQueueDelayQueue在内部阻止元素，直到某个延迟到期。元素必须实现java.util.concurrent.Delayed接口。以下是该接口的定义： public interface Delayed extends Comparable&lt;Delayed&lt; { public long getDelay(TimeUnit timeUnit); } 只有一个方法，就是要获取消费延时。 延时阻塞队列使用了优先阻塞队列来存储数据，数据的获取是有优先级的，这一点需要注意，在这点上，我们应该和java的线程池的调度线程池的实现联系起来，在java的调度线程池的实现上，也使用了延时队列，而优先级队列可以保证线程池调度的任务都是根据时间优先级被调度的。take方法首先从优先队列中获取第一个元素，然后询问是否需要延时，如果不需要，则直接返回，否则延时设定的时间之后再返回。 Example： public class DelayQueueExample { public static void main(String[] args) { DelayQueue queue = new DelayQueue(); Delayed element1 = new DelayedElement(); queue.put(element1); Delayed element2 = queue.take(); } } LinkedBlockingQueueLinkedBlockingQueue使用链表来作为队列的数据结构，下面就是链表节点的数据结构： static class Node&lt;E> { E item; /** * One of: * - the real successor Node * - this Node, meaning the successor is head.next * - null, meaning there is no successor (this is the last node) */ Node&lt;E> next; Node(E x) { item = x; } } LinkedBlockingQueue将元素保留在链接结构（链接节点）内部。如果需要，该连接结构可任选地具有上限。如果未指定上限，则使用Integer.MAX_VALUE作为上限。 LinkedBlockingQueue在内部以FIFO（先进先出）顺序存储元素。队列的头部是队列中最长时间的元素，队列的尾部是队列中最短时间的元素。 Example： BlockingQueue&lt;String> unbounded = new LinkedBlockingQueue&lt;String>(); BlockingQueue&lt;String> bounded = new LinkedBlockingQueue&lt;String>(1024); bounded.put(\"Value\"); String value = bounded.take(); PriorityBlockingQueuePriorityBlockingQueue是一个无限制的并发队列。 它使用与java.util.PriorityQueue类相同的排序规则。 不能将null插入此队列。 插入PriorityBlockingQueue的所有元素都必须实现java.lang.Comparable接口。 因此，元素根据您在Comparable实现中决定的优先级进行排序。 需要注意的是：PriorityBlockingQueue不会对具有相同优先级的元素强制执行任何特定行为（compare（）== 0）。 如果从PriorityBlockingQueue获取Iterator，Iterator不保证按优先级顺序迭代元素。 Example： BlockingQueue queue = new PriorityBlockingQueue(); //String implements java.lang.Comparable queue.put(\"Value\"); String value = queue.take(); SynchronousQueueSynchronousQueue是一个内部只能包含单个元素的队列。 将元素插入队列的线程被阻塞，直到另一个线程从队列中获取该元素。 同样，如果线程尝试获取元素并且当前不存在任何元素，则该线程将被阻塞，直到线程将元素插入队列。是最为复杂的阻塞队列。 任何插入操作都需要等待其他线程来消费，否则就会阻塞等待，也就是说，生产线程生产出一条数据之后就要等待消费者线程来将其消费掉，才能继续生产数据，否则就会阻塞等待消费。队列中会把到来的线程缓存起来，当然会进行一些操作，下面是大概的算法： 1、队列初始化为null 2、当一个线程达到之后，如果队列为null，则将该线程放到队列中去，否则，判断队列中的第一个元素是否和当前到达的元素 匹配，如果匹配，那么两个线程的数据交易完成，否则也将新到达的线程数据缓存到队列中。 SynchronousQueue通过使用Transferer类的transfer(E e, boolean timed, long nanos)方法来完成数据交易操作，根据fair模式和non-fair模式有两种类型的Transferer，fair模式对应于TransferQueue，non-fair模式对应TransferStack。 Java BlockingQueue Example这是一个Java BlockingQueue示例。该示例使用BlockingQueue接口的ArrayBlockingQueue实现。 实现的流程如下，BlockingQueueExample类在单独的线程中启动Producer和Consumer。 Producer将字符串插入共享的BlockingQueue，然后Consumer将它们取出。 Producer编写生产者代码： public class Producer implements Runnable { protected BlockingQueue queue = null; public Producer(BlockingQueue queue) { this.queue = queue; } @Override public void run() { try { queue.put(\"1\"); Thread.sleep(1000); queue.put(\"2\"); Thread.sleep(1000); queue.put(\"3\"); } catch (InterruptedException e) { e.printStackTrace(); } } } Consumer消费者代码： public class Consumer implements Runnable { protected BlockingQueue queue = null; public Consumer(BlockingQueue queue) { this.queue = queue; } @Override public void run() { try { System.out.println(queue.take()); System.out.println(queue.take()); System.out.println(queue.take()); } catch (InterruptedException e) { e.printStackTrace(); } } } Example示例代码(main())： public class ArrayBlockingQueueExample { public static void main(String[] args) throws InterruptedException { ArrayBlockingQueue queue = new ArrayBlockingQueue(1024); Producer producer = new Producer(queue); Consumer consumer = new Consumer(queue); new Thread(producer).start(); new Thread(consumer).start(); Thread.sleep(4000); } } 运行结果： 1 2 3 Process finished with exit code 0","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"concurrent","slug":"concurrent","permalink":"https://www.cayzlh.com/tags/concurrent/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"}]},{"title":"使用markdown画流程图、时序图","date":"2019-01-17T02:20:40.000Z","path":"2019/01/17/36752c3e.html","text":"使用markdown来写文章，做笔记是非常方便的，这里记录一些高级用法，使用markdown画流程图、时序图、甘特图。 工具：Typora UML时序图在hexo中需要配合使用hexo-filter-sequence以及hexo-filter-mermaid-diagrams插件支持渲染，具体参考：Hexo常用插件 npm install --save hexo-filter-mermaid-diagrams npm install --save hexo-filter-sequence npm install --save hexo-filter-flowchart 简单示例源代码(反斜杠用于转义，实际不需要)： \\`\\`\\`sequence A->B: Hello B(请求)? Note right of B: 对B的一些描述信息 Note left of A: 对A的一些描述 B-->A: I'm find(响应)!两杠是虚线 A->B: I'm really find. B-B: I'm touch myself. \\`\\`\\` 效果： A->B: Hello B(请求)? Note right of B: 对B的一些描述信息 Note left of A: 对A的一些描述 B-->A: I'm find(响应)!两杠是虚线 A->B: I'm really find. B-B: I'm touch myself. 复杂示例源代码： \\`\\`\\`sequence Title: 使用：复杂使用 A->B: Hello B?（请求） Note right of B: 对B的描述 Note left of A: 对A的描述(提示) B-->A: I'm Find!(响应) B->C: How are you? C-->>A: B touch me A->B: are you sure？ Note over C,B: We are friend participant C Note right of C: 没人陪我玩 \\`\\`\\` 效果： Title: 使用：复杂使用 A->B: Hello B?（请求） Note right of B: 对B的描述 Note left of A: 对A的描述(提示) B-->A: I'm Find!(响应) B->C: How are you? C-->>A: B touch me A->B: are you sure？ Note over C,B: We are friend participant C Note right of C: 没人陪我玩 标准示例（使用mermaid标签）以下是标准的UML时序图示例： 源码： \\`\\`\\`mermaid %% 时序图例子,-> 直线，-->虚线，->>实线箭头 sequenceDiagram participant 张三 participant 李四 张三->王五: 王五你好吗？ loop 健康检查 王五->王五: 与疾病战斗 end Note right of 王五: 合理 食物 &lt;br/>看医生... 李四-->>张三: 很好! 王五->李四: 你怎么样? 李四-->王五: 很好! \\`\\`\\` 效果： %% 时序图例子,-> 直线，-->虚线，->>实线箭头 sequenceDiagram participant 张三 participant 李四 张三->王五: 王五你好吗？ loop 健康检查 王五->王五: 与疾病战斗 end Note right of 王五: 合理 食物 看医生... 李四-->>张三: 很好! 王五->李四: 你怎么样? 李四-->王五: 很好! 流程图横向流程图源码： \\`\\`\\`mermaid graph LR A[方形] -->B(圆角) B --> C{条件a} C -->|a=1| D[结果1] C -->|a=2| E[结果2] F[横向流程图] \\`\\`\\` 效果： graph LR A[方形] -->B(圆角) B --> C{条件a} C -->|a=1| D[结果1] C -->|a=2| E[结果2] F[横向流程图] 纵向流程图源码： \\`\\`\\`mermaid graph TD A[方形] -->B(圆角) B --> C{条件a} C -->|a=1| D[结果1] C -->|a=2| E[结果2] F[竖向流程图] \\`\\`\\` 效果： graph TD A[方形] -->B(圆角) B --> C{条件a} C -->|a=1| D[结果1] C -->|a=2| E[结果2] F[竖向流程图] 标准流程图(flow)源码： \\`\\`\\`flow st=>start: 开始框 op=>operation: 处理框 cond=>condition: 判断框(是或否?) sub1=>subroutine: 子流程 io=>inputoutput: 输入输出框 e=>end: 结束框 st->op->cond cond(yes)->io->e cond(no)->sub1(right)->op \\`\\`\\` 效果： st=>start: 开始框 op=>operation: 处理框 cond=>condition: 判断框(是或否?) sub1=>subroutine: 子流程 io=>inputoutput: 输入输出框 e=>end: 结束框 st->op->cond cond(yes)->io->e cond(no)->sub1(right)->op 甘特图源码： \\`\\`\\`mermaid %% 语法示例 gantt dateFormat YYYY-MM-DD title 软件开发甘特图 section 设计 需求 :done, des1, 2018-01-06,2014-01-08 原型 :active, des2, 2018-01-09, 3d UI设计 : des3, after des2, 5d 未来任务 : des4, after des3, 5d section 开发 学习准备理解需求 :crit, done, 2018-01-06,24h 设计框架 :crit, done, after des2, 2d 开发 :crit, active, 3d 未来任务 :crit, 5d 耍 :2d section 测试 功能测试 :active, a1, after des3, 3d 压力测试 :after a1 , 20h 测试报告 : 48h \\`\\`\\` 效果： 当前在hexo中渲染不出来，在Typora能展示如下，后续解决Hexo展示问题：","tags":[{"name":"markdown","slug":"markdown","permalink":"https://www.cayzlh.com/tags/markdown/"}],"categories":[{"name":"雕虫小技","slug":"雕虫小技","permalink":"https://www.cayzlh.com/categories/%E9%9B%95%E8%99%AB%E5%B0%8F%E6%8A%80/"}]},{"title":"Docker的网络模式","date":"2019-01-05T13:18:26.000Z","path":"2019/01/05/ad4a4531.html","text":"Docker在创建容器的时候，可以使用--net选项指定容器的的网络模式。 网络模式Docker支持4种网络模式供大家选择： host模式，使用- -net=host指定。 container模式，使用- -net=container:NAME_or_ID指定。 none模式，使用- -net=none指定。 bridge模式，使用- -net=bridge指定，默认设置。 host模式众所周知，Docker使用了Linux的Namespaces技术来进行资源隔离，如PID Namespace隔离进程，Mount Namespace隔离文件系统，Network Namespace隔离网络等。一个Network Namespace提供了一份独立的网络环境，包括网卡、路由、Iptable规则等都与其他的Network Namespace隔离。一个Docker容器一般会分配一个独立的Network Namespace。但如果启动容器的时候使用host模式，那么这个容器将不会获得一个独立的Network Namespace，而是和宿主机共用一个Network Namespace。容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口。 例如，我们在10.10.101.105/24的机器上用host模式启动一个含有web应用的Docker容器，监听tcp80端口。当我们在容器中执行任何类似ifconfig命令查看网络环境时，看到的都是宿主机上的信息。而外界访问容器中的应用，则直接使用10.10.101.105:80即可，不用任何NAT转换，就如直接跑在宿主机中一样。但是，容器的其他方面，如文件系统、进程列表等还是和宿主机隔离的。 container模式在理解了host模式后，这个模式也就好理解了。这个模式指定新创建的容器和已经存在的一个容器共享一个Network Namespace，而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的IP，而是和一个指定的容器共享IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过lo网卡设备通信。 none模式这个模式和前两个不同。在这种模式下，Docker容器拥有自己的Network Namespace，但是，并不为Docker容器进行任何网络配置。也就是说，这个Docker容器没有网卡、IP、路由等信息。需要我们自己为Docker容器添加网卡、配置IP等。 bridge模式bridge模式是Docker默认的网络设置，此模式会为每一个容器分配Network Namespace、设置IP等，并将一个主机上的Docker容器连接到一个虚拟网桥上。 bridge模式的拓扑当Docker server启动时，会在主机上创建一个名为docker0的虚拟网桥，此主机上启动的Docker容器会连接到这个虚拟网桥上。虚拟网桥的工作方式和物理交换机类似，这样主机上的所有容器就通过交换机连在了一个二层网络中。接下来就要为容器分配IP了，Docker会从RFC1918所定义的私有IP网段中，选择一个和宿主机不同的IP地址和子网分配给docker0，连接到docker0的容器就从这个子网中选择一个未占用的IP使用。如一般Docker会使用172.17.0.0/16这个网段，并将172.17.42.1/16分配给docker0网桥（在主机上使用ifconfig命令是可以看到docker0的，可以认为它是网桥的管理接口，在宿主机上作为一块虚拟网卡使用）。单机环境下的网络拓扑如下，主机地址为10.10.101.105/24。 - - 默认模式安装完Docker的时候，会自动创建三个网络。使用docker network ls命令可以查看这些网络： $ docker network ls NETWORK ID NAME DRIVER SCOPE 75b73b341642 bridge bridge local dbef3961eb84 host host local 90741a2555ee none null local 这三个网络都建在Docker中。运行容器时，可以使用该--network标志来指定容器应连接到的网络。 默认网桥Docker 服务启动后默认会创建一个 docker0 网桥（其上有一个 docker0 内部接口），它在内核层连通了其他的物理或虚拟网卡，这就将所有容器和本地主机都放到同一个物理网络。 Docker 默认指定了 docker0 接口 的 IP 地址和子网掩码，让主机和容器之间可以通过网桥相互通信，它还给出了 MTU（接口允许接收的最大传输单元），通常是 1500 Bytes，或宿主主机网络路由上支持的默认值。这些值都可以在服务启动的时候进行配置。 bridge所有Docker主机上都存在默认网络。如果您不指定其他网络，则新的容器会自动连接到默认bridge网络。 使用docker network inspect命令可以查看相关的网络信息： $ docker network inspect 75b73b341642 [ { \"Name\": \"bridge\", \"Id\": \"75b73b3416429364a268ba6db607cb6bffbc921241714228d22fd95c15cde76f\", \"Created\": \"2019-01-01T05:13:00.609463Z\", \"Scope\": \"local\", \"Driver\": \"bridge\", \"EnableIPv6\": false, \"IPAM\": { \"Driver\": \"default\", \"Options\": null, \"Config\": [ { \"Subnet\": \"172.17.0.0/16\", \"Gateway\": \"172.17.0.1\" } ] }, \"Internal\": false, \"Attachable\": false, \"Ingress\": false, \"ConfigFrom\": { \"Network\": \"\" }, \"ConfigOnly\": false, \"Containers\": { \"1bd6dc5dbb7c6a73801ce682d4fe590cff14ba046837c75de70b7a2f756cdd21\": { \"Name\": \"boring_nash\", \"EndpointID\": \"060084e59605428932e9862193ede495b23459d4d8039b1ef4e0f25099726599\", \"MacAddress\": \"02:42:ac:11:00:03\", \"IPv4Address\": \"172.17.0.3/16\", \"IPv6Address\": \"\" }, \"3dc606b07fbbbc2e2040104764b81cf6fbccf1594f4da99fcf03264ad2fcb9d6\": { \"Name\": \"rabbitmq\", \"EndpointID\": \"08031fb6659f74caa2940d473f3c5ccbc849a5af485361705e63c3df66927e8c\", \"MacAddress\": \"02:42:ac:11:00:02\", \"IPv4Address\": \"172.17.0.2/16\", \"IPv6Address\": \"\" }, \"4b8887d1cf1cbe7c8d17990d2c91dce95f7099e9a9f178b6feed525b7879a369\": { \"Name\": \"objective-mysql\", \"EndpointID\": \"9732e3b010e7053cf8e3d0f0985e5e26557d75a4930d100452ac71c5e97ecc15\", \"MacAddress\": \"02:42:ac:11:00:04\", \"IPv4Address\": \"172.17.0.4/16\", \"IPv6Address\": \"\" } }, \"Options\": { \"com.docker.network.bridge.default_bridge\": \"true\", \"com.docker.network.bridge.enable_icc\": \"true\", \"com.docker.network.bridge.enable_ip_masquerade\": \"true\", \"com.docker.network.bridge.host_binding_ipv4\": \"0.0.0.0\", \"com.docker.network.bridge.name\": \"docker0\", \"com.docker.network.driver.mtu\": \"1500\" }, \"Labels\": {} } ]","tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cayzlh.com/tags/Docker/"}],"categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Docker","slug":"微服务/Docker","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/Docker/"}]},{"title":"SpringCloud（分布式链路跟踪）","date":"2019-01-04T02:39:41.000Z","path":"2019/01/04/a773bf3d.html","text":"Spring Cloud Sleuth一般的，一个分布式服务跟踪系统主要由三部分构成： 数据收集 数据存储 数据展示 根据系统大小不同，每一部分的结构又有一定变化。譬如，对于大规模分布式系统，数据存储可分为实时数据和全量数据两部分，实时数据用于故障排查（Trouble Shooting），全量数据用于系统优化；数据收集除了支持平台无关和开发语言无关系统的数据收集，还包括异步数据收集（需要跟踪队列中的消息，保证调用的连贯性），以及确保更小的侵入性；数据展示又涉及到数据挖掘和分析。虽然每一部分都可能变得很复杂，但基本原理都类似。 服务追踪的追踪单元是从客户发起请求（request）抵达被追踪系统的边界开始，到被追踪系统向客户返回响应（response）为止的过程，称为一个trace。每个 trace 中会调用若干个服务，为了记录调用了哪些服务，以及每次调用的消耗时间等信息，在每次调用服务时，埋入一个调用记录，称为一个span。这样，若干个有序的 span 就组成了一个 trace。在系统向外界提供服务的过程中，会不断地有请求和响应发生，也就会不断生成 trace，把这些带有span 的 trace 记录下来，就可以描绘出一幅系统的服务拓扑图。附带上 span 中的响应时间，以及请求成功与否等信息，就可以在发生问题的时候，找到异常的服务；根据历史数据，还可以从系统整体层面分析出哪里性能差，定位性能优化的目标。 Spring Cloud Sleuth为服务之间调用提供链路追踪。通过Sleuth可以很清楚的了解到一个服务请求经过了哪些服务，每个服务处理花费了多长。从而让我们可以很方便的理清各微服务间的调用关系。此外Sleuth可以帮助我们： 耗时分析: 通过Sleuth可以很方便的了解到每个采样请求的耗时，从而分析出哪些服务调用比较耗时; 可视化错误: 对于程序未捕捉的异常，可以通过集成Zipkin服务界面上看到; 链路优化: 对于调用比较频繁的服务，可以针对这些服务实施一些优化措施。 spring cloud sleuth可以结合zipkin，将信息发送到zipkin，利用zipkin的存储来存储信息，利用zipkin ui来展示数据。 这是Spring Cloud Sleuth的概念图： - ZipKinZipkin 是一个开放源代码分布式的跟踪系统，由Twitter公司开源，它致力于收集服务的定时数据，以解决微服务架构中的延迟问题，包括数据的收集、存储、查找和展现。 每个服务向zipkin报告计时数据，zipkin会根据调用关系通过Zipkin UI生成依赖关系图，显示了多少跟踪请求通过每个服务，该系统让开发者可通过一个 Web 前端轻松的收集和分析数据，例如用户每次请求服务的处理时间等，可方便的监测系统中存在的瓶颈。 Zipkin提供了可插拔数据存储方式：In-Memory、MySql、Cassandra以及Elasticsearch。 实践Zipkin 分为两端，一个是 Zipkin 服务端，一个是 Zipkin 客户端，客户端也就是微服务的应用。客户端会配置服务端的 URL 地址，一旦发生服务间的调用的时候，会被配置在微服务里面的 Sleuth 的监听器监听，并生成相应的 Trace 和 Span 信息发送给服务端。发送的方式主要有两种，一种是 HTTP 报文的方式，还有一种是消息总线的方式如 RabbitMQ。 准备工作无论是用HTTP的方式还是消息总线的方式，都需要： 一个注册中心，用之前的就行 一个Zipkin服务端 两个微服务应用，trace-a和trace-b，其中trace-a中有一个 REST 接口/trace-a，调用该接口后将触发对trace-b应用的调用。 Zipkin服务端使用Docker： pull image docker pull openzipkin/zipkin run container docker run -d -p 9411:9411 openzipkin/zipkin 启动后，访问http://localhost:9411/zipkin/就能看到如下界面： - 服务端OK。 微服务应用创建两个基本的Spring Boot工程，分别名为trace-a和trace-b。 pom配置两个工程的pom文件配置都引入以下依赖： &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-webflux&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-client&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-sleuth&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-zipkin&lt;/artifactId> &lt;/dependency> &lt;/dependencies> 配置文件两者的配置文件也一样（除了spring. application.name和server.port，自行修改） spring: application: name: trace-a sleuth: web: client: enabled: true sampler: probability: 1.0 # 将采样比例设置为 1.0，也就是全部都需要。默认是 0.1 zipkin: base-url: http://localhost:9411/ # 指定了 Zipkin 服务器的地址 server: port: 28092 eureka: client: service-url: defaultZone: http://localhost:28081/eureka/ Spring Cloud Sleuth 有一个 Sampler 策略，可以通过这个实现类来控制采样算法。采样器不会阻碍 span 相关 id 的产生，但是会对导出以及附加事件标签的相关操作造成影响。 Sleuth 默认采样算法的实现是 Reservoir sampling，具体的实现类是 PercentageBasedSampler，默认的采样比例为: 0.1(即 10%)。不过我们可以通过spring.sleuth.sampler.percentage来设置，所设置的值介于 0.0 到 1.0 之间，1.0 则表示全部采集。 编码对trace-a和trace-b进行编码。 trace-a配置一个WebClient Bean： @SpringBootApplication public class TraceAApplication { public static void main(String[] args) { SpringApplication.run(TraceAApplication.class, args); } @Autowired private LoadBalancerExchangeFilterFunction lbFunction; @Bean public WebClient webClient() { return WebClient.builder() .baseUrl(\"http://trace-b\") .filter(lbFunction).build(); } } 创建一个TraceAController： @RestController public class TraceAController { @Autowired private WebClient webClient; @GetMapping(\"/trace-a\") public Mono&lt;String> trace() { System.out.println(\"call trace-a.\"); return webClient.get().uri(\"/trace-b\") .retrieve().bodyToMono(String.class); } } trace-btrace-b的启动类如下，使用默认的代码，不需修改： @SpringBootApplication public class TraceBApplication { public static void main(String[] args) { SpringApplication.run(TraceBApplication.class, args); } } 创建一个TraceBController： @RestController public class TraceBController { @GetMapping(\"/trace-b\") public Mono&lt;String> trace() { System.out.println(\"call trace-b.\"); return Mono.just(\"Trace.\"); } } 至此，准备工作就完成了。Spring 应用在监测到 classpath 中有 Sleuth 和 Zipkin 后，会自动在 WebClient（或 RestTemplate）的调用过程中向 HTTP 请求注入追踪信息，并向 Zipkin Server 发送这些信息。 验证分别启动服务注册中心、trace-a和trace-b，访问http://localhost:28092/trace-a，可以得到返回值Trace.，同时在两个工程的控制台都能看到相关日志输出： # trace-a工程控制台 call trace-a. # trace-b工程控制台 call trace-b. 访问http://localhost:9411，点击Find Traces看到有一条记录： - 点击进去可以看到详细信息： - 消息总线-RabbitMQ方式Zipkin 不再推荐我们来自定义 Server 端了，所以在最新版本的 Spring Cloud 依赖管理里已经找不到 zipkin-server 了。 通过环境变量让Zipkin从RabbitMQ中读取信息： RABBIT_ADDRESSES=localhost java -jar zipkin.jar 关于 Zipkin 的 Client 端，也就是微服务应用，我们就在之前 trace-a、trace-b 的基础上修改，只要在他们的依赖里都引入spring-cloud-stream-binder-rabbit就好了，别的不用改。 &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-stream-binder-rabbit&lt;/artifactId> &lt;/dependency> 参考 分布式链路跟踪 Sleuth 与 Zipkin【Finchley 版】 使用Spring Cloud Sleuth和Zipkin进行分布式链路跟踪","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.cayzlh.com/tags/SpringCloud/"},{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"SpringCloud","slug":"Spring/SpringCloud","permalink":"https://www.cayzlh.com/categories/Spring/SpringCloud/"}]},{"title":"SpringCloud（服务网关zuul）","date":"2019-01-03T02:00:46.000Z","path":"2019/01/03/d3f1148e.html","text":"API GatewayAPI Gateway是微服务架构中不可或缺的部分：http://dockone.io/article/482。 API Gateway是一个服务器，也可以说是进入系统的唯一节点。这跟面向对象设计模式中的Facade模式很像。API Gateway封装内部系统的架构，并且提供API给各个客户端。它还可能有其他功能，如授权、监控、负载均衡、缓存、请求分片和管理、静态响应处理等。 API Gateway负责请求转发、合成和协议转换。所有来自客户端的请求都要先经过API Gateway，然后路由这些请求到对应的微服务。API Gateway将经常通过调用多个微服务来处理一个请求以及聚合多个服务的结果。它可以在web协议与内部使用的非Web友好型协议间进行转换，如HTTP协议、WebSocket协议。 API Gateway可以提供给客户端一个定制化的API。它暴露一个粗粒度API给移动客户端。以产品最终页这个使用场景为例。API Gateway提供一个服务提供点（/productdetails?productid=xxx）使得移动客户端可以在一个请求中检索到产品最终页的全部数据。API Gateway通过调用多个服务来处理这一个请求并返回结果，涉及产品信息、推荐、评论等。 一个很好的API Gateway例子是Netfix API Gateway。Netflix流服务提供数百个不同的微服务，包括电视、机顶盒、智能手机、游戏系统、平板电脑等。起初，Netflix视图提供一个适用全场景的API。但是，他们发现这种形式不好用，因为涉及到各式各样的设备以及它们独特的需求。现在，他们采用一个API Gateway来提供容错性高的API，针对不同类型设备有相应代码。事实上，一个适配器处理一个请求平均要调用6到8个后端服务。Netflix API Gateway每天处理数十亿的请求。 API Gateway的优点和缺点如你所料，采用API Gateway也是优缺点并存的。API Gateway的一个最大好处是封装应用内部结构。相比起来调用指定的服务，客户端直接跟gatway交互更简单点。API Gateway提供给每一个客户端一个特定API，这样减少了客户端与服务器端的通信次数，也简化了客户端代码。 API Gateway也有一些缺点。它是一个高可用的组件，必须要开发、部署和管理。还有一个问题，它可能成为开发的一个瓶颈。开发者必须更新API Gateway来提供新服务提供点来支持新暴露的微服务。更新API Gateway时必须越轻量级越好。否则，开发者将因为更新Gateway而排队列。但是，除了这些缺点，对于大部分的应用，采用API Gateway的方式都是有效的。 使用API Gateway后，客户端和微服务之间的网络图变成下图： 通过API Gateway，可以统一向外部系统提供REST API。Spring Cloud中使用Zuul作为API Gateway。Zuul提供了动态路由、监控、回退、安全等功能。 ZuulNetflix开源的微服务网关，核心是一系列过滤器： 身份认证安全 审查与监控 动态路由 压力测试 附再分配 静态响应处理 多区域弹性 Zuul过滤器Spring Cloud中使用Zuul作为API Gateway。Zuul提供了动态路由、监控、回退、安全等功能。主要为4种标准类型： PRE：在请求被路由之前调用 ROUTING：这种过滤器将请求路由到微服务 POST：在路由到微服务以后执行 ERROR：在其他阶段发生错误时自信该过滤器 Spring Cloud ZuulSpring Cloud Zuul路由是微服务架构的不可或缺的一部分，提供动态路由，监控，弹性，安全等的边缘服务。Zuul是Netflix出品的一个基于JVM路由和服务端的负载均衡器。 准备工作新建一个Spring Boot项目，命名为：api-gateway， POM配置在pom.xml中引入以下依赖： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;parent> &lt;groupId>com.cayzlh&lt;/groupId> &lt;artifactId>spring-cloud-demos-parent&lt;/artifactId> &lt;version>0.0.1&lt;/version> &lt;relativePath/> &lt;!-- lookup parent from repository --> &lt;/parent> &lt;artifactId>api-gateway&lt;/artifactId> &lt;version>0.0.1-SNAPSHOT&lt;/version> &lt;name>api-gateway&lt;/name> &lt;description>Demo project for Spring Boot&lt;/description> &lt;properties> &lt;java.version>1.8&lt;/java.version> &lt;/properties> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-zuul&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-client&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;build> &lt;plugins> &lt;plugin> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-maven-plugin&lt;/artifactId> &lt;/plugin> &lt;/plugins> &lt;/build> &lt;/project> 配置文件在配置文件 application.yml 中加入服务名、端口号、Eureka 注册中心的地址： spring: application: name: api-gateway server: port: 28091 eureka: client: service-url: defaultZone: http://localhost:28081/eureka/ 启动类使用@EnableZuulProxy注解开启Zuul功能： @EnableZuulProxy @SpringBootApplication public class ApiGatewayApplication { public static void main(String[] args) { SpringApplication.run(ApiGatewayApplication.class, args); } } 至此，一个基于Spring Cloud Zuul的服务网关就已经构建完成。分别启动注册中心、服务生产者、服务消费者、API-GATEWAY： 启动完成后，访问http://localhost:208081，可以看到上面的结果。 测试由于 Spring Cloud Zuul 在整合了 Eureka 之后，具备默认的服务路由功能，即：当我们这里构建的api-gateway应用启动并注册到 Eureka 之后，服务网关会发现上面我们启动的两个服务producer和consumer，这时候 Zuul 就会创建两个路由规则。每个路由规则都包含两部分，一部分是外部请求的匹配规则，另一部分是路由的服务 ID。针对当前示例的情况，Zuul 会创建下面的两个路由规则： 转发到eureka-producer服务的请求规则为：/eureka-producer/** 转发到eureka-consumer服务的请求规则为：/eureka-consumer/** 最后，我们可以通过访问28091端口的服务网关来验证上述路由的正确性： 比如访问：http://localhost:28091/eureka-consumer/hello/zhangsan，该请求将最终被路由到consumer的/hello接口上： 以上结果说明zuul已经开始生效了。 过滤器Zuul还有更多的应用场景，比如：鉴权、流量转发、请求统计等等，这些功能都可以使用Zuul来实现。 Zuul的核心Filter是Zuul的核心，用来实现对外服务的控制。Filter的生命周期有4个，分别是PRE、ROUTING、POST、ERROR，整个生命周期可以用下图来表示： Zuul大部分功能都是通过过滤器来实现的，这些过滤器类型对应于请求的典型生命周期。 PRE： 这种过滤器在请求被路由之前调用。我们可利用这种过滤器实现身份验证、在集群中选择请求的微服务、记录调试信息等。 ROUTING：这种过滤器将请求路由到微服务。这种过滤器用于构建发送给微服务的请求，并使用Apache HttpClient或Netfilx Ribbon请求微服务。 POST：这种过滤器在路由到微服务以后执行。这种过滤器可用来为响应添加标准的HTTP Header、收集统计信息和指标、将响应从微服务发送给客户端等。 ERROR：在其他阶段发生错误时执行该过滤器。 除了默认的过滤器类型，Zuul还允许我们创建自定义的过滤器类型。例如，我们可以定制一种STATIC类型的过滤器，直接在Zuul中生成响应，而不将请求转发到后端的微服务。 Zuul中默认实现的Filter 类型 顺序 过滤器 功能 pre -3 ServletDetectionFilter 标记处理Servlet的类型 pre -2 Servlet30WrapperFilter 包装HttpServletRequest请求 pre -1 FormBodyWrapperFilter 包装请求体 route 1 DebugFilter 标记调试标志 route 5 PreDecorationFilter 处理请求上下文供后续使用 route 10 RibbonRoutingFilter serviceId请求转发 route 100 SimpleHostRoutingFilter url请求转发 route 500 SendForwardFilter forward请求转发 post 0 SendErrorFilter 处理有错误的请求响应 post 1000 SendResponseFilter 处理正常的请求响应 - 禁用指定的Filter可以在application.xml中配置需要禁用的filter，以zuul.&lt;SimpleClassName&gt;.&lt;filterType&gt;.disable=true这样的格式配置，比如要禁用org.springframework.cloud.netflix.zuul.filters.post.SendResponseFilter就设置： zuul: SendResponseFilter: post: disable: true 自定义Filter我们假设有这样一个场景，因为服务网关应对的是外部的所有请求，为了避免产生安全隐患，我们需要对请求做一定的限制，比如请求中含有 Token 便让请求继续往下走，如果请求不带 Token 就直接返回并给出提示。 首先自定义一个 Filter，继承 ZuulFilter 抽象类，在 run() 方法中验证参数是否含有 Token，具体如下： public class TokenFilter extends ZuulFilter { /** * 过滤器的类型，它决定过滤器在请求的哪个生命周期中执行。 * 这里定义为pre，代表会在请求被路由之前执行。 * * @return */ @Override public String filterType() { return \"pre\"; } /** * filter执行顺序，通过数字指定。 * 数字越大，优先级越低。 * * @return */ @Override public int filterOrder() { return 0; } /** * 判断该过滤器是否需要被执行。这里我们直接返回了true，因此该过滤器对所有请求都会生效。 * 实际运用中我们可以利用该函数来指定过滤器的有效范围。 * * @return */ @Override public boolean shouldFilter() { return true; } /** * 过滤器的具体逻辑 * * @return */ @Override public Object run() { RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); String token = request.getParameter(\"token\"); if (token == null || token.isEmpty()) { ctx.setSendZuulResponse(false); ctx.setResponseStatusCode(401); ctx.setResponseBody(\"token is empty\"); } return null; } } 在上面实现的过滤器代码中，我们通过继承ZuulFilter抽象类并重写了下面的四个方法来实现自定义的过滤器。这四个方法分别定义了： filterType()：过滤器的类型，它决定过滤器在请求的哪个生命周期中执行。这里定义为pre，代表会在请求被路由之前执行。 filterOrder()：过滤器的执行顺序。当请求在一个阶段中存在多个过滤器时，需要根据该方法返回的值来依次执行。通过数字指定，数字越大，优先级越低。 shouldFilter()：判断该过滤器是否需要被执行。这里我们直接返回了true，因此该过滤器对所有请求都会生效。实际运用中我们可以利用该函数来指定过滤器的有效范围。 run()：过滤器的具体逻辑。这里我们通过ctx.setSendZuulResponse(false)令 Zuul 过滤该请求，不对其进行路由，然后通过ctx.setResponseStatusCode(401)设置了其返回的错误码，当然我们也可以进一步优化我们的返回，比如，通过ctx.setResponseBody(body)对返回 body 内容进行编辑等。 在实现了自定义过滤器之后，它并不会直接生效，我们还需要为其创建具体的 Bean 才能启动该过滤器，比如，在应用主类中增加如下内容： @EnableZuulProxy @SpringBootApplication public class ApiGatewayApplication { public static void main(String[] args) { SpringApplication.run(ApiGatewayApplication.class, args); } @Bean public TokenFilter tokenFilter() { return new TokenFilter(); } } 在对api-gateway服务完成了上面的改造之后，我们可以重新启动它，并发起下面的请求，对上面定义的过滤器做一个验证： 访问 http://localhost:14000/eureka-consumer/hello/zhangsan 返回 401 错误和token is empty 访问 http://localhost:14000/eureka-consumer/hello/zhangsan?token=token 正确路由到eureka-consumer的/hello接口，并返回Hello, zhangsan!, 现在时间：1546506130007 路由熔断当我们的后端服务出现异常的时候，我们不希望将异常抛出给最外层，期望服务可以自动进行一降级。Zuul给我们提供了这样的支持。当某个服务出现异常时，直接返回我们预设的信息。 我们通过自定义的fallback方法，并且将其指定给某个route来实现该route访问出问题的熔断处理。主要继承ZuulFallbackProvider接口来实现，ZuulFallbackProvider默认有两个方法，一个用来指明熔断拦截哪个服务，一个定制返回内容。 public interface ZuulFallbackProvider { /** * The route this fallback will be used for. * @return The route the fallback will be used for. */ public String getRoute(); /** * Provides a fallback response. * @return The fallback response. */ public ClientHttpResponse fallbackResponse(); } 实现类通过实现getRoute方法，告诉Zuul它是负责哪个route定义的熔断。而fallbackResponse方法则是告诉 Zuul 断路出现时，它会提供一个什么返回值来处理请求。 后来Spring又扩展了此类，丰富了返回方式，在返回的内容中添加了异常信息，因此最新版本建议直接继承类FallbackProvider 。 路由重试有时候因为网络或者其它原因，服务可能会暂时的不可用，这个时候我们希望可以再次对服务进行重试，Zuul也帮我们实现了此功能，需要结合Spring Retry 一起来实现。需要添加依赖： &lt;dependency> &lt;groupId>org.springframework.retry&lt;/groupId> &lt;artifactId>spring-retry&lt;/artifactId> &lt;/dependency> 开启重试在某些情况下是有问题的，比如当压力过大，一个实例停止响应时，路由将流量转到另一个实例，很有可能导致最终所有的实例全被压垮。说到底，断路器的其中一个作用就是防止故障或者压力扩散。用了retry，断路器就只有在该服务的所有实例都无法运作的情况下才能起作用。这种时候，断路器的形式更像是提供一种友好的错误信息，或者假装服务正常运行的假象给使用者。 不用retry，仅使用负载均衡和熔断，就必须考虑到是否能够接受单个服务实例关闭和eureka刷新服务列表之间带来的短时间的熔断。如果可以接受，就无需使用retry。 - Zuul高可用不同的客户端使用不同的负载将请求分发到后端的Zuul，Zuul在通过Eureka调用后端服务，最后对外输出。因此为了保证Zuul的高可用性，前端可以同时启动多个Zuul实例进行负载，在Zuul的前端使用Nginx或者F5进行负载转发以达到高可用性。 参考 服务网关 Zuul（路由）【Finchley 版】 服务网关zuul初级篇 服务网关Zuul高级篇 服务网关 Zuul（过滤器）【Finchley 版】","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.cayzlh.com/tags/SpringCloud/"},{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"SpringCloud","slug":"Spring/SpringCloud","permalink":"https://www.cayzlh.com/categories/Spring/SpringCloud/"}]},{"title":"Docker使用rabbitmq","date":"2019-01-01T12:28:08.000Z","path":"2019/01/01/94bbf97f.html","text":"什么是RabbitMQ？RabbitMQ是开源消息代理软件（有时称为面向消息的中间件），它实现了高级消息队列协议（AMQP）。RabbitMQ服务器采用Erlang编程语言编写，构建于Open Telecom Platform框架之上，用于集群和故障转移。与代理接口的客户端库可用于所有主要编程语言。 如何在Docker使用RabbitMQ镜像运行守护进程关于RabbitMQ的一个重要注意事项是它根据所谓的“节点名称”存储数据，默认为主机名。这对于在Docker中的使用意味着我们应该为每个守护进程指定-h/ --hostnameexplicit，这样我们就不会获得随机主机名并且可以跟踪我们的数据： $ docker run -d --hostname my-rabbit --name some-rabbit rabbitmq:3 这将启动一个侦听默认端口5672的RabbitMQ容器。如果你给它一分钟，那么docker logs some-rabbit你会在输出中看到类似于的块： =INFO REPORT==== 6-Jul-2015::20:47:02 === node : rabbit@my-rabbit home dir : /var/lib/rabbitmq config file(s) : /etc/rabbitmq/rabbitmq.config cookie hash : UoNOcDhfxW9uoZ92wh6BjA== log : tty sasl log : tty database dir : /var/lib/rabbitmq/mnesia/rabbit@my-rabbit 请注意database dir那里，特别是它的“节点名称”附加到文件存储的末尾。/var/lib/rabbitmq默认情况下，此图像会生成所有卷。 内存限制RabbitMQ包含明确跟踪和管理内存使用的功能，因此需要了解cgroup强加的限制。 上游配置设置为vm_memory_high_watermark，文档中的“Memory Alarms”中对此进行了描述。 在此图像中，此值通过设置RABBITMQ_VM_MEMORY_HIGH_WATERMARK。此环境变量的值解释如下： 0.49被视为49%，就像上游（{ vm_memory_high_watermark, 0.49 }） 56%被视为56%（0.56; { vm_memory_high_watermark, 0.56 }） 1073741824被视为绝对字节数（{ vm_memory_high_watermark, { absolute, 1073741824 } }） 1024MiB被视为具有unit（{ vm_memory_high_watermark, { absolute, &quot;1024MiB&quot; } }）的绝对字节数 主要的行为差异在于如何处理百分比。如果当前容器具有内存限制（--memory/ -m），则将根据内存限制将百分比值计算为绝对字节值，而不是按原样传递给RabbitMQ。例如，对于一个容器运行--memory 2048m（以及隐含的上游默认RABBITMQ_VM_MEMORY_HIGH_WATERMARK的40%）将设置有效限制819MB（这是40%的2048MB）。 管理插件默认情况下安装并启用了管理插件提供的第二组标签，可在标准管理端口15672上使用，默认用户名和密码为guest/ guest： $ docker run -d --hostname my-rabbit --name some-rabbit rabbitmq:3-management 您可以通过http://container-ip:15672浏览器访问它，或者如果您需要在主机外部访问，请访问端口8080： $ docker run -d --hostname my-rabbit --name some-rabbit -p 8080:15672 \\ rabbitmq:3-management 然后，您可以转到http://localhost:8080或http://host-ip:8080在浏览器中。 环境变量Dockerfile中定义了一小部分可能的环境变量，这些变量将通过docker引擎传递（如下所示）。有关RabbitMQ本身支持的环境变量列表，请参阅：https：//www.rabbitmq.com/configure.html 对于没有管理插件的SSL配置： RABBITMQ_SSL_CACERTFILE RABBITMQ_SSL_CERTFILE RABBITMQ_SSL_DEPTH RABBITMQ_SSL_FAIL_IF_NO_PEER_CERT RABBITMQ_SSL_KEYFILE RABBITMQ_SSL_VERIFY 对于使用管理插件的SSL配置： RABBITMQ_MANAGEMENT_SSL_CACERTFILE RABBITMQ_MANAGEMENT_SSL_CERTFILE RABBITMQ_MANAGEMENT_SSL_DEPTH RABBITMQ_MANAGEMENT_SSL_FAIL_IF_NO_PEER_CERT RABBITMQ_MANAGEMENT_SSL_KEYFILE RABBITMQ_MANAGEMENT_SSL_VERIFY 设置默认用户和密码如果你想改变默认的用户名和密码guest/ guest，你可以用这样做RABBITMQ_DEFAULT_USER和RABBITMQ_DEFAULT_PASS环境变量： $ docker run -d --hostname my-rabbit --name some-rabbit \\ -e RABBITMQ_DEFAULT_USER=user \\ -e RABBITMQ_DEFAULT_PASS=password rabbitmq:3-management 然后，您可以转到http://localhost:8080或http://host-ip:8080在浏览器中使用user/ password来访问管理控制台 要从文件而不是环境变量中获取用户名和密码_FILE，请在环境变量名称中添加后缀（例如，RABBITMQ_DEFAULT_USER_FILE=/run/secrets/xxx使用Docker Secrets）。 设置默认vhost如果要更改默认vhost，可以使用RABBITMQ_DEFAULT_VHOST环境变量： $ docker run -d --hostname my-rabbit --name some-rabbit\\ -e RABBITMQ_DEFAULT_VHOST=my_vhost rabbitmq:3-management 启用HiPE有关各种配置选项的更多信息，请参见RabbitMQ“配置”。 要在启动时启用HiPE编译器，请使用RABBITMQ_HIPE_COMPILEset to 1。根据官方文件： 设置为true以使用HiPE预编译RabbitMQ的部分，HiPE是Erlang的即时编译器。这将以增加启动时间为代价来增加服务器吞吐量。您可能会在启动时延迟几分钟后看到20-50％的性能提升。 因此，在配置运行状况检查，自动群集等时考虑启动延迟非常重要。 启用插件例 enabled_plugins [rabbitmq_federation_management,rabbitmq_management,rabbitmq_mqtt,rabbitmq_stomp]. 附加配置如果需要其他配置，建议提供适当的/etc/rabbitmq/rabbitmq.conf文件（有关详细信息，请参阅RabbitMQ文档的“配置文件”部分），例如通过bind-mount，Docker Configs或Dockerfile带有COPY指令的short 。 或者，可以使用RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS环境变量，其语法在Erlang OTP设计原则用户指南的7.8节（“配置应用程序”）中描述（-ApplName is 的适当值-rabbit），此方法需要稍微不同的再现相当于rabbitmq.conf。例如，配置channel_max看起来像-e RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=&quot;-rabbit channel_max 4007&quot;。变量channel_max与其值之间的空间在4007环境中翻译时正确变为逗号的位置。 其他配置键将被指定为列表。例如，配置两者channel_max并auth_backends看起来像-e RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=&quot;-rabbit channel_max 4007 auth_backends [rabbit_auth_backend_ldap,rabbit_auth_backend_internal]&quot;。请注意，某些变量（例如for）auth_backends要求将其值括在括号中，并将多个值明确地包括在逗号中作为分隔符。 连接到守护进程$ docker run --name some-app --link some-rabbit:rabbit \\ -d application-that-uses-rabbitmq spring cloud bus中使用拉取rabbitmq镜像执行以下命令，拉取latest版官方镜像： docker pull rabbitmq:management 使用带管理界面的镜像。 使用镜像执行以下命令，使用镜像： docker run -d --name rabbitmq --publish 5671:5671 \\ --publish 5672:5672 --publish 4369:4369 \\ --publish 25672:25672 --publish 15671:15671 --publish 15672:15672 \\ rabbitmq:management 启动之后访问http://localhost:15672/能够看到Web管理界面，使用guest / guest登录之后看到如下界面，说明镜像已经运行。 参考 rabbitmq https://blog.cayzlh.com/2019/01/01/2019010101/","tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cayzlh.com/tags/Docker/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://www.cayzlh.com/tags/rabbitmq/"}],"categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Docker","slug":"微服务/Docker","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/Docker/"}]},{"title":"SpringCloud（配置中心和消息总线）","date":"2019-01-01T01:16:17.000Z","path":"2019/01/01/b2f3c839.html","text":"在SpringCloud（Git版配置中心）中有提到过，如果需要客户端获取到最新的配置信息需要执行refresh，我们可以利用webhook的机制每次提交代码发送请求来刷新客户端，当客户端越来越多的时候，需要每个客户端都执行一遍，这种方案就不太适合了。使用Spring Cloud Bus可以完美解决这一问题。 Spring Cloud BusSpring cloud bus通过轻量消息代理连接各个分布的节点。这会用在广播状态的变化（例如配置变化）或者其他的消息指令。Spring bus的一个核心思想是通过分布式的启动器对spring boot应用进行扩展，也可以用来建立一个多个应用之间的通信频道。目前唯一实现的方式是用AMQP消息代理作为通道，同样特性的设置（有些取决于通道的设置）在更多通道的文档中。 Spring cloud bus可以将它理解为管理和传播所有分布式项目中的消息既可，其实本质是利用了MQ的广播机制在分布式的系统中传播消息，目前常用的有Kafka和RabbitMQ。利用bus的机制可以做很多的事情，其中配置中心客户端刷新就是典型的应用场景之一，我们用一张图来描述bus在配置中心使用的机制。 根据此图我们可以看出利用Spring Cloud Bus做配置更新的步骤: 提交代码触发post给客户端A发送bus/refresh 客户端A接收到请求从Server端更新配置并且发送给Spring Cloud Bus Spring Cloud bus接到消息并通知给其它客户端 其它客户端接收到通知，请求Server端获取最新配置 全部客户端均获取到最新的配置 RabbitMQ由于需要用到MQ，这里使用Docker安装RabbitMQ来用作示例，Docker教程。 Docker中使用RabbitMQRabbitMQ是开源消息代理软件（有时称为面向消息的中间件），它实现了高级消息队列协议（AMQP）。RabbitMQ服务器采用Erlang编程语言编写，构建于Open Telecom Platform框架之上，用于集群和故障转移。与代理接口的客户端库可用于所有主要编程语言。 拉取rabbitmq镜像执行以下命令，拉取latest版官方镜像： docker pull rabbitmq:management 使用带管理界面的镜像。 使用镜像执行以下命令，使用镜像： docker run -d --name rabbitmq --publish 5671:5671 \\ --publish 5672:5672 --publish 4369:4369 \\ --publish 25672:25672 --publish 15671:15671 --publish 15672:15672 \\ rabbitmq:management 启动之后访问http://localhost:15672/能够看到Web管理界面，使用guest / guest登录之后看到如下界面，说明镜像已经运行。 很好， 现在开始改造代码。 服务端pom配置在pom.xml中添加以下依赖： &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-config-server&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-client&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-bus&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-stream-binder-rabbit&lt;/artifactId> &lt;/dependency> 以上四个依赖是必须的 配置文件修改application.yml文件： spring: application: name: config-server cloud: config: server: git: uri: https://github.com/cayzlh/SpringCloudDemos # 配置git仓库的地址 search-paths: config-repo # git仓库地址下的相对地址，可以配置多个，用,分割。 bus: enabled: true trace: enabled: true server: port: 28088 eureka: client: service-url: defaultZone: http://localhost:28081/eureka/ management: endpoints: web: exposure: include: bus-refresh 主要增加的内容有： spring.cloud.bus.enable spring.cloud.bus.trace.enable Management.endpoints.web.exposure.include 启动类添加@EnableConfigServer注解： @EnableDiscoveryClient @EnableConfigServer @SpringBootApplication public class ConfigServerGitApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerGitApplication.class, args); } } 客户端pom配置在 pom.xml 里添加以下依赖，前 5 个是必须的，最后一个 webflux 可以用 web 来代替： &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-config&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-client&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-bus&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-stream-binder-rabbit&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-actuator&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-webflux&lt;/artifactId> &lt;/dependency> 如果缺了spring-boot-starter-actuator，当对服务端执行/actuator/bus-refresh的时候，客户端接收不到信息。 配置文件有两个配置文件，application.xml： spring: application: name: config-client-git cloud: enabled: true bus: trace: enabled: true server: port: 28089 management: endpoints: web: exposure: include: refresh 启用spring cloud bus，bootstrap.xml： spring: cloud: config: name: test-config profile: test label: master discovery: enabled: true service-id: config-server eureka: client: service-url: defaultZone: http://localhost:28081/eureka/ controller基本上没有啥改动 @RefreshScope @RestController public class HelloController { @Value(\"${test.hello:error}\") private String profile; @GetMapping(\"/info\") public Mono&lt;String> hello() { return Mono.justOrEmpty(profile); } } @RefreshScope注解必须加上，否则客户端会受到服务端的更新消息，但是更新不了，因为不知道更新哪里的。 启动类默认的就可以 @EnableDiscoveryClient @SpringBootApplication public class ConfitClientApplication { public static void main(String[] args) { SpringApplication.run(ConfitClientApplication.class, args); } } 测试分别启动注册中心、config-server-git、config-client（其中client分别用不同端口启动两个以上实例，用以模拟多个客户端），启动后，RabbitMQ 中会自动创建一个 topic 类型的 Exchange 和两个以springCloudBus.anonymous.开头的匿名 Queue： - - 使用postman请求http://localhost:28089/info，得到结果（各个端口的客户端接口都请求）： - 修改test-config-test.yml，将里面的内容改成： test: hello: test, are you ok ?? bus !! 将其push到GitHub，在终端执行以下命令： curl -X POST http://localhost:28088/actuator/bus-refresh/ 再次请求两个客户端的http://localhost:28089/info接口，都能得到如下结果，说明成功了： - 只要开启 Spring Cloud Bus 后，不管是对 config-server 还是 config-client 执行/actuator/bus-refresh都是可以更新配置的。 其他当使用SpringBoot-2.1.1.RELEASE的时候，启动的时候会报错以下错误： Failed to introspect Class \\[org.springframework.cloud.stream.config.BindingServiceConfiguration] from ClassLoader \\[sun.misc.Launcher$AppClassLoader@18b4aac2] 这个留着以后研究。。 参考 配置中心和消息总线（配置中心终结版） 配置中心（消息总线）【Finchley 版】","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.cayzlh.com/tags/SpringCloud/"},{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"SpringCloud","slug":"Spring/SpringCloud","permalink":"https://www.cayzlh.com/categories/Spring/SpringCloud/"}]},{"title":"SpringCloud（配置中心服务化与高可用）","date":"2018-12-31T06:48:58.000Z","path":"2018/12/31/2f34c065.html","text":"使用配置中心的客户端都是直接调用配置中心的server端来获取配置文件信息。这样就存在了一个问题，客户端和服务端的耦合性太高，如果server端要做集群，客户端只能通过原始的方式来路由，server端改变IP地址的时候，客户端也需要修改配置，不符合springcloud服务治理的理念。springcloud提供了这样的解决方案，我们只需要将server端当做一个服务注册到eureka中，client端去eureka中去获取配置中心server端的服务既可。 在上一篇中，我们主要完成了： 构建了 config-server，连接到 Git 仓库 在 Git 上创建了一个 config-repo 目录，用来存储配置信息 构建了 config-client，来获取 Git 中的配置信息 在 config-client 中开启了 Refresh，动态刷新配置信息 接下来，基于配置中心Git版本来进行改造。 Server端改造POM在pom.xml文件中添加依赖： &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-client&lt;/artifactId> &lt;/dependency> 配置文件在application.yml中添加erueka配置： eureka: client: service-url: defaultZone: http://localhost:28081/eureka/ 启动类给启动类加上@EnableDiscoveryClient注解，激活对配置中心的支持： @EnableDiscoveryClient @EnableConfigServer @SpringBootApplication public class ConfigServerGitApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerGitApplication.class, args); } } Server端改造完成，依次启动注册中心、config-server，访问http://localhost:28081，就会看到config-server已注册到注册中心。 客户端改造POM在pom.xml中添加依赖： &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-client&lt;/artifactId> &lt;/dependency> bootstrap.yml修改bootstrap.yml配置文件： spring: cloud: config: name: test-config profile: dev label: master discovery: enabled: true service-id: config-server eureka: client: service-url: defaultZone: http://localhost:28081/eureka/ 主要是去掉了spring.cloud.config.uri直接指向 Server 端地址的配置，增加了最后的三个配置： spring.cloud.config.discovery.enabled：开启 Config 服务发现支持 spring.cloud.config.discovery.serviceId：指定 Server 端的 name, 也就是 Server 端spring.application.name的值 eureka.client.service-url.defaultZone：指向配置中心的地址 这三个配置文件都需要放到bootstrap.yml的配置中。 启动类启动类给启动类加上@EnableDiscoveryClient注解，激活对配置中心的支持： @EnableDiscoveryClient @SpringBootApplication public class ConfitClientApplication { public static void main(String[] args) { SpringApplication.run(ConfitClientApplication.class, args); } } Client端也改造完成，启动Client端，访问http://localhost:28081，可以看到Client也已经注册到注册中心: 测试在postman请求http://localhost:28089/info，得到结果如下，说明改造成功： 高可用启动两个 Server 端，端口分别为 28088 和 28090，提供高可用的 Server 端支持。这样在其中一个Server挂掉的时候，还有另一个Server可以继续提供服务。 具体实施： # 打包 ./mvn clean package -Dmaven.test.skip=true # 启动两个 Server java -jar target/config-server-git-0.0.1-SNAPSHOT.jar --server.port=28089 java -jar target/config-server-git-0.0.1-SNAPSHOT.jar --server.port=28090 分别使用postman去请求两个端口的服务端，都能正确返回配置信息，说明高可用集成成功。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.cayzlh.com/tags/SpringCloud/"},{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"SpringCloud","slug":"Spring/SpringCloud","permalink":"https://www.cayzlh.com/categories/Spring/SpringCloud/"}]},{"title":"SpringCloud（Git版配置中心）","date":"2018-12-30T07:00:19.000Z","path":"2018/12/30/5e7c1be9.html","text":"Spring Cloud Config随着线上项目变的日益庞大，每个项目都散落着各种配置文件，如果采用分布式的开发模式，需要的配置文件随着服务增加而不断增多。某一个基础服务信息变更，都会引起一系列的更新和重启，运维苦不堪言也容易出错。配置中心便是解决此类问题的灵丹妙药。Spring Cloud Config，因为它功能全面强大，可以无缝的和spring体系相结合。 Spring Cloud Config 是 Spring Cloud 团队创建的一个全新项目，用来为分布式系统中的基础设施和微服务应用提供集中化的外部配置支持，它分为服务端与客户端两个部分。其中服务端也称为分布式配置中心，它是一个独立的微服务应用，用来连接配置仓库并为客户端提供获取配置信息、加密 / 解密信息等访问接口；而客户端则是微服务架构中的各个微服务应用或基础设施，它们通过指定的配置中心来管理应用资源与业务相关的配置内容，并在启动的时候从配置中心获取和加载配置信息。Spring Cloud Config 实现了对服务端和客户端中环境变量和属性配置的抽象映射，所以它除了适用于 Spring 构建的应用程序之外，也可以在任何其他语言运行的应用程序中使用。由于 Spring Cloud Config 实现的配置中心默认采用 Git 来存储配置信息，所以使用 Spring Cloud Config 构建的配置服务器，天然就支持对微服务应用配置信息的版本管理，并且可以通过 Git 客户端工具来方便的管理和访问配置内容。当然它也提供了对其他存储方式的支持，比如：SVN 仓库、本地化文件系统。 配置中心提供的功能： 提供服务端和客户端支持 集中管理各环境的配置文件 配置文件修改之后，可以快速的生效 可以进行版本管理 支持大的并发查询 支持各种语言 准备工作在 Github 上面创建了一个文件夹 config-repo 用来存放配置文件，创建以下三个配置文件： // 开发环境 test-config-dev.yml // 测试环境 test-config-test.yml // 生产环境 test-config-prod.yml 每个文件都写一个test.hello属性，属性值分别是dev、test、prod，如： test: hello: test Server端创建一个基础的 Spring Boot 工程，命名为：config-server-git。 POM&lt;properties> &lt;java.version>1.8&lt;/java.version> &lt;spring-cloud.version>Finchley.RELEASE&lt;/spring-cloud.version> &lt;/properties> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-config-server&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;dependencyManagement> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-dependencies&lt;/artifactId> &lt;version>${spring-cloud.version}&lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> &lt;/dependencies> &lt;/dependencyManagement> 添加spring-cloud-config-server依赖。 配置文件在配置文件中配置服务的基本信息以及git的地址： spring: application: name: config-server cloud: config: server: git: uri: https://github.com/cayzlh/SpringCloudDemos # 配置git仓库的地址 search-paths: config-repo # git仓库地址下的相对地址，可以配置多个，用,分割。 server: port: 28088 Spring Cloud Config 也提供本地存储配置的方式。我们只需要设置属性spring.profiles.active=native，Config Server 会默认从应用的src/main/resource目录下检索配置文件。也可以通过spring.cloud.config.server.native.searchLocations=file:E:/properties/属性来指定配置文件的位置。虽然 Spring Cloud Config 提供了这样的功能，但是为了支持更好的管理内容和版本控制的功能，还是推荐使用 Git 的方式。 如果我们的 Git 仓库需要权限访问，那么可以通过配置下面的两个属性来实现；spring.cloud.config.server.git.username：访问 Git 仓库的用户名spring.cloud.config.server.git.password：访问 Git 仓库的用户密码 启动类启动类添加@EnableConfigServer，激活对配置中心的支持： @EnableConfigServer @SpringBootApplication public class ConfigServerGitApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerGitApplication.class, args); } } Server端的配置到此为止 测试测试 Server 端是否可以读取到 github 上面的配置信息，通过postman请求http://localhost:28088/test-config/test，返回如下信息： { \"name\": \"test-config\", \"profiles\": [ \"test\" ], \"label\": null, \"version\": \"cd3f7acc23d556b64499d08ea9a14d2ee23c4534\", \"state\": null, \"propertySources\": [ { \"name\": \"https://github.com/cayzlh/\\ SpringCloudDemos/config-repo/test-config-test.yml\", \"source\": { \"test.hello\": \"test\" } } ] } 注：路径中的test-config是指config-repo中的文件名前缀。 修改test-config-test.yml中的内容，再次在postman请求，发现返回的内容是最新的了，说明Server端会自动读取最新提交的内容。 仓库中的配置文件会被转换成 Web 接口，访问可以参照以下的规则： /{application}/{profile}[/{label}] /{application}-{profile}.yml /{label}/{application}-{profile}.yml /{application}-{profile}.properties /{label}/{application}-{profile}.properties 上面的 URL 会映射{application}-{profile}.yml对应的配置文件，其中{label}对应 Git 上不同的分支，默认为 master。以 config-client-dev.yml 为例子，它的 application 是 config-client，profile 是 dev。 Client端在微服务应用中获取上述的配置信息。再创建一个基础的 Spring Boot 应用，命名为 config-client。 POM修改pom文件，引入如下配置： &lt;properties> &lt;java.version>1.8&lt;/java.version> &lt;spring-cloud.version>Finchley.RELEASE&lt;/spring-cloud.version> &lt;/properties> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-webflux&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-config&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;dependencyManagement> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-dependencies&lt;/artifactId> &lt;version>${spring-cloud.version}&lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> &lt;/dependencies> &lt;/dependencyManagement> spring-boot-starter-webflux 是为了方便 Web 测试。Spring WebFlux 是随 Spring 5 推出的响应式 Web 框架。 配置文件需要两个配置文件，application.yml和bootstrap.yml。 application.yml： spring: application: name: config-client-git server: port: 28089 bootstrap.yml： spring: cloud: config: uri: http://localhost:28088 # 配置中心的具体地址，即 config-server name: test-config # 对应 {application} 部分 profile: test # 对应 {profile} 部分 label: master # 对应 {label} 部分，即 Git 的分支。如果配置中心使用的是本地存储，则该参数无用 spring.application.name：对应{application}部分 spring.cloud.config.profile：对应{profile}部分 spring.cloud.config.label：对应git的分支。如果配置中心使用的是本地存储，则该参数无用 spring.cloud.config.uri：配置中心的具体地址 spring.cloud.config.discovery.service-id：指定配置中心的service-id，便于扩展为高可用配置集群。 上面这些与 Spring Cloud Config 相关的属性必须配置在 bootstrap.yml 中，config 部分内容才能被正确加载。因为 config 的相关配置会先于 application.yml，而 bootstrap.yml 的加载也是先于 application.yml。 启动类不需要修改： @SpringBootApplication public class ConfitClientApplication { public static void main(String[] args) { SpringApplication.run(ConfitClientApplication.class, args); } } 新建HelloController，使用@value注解来获取Server端参数的值 @RestController public class HelloController { @Value(\"${test.hello:error}\") private String profile; @GetMapping(\"/info\") public Mono&lt;String> hello() { return Mono.justOrEmpty(profile); } } 测试使用postman请求http://localhost:28089/info，返回如下结果，则说明Client端成功获取到了Server端的配置值。 至此，SpringCloud的Git版配置中心就完成了。 RefreshSpring Cloud Config分服务端和客户端，服务端负责将git（svn）中存储的配置文件发布成REST接口，客户端可以从服务端REST接口获取配置。但客户端并不能主动感知到配置的变化，从而主动去获取新的配置。客户端如何去主动获取新的配置信息呢，springcloud已经给我们提供了解决方案，每个客户端通过POST方法触发各自的/refresh。 仅修改客户端项目，就可以实现 refresh 的功能。 添加依赖&lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-actuator&lt;/artifactId> &lt;/dependency> 增加了spring-boot-starter-actuator包，spring-boot-starter-actuator是一套监控的功能，可以监控程序在运行时状态，其中就包括/actuator/refresh的功能。 开启更新机制需要给加载变量的类上面加载@RefreshScope，在客户端执行/actuator/refresh的时候就会更新此类下面的变量值。 @RefreshScope @RestController public class HelloController { @Value(\"${test.hello:error}\") private String profile; @GetMapping(\"/info\") public Mono&lt;String> hello() { return Mono.justOrEmpty(profile); } } 配置文件SpringBoot1.5以后需要添加以下配置以将/actuator/refresh这个 Endpoint 暴露出来： management: endpoints: web: exposure: include: refresh 测试重启 config-client，我们以 POST 请求的方式来访问http://localhost:28089/actuator/refresh就会更新配置文件至最新版本。 修改test-config-test.yml文件的内容 使用postman请求http://localhost:28089/actuator/refresh接口 再请求http://localhost:28089/info接口 发现配置内容已经更新到最新了 至此，配置中心的配置刷新就算完成了，但是这样做有个弊端，就是每次更新了配置之后都要请求refresh接口，这就很麻烦。。 WebhookWebhook 是当某个事件发生时，通过发送 HTTP POST 请求的方式来通知信息接收方。Webhook 来监测你在 Github.com 上的各种事件，最常见的莫过于 push 事件。如果你设置了一个监测 push 事件的 Webhook，那么每当你的这个项目有了任何提交，这个 Webhook 都会被触发，这时 Github 就会发送一个 HTTP POST 请求到你配置好的地址。 如此一来，你就可以通过这种方式去自动完成一些重复性工作，比如，你可以用 Webhook 来自动触发一些持续集成（CI）工具的运作，比如 Travis CI；又或者是通过 Webhook 去部署你的线上服务器。下图就是 Github 上面的 Webhook 配置。 Payload URL ：触发后回调的 URL Content type ：数据格式，两种一般使用 json Secret ：用作给 POST 的 body 加密的字符串。采用 HMAC 算法 events ：触发的事件列表。 - events 事件类型 描述 push 仓库有 push 时触发。默认事件 create 当有分支或标签被创建时触发 delete 当有分支或标签被删除时触发 - 这样我们就可以利用 hook 的机制去触发客户端的更新，但是当客户端越来越多的时候，hook 机制也不够优雅了，另外每次增加客户端都需要改动 hook 也是不现实的。其实，Spring Cloud 给了我们更好解决方案——Spring Cloud Bus。 参考 配置中心git示例 配置中心svn示例和refresh Spring Cloud（七）：配置中心（Git 版与动态刷新）【Finchley 版】","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.cayzlh.com/tags/SpringCloud/"},{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"SpringCloud","slug":"Spring/SpringCloud","permalink":"https://www.cayzlh.com/categories/Spring/SpringCloud/"}]},{"title":"SpringCloud（Hystrix监控数据聚合Turbine）","date":"2018-12-29T14:42:33.000Z","path":"2018/12/29/9090e9d4.html","text":"在复杂的分布式系统中，相同服务的节点经常需要部署上百甚至上千个，很多时候，运维人员希望能够把相同服务的节点状态以一个整体集群的形式展现出来，这样可以更好的把握整个系统的状态。 为此，Netflix提供了一个开源项目（Turbine）来提供把多个hystrix.stream的内容聚合为一个数据源供Dashboard展示。 创建Turbine创建一个名为Turbine的Spring Boot工程 POM在pom.xml中添加如下依赖： &lt;properties> &lt;java.version>1.8&lt;/java.version> &lt;spring-cloud.version>Finchley.RELEASE&lt;/spring-cloud.version> &lt;/properties> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-turbine&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;dependencyManagement> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-dependencies&lt;/artifactId> &lt;version>${spring-cloud.version}&lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> &lt;/dependencies> &lt;/dependencyManagement> 启动类在启动类上使用@EnableTurbine注解开启 Turbine @EnableTurbine @SpringBootApplication public class TurbineApplication { public static void main(String[] args) { SpringApplication.run(TurbineApplication.class, args); } } 配置文件在 application.yml 加入 Eureka 和 Turbine 的相关配置 spring: application: name: hystrix-dashboard-turbine server: port: 28087 management: port: 28088 eureka: client: service-url: defaultZone: http://localhost:28081/eureka/ turbine: app-config: eureka-consumer cluster-name-expression: new String(\"default\") combine-host-port: true 参数： turbine.app-config参数指定了需要收集监控信息的服务名； turbine.cluster-name-expression 参数指定了集群名称为 default，当我们服务数量非常多的时候，可以启动多个 Turbine 服务来构建不同的聚合集群，而该参数可以用来区分这些不同的聚合集群，同时该参数值可以在 Hystrix 仪表盘中用来定位不同的聚合集群，只需要在 Hystrix Stream 的 URL 中通过 cluster 参数来指定； turbine.combine-host-port参数设置为true，可以让同一主机上的服务通过主机名与端口号的组合来进行区分，默认情况下会以 host 来区分不同的服务，这会使得在本地调试的时候，本机上的不同服务聚合成一个服务来统计。 其中：new String(&quot;default&quot;)这个一定要用 String 来包一下，否则启动的时候会抛出异常： org.springframework.expression.spel.SpelEvaluationException: EL1008E: Property or field 'default' cannot be found on object of type 'com.netflix.appinfo.InstanceInfo' - maybe not public or not valid? 测试启动服务，访问http://localhost:28086/hystrix，开启对http://localhost:28087/turbine.stream的监控，能够看到针对服务eureka-consumer的聚合监控数据。 此时的服务架构如下图： 参考 Spring Cloud（六）：Hystrix 监控数据聚合 Turbine【Finchley 版】 springcloud(五)：熔断监控Hystrix Dashboard和Turbine","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.cayzlh.com/tags/SpringCloud/"},{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"SpringCloud","slug":"Spring/SpringCloud","permalink":"https://www.cayzlh.com/categories/Spring/SpringCloud/"}]},{"title":"记一波easyexcel使用小坑","date":"2018-12-28T14:53:07.000Z","path":"2018/12/28/5b3dcf26.html","text":"JAVA解析Excel工具easyexcel Java解析、生成Excel比较有名的框架有Apache poi、jxl。但他们都存在一个严重的问题就是非常的耗内存，poi有一套SAX模式的API可以一定程度的解决一些内存溢出的问题，但POI还是有一些缺陷，比如07版Excel解压缩以及解压后存储都是在内存中完成的，内存消耗依然很大。easyexcel重写了poi对07版Excel的解析，能够原本一个3M的excel用POI sax依然需要100M左右内存降低到KB级别，并且再大的excel不会出现内存溢出，03版依赖POI的sax模式。在上层做了模型转换的封装，让使用者更加简单方便。 小坑最近在使用easyexcel的时候，碰到一个小坑： 在使用Safari浏览器进行导出的时候，导出的文件会自动增加一个.xlw后缀，很烦。。 后来通过搜索解决了问题，在这里记录一波。 将原来的代码： response.setContentType(\"application/vnd.ms-excel\"); 改成： response.setContentType( \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"); 然后所有浏览器都没有问题了。 工具类贴一下easyexcel导出的工具类： public class ExcelUtil { private static Logger logger = LoggerFactory.getLogger(ExcelUtil.class); /** * 导出 * * @param list 导出数据 * @param excelName excel名称 * @param response response * @param clazz clazz */ public static void export(List&lt;? extends BaseRowModel> list, String excelName, HttpServletResponse response, Class&lt;? extends BaseRowModel> clazz) { ServletOutputStream out = null; ExcelWriter writer = null; try { out = response.getOutputStream(); writer = new ExcelWriter(out, ExcelTypeEnum.XLSX, true); String fileName = excelName + new SimpleDateFormat(\"yyyy-MM-dd\").format(new Date()); Sheet sheet2 = new Sheet(2, 3, clazz, \"sheet\", null); writer.write(list, sheet2); response.setCharacterEncoding(\"utf-8\"); // response.setContentType(\"application/vnd.ms-excel\"); response.setContentType( \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"); setFileDownloadHeader(response, fileName); out.flush(); } catch (Exception e) { e.printStackTrace(); } finally { if (null != writer) { writer.finish(); } if (null != out) { try { out.flush(); } catch (IOException e) { logger.error(\"excel导出出错\", e); } } } } private static void setFileDownloadHeader( HttpServletResponse response, String filename) { String headerValue = \"attachment;\"; headerValue += \" filename=\\\"\" + encodeURIComponent(filename) + \"\\\";\"; headerValue += \" filename*=utf-8''\" + encodeURIComponent(filename + \".xlsx\"); response.setHeader(\"Content-Disposition\", headerValue); } private static String encodeURIComponent(String value) { try { return URLEncoder.encode(value, \"UTF-8\") .replaceAll(\"\\\\+\", \"%20\"); } catch (UnsupportedEncodingException e) { e.printStackTrace(); return null; } } }","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"easyexcel","slug":"easyexcel","permalink":"https://www.cayzlh.com/tags/easyexcel/"}],"categories":[{"name":"笔记本","slug":"笔记本","permalink":"https://www.cayzlh.com/categories/%E7%AC%94%E8%AE%B0%E6%9C%AC/"}]},{"title":"SpringCloud（Hystrix熔断监控面板）","date":"2018-12-23T06:48:06.000Z","path":"2018/12/23/c10f5abe.html","text":"文章内容部分摘抄自springcloud(五)：熔断监控Hystrix Dashboard和Turbine 断路器是根据一段时间内的请求来判断并操作断路器的打开和关闭状态的。 Hystrix-dashboard是一款针对Hystrix进行实时监控的工具，通过Hystrix Dashboard我们可以在直观地看到各Hystrix Command的请求响应时间, 请求成功率等数据。但是只使用Hystrix Dashboard的话, 你只能看到单个应用内的服务信息, 这明显不够. 我们需要一个工具能让我们汇总系统内多个服务的数据并显示到Hystrix Dashboard上, 这个工具就是Turbine. Hystrix Dashboard创建一个SpringBoot工程，起名为hystrix-dashboard。 pom配置在pom.xml中引入相关依赖： &lt;properties> &lt;java.version>1.8&lt;/java.version> &lt;spring-cloud.version>Finchley.RELEASE&lt;/spring-cloud.version> &lt;/properties> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-hystrix&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;dependencyManagement> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-dependencies&lt;/artifactId> &lt;version>${spring-cloud.version}&lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> &lt;/dependencies> &lt;/dependencyManagement> 启动类启动类加上@EnableHystrixDashboard注解 @EnableHystrixDashboard @SpringBootApplication public class HystrixDashboardApplication { public static void main(String[] args) { SpringApplication.run(HystrixDashboardApplication.class, args); } } 配置文件修改配置文件，添加以下内容： spring: application: name: hystrix-dashboard server: port: 28086 启动服务启动服务，访问http://localhost:28086/hystrix，看到如下界面： 说明 这段来源：https://windmt.com/2018/04/16/spring-cloud-5-hystrix-dashboard/ 通过 Hystrix Dashboard 主页面的文字介绍，我们可以知道，Hystrix Dashboard 共支持三种不同的监控方式： 默认的集群监控：通过 URL：http://turbine-hostname:port/turbine.stream 开启，实现对默认集群的监控。 指定的集群监控：通过 URL：http://turbine-hostname:port/turbine.stream?cluster=[clusterName] 开启，实现对 clusterName 集群的监控。 单体应用的监控： 通过 URL：http://hystrix-app:port/hystrix.stream 开启 ，实现对具体某个服务实例的监控。（现在这里的 URL 应该为 http://hystrix-app:port/actuator/hystrix.stream，Actuator 2.x 以后 \b\b endpoints 全部在/actuator下，可以通过management.endpoints.web.base-path修改） 前两者都对集群的监控，需要整合 Turbine 才能实现。这一部分我们先实现对单体应用的监控，这里的单体应用就用我们之前使用 Feign 和 Hystrix 实现的服务消费者——eureka-consumer。 页面上的另外两个参数： Delay：控制服务器上轮询监控信息的延迟时间，默认为 2000 毫秒，可以通过配置该属性来降低客户端的网络和 CPU 消耗。 Title：该参数可以展示合适的标题。 添加endpoint既然 Hystrix Dashboard 监控单实例节点需要通过访问实例的/actuator/hystrix.stream接口来实现，自然我们需要为服务实例添加这个 endpoint。 使用前面的eureka-consumer工程； 修改pom配置在dependencies节点下添加以下依赖： &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-hystrix&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-actuator&lt;/artifactId> &lt;/dependency> 启动类修改启动类，添加@EnableCircuitBreaker或者@EnableHystrix注解，开启断路器功能； @EnableCircuitBreaker @EnableFeignClients @SpringBootApplication public class EurekaConsumerApplication { public static void main(String[] args) { SpringApplication.run(EurekaConsumerApplication.class, args); } } 配置文件在配置文件中添加： management: endpoints: web: exposure: include: hystrix.stream management.endpoints.web.exposure.include这个是用来暴露 endpoints 的。由于 endpoints 中会包含很多敏感信息，除了 health 和 info 两个支持 web 访问外，其他的默认不支持 web 访问。 测试 分别再启动注册中心、服务生产者、服务消费者。 在Hystrix Dashboard中输入http://localhost:28085/actuator/hystrix.stream，然后点击下方的Monitor Stream按钮，可以看到Loding界面。 这个时候访问http://localhost:28085/hello/zhangsan，访问成功后再回来DashBoard页面，可以看到： 图像解读以上图来说明其中各元素的具体含义： 实心圆：它有颜色和大小之分，分别代表实例的监控程度和流量大小。如上图所示，它的健康度从绿色、黄色、橙色、红色递减。通过该实心圆的展示，我们就可以在大量的实例中快速的发现故障实例和高压力实例。 曲线：用来记录 2 分钟内流量的相对变化，我们可以通过它来观察到流量的上升和下降趋势。 其他数量指标 结束到此，单个服务的熔断监控已经完成。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.cayzlh.com/tags/SpringCloud/"},{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"SpringCloud","slug":"Spring/SpringCloud","permalink":"https://www.cayzlh.com/categories/Spring/SpringCloud/"}]},{"title":"SpringCloud（熔断器Hystrix）","date":"2018-12-22T08:04:16.000Z","path":"2018/12/22/5a724b6.html","text":"使用Feign Hystrix做熔断器熔断作用在服务调用的一端，要实现熔断器， 只需在服务消费者（eureka-consumer）上做改动就行。 Feign中已经依赖了Hystrix所以在maven配置上不用做任何改动。 修改配置文件spring: application: name: eureka-consumer eureka: client: service-url: defaultZone: http://localhost:28081/eureka/ server: port: 28085 feign: hystrix: enabled: true 创建一个回调方法类创建 HelloRemoteHystrix 类实现 HelloRemote 中实现回调的方法 @Component public class HelloRemoteHystrix implements HelloRemote { @Override public String hello(@RequestParam(value = \"name\") String name) { return \"Hello，\"+name+\" ，当前服务崩了。\"; } } 设置fallback属性在HelloRemote类添加指定 fallback 类，在服务熔断的时候返回 fallback 类中的内容。 @FeignClient(name = \"eureka-producer\", fallback = HelloRemoteHystrix.class) public interface HelloRemote { @GetMapping(\"/hello/\") String hello(@RequestParam(value = \"name\") String name); } 代码部分，到此为止就ok了。 测试启动三个项目（注册中心、服务提供者、服务消费者） 访问http://localhost:28085/hello/zhangsan返回结果： 可以看到当前是正常返回结果的，这个时候，把服务提供者的服务kill掉，再次访问http://localhost:28085/hello/zhangsan，返回结果： 说明熔断成功！ 雪崩效应 这段摘自纯洁的微笑博客 在微服务架构中通常会有多个服务层调用，基础服务的故障可能会导致级联故障，进而造成整个系统不可用的情况，这种现象被称为服务雪崩效应。服务雪崩效应是一种因“服务提供者”的不可用导致“服务消费者”的不可用,并将不可用逐渐放大的过程。 如果下图所示：A作为服务提供者，B为A的服务消费者，C和D是B的服务消费者。A不可用引起了B的不可用，并将不可用像滚雪球一样放大到C和D时，雪崩效应就形成了。 熔断器 这段摘自纯洁的微笑博客 熔断器的原理很简单，如同电力过载保护器。它可以实现快速失败，如果它在一段时间内侦测到许多类似的错误，会强迫其以后的多个调用快速失败，不再访问远程服务器，从而防止应用程序不断地尝试执行可能会失败的操作，使得应用程序继续执行而不用等待修正错误，或者浪费CPU时间去等到长时间的超时产生。熔断器也可以使应用程序能够诊断错误是否已经修正，如果已经修正，应用程序会再次尝试调用操作。 熔断器模式就像是那些容易导致错误的操作的一种代理。这种代理能够记录最近调用发生错误的次数，然后决定使用允许操作继续，或者立即返回错误。 熔断器开关相互转换的逻辑如下图： 熔断器就是保护服务高可用的最后一道防线。 Hystrix特性断路器机制断路器很好理解, 当Hystrix Command请求后端服务失败数量超过一定比例(默认50%), 断路器会切换到开路状态(Open). 这时所有请求会直接失败而不会发送到后端服务. 断路器保持在开路状态一段时间后(默认5秒), 自动切换到半开路状态(HALF-OPEN). 这时会判断下一次请求的返回情况, 如果请求成功, 断路器切回闭路状态(CLOSED), 否则重新切换到开路状态(OPEN). Hystrix的断路器就像我们家庭电路中的保险丝, 一旦后端服务不可用, 断路器会直接切断请求链, 避免发送大量无效请求影响系统吞吐量, 并且断路器有自我检测并恢复的能力. FallbackFallback相当于是降级操作. 对于查询操作, 我们可以实现一个fallback方法, 当请求后端服务出现异常的时候, 可以使用fallback方法返回的值. fallback方法的返回值一般是设置的默认值或者来自缓存. 资源隔离在Hystrix中, 主要通过线程池来实现资源隔离. 通常在使用的时候我们会根据调用的远程服务划分出多个线程池. 例如调用产品服务的Command放入A线程池, 调用账户服务的Command放入B线程池. 这样做的主要优点是运行环境被隔离开了. 这样就算调用服务的代码存在bug或者由于其他原因导致自己所在线程池被耗尽时, 不会对系统的其他服务造成影响. 但是带来的代价就是维护多个线程池会对系统带来额外的性能开销. 如果是对性能有严格要求而且确信自己调用服务的客户端代码不会出问题的话, 可以使用Hystrix的信号模式(Semaphores)来隔离资源. 总结通过使用 Hystrix，我们能方便的防止雪崩效应，同时使系统具有自动降级和自动恢复服务的效果。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.cayzlh.com/tags/SpringCloud/"},{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"SpringCloud","slug":"Spring/SpringCloud","permalink":"https://www.cayzlh.com/categories/Spring/SpringCloud/"}]},{"title":"SpringCloud（服务提供与发现Eureka）","date":"2018-12-20T02:41:15.000Z","path":"2018/12/20/b6f15c0c.html","text":"提供三个角色：服务注册中心、服务提供者、服务消费者。用来模拟Eureka服务提供者与消费者关系。 流程 启动注册中心 服务提供者生产服务并注册到服务中心中 消费者从服务中心中获取服务并执行 （图片来源于网络） 服务注册中心参考另一片笔记《SpringCloud（注册中心Eureka）》 服务提供者提供一个hello()方法打印一个字符串。 新建一个名为spring-cloud-producer的SpringBoot工程POM文件部分配置&lt;properties> &lt;java.version>1.8&lt;/java.version> &lt;spring-cloud.version>Finchley.RELEASE&lt;/spring-cloud.version> &lt;/properties> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-client&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;dependencyManagement> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-dependencies&lt;/artifactId> &lt;version>${spring-cloud.version}&lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> &lt;/dependencies> &lt;/dependencyManagement> application.yml文件配置spring: application: name: eureka-producer eureka: client: service-url: defaultZone: http://localhost:28081/eureka/ server: port: 28084 通过spring.application.name属性，我们可以指定微服务的名称后续在调用的时候只需要使用该名称就可以进行服务的访问。eureka.client.serviceUrl.defaultZone属性对应服务注册中心的配置内容，指定服务注册中心的位置。为了在本机上测试区分服务提供方和服务注册中心，使用server.port属性设置不同的端口。 启动类保持默认生成的即可， Finchley.RC1 这个版本的 Spring Cloud 已经无需添加@EnableDiscoveryClient注解了。如果引入了相关的jar包，需要禁用服务注册与发现，只需设置eureka.client.enabled=false @SpringBootApplication public class SpringCloudProducerApplication { public static void main(String[] args) { SpringApplication.run(SpringCloudProducerApplication.class, args); } } 定义一个简单Controller接口，用来提供hello服务@RestController @RequestMapping(\"/hello\") public class HelloController { @GetMapping(\"/\") public String hello(@RequestParam String name) { return \"Hello, \" + name + \", 现在时间：\" + System.currentTimeMillis(); } } 至此，服务提供者就开发完成了。分别启动服务注册中心和服务提供者，可以在注册http://localhost:28081中心看到EUERKA-PRODUCER服务。 访问http://localhost:28084/hello/?name=zhangsan 可以看到有返回结果，说明服务提供者已经配置完成。 服务消费者创建服务消费者根据使用 API 的不同，大致分为三种方式（LoadBalancerClient、Spring Cloud Ribbon和Feign 调用实现）。在实际使用中用的应该都是 Feign，这里只记录Feign。 创建一个名为eureka-consumer的SpringBoot工程POM包配置&lt;properties> &lt;java.version>1.8&lt;/java.version> &lt;spring-cloud.version>Finchley.RELEASE&lt;/spring-cloud.version> &lt;/properties> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-openfeign&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-client&lt;/artifactId> &lt;/dependency> &lt;/dependencies> &lt;dependencyManagement> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-dependencies&lt;/artifactId> &lt;version>${spring-cloud.version}&lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> &lt;/dependencies> &lt;/dependencyManagement> 配置文件spring: application: name: eureka-consumer eureka: client: service-url: defaultZone: http://localhost:28081/eureka/ server: port: 28085 启动类在启动类上加上@EnableFeignClients @EnableFeignClients @SpringBootApplication public class EurekaConsumerApplication { public static void main(String[] args) { SpringApplication.run(EurekaConsumerApplication.class, args); } } Feign 调用实现创建一个 Feign 的客户端接口定义。使用@FeignClient注解来指定这个接口所要调用的服务名称，接口中定义的各个函数使用 Spring MVC 的注解就可以来绑定服务提供方的 REST 接口，比如下面就是绑定 eureka-producer 服务的/hello/接口的例子： @FeignClient(name = \"eureka-producer\") public interface HelloRemote { @GetMapping(\"/hello/\") String hello(@RequestParam(value = \"name\") String name); } 此类中的方法和远程服务中 Contoller 中的方法名和参数需保持一致。 Controller将HelloRemote注入到Controller中，像普通方法一样调用。 @RestController @RequestMapping(\"/hello\") public class HelloController { @Autowired HelloRemote helloRemote; @GetMapping(\"/{name}\") public String index(@PathVariable(\"name\") String name) { return helloRemote.hello(name + \"!\"); } } 通过 Spring Cloud Feign 来实现服务调用的方式非常简单，通过@FeignClient定义的接口来统一的声明我们需要依赖的微服务接口。而在具体使用的时候就跟调用本地方法一点的进行调用即可。由于 Feign 是基于 Ribbon 实现的，所以它自带了客户端负载均衡功能，也可以通过 Ribbon 的 IRule 进行策略扩展。另外，Feign 还整合的 Hystrix 来实现服务的容错保护。 在 Finchley.RC1 版本中，Feign 的 Hystrix 默认是关闭的。 启动服务，在注册http://localhost:28081中心看到eureka-consumer服务。 访问http://localhost:28085/hello/zhangsan，得到如下结果，说明消费者成功消费了提供者的服务。 其他要想使用 Feign，至少需要以下三个依赖 spring-boot-starter-web spring-cloud-starter-openfeign spring-cloud-starter-netflix-eureka-cli HelloRemote类中的方法参数要加上@RequestParam注解Get请求的类型， 要加上@RequestParam注解，否则会报错。。 当参数没有被@RequestParam注解修饰时，会自动被当做 request body 来处理。只要有 body，就会被 Feign 认为是 POST 请求，所以整个服务是被当作带有 request parameter 和 body 的 POST 请求发送出去的。 负载均衡将producer工程打包成Jar包，然后启动两个线程，分别注册到服务注册中心。 当通过消费者调用的时候，会交替消费两个服务，以此来实现负载均衡。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.cayzlh.com/tags/SpringCloud/"},{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"SpringCloud","slug":"Spring/SpringCloud","permalink":"https://www.cayzlh.com/categories/Spring/SpringCloud/"}]},{"title":"SpringCloud（注册中心Eureka）","date":"2018-12-16T05:25:28.000Z","path":"2018/12/16/b21e91d6.html","text":"Eureka是Netflix开源的一款提供服务注册和发现的产品，它提供了完整的Service Registry和Service Discovery实现。也是springcloud体系中最重要最核心的组件之一。 服务中心服务中心又称注册中心，管理各种服务功能包括服务的注册、发现、熔断、负载、降级等，比如dubbo admin后台的各种功能。 EurekaEureka 是一个基于 REST 的服务，主要在 AWS 云中使用, 定位服务来进行中间层服务器的负载均衡和故障转移。 Spring Cloud 封装了 Netflix 公司开发的 Eureka 模块来实现服务注册和发现。Eureka 采用了 C-S 的设计架构。Eureka Server 作为服务注册功能的服务器，它是服务注册中心。而系统中的其他微服务，使用 Eureka 的客户端连接到 Eureka Server，并维持心跳连接。这样系统的维护人员就可以通过 Eureka Server 来监控系统中各个微服务是否正常运行。Spring Cloud 的一些其他模块（比如Zuul）就可以通过 Eureka Server 来发现系统中的其他微服务，并执行相关的逻辑。 Eureka由两个组件组成：Eureka服务器和Eureka客户端。Eureka服务器用作服务注册服务器。Eureka客户端是一个java客户端，用来简化与服务器的交互、作为轮询负载均衡器，并提供服务的故障切换支持。Netflix在其生产环境中使用的是另外的客户端，它提供基于流量、资源利用率以及出错状态的加权负载均衡。 Eureka的基本架构，由3个角色组成： 1、Eureka Server 提供服务注册和发现 2、Service Provider 服务提供方 将自身服务注册到Eureka，从而使服务消费方能够找到 3、Service Consumer 服务消费方 从Eureka获取注册服务列表，从而能够消费服务 案例Eureka Serverspring cloud已经帮我实现了服务注册中心，我们只需要很简单的几个步骤就可以完成。 新建一个SpringBoot工程，取名为eureka-server，springboot使用的版本是2.1.1.RELEASE 在pom中添加依赖： &lt;properties> &lt;java.version>1.8&lt;/java.version> &lt;spring-cloud.version>Finchley.RELEASE&lt;/spring-cloud.version> &lt;/properties> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-netflix-eureka-server&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;/dependency> &lt;/dependencies> &lt;dependencyManagement> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.cloud&lt;/groupId> &lt;artifactId>spring-cloud-dependencies&lt;/artifactId> &lt;version>${spring-cloud.version}&lt;/version> &lt;type>pom&lt;/type> &lt;scope>import&lt;/scope> &lt;/dependency> &lt;/dependencies> &lt;/dependencyManagement> 这里spring-cloud的版本用的是Finchley.RELEASE，spring-boot的版本是2.1.1.RELEASE。因此依赖使用的是spring-cloud-starter-netflix-eureka-server. 在启动类中加上@EnableEurekaServer注解 @EnableEurekaServer @SpringBootApplication public class EurekaServerApplication { public static void main(String[] args) { SpringApplication.run(EurekaServerApplication.class, args); } } 配置文件： server: port: 28081 spring: application: name: eureka-server eureka: client: fetch-registry: false register-with-eureka: false service-url: defaultZone: http://localhost:${server.port}/eureka/ eureka.client.register-with-eureka ：表示是否将自己注册到Eureka Server，默认为true。 eureka.client.fetch-registry ：表示是否从Eureka Server获取注册信息，默认为true。 eureka.client.serviceUrl.defaultZone ：设置与Eureka Server交互的地址，查询服务和注册服务都需要依赖这个地址。默认是http://localhost:8761/eureka ；多个地址可使用 , 分隔。 启动工程后，访问：http://localhost:28081，可以看到如下页面，其中还没有发现任何服务。 集群注册中心这么关键的服务，如果是单点话，遇到故障就是毁灭性的。在一个分布式系统中，服务注册中心是最重要的基础部分，理应随时处于可以提供服务的状态。为了维持其可用性，使用集群是很好的解决方案。Eureka通过互相注册的方式来实现高可用的部署，所以我们只需要将Eureke Server配置其他可用的serviceUrl就能实现高可用部署。 三节点注册中心尝试一下三节点的注册中心的搭建。 修改application.yml文件： spring: profiles: active: peer1 --- server: port: 28081 spring: profiles: peer1 application: name: eureka-server eureka: instance: hostname: peer1 client: fetch-registry: false register-with-eureka: false service-url: defaultZone: http://peer2:28082/eureka/,http://peer3:28083/eureka/ --- server: port: 28082 spring: profiles: peer2 application: name: eureka-server eureka: instance: hostname: peer2 client: fetch-registry: false register-with-eureka: false service-url: defaultZone: http://peer1:28081/eureka/,http://peer3:28083/eureka/ --- server: port: 28083 spring: profiles: peer3 application: name: eureka-server eureka: instance: hostname: peer3 client: fetch-registry: false register-with-eureka: false service-url: defaultZone: http://peer2:28082/eureka/,http://peer1:28081/eureka/ 修改本机的hosts文件 sudo vi /etc/hosts 添加如下内容： 127.0.0.1 peer1 peer2 peer3 用来模拟不同的环境。 打开idea的Terminal，依次执行下面命令： # 打包 mvn clean package -Dmaven.test.skip=true # 分别以 peer1 和 peer2 配置信息启动 Eureka java -jar target/eureka-server-0.0.1-SNAPSHOT.jar --spring.profiles.active=peer1 java -jar target/eureka-server-0.0.1-SNAPSHOT.jar --spring.profiles.active=peer2 java -jar target/eureka-server-0.0.1-SNAPSHOT.jar --spring.profiles.active=peer3 依次启动完成后，访问http://peer1:28081，效果如下： 到此三节点的配置已经完成。 注意事项 在搭建 Eureka Server 集群的时候，要把eureka.client.register-with-eureka和eureka.client.fetch-registry均改为true（默认）。否则会出现实例列表为空，且 peer2 不在 available-replicas 而在 unavailable-replicas 的情况（这时其实只是启动了两个单点实例）。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.cayzlh.com/tags/SpringCloud/"},{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"SpringCloud","slug":"Spring/SpringCloud","permalink":"https://www.cayzlh.com/categories/Spring/SpringCloud/"}]},{"title":"微服务的优缺点","date":"2018-12-15T05:51:26.000Z","path":"2018/12/15/ded3e7ee.html","text":"本文来自Nginx官方博客，是微服务系列文章的第一篇，主要探讨了传统的单体式应用的不足，以及微服务架构的优势与挑战。正如作者所说，微服务架构更适合用于构建复杂的应用，尽管它也有自己的不足。 转自：微服务实战（一）：微服务架构的优势与不足 单体式应用的不足单体式应用开发简单却有很大的局限性。一个简单的应用会随着时间推移逐渐变大。在每次的sprint中，开发团队都会面对新“故事”，然后开发许多新代码。几年后，这个小而简单的应用会变成了一个巨大的怪物。 一旦你的应用变成一个又大又复杂的怪物，那开发团队肯定很痛苦。敏捷开发和部署举步维艰，其中最主要问题就是这个应用太复杂，以至于任何单个开发者都不可能搞懂它。因此，修正bug和正确的添加新功能变的非常困难，并且很耗时。另外，团队士气也会走下坡路。如果代码难于理解，就不可能被正确的修改。最终会走向巨大的、不可理解的泥潭。 单体式应用也会降低开发速度。应用越大，启动时间会越长。比如，最近的一个调查表明，有时候应用的启动时间居然超过了12分钟。我还听说某些应用需要40分钟启动时间。如果开发者需要经常重启应用，那么大部分时间就要在等待中渡过，生产效率受到极大影响。 另外，复杂而巨大的单体式应用也不利于持续性开发。今天，SaaS应用常态就是每天会改变很多次，而这对于单体式应用模式非常困难。另外，这种变化带来的影响并没有很好的被理解，所以不得不做很多手工测试。那么接下来，持续部署也会很艰难。 单体式应用在不同模块发生资源冲突时，扩展将会非常困难。比如，一个模块完成一个CPU敏感逻辑，应该部署在AWS EC2 Compute Optimized instances，而另外一个内存数据库模块更合适于EC2 Memory-optimized instances。然而，由于这些模块部署在一起，因此不得不在硬件选择上做一个妥协。 单体式应用另外一个问题是可靠性。因为所有模块都运行在一个进程中，任何一个模块中的一个bug，比如内存泄露，将会有可能弄垮整个进程。除此之外，因为所有应用实例都是唯一的，这个bug将会影响到整个应用的可靠性。 最后，单体式应用使得采用新架构和语言非常困难。比如，设想你有两百万行采用XYZ框架写的代码。如果想改成ABC框架，无论是时间还是成本都是非常昂贵的，即使ABC框架更好。因此，这是一个无法逾越的鸿沟。你不得不在最初选择面前低头。 总结一下：一开始你有一个很成功的关键业务应用，后来就变成了一个巨大的，无法理解的怪物。因为采用过时的，效率低的技术，使得雇佣有潜力的开发者很困难。应用无法扩展，可靠性很低，最终，敏捷性开发和部署变的无法完成。 微处理架构——处理复杂事物许多公司，比如Amazon、eBay和NetFlix，通过采用微处理结构模式解决了上述问题。其思路不是开发一个巨大的单体式的应用，而是将应用分解为小的、互相连接的微服务。 一个微服务一般完成某个特定的功能，比如下单管理、客户管理等等。每一个微服务都是微型六角形应用，都有自己的业务逻辑和适配器。一些微服务还会发布API给其它微服务和应用客户端使用。其它微服务完成一个Web UI，运行时，每一个实例可能是一个云VM或者是Docker容器。 微服务架构模式在上图中对应于代表可扩展Scale Cube的Y轴，这是一个在《The Art of Scalability》书中描述过的三维扩展模型。另外两个可扩展轴，X轴由负载均衡器后端运行的多个应用副本组成，Z轴是将需求路由到相关服务。 应用基本可以用以上三个维度来表示，Y轴代表将应用分解为微服务。运行时，X轴代表运行多个隐藏在负载均衡器之后的实例，提供吞吐能力。一些应用可能还是用Z轴将服务分区。下面的图演示行程管理服务如何部署在运行于AWS EC2上的Docker上。 运行时，行程管理服务由多个服务实例构成。每一个服务实例都是一个Docker容器。为了保证高可用，这些容器一般都运行在多个云VM上。服务实例前是一层诸如NGINX的负载均衡器，他们负责在各个实例间分发请求。负载均衡器也同时处理其它请求，例如缓存、权限控制、API统计和监控。 这种微服务架构模式深刻影响了应用和数据库之间的关系，不像传统多个服务共享一个数据库，微服务架构每个服务都有自己的数据库。另外，这种思路也影响到了企业级数据模式。同时，这种模式意味着多份数据，但是，如果你想获得微服务带来的好处，每个服务独有一个数据库是必须的，因为这种架构需要这种松耦合。下面的图演示示例应用数据库架构。 每种服务都有自己的数据库，另外，每种服务可以用更适合自己的数据库类型，也被称作多语言一致性架构。比如，驾驶员管理（发现哪个驾驶员更靠近乘客），必须使用支持地理信息查询的数据库。 表面上看来，微服务架构模式有点像SOA，他们都由多个服务构成。但是，可以从另外一个角度看此问题，微服务架构模式是一个不包含Web服务（WS-）和ESB服务的SOA。微服务应用乐于采用简单轻量级协议，比如REST，而不是WS-，在微服务内部避免使用ESB以及ESB类似功能。微服务架构模式也拒绝使用canonical schema等SOA概念。 微服务的好处微服务架构模式有很多好处。首先，通过分解巨大单体式应用为多个服务方法解决了复杂性问题。在功能不变的情况下，应用被分解为多个可管理的分支或服务。每个服务都有一个用RPC-或者消息驱动API定义清楚的边界。微服务架构模式给采用单体式编码方式很难实现的功能提供了模块化的解决方案，由此，单个服务很容易开发、理解和维护。 第二，这种架构使得每个服务都可以有专门开发团队来开发。开发者可以自由选择开发技术，提供API服务。当然，许多公司试图避免混乱，只提供某些技术选择。然后，这种自由意味着开发者不需要被迫使用某项目开始时采用的过时技术，他们可以选择现在的技术。甚至于，因为服务都是相对简单，即使用现在技术重写以前代码也不是很困难的事情。 第三，微服务架构模式是每个微服务独立的部署。开发者不再需要协调其它服务部署对本服务的影响。这种改变可以加快部署速度。UI团队可以采用AB测试，快速的部署变化。微服务架构模式使得持续化部署成为可能。 最后，微服务架构模式使得每个服务独立扩展。你可以根据每个服务的规模来部署满足需求的规模。甚至于，你可以使用更适合于服务资源需求的硬件。比如，你可以在EC2 Compute Optimized instances上部署CPU敏感的服务，而在EC2 memory-optimized instances上部署内存数据库。 微服务的不足Fred Brooks在30年前写道，“there are no silver bullets”，像任何其它科技一样，微服务架构也有不足。其中一个跟他的名字类似，『微服务』强调了服务大小，实际上，有一些开发者鼓吹建立稍微大一些的，10-100 LOC服务组。尽管小服务更乐于被采用，但是不要忘了这只是终端的选择而不是最终的目的。微服务的目的是有效的拆分应用，实现敏捷开发和部署。 另外一个主要的不足是，微服务应用是分布式系统，由此会带来固有的复杂性。开发者需要在RPC或者消息传递之间选择并完成进程间通讯机制。更甚于，他们必须写代码来处理消息传递中速度过慢或者不可用等局部失效问题。当然这并不是什么难事，但相对于单体式应用中通过语言层级的方法或者进程调用，微服务下这种技术显得更复杂一些。 另外一个关于微服务的挑战来自于分区的数据库架构。商业交易中同时给多个业务分主体更新消息很普遍。这种交易对于单体式应用来说很容易，因为只有一个数据库。在微服务架构应用中，需要更新不同服务所使用的不同的数据库。使用分布式交易并不一定是好的选择，不仅仅是因为CAP理论，还因为今天高扩展性的NoSQL数据库和消息传递中间件并不支持这一需求。最终你不得不使用一个最终一致性的方法，从而对开发者提出了更高的要求和挑战。 测试一个基于微服务架构的应用也是很复杂的任务。比如，采用流行的Spring Boot架构，对一个单体式web应用，测试它的REST API，是很容易的事情。反过来，同样的服务测试需要启动和它有关的所有服务（至少需要这些服务的stubs）。再重申一次，不能低估了采用微服务架构带来的复杂性。 另外一个挑战在于，微服务架构模式应用的改变将会波及多个服务。比如，假设你在完成一个案例，需要修改服务A、B、C，而A依赖B，B依赖C。在单体式应用中，你只需要改变相关模块，整合变化，部署就好了。对比之下，微服务架构模式就需要考虑相关改变对不同服务的影响。比如，你需要更新服务C，然后是B，最后才是A，幸运的是，许多改变一般只影响一个服务，而需要协调多服务的改变很少。 部署一个微服务应用也很复杂，一个分布式应用只需要简单在复杂均衡器后面部署各自的服务器就好了。每个应用实例是需要配置诸如数据库和消息中间件等基础服务。相对比，一个微服务应用一般由大批服务构成。例如，根据Adrian Cockcroft，Hailo有160个不同服务构成，NetFlix有大约600个服务。每个服务都有多个实例。这就造成许多需要配置、部署、扩展和监控的部分，除此之外，你还需要完成一个服务发现机制（后续文章中发表），以用来发现与它通讯服务的地址（包括服务器地址和端口）。传统的解决问题办法不能用于解决这么复杂的问题。接续而来，成功部署一个微服务应用需要开发者有足够的控制部署方法，并高度自动化。 一种自动化方法是使用PaaS服务，例如Cloud Foundry。PaaS给开发者提供一个部署和管理微服务的简单方法，它把所有这些问题都打包内置解决了。同时，配置PaaS的系统和网络专家可以采用最佳实践和策略来简化这些问题。另外一个自动部署微服务应用的方法是开发对于你来说最基础的PaaS系统。一个典型的开始点是使用一个集群化方案，比如配合Docker使用Mesos或者Kubernetes。后面的系列我们会看看如何基于软件部署方法例如NGINX，可以方便的在微服务层面提供缓存、权限控制、API统计和监控。 总结构建复杂的应用真的是非常困难。单体式的架构更适合轻量级的简单应用。如果你用它来开发复杂应用，那真的会很糟糕。微服务架构模式可以用来构建复杂应用，当然，这种架构模型也有自己的缺点和挑战。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.cayzlh.com/tags/SpringCloud/"},{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}]},{"title":"Spring Cloud中的名词解释","date":"2018-12-02T07:49:29.000Z","path":"2018/12/02/60e9e95d.html","text":"微服务近年来，在软件开发领域关于微服务的讨论呈现出火爆的局面，有人倾向于在系统设计与开发中采用微服务方式实现软件系统的松耦合、跨部门开发，被认为是IT软件架构的未来方向，Martin Fowler也给微服务架构极高的评价；同时，反对之声也很强烈，持反对观点的人表示微服务增加了系统维护、部署的难度，导致一些功能模块或代码无法复用，同时微服务允许使用不同的语言和框架来开发各个系统模块，这又会增加系统集成与测试的难度，而且随着系统规模的日渐增长，微服务在一定程度上也会导致系统变得越来越复杂。尽管一些公司已经在生产系统中采用了微服务架构，并且取得了良好的效果；但更多公司还是处在观望的态度。 什么是微服务架构呢？简单说就是将一个完整的应用（单体应用）按照一定的拆分规则（后文讲述）拆分成多个不同的服务，每个服务都能独立地进行开发、部署、扩展。服务于服务之间通过注入RESTful api或其他方式调用。 版本版本号包含 英文单词（release train） + SRX（service release）（X：数字） release train：按伦敦地铁站名A-Z进行首字母迭代排序 SR：一般表示当前修复BUG的版本编号 例：Camden SR4、Camden SR5、Dalston SR1 而大多数Spring项目都以“主版本号.次版本号.增量版本号.里程碑版本号”的形式命名版本号，例如 Spring Framework 稳定版本 4.3.5.RELEASE、里程碑版本 5.0.0.M4 等。 Spring CloudSpring Cloud是在Spring Boot的基础上构建的，用于简化分布式系统构建的工具集，为开发人员提供快速建立分布式系统中的一些常见的模式。 例如：配置管理（configuration management），服务发现（service discovery），断路器（circuit breakers），智能路由（ intelligent routing），微代理（micro-proxy），控制总线（control bus），一次性令牌（ one-time tokens），全局锁（global locks），领导选举（leadership election），分布式会话（distributed sessions），集群状态（cluster state）。 Spring Cloud 包含了多个子项目： 例如：Spring Cloud Config、Spring Cloud Netflix等 Spring Cloud 项目主页：http://projects.spring.io/spring-cloud/ 服务发现在微服务架构中，服务发现（Service Discovery）是关键原则之一。手动配置每个客户端或某种形式的约定是很难做的，并且很脆弱。Spring Cloud提供了多种服务发现的实现方式，例如：Eureka、Consul、Zookeeper。 EurekaEureka是Netflix开发的服务发现组件，本身是一个基于REST的服务。 Spring Cloud将它集成在其子项目spring-cloud-netflix中，以实现Spring Cloud的服务发现功能。 ConsulConsul 是 HashiCorp 公司推出的开源工具，用于实现分布式系统的服务发现与配置。与其他分布式服务注册与发现的方案，Consul的方案更“一站式”，内置了服务注册与发现框 架、分布一致性协议实现、健康检查、Key/Value存储、多数据中心方案，不再需要依赖其他工具（比如ZooKeeper等）。使用起来也较 为简单。Consul使用Go语言编写，因此具有天然可移植性(支持Linux、windows和Mac OS X)；安装包仅包含一个可执行文件，方便部署，与Docker等轻量级容器可无缝配合 。 RibbonRibbon是Netflix发布的开源项目，主要功能是提供客户端的软件负载均衡算法，将Netflix的中间层服务连接在一起。Ribbon客户端组件提供一系列完善的配置项如连接超时，重试等。简单的说，就是在配置文件中列出Load Balancer后面所有的机器，Ribbon会自动的帮助你基于某种规则（如简单轮询，随机连接等）去连接这些机器。我们也很容易使用Ribbon实现自定义的负载均衡算法。简单地说，Ribbon是一个客户端负载均衡器。 Ribbon工作时分为两步：第一步先选择 Eureka Server, 它优先选择在同一个Zone且负载较少的Server；第二步再根据用户指定的策略，在从Server取到的服务注册列表中选择一个地址。其中Ribbon提供了多种策略，例如轮询、随机、根据响应时间加权等。 FeignFeign是一个声明式的web service客户端，它使得编写web service客户端更为容易。创建接口，为接口添加注解，即可使用Feign。Feign可以使用Feign注解或者JAX-RS注解，还支持热插拔的编码器和解码器。Spring Cloud为Feign添加了Spring MVC的注解支持，并整合了Ribbon和Eureka来为使用Feign时提供负载均衡。 熔断器雪崩效应在微服务架构中通常会有多个服务层调用，基础服务的故障可能会导致级联故障，进而造成整个系统不可用的情况，这种现象被称为服务雪崩效应。服务雪崩效应是一种因“服务提供者”的不可用导致“服务消费者”的不可用,并将不可用逐渐放大的过程。 如果下图所示：A作为服务提供者，B为A的服务消费者，C和D是B的服务消费者。A不可用引起了B的不可用，并将不可用像滚雪球一样放大到C和D时，雪崩效应就形成了。 熔断器（CircuitBreaker）熔断器的原理很简单，如同电力过载保护器。它可以实现快速失败，如果它在一段时间内侦测到许多类似的错误，会强迫其以后的多个调用快速失败，不再访问远程服务器，从而防止应用程序不断地尝试执行可能会失败的操作，使得应用程序继续执行而不用等待修正错误，或者浪费CPU时间去等到长时间的超时产生。熔断器也可以使应用程序能够诊断错误是否已经修正，如果已经修正，应用程序会再次尝试调用操作。 熔断器模式就像是那些容易导致错误的操作的一种代理。这种代理能够记录最近调用发生错误的次数，然后决定使用允许操作继续，或者立即返回错误。 熔断器开关相互转换的逻辑如下图： Hystrix在Spring Cloud中使用了Netflix开发的Hystrix来实现熔断器。 Hystrix DashboardHystrix监控，除了隔离依赖服务的调用以外，Hystrix还提供了近实时的监控，Hystrix会实时、累加地记录所有关于HystrixCommand的执行信息，包括每秒执行多少请求多少成功，多少失败等。Netflix通过hystrix-metrics-event-stream项目实现了对以上指标的监控。 Turbine在复杂的分布式系统中，相同服务的节点经常需要部署上百甚至上千个，很多时候，运维人员希望能够把相同服务的节点状态以一个整体集群的形式展现出来，这样可以更好的把握整个系统的状态。 为此，Netflix提供了一个开源项目（Turbine）来提供把多个hystrix.stream的内容聚合为一个数据源供Dashboard展示。 和Hystrix Dashboard一样，Turbine也可以下载war包部署到Web容器。 ZuulNetflix开源的微服务网关，核心是一系列过滤器： 身份认证安全 审查与监控 动态路由 压力测试 附再分配 静态响应处理 多区域弹性 Zuul过滤器Spring Cloud中使用Zuul作为API Gateway。Zuul提供了动态路由、监控、回退、安全等功能。主要为4种标准类型： PRE：在请求被路由之前调用 ROUTING：这种过滤器将请求路由到微服务 POST：在路由到微服务以后执行 ERROR：在其他阶段发生错误时自信该过滤器 Sleuth为Spring Cloud 提供了分布式跟踪的解决方案，它大量借助了Google Dapper、Twitter Zipkin 和 Apache HTrace的设计。Sleuth的术语：span（跨度）、trace（跟踪）、annotation（标注） 配置中心Spring Cloud Config提供了一种在分布式系统中外部化配置服务器和客户端的支持。配置服务器有一个中心位置，管理所有环境下的应用的外部属性。客户端和服务器映射到相同Spring Eventment 和 PropertySrouce抽象的概念，所以非常适合Spring应用，但也可以在任何语言开发的任何应用中使用。在一个应用从开发、测试到生产的过程中，你可以分别地管理开发、测试、生产环境的配置，并且在迁移的时候获取相应的配置来运行。 Config Server 存储后端默认使用git存储配置信息，因此可以很容易支持标记配置环境的版本，同时可以使用一个使用广泛的工具管理配置内容。当然添加其他方式的存储实现也是很容易的。 API GatewayAPI Gateway是微服务架构中不可或缺的部分：http://dockone.io/article/482。 API Gateway是一个服务器，也可以说是进入系统的唯一节点。这跟面向对象设计模式中的Facade模式很像。API Gateway封装内部系统的架构，并且提供API给各个客户端。它还可能有其他功能，如授权、监控、负载均衡、缓存、请求分片和管理、静态响应处理等。 API Gateway负责请求转发、合成和协议转换。所有来自客户端的请求都要先经过API Gateway，然后路由这些请求到对应的微服务。API Gateway将经常通过调用多个微服务来处理一个请求以及聚合多个服务的结果。它可以在web协议与内部使用的非Web友好型协议间进行转换，如HTTP协议、WebSocket协议。 API Gateway可以提供给客户端一个定制化的API。它暴露一个粗粒度API给移动客户端。以产品最终页这个使用场景为例。API Gateway提供一个服务提供点（/productdetails?productid=xxx）使得移动客户端可以在一个请求中检索到产品最终页的全部数据。API Gateway通过调用多个服务来处理这一个请求并返回结果，涉及产品信息、推荐、评论等。 一个很好的API Gateway例子是Netfix API Gateway。Netflix流服务提供数百个不同的微服务，包括电视、机顶盒、智能手机、游戏系统、平板电脑等。起初，Netflix视图提供一个适用全场景的API。但是，他们发现这种形式不好用，因为涉及到各式各样的设备以及它们独特的需求。现在，他们采用一个API Gateway来提供容错性高的API，针对不同类型设备有相应代码。事实上，一个适配器处理一个请求平均要调用6到8个后端服务。Netflix API Gateway每天处理数十亿的请求。 API Gateway的优点和缺点如你所料，采用API Gateway也是优缺点并存的。API Gateway的一个最大好处是封装应用内部结构。相比起来调用指定的服务，客户端直接跟gatway交互更简单点。API Gateway提供给每一个客户端一个特定API，这样减少了客户端与服务器端的通信次数，也简化了客户端代码。 API Gateway也有一些缺点。它是一个高可用的组件，必须要开发、部署和管理。还有一个问题，它可能成为开发的一个瓶颈。开发者必须更新API Gateway来提供新服务提供点来支持新暴露的微服务。更新API Gateway时必须越轻量级越好。否则，开发者将因为更新Gateway而排队列。但是，除了这些缺点，对于大部分的应用，采用API Gateway的方式都是有效的。 使用API Gateway后，客户端和微服务之间的网络图变成下图： 通过API Gateway，可以统一向外部系统提供REST API。Spring Cloud中使用Zuul作为API Gateway。Zuul提供了动态路由、监控、回退、安全等功能。 图文来源：https://github.com/eacdy/spring-cloud-book、Google","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.cayzlh.com/tags/SpringCloud/"},{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"SpringCloud","slug":"Spring/SpringCloud","permalink":"https://www.cayzlh.com/categories/Spring/SpringCloud/"}]},{"title":"Spring统一异常返回","date":"2018-11-29T12:31:21.000Z","path":"2018/11/29/49e36d40.html","text":"记录一次在Spring中处理统一异常处理的方法 @RestControllerAdvice@ControllerAdvice，是Spring3.2提供的新注解，从名字上可以看出大体意思是控制器增强。 @ExceptionHandler@ExceptionHandler用来与@RestControllerAdvice配合使用，当捕获到指定的异常时，可以作出相应处理。 这里展示当参数签名失败时的异常处理： @RestControllerAdvice public class SignatureExceptionHandler extends ResponseEntityExceptionHandler { public SignatureExceptionHandler() { } @ExceptionHandler(SignatureExpireException.class) public RestResponse&lt;?> handleSignatureExpireException(SignatureExpireException ex) { // 当然， 这是最简单的处理，还可以有多种拓展方式，这里只展示一下怎么使用 return ResultBuilder.signatureError(ErrorCodeEnum.SIGNATURE_ERROR, ex.getMessage()); } } 这时， 当捕获到SignatureExpireException异常的时候， 就会进入这个handler里面来处理。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"}]},{"title":"签名参数Map字典排序","date":"2018-11-28T13:53:56.000Z","path":"2018/11/28/6ad41dce.html","text":"由于业务需要，需要对请求进行的签名，其中有一部分的算法就是需要对所有参数进行字典排序 /** * 方法用途: 对所有传入参数按照字段名的 ASCII 码从小到大排序（字典序），并且生成url参数串 * * @param paramsMap 要排序的Map对象 * @param urlEncode 是否需要URLENCODE * @param keyToLower 是否需要将Key转换为全小写 true:key转化成小写，false:不转化 * @return */ public static String formatUrlMap(Map&lt;String, Object> paramsMap, boolean urlEncode, boolean keyToLower) { String buff = \"\"; Map&lt;String, Object> tmpMap = paramsMap; try { List&lt;Map.Entry&lt;String, Object>> infoIds = new ArrayList&lt;Map.Entry&lt;String, Object>>(tmpMap.entrySet()); //对所有传入参数按照字段名的ASCII码从小到大排序（字典序） Collections.sort(infoIds, new Comparator&lt;Map.Entry&lt;String, Object>>() { public int compare(Map.Entry&lt;String, Object> o1, Map.Entry&lt;String, Object> o2) { return (o1.getKey()).toString().compareTo(o2.getKey()); } }); //构造URL 键值对的格式 StringBuffer buf = new StringBuffer(); for (Map.Entry&lt;String, Object> item : infoIds) { if (StringUtils.isNotBlank(item.getKey())) { String key = item.getKey(); String value = item.getValue().toString(); if (urlEncode) { value = URLEncoder.encode(value, \"utf-8\"); } if (keyToLower) { buf.append(key.toLowerCase() + \"=\" + value); } else { buf.append(key + \"=\" + value); } buf.append(\"&amp;\"); } } buff = buf.toString(); if (StringUtils.isNotEmpty(buff)) { buff = buff.substring(0, buff.length() - 1); } } catch (Exception e) { e.printStackTrace(); return null; } return buff; } 排序后可以进行其他处理，比如拼上nonce、时间戳等；","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"}]},{"title":"Maven中dependencyManagement的作用","date":"2018-11-27T01:23:15.000Z","path":"2018/11/27/bc329e47.html","text":"说明使用dependencyManagement可以统一管理项目的版本号，确保应用的各个项目的依赖和版本一致，不用每个模块项目都弄一个版本号，不利于管理，当需要变更版本号的时候只需要在父类容器里更新，不需要任何一个子项目的修改；如果某个子项目需要另外一个特殊的版本号时，只需要在自己的模块dependencies中声明一个版本号即可。子类就会使用子类声明的版本号，不继承于父类版本号。 ##dependencyManagement与dependencys的区别 1)Dependencies相对于dependencyManagement，所有生命在dependencies里的依赖都会自动引入，并默认被所有的子项目继承。 2)dependencyManagement里只是声明依赖，并不自动实现引入，因此子项目需要显示的声明需要用的依赖。如果不在子项目中声明依赖，是不会从父项目中继承下来的；只有在子项目中写了该依赖项，并且没有指定具体版本，才会从父项目中继承该项，并且version和scope都读取自父pom;另外如果子项目中指定了版本号，那么会使用子项目中指定的jar版本。 示例说明在父模块中： &lt;dependencyManagement> &lt;dependencies> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;version>5.1.44&lt;/version> &lt;/dependency> &lt;/dependencies> &lt;/dependencyManagement> 在子模块中： &lt;dependencies> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;/dependency> &lt;/dependencies> 只需要指定groupId和artifactId即可，不需要额外指定版本号； 在Maven多模块的时候，管理依赖关系是非常重要的，各种依赖包冲突，查询问题起来非常复杂，使用dependencyManagement可以有效的管理。","tags":[{"name":"Maven","slug":"Maven","permalink":"https://www.cayzlh.com/tags/Maven/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"},{"name":"Maven","slug":"Java/Maven","permalink":"https://www.cayzlh.com/categories/Java/Maven/"}]},{"title":"Linux下find与exec的使用","date":"2018-11-25T08:51:42.000Z","path":"2018/11/25/194d48ee.html","text":"exec命令用于调用并执行指令的命令。exec命令通常用在shell脚本程序中，可以调用其他的命令。如果在当前终端中使用命令，则当指定的命令执行完毕后会立即退出终端。 exec的基本用法-exec参数后面跟的就是我们想进一步操作的命令，比如rm，mv等等。exec是以分号”;“作为结束标识符的，考虑到各个系统平台对分号的不同解释，我们在分号前再加个反斜杠，便于移植。而在分号前，通常也会有一对花括号{}，代表前面find命令查找出来的文件名。 Example 1 使用find命令查找相关文件后，再使用ls命令将它们的详细信息列出来想把当前目录下所有的.o文件全部找出来，并用 ls -l 命令将它们列出来。实现这个需求的命令如下： find . -name \"*.o\" -type f -exec ls -l {} \\; 在这里，我们用find 命令匹配到了当前目录下的所有.o文件，并在 -exec 选项中使用 ls -l 命令将它们的详细信息列出来。 Example 2 使用find命令查找相关文件后，再使用rm命令将它们删除想把当前目录下所有的.o文件全部找出来，并用rm命令将它们删除。实现这个需求的命令如下： find . -name \"*.o\" -exec rm {} \\; 执行完这个命令后，该目录下所有的.o文件都被删除。 Example 3 使用-exec选项的安全模式，将对每个匹配到的文件进行操作之前提示用户在实例2中，匹配到文件后就立刻执行rm命令，这样操作有些危险，因为如果一旦误操作，有可能会引起灾难性的后果。 exec的安全模式就是为了避免这个问题而产生。它会在匹配到某个文件后，在进行操作之前会先问一下你，经过确认它才会进行相应操作。 同样的实例2的需求，如果采用安全模式的话，命令是这样的： find . -name \"*.o\" -ok rm {} \\; Example 4 搜索匹配到的文件中的关键内容假如现在有个很大型的项目（如Linux内核），想在里面搜索一个含有某关键字的文件。可以使用grep命令检索所有的文件。这样做肯定是可以的，但如果项目很大的话，这样太耗时了，效率太低。 可以先用find命令找到所以相关文件，然后再用grep命令检索那些文件即可。因为已经使用find过滤一遍了，所以这样操作会节约很多时间，提高效率。 命令如下： find . -name \"*.h\" -exec grep -rns \"hello\" {} \\; Example 5 查找文件并移动到指定目录这个需求就比较简单了。比如现在想把所有的.o文件找出来，然后新他们mv到buil目录。命令如下： find . -name \"*.o\" -exec cp {} build \\;","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.cayzlh.com/tags/Linux/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"}]},{"title":"Java使用Optional优雅地判空","date":"2018-11-24T14:38:11.000Z","path":"2018/11/24/cdbc6817.html","text":"Java8特性中的Optional可以用来优雅的判空，Optional来自官方的介绍如下： A container object which may or may not contain a non-null value. If a value is present, isPresent() will return true and get() will return the value. 一个可能包含也可能不包含非null值的容器对象。 如果存在值，isPresent()将返回true，get()将返回该值。 如下代码，需要获得Test2中的Info信息，但是参数为Test4，我们要一层层的申请，每一层都获得的对象都可能是空，最后的代码看起来就像这样。 public String testSimple(Test4 test) { if (test == null) { return \"\"; } if (test.getTest3() == null) { return \"\"; } if (test.getTest3().getTest2() == null) { return \"\"; } if (test.getTest3().getTest2().getInfo() == null) { return \"\"; } return test.getTest3().getTest2().getInfo(); } 使用Optional： public String testOptional(Test test) { return Optional.ofNullable(test).flatMap(Test::getTest3) .flatMap(Test3::getTest2) .map(Test2::getInfo) .orElse(\"\"); } 1、Optional.ofNullable(test)，如果test为空，则返回一个单例空Optional对象，如果非空则返回一个Optional包装对象，Optional将test包装； public static &lt;T> Optional&lt;T> ofNullable(T value) { return value == null ? empty() : of(value); } 2、flatMap(Test::getTest3)判断test是否为空，如果为空，继续返回第一步中的单例Optional对象，否则调用Test的getTest3方法； public&lt;U> Optional&lt;U> flatMap(Function&lt;? super T, Optional&lt;U>> mapper) { Objects.requireNonNull(mapper); if (!isPresent()) return empty(); else { return Objects.requireNonNull(mapper.apply(value)); } } 3、flatMap(Test3::getTest2)同上调用Test3的getTest2方法； 4、map(Test2::getInfo)同flatMap类似，但是flatMap要求Test3::getTest2返回值为Optional类型，而map不需要，flatMap不会多层包装，map返回会再次包装Optional； public&lt;U> Optional&lt;U> map(Function&lt;? super T, ? extends U> mapper) { Objects.requireNonNull(mapper); if (!isPresent()) return empty(); else { return Optional.ofNullable(mapper.apply(value)); } } 5、orElse(&quot;&quot;);获得map中的value，不为空则直接返回value，为空则返回传入的参数作为默认值。 public T orElse(T other) { return value != null ? value : other; } 使用Optional后的代码是不是瞬间变得非常整洁，或许看到这段代码你会有很多疑问，针对复杂的一长串判空，Optional有它的优势，但是对于简单的判空使用Optional也会增加代码的阅读成本、编码量以及团队新成员的学习成本。毕竟Optional在现在还并没有那样流行，它还拥有一定的局限性。 文章内容来源 http://blog.imuxuan.com Java知音 微信公众号","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"}]},{"title":"Linux排查Java问题工具单","date":"2018-11-23T14:41:08.000Z","path":"2018/11/23/77eeefb9.html","text":"记录一些在Linux中排查Java问题的工具，可以让后续忘记了可快速翻阅 Linux命令tail最常用的tail -f tail -200f error.log # 倒数200行并进入实时监听文件写入模式 grepgrep forest f.txt #文件查找 grep forest f.txt cpf.txt #多文件查找 grep 'log' /home/admin -r -n #目录下查找所有符合关键字的文件 cat f.txt | grep -i shopbase grep 'shopbase' /home/admin -r -n --include *.{vm,java} #指定文件后缀 grep 'shopbase' /home/admin -r -n --exclude *.{vm,java} #反匹配 seq 10 | grep 5 -A 3 #上匹配 seq 10 | grep 5 -B 3 #下匹配 seq 10 | grep 5 -C 3 #上下匹配，平时用这个就妥了 cat f.txt | grep -c 'SHOPBASE' awk基础命令grep forest f.txt #文件查找 grep forest f.txt cpf.txt #多文件查找 grep 'log' /home/admin -r -n #目录下查找所有符合关键字的文件 cat f.txt | grep -i shopbase grep 'shopbase' /home/admin -r -n --include *.{vm,java} #指定文件后缀 grep 'shopbase' /home/admin -r -n --exclude *.{vm,java} #反匹配 seq 10 | grep 5 -A 3 #上匹配 seq 10 | grep 5 -B 3 #下匹配 seq 10 | grep 5 -C 3 #上下匹配，平时用这个就妥了 cat f.txt | grep -c 'SHOPBASE' 匹配awk '/ldb/ {print}' f.txt #匹配ldb awk '!/ldb/ {print}' f.txt #不匹配ldb awk '/ldb/ && /LISTEN/ {print}' f.txt #匹配ldb和LISTEN awk '$5 ~ /ldb/ {print}' f.txt #第五列匹配ldb 内建变量NR:NR表示从awk开始执行后，按照记录分隔符读取的数据次数，默认的记录分隔符为换行符，因此默认的就是读取的数据行数，NR可以理解为Number of Record的缩写。 FNR:在awk处理多个输入文件的时候，在处理完第一个文件后，NR并不会从1开始，而是继续累加，因此就出现了FNR，每当处理一个新文件的时候，FNR就从1开始计数，FNR可以理解为File Number of Record。 NF: NF表示目前的记录被分割的字段的数目，NF可以理解为Number of Field。 findsudo -u admin find /home/admin /tmp /usr -name \\*.log(多个目录去找) find . -iname \\*.txt(大小写都匹配) find . -type d(当前目录下的所有子目录) find /usr -type l(当前目录下所有的符号链接) find /usr -type l -name \"z*\" -ls(符号链接的详细信息 eg:inode,目录) find /home/admin -size +250000k(超过250000k的文件，当然+改成-就是小于了) find /home/admin f -perm 777 -exec ls -l {} \\; (按照权限查询文件) find /home/admin -atime -1 1天内访问过的文件 find /home/admin -ctime -1 1天内状态改变过的文件 find /home/admin -mtime -1 1天内修改过的文件 find /home/admin -amin -1 1分钟内访问过的文件 find /home/admin -cmin -1 1分钟内状态改变过的文件 find /home/admin -mmin -1 1分钟内修改过的文件 pgm批量查询vm-shopbase满足条件的日志 pgm -A -f vm-shopbase \\ 'cat /home/admin/shopbase/logs/shopbase.log.2017-01-17|grep 2069861630' toptop除了看一些基本信息之外，剩下的就是配合来查询vm的各种问题了 ps -ef | grep java top -H -p pid 获得线程10进制转16进制后jstack去抓看这个线程到底在干啥 其他netstat -nat|awk '{print $6}'|sort|uniq -c|sort -rn # 查看当前连接 Java自带工具jps用一条命令： sudo -u admin /opt/taobao/java/bin/jps -mlvV jstack普通用法：sudo -u admin /opt/taobao/install/ajdk-8_1_1_fp1-b52/bin/jstack 2815 native + java栈：sudo -u admin /opt/taobao/install/ajdk-8_1_1_fp1-b52/bin/jstack -m 2815 jinfo可看系统启动的参数 sudo -u admin /opt/install/ajdk-8_1_1_fp1-b52/bin/jinfo -flags 2815 jamp 查看堆的情况 sudo -u admin /opt/install/ajdk-8_1_1_fp1-b52/bin/jmap -heap 2815 dump sudo -u admin /opt/install/ajdk-8_1_1_fp1-b52/bin/jmap \\ -dump:live,format=b,file=/tmp/heap2.bin 2815 或者 sudo -u admin /opt/install/ajdk-8_1_1_fp1-b52/bin/jmap \\ -dump:format=b,file=/tmp/heap3.bin 2815 查看堆被谁占用，配合zprofiler和btrace，更方便的排查问题 sudo -u admin /opt/install/ajdk-8_1_1_fp1-b52/bin/jmap \\ -histo 2815 | head -10 jstatjstat参数众多，但是使用一个就够了 sudo -u admin /opt/install/ajdk-8_1_1_fp1-b52/bin/jstat \\ -gcutil 2815 1000 jdbjdb可以用来预发debug,假设你预发的java_home是/opt/taobao/java/，远程调试端口是8000，那么： sudo -u admin /opt/java/bin/jdb -attach 8000","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"Linux","slug":"Linux","permalink":"https://www.cayzlh.com/tags/Linux/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"}]},{"title":"Shell脚本简明教程","date":"2018-11-18T08:33:34.000Z","path":"2018/11/18/6e1eac13.html","text":"Shell脚本,就是利用Shell的命令解释的功能，对一个纯文本的文件进行解析，然后执行这些功能，也可以说Shell脚本就是一系列命令的集合。 Shell可以直接使用在win/Unix/Linux上面，并且可以调用大量系统内部的功能来解释执行程序，如果熟练掌握Shell脚本，可以让我们操作计算机变得更加轻松，也会节省很多时间。 Shell的应用场景Shell能做什么 将一些复杂的命令简单化(平时我们提交一次github代码可能需要很多步骤，但是可以用Shell简化成一步) 可以写一些脚本自动实现一个工程中自动更换最新的sdk(库) 自动打包、编译、发布等功能 清理磁盘中空文件夹 总之一切有规律的活脚本都可以尝试一下 Shell不能做什么 需要精密的运算的时候 需要语言效率很高的时候 需要一些网络操作的时候 总之Shell就是可以快速开发一个脚本简化开发流程，并不可以用来替代高级语言 Shell工作原理Shell可以被称作是脚本语言，因为它本身是不需要编译的，而是通过解释器解释之后再编译执行，和传统语言相比多了解释的过程所以效率会略差于传统的直接编译的语言。 如何编写Shell脚本最简单的脚本： #!/bin/bash echo \"Hello World.\" 只需要打开文本编辑工具，编辑成以上的样子,然后保存成test.sh 运行脚本： chmod +x ./test.sh ./test.sh Hello World. 关于第一行中的#!/bin/bash： 比较常见的说法是：第一行的内容指定了shell脚本解释器的路径，而且这个指定路径只能放在文件的第一行 Shell中的变量myText=\"hello world\" muNum=100 这里面需要注意的就是，“=”前后不能有空格，命名规则就和其它语言一样了。 访问变量myText=\"hello world\" muNum=100 echo $myText echo muNum 当想要访问变量的时候，需要使用$，否则输出的将是纯文本内容。 Shell中的四则运算 运算符 含义 + 加法运算 - 减法运算 * 乘法运算 / 除法运算 例子：#!/bin/bash echo \"Hello World !\" a=3 b=5 val=`expr $a + $b` echo \"Total value : $val\" val=`expr $a - $b` echo \"Total value : $val\" val=`expr $a \\* $b` echo \"Total value : $val\" val=`expr $a / $b` echo \"Total value : $val\" 这里面需要注意的就是，定义变量的时候“=”前后是不能有空格的，但是进行四则运算的时候运算符号前后一定要有空格，乘法的时候需要进行转义。 其它运算符 =、==、!=、！、-o、-a 运算符 含义 % 求余 == 相等 = 赋值 != 不相等 ! 与 -o 或 -a 非 例子：a=3 b=5 val=`expr $a / $b` echo \"Total value : $val\" val=`expr $a % $b` echo \"Total value : $val\" if [ $a == $b ] then echo \"a is equal to b\" fi if [ $a != $b ] then echo \"a is not equal to b\" fi 关系运算符 运算符 含义 -eq 两个数相等返回true -ne 两个数不相等返回true -gt 左侧数大于右侧数返回true -It 左侧数小于右侧数返回true -ge 左侧数大于等于右侧数返回true -le 左侧数小于等于右侧数返回true 例子：#!/bin/sh a=10 b=20 if [ $a -eq $b ] then echo \"true\" else echo \"false\" fi if [ $a -ne $b ] then echo \"true\" else echo \"false\" fi if [ $a -gt $b ] then echo \"true\" else echo \"false\" fi if [ $a -lt $b ] then echo \"true\" else echo \"false\" fi if [ $a -ge $b ] then echo \"true\" else echo \"false\" fi if [ $a -le $b ] then echo \"true\" else echo \"false\" fi 字符串运算符 运算符 含义 = 两个字符串相等返回true != 两个字符串不相等返回true -z 字符串长度为0返回true -n 字符串长度不为0返回true 还有： 运算符 含义 -d file 检测文件是否是目录，如果是，则返回 true -r file 检测文件是否可读，如果是，则返回 true -w file 检测文件是否可写，如果是，则返回 true -x file 检测文件是否可执行，如果是，则返回 true -s file 检测文件是否为空（文件大小是否大于0，不为空返回 true -e file 检测文件（包括目录）是否存在，如果是，则返回 true 字符串#!/bin/sh mtext=\"hello\" #定义字符串 mtext2=\"world\" mtext3=$mtext\" \"$mtext2 #字符串的拼接 echo $mtext3 #输出字符串 echo ${#mtext3} #输出字符串长度 echo ${mtext3:1:4} #截取字符串 数组#!/bin/sh array=(1 2 3 4 5) #定义数组 array2=(aa bb cc dd ee) #定义数组 value=${array[3]} #找到某一个下标的数，然后赋值 echo $value #打印 value2=${array2[3]} #找到某一个下标的数，然后赋值 echo $value2 #打印 length=${#array[*]} #获取数组长度 echo $length 输出程序echo #!/bin/sh echo \"hello world\" echo hello world text=\"hello world\" echo $text echo -e \"hello world\" #输出并且换行 echo \"hello world\" > a.txt #重定向到文件 echo `date` #输出当前系统时间 判断语句 if if-else if-elseIf case #!/bin/sh a=10 b=20 if [ $a == $b ] then echo \"true\" fi if [ $a == $b ] then echo \"true\" else echo \"false\" fi if [ $a == $b ] then echo \"a is equal to b\" elif [ $a -gt $b ] then echo \"a is greater than b\" elif [ $a -lt $b ] then echo \"a is less than b\" else echo \"None of the condition met\" fi test命令test $[num1] -eq $[num2] #判断两个变量是否相等 test num1=num2 #判断两个数字是否相等 参数 含义 -e file 文件存在则返回真 -r file 文件存在并且可读则返回真 -w file 文件存在并且可写则返回真 -x file 文件存在并且可执行则返回真 -s file 文件存在并且内容不为空则返回真 -d file 文件目录存在则返回真 for循环#!/bin/sh for i in {1..5} do echo $i done for i in 5 6 7 8 9 do echo $i done for FILE in $HOME/.bash* do echo $FILE done while循环#!/bin/sh COUNTER=0 while [ $COUNTER -lt 5 ] do COUNTER=`expr $COUNTER + 1` echo $COUNTER done echo '请输入。。。' echo 'ctrl + d 即可停止该程序' while read FILM do echo \"Yeah! great film the $FILM\" done 以上是while循环的两种用法，第一种是比较常规的，执行循环，然后每次都把控制的数加1，就可以让while循环有退出的条件了。第二种是用户从键盘数据，然后把用户输入的文字输出出来。 跳出循环break #跳出所有循环 break n #跳出第n层f循环 continue #跳出当前循环 函数#!/bin/sh sysout(){ echo \"hello world\" } sysout 定义一个没有返回值的函数，然后调用该函数。 #!/bin/sh test(){ aNum=3 anotherNum=5 return $(($aNum+$anotherNum)) } test result=$? echo $result 定义一个有返回值的函数，调用该函数，输出结果。 #!/bin/sh test(){ echo $1 #接收第一个参数 echo $2 #接收第二个参数 echo $3 #接收第三个参数 echo $# #接收到参数的个数 echo $* #接收到的所有参数 } test aa bb cc 定义了一个需要传递参数的函数。 重定向echo result > file #将结果写入文件，结果不会在控制台展示，而是在文件中，覆盖写 echo result >> file #将结果写入文件，结果不会在控制台展示，而是在文件中，追加写 echo input < file #获取输入流 写一个自动输入命令的脚本自动提交github的脚本 #!/bin/bash echo \"-------Begin-------\" git add . git commit -m $1 echo $1 git push origin master echo \"--------End--------\" IntelliJ IDEA中编写Shell脚本使用bashsupport插件。 具体参考这个链接：IDEA中编写脚本并运行shell脚本 参考 [程序猿] 微信公众号 关玮琳linSir","tags":[{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"Linux","slug":"Linux","permalink":"https://www.cayzlh.com/tags/Linux/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"}]},{"title":"Git常用命令整理","date":"2018-11-10T13:19:46.000Z","path":"2018/11/10/d0c5e74e.html","text":"Git的四个组成部分： 远程操作详解git clone远程操作的第一步，通常是从远程主机克隆一个版本库，这时就要用到git clone命令。 git clone 比如： git clone https://github.com/cayzlh/Scaffold.git 该命令会在本地主机生成一个目录，与远程主机的版本库同名。如果要指定不同的目录名，可以将目录名作为git clone命令的第二个参数。 git clone git clone支持多种协议，除了HTTP(s)以外，还支持SSH、Git、本地文件协议等： git clone http[s]://example.com/path/to/repo.git/ git clone ssh://example.com/path/to/repo.git/ git clone git://example.com/path/to/repo.git/ git clone /opt/git/project.git git clone file:///opt/git/project.git git clone ftp[s]://example.com/path/to/repo.git/ git clone rsync://example.com/path/to/repo.git/ SSH协议还有另一种写法： $ git clone [user@]example.com:path/to/repo.git/ git remote为了便于管理，Git要求每个远程主机都必须指定一个主机名。git remote命令就用于管理主机名。 不带选项的时候，git remote命令列出所有远程主机。 git remote origin 使用-v选项，可以参看远程主机的网址。 git remote -v origin https://github.com/cayzlh/Scaffold.git (fetch) origin https://github.com/cayzlh/Scaffold.git (push) 当前只有一台远程主机，叫做origin，以及它的网址。 克隆版本库的时候，所使用的远程主机自动被Git命名为origin。如果想用其他的主机名，需要用git clone命令的-o选项指定。 git clone -o Scaffold https://github.com/cayzlh/Scaffold.git git remote Scaffold git remote show命令加上主机名，可以查看该主机的详细信息。 git remote show git remote add命令用于添加远程主机。 git remote add git remote rm命令用于删除远程主机。 git remote rm git remote rename命令用于远程主机的改名。 git remote rename git fetch一旦远程主机的版本库有了更新（Git术语叫做commit），需要将这些更新取回本地，这时就要用到git fetch命令。 git fetch 这个命令表述将某个远程主机的更新，全部取回本地。 取回origin主机的master分支。 git fetch origin master git branch命令的-r选项，可以用来查看远程分支，-a选项查看所有分支。 git branch -r origin/HEAD -> origin/master origin/master 上面命令表示，本地主机的当前分支是master，远程分支是origin/master。 取回远程主机的更新以后，可以在它的基础上，使用git checkout命令创建一个新的分支。 git checkout -b newBrach origin/master 上面命令表示，在origin/master的基础上，创建一个新分支。 此外，也可以使用git merge命令或者git rebase命令，在本地分支上合并远程分支。 git merge origin/master # 或者 git rebase origin/master 上面命令表示在当前分支上，合并origin/master。 git pullgit pull命令的作用是，取回远程主机某个分支的更新，再与本地的指定分支合并。它的完整格式稍稍有点复杂。 git pull : 比如，取回origin主机的next分支，与本地的master分支合并，需要写成下面这样。 git pull origin next:master 如果远程分支是与当前分支合并，则冒号后面的部分可以省略。 git pull origin next 上面命令表示，取回origin/next分支，再与当前分支合并。实质上，这等同于先做git fetch，再做git merge。 git fetch origin git merge origin/next 在某些场合，Git会自动在本地分支与远程分支之间，建立一种追踪关系（tracking）。比如，在git clone的时候，所有本地分支默认与远程主机的同名分支，建立追踪关系，也就是说，本地的master分支自动”追踪”origin/master分支。 Git也允许手动建立追踪关系。 git branch --set-upstream master origin/next 上面命令指定master分支追踪origin/next分支。 如果当前分支与远程分支存在追踪关系，git pull就可以省略远程分支名。 git pull origin 上面命令表示，本地的当前分支自动与对应的origin主机”追踪分支”（remote-tracking branch）进行合并。 如果当前分支只有一个追踪分支，连远程主机名都可以省略。 git pull 上面命令表示，当前分支自动与唯一一个追踪分支进行合并。 如果合并需要采用rebase模式，可以使用--rebase选项。 git pull --rebase : 如果远程主机删除了某个分支，默认情况下，git pull 不会在拉取远程分支的时候，删除对应的本地分支。这是为了防止，由于其他人操作了远程主机，导致git pull不知不觉删除了本地分支。 但是，你可以改变这个行为，加上参数 -p 就会在本地删除远程已经删除的分支。 git pull -p # 等同于下面的命令 git fetch --prune origin git fetch -p git pushgit push命令用于将本地分支的更新，推送到远程主机。它的格式与git pull命令相仿。 git push : 注意，分支推送顺序的写法是&lt;来源地&gt;:&lt;目的地&gt;，所以git pull是&lt;远程分支&gt;:&lt;本地分支&gt;，而git push是&lt;本地分支&gt;:&lt;远程分支&gt;。 如果省略远程分支名，则表示将本地分支推送与之存在”追踪关系”的远程分支（通常两者同名），如果该远程分支不存在，则会被新建。 git push origin master 上面命令表示，将本地的master分支推送到origin主机的master分支。如果后者不存在，则会被新建。 如果省略本地分支名，则表示删除指定的远程分支，因为这等同于推送一个空的本地分支到远程分支。 git push origin :master # 等同于 git push origin --delete master 上面命令表示删除origin主机的master分支。 如果当前分支与远程分支之间存在追踪关系，则本地分支和远程分支都可以省略。 git push origin 上面命令表示，将当前分支推送到origin主机的对应分支。 如果当前分支只有一个追踪分支，那么主机名都可以省略。 git push 如果当前分支与多个主机存在追踪关系，则可以使用-u选项指定一个默认主机，这样后面就可以不加任何参数使用git push。 git push -u origin master 上面命令将本地的master分支推送到origin主机，同时指定origin为默认主机，后面就可以不加任何参数使用git push了。 不带任何参数的git push，默认只推送当前分支，这叫做simple方式。此外，还有一种matching方式，会推送所有有对应的远程分支的本地分支。Git 2.0版本之前，默认采用matching方法，现在改为默认采用simple方式。如果要修改这个设置，可以采用git config命令。 git config --global push.default matching # 或者 git config --global push.default simple 还有一种情况，就是不管是否存在对应的远程分支，将本地的所有分支都推送到远程主机，这时需要使用--all选项。 git push --all origin 上面命令表示，将所有本地分支都推送到origin主机。 如果远程主机的版本比本地版本更新，推送时Git会报错，要求先在本地做git pull合并差异，然后再推送到远程主机。这时，如果你一定要推送，可以使用--force选项。 git push --force origin 上面命令使用--force选项，结果导致远程主机上更新的版本被覆盖。除非你很确定要这样做，否则应该尽量避免使用--force选项。 最后，git push不会推送标签（tag），除非使用--tags选项。 git push origin --tags 速查手册初始化仓库git init 将文件添加到仓库git add 文件名 # 将工作区的某个文件添加到暂存区 git add -u # 添加所有被tracked文件中被修改或删除的文件信息到暂存区，不处理untracked的文件 git add -A # 添加所有被tracked文件中被修改或删除的文件信息到暂存区，包括untracked的文件 git add . # 将当前工作区的所有文件都加入暂存区 git add -i # 进入交互界面模式，按需添加文件到缓存区 将暂存区文件提交到本地仓库git commit -m \"提交说明\" # 将暂存区内容提交到本地仓库 git commit -a -m \"提交说明\" # 跳过缓存区操作，直接把工作区内容提交到本地仓库 查看仓库当前状态git status 比较文件异同git diff # 工作区与暂存区的差异 git diff 分支名 #工作区与某分支的差异，远程分支这样写：remotes/origin/分支名 git diff HEAD # 工作区与HEAD指针指向的内容差异 git diff 提交id 文件路径 # 工作区某文件当前版本与历史版本的差异 git diff --stage # 工作区文件与上次提交的差异(1.6 版本前用 --cached) git diff 版本TAG # 查看从某个版本后都改动内容 git diff 分支A 分支B # 比较从分支A和分支B的差异(也支持比较两个TAG) git diff 分支A...分支B # 比较两分支在分开后各自的改动 # 另外：如果只想统计哪些文件被改动，多少行被改动，可以添加 --stat 参数 查看历史记录git log # 查看所有commit记录(SHA-A校验和，作者名称，邮箱，提交时间，提交说明) git log -p -次数 # 查看最近多少次的提交记录 git log --stat # 简略显示每次提交的内容更改 git log --name-only # 仅显示已修改的文件清单 git log --name-status # 显示新增，修改，删除的文件清单 git log --oneline # 让提交记录以精简的一行输出 git log –graph –all --online # 图形展示分支的合并历史 git log --author=作者 # 查询作者的提交记录(和grep同时使用要加一个--all--match参数) git log --grep=过滤信息 # 列出提交信息中包含过滤信息的提交记录 git log -S查询内容 # 和--grep类似，S和查询内容间没有空格 git log fileName # 查看某文件的修改记录，找背锅专用 代码回滚git reset HEAD^ # 恢复成上次提交的版本 git reset HEAD^^ # 恢复成上上次提交的版本，就是多个^，以此类推或用~次数 git reflog git reset --hard 版本号 # --soft：只是改变HEAD指针指向，缓存区和工作区不变； # --mixed：修改HEAD指针指向，暂存区内容丢失，工作区不变； # --hard：修改HEAD指针指向，暂存区内容丢失，工作区恢复以前状态； 同步远程仓库git push -u origin master 删除版本库文件git rm 文件名 版本库里的版本替换工作区的版本git checkout -- test.txt 本地仓库内容推送到远程仓库git remote add origin git@github.com:帐号名/仓库名.git 从远程仓库克隆项目到本地git clone git@github.com:git帐号名/仓库名.git 创建分支git checkout -b dev # -b表示创建并切换分支 # 上面一条命令相当于一面的二条： git branch dev # 创建分支 git checkout dev # 切换分支 查看分支git branch 合并分支git merge dev # 用于合并指定分支到当前分支 git merge --no-ff -m \"merge with no-ff\" dev # 加上--no-ff参数就可以用普通模式合并，合并后的历史有分支，能看出来曾经做过合并 删除分支git branch -d dev 查看分支合并图git log --graph --pretty=oneline --abbrev-commit 查看远程库信息git remote # -v 显示更详细的信息 git相关配置# 安装完Git后第一件要做的事，设置用户信息(global可换成local在单独项目生效)： git config --global user.name \"用户名\" # 设置用户名 git config --global user.email \"用户邮箱\" #设置邮箱 git config --global user.name # 查看用户名是否配置成功 git config --global user.email # 查看邮箱是否配置 # 其他查看配置相关 git config --global --list # 查看全局设置相关参数列表 git config --local --list # 查看本地设置相关参数列表 git config --system --list # 查看系统配置参数列表 git config --list # 查看所有Git的配置(全局+本地+系统) git config --global color.ui true //显示git相关颜色 撤消某次提交git revert HEAD # 撤销最近的一个提交 git revert 版本号 # 撤销某次commit 拉取远程分支到本地仓库git checkout -b 本地分支 远程分支 # 会在本地新建分支，并自动切换到该分支 git fetch origin 远程分支:本地分支 # 会在本地新建分支，但不会自动切换，还需checkout git branch --set-upstream 本地分支 远程分支 # 建立本地分支与远程分支的链接 标签命令git tag &lt;标签&gt; # 打标签命令，默认为HEAD git tag # 显示所有标签 git tag &lt;标签 ?版本号&gt; # 给某个commit版本添加标签 git show &lt;标签&gt; # 显示某个标签的详细信息同步远程仓库更新git fetch origin master # 从远程获取最新的到本地，首先从远程的origin的master主分支下载最新的版本到origin/master分支上，然后比较本地的master分支和origin/master分支的差别，最后进行合并。 git fetch比git pull更加安全 不常见但实用的命令拉取远程代码并且覆盖本地更改git fetch origin && git reset –hard origin/master 列出远程和本地所有分支git branch -a git branch -r 强制更新远程分支git push origin master -f 回滚一个 mergegit revert -m 1 xxxx 修改之前的提交记录或者很久前提交的记录git rebase –interactive ID^ 将需要修改的记录的 pick 改成 edit，执行更改： git commit –all –amend git rebase –continue 使用多个远程代码库，并且使用多个不同的 SSH KeyHost bitbucket.org HostName bitbucket.org PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa User git Host bitbucket.org-key2 HostName bitbucket.org IdentityFile ~/.ssh/key2_id_rsa User git 修改 .git/config： [remote “origin”] url = git@bitbucket.org-key2:XXXX/yyyy.git fetch = +refs/heads/*:refs/remotes/origin/* 和外部团队协作需要的维护多个远程库，合并其他库的更新的过程git remote rename origin upstream git remote add origin URL_TO_GITHUB_REPO git push origin master git pull upstream master && git push origin master 撤销 Git 的最后一次提交git reset –soft HEAD~1 参考 阮一峰的网络日志 芋道源码 微信公众号","tags":[{"name":"Git","slug":"Git","permalink":"https://www.cayzlh.com/tags/Git/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"},{"name":"Git","slug":"运维/Git","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/Git/"}]},{"title":"搭建Git服务器","date":"2018-11-10T12:35:39.000Z","path":"2018/11/10/ddd0bb47.html","text":"虽然以前也搭过，但是重新搭建一次的时候还要重新从网络上查找资料； 最近想着别把租来的服务器荒了，自己搭个Git服务器放点东西上去，顺路记录一波搭建过程。 第一步在服务器上安装 git： centos： sudo yum install git ubuntu： sudo apt-get install git 第二步创建 git 用户，用来运行git服务 sudo adduser git 可以同时为git用户修改密码 sudo passwd git 第三步免密登录 通过证书的方式来通过ssh使用git功能，需要创建证书，并收集需要登录的用户的公钥文件（~/.ssh/id_rsa.pub），导入到/home/git/.ssh/authorized_keys文件内，一行一个； 公钥可以通过执行ssh-keygen -t rsa -C &quot;yourname@mail.com&quot;进行生成 修改authorized_keys文件的权限 chmod 600 authorized_keys 这一步必须要做，不然验证的时候还是会需要让你输入密码，具体原因不知； 第四步初始化git仓库，找个地放用来放你的git仓库，这里我选了/data/repositorys这个路径； git init --bare TestGit.git git创建一个裸仓库，裸仓库没有工作区，因为服务器上的git仓库纯粹为了共享，所有不能让用户直接登录到服务器上去改工作区，并且服务器的git仓库通常以 .git 结尾。然后，修改owner改为git： sudo chown -R git:git TestGit.git 第五步禁用shell登录：处于安全的考虑，第二步创建的git用户不允许登录shell，这可以通过编辑 /etc/passwd文件完成。 git:x:1003:1003::/home/git:/bin/bash 改为： git:x:1003:1003::/home/git:/usr/bin/git-shell 这样，git用户可以正常通过ssh使用git，但无法登录shell，因为我们为git用户指定的git-shell每次一登录就自动退出。 第六步验证，克隆远程仓库：现在，可以通过git clone命令克隆远程仓库了，在各自的电脑上运行： git clone git@server:/data/repositorys/TestGit.git 如果服务器SSH端口不是默认的22的话，可以这样： git clone ssh://git@server:port/data/repositorys/TestGit.git 运行完成后，正常的情况下会出现以下提示： Cloning into 'TestGit'... warning: You appear to have cloned an empty repository. 参考 Google","tags":[{"name":"Git","slug":"Git","permalink":"https://www.cayzlh.com/tags/Git/"},{"name":"Linux","slug":"Linux","permalink":"https://www.cayzlh.com/tags/Linux/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"},{"name":"Git","slug":"运维/Git","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/Git/"}]},{"title":"Docker使用redis镜像","date":"2018-11-05T06:27:02.000Z","path":"2018/11/05/e23d00ab.html","text":"Redis是一个开源的，联网的，内存中的键值数据存储，具有可选的持久性。 安装redisdocker pull redis 启动Docker实例docker run --name some-redis -d redis 或者从持久存储开始： docker run --name some-redis -d redis redis-server --appendonly yes 绑定本地端口： docker run --name dev-redis -p 6379:6379 -d redis redis-server --appendonly yes 或者通过redis-cli docker run -it --link some-redis:redis --rm redis redis-cli -h redis -p 6379 另外，如果想使用自己的redis.conf …… 您可以创建自己的Dockerfile，将上下文中的redis.conf添加到/ data /中，就像这样： FROM redis COPY redis.conf /usr/local/etc/redis/redis.conf CMD [ \"redis-server\", \"/usr/local/etc/redis/redis.conf\" ] 或者，您可以使用docker run选项在相同的行中指定某些内容： docker run -v /myredis/conf/redis.conf:/usr/local/etc/redis/redis.conf \\ --name myredis redis redis-server /usr/local/etc/redis/redis.conf","tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cayzlh.com/tags/Docker/"}],"categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Docker","slug":"微服务/Docker","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/Docker/"}]},{"title":"Docker免sudo操作","date":"2018-11-05T06:17:30.000Z","path":"2018/11/05/6082d88c.html","text":"Docker命令默认在Linux默认使用root用户执行，官方原文： The docker daemon binds to a Unix socket instead of a TCP port. By default that Unix socket is owned by the user root and other users can access it with sudo. For this reason, docker daemon always runs as the root user.To avoid having to use sudo when you use the docker command, create a Unix group called docker and add users to it. When the docker daemon starts, it makes the ownership of the Unix socket read/writable by the docker group. docker守护程序绑定到Unix套接字而不是TCP端口。 默认情况下，Unix套接字由用户root拥有，其他用户可以使用sudo访问它。 因此，docker守护程序始终以root用户身份运行。要避免在使用docker命令时使用sudo，请创建一个名为docker的Unix组并向其添加用户。 当docker守护程序启动时，它会使docker组对Unix套接字的所有权进行读/写。 但是我们自己使用的时候通常会觉得比较麻烦，以下步骤将用户加入Docker用户组，不需要使用sudo命令来执行docker的命令。 创建docker组sudo groupadd docker 将当前用户加入docker组sudo gpasswd -a ${USER} docker 重新启动docker服务（下面是CentOS7的命令）sudo systemctl restart docker 当前用户退出系统重新登陆 重新登录后可以直接执行docker命令： docker ps","tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cayzlh.com/tags/Docker/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"}]},{"title":"Linux中方便的Bash别名","date":"2018-11-03T06:12:15.000Z","path":"2018/11/03/d3d5eec6.html","text":"Linux中通过alias创建别名, 可以将命令行上常用的长命令简化成一个易懂的短命令来使用; 要使用Bash别名, 需要将其添加到.bash_profile文件, 该文件位于 ~/目录中. 解压tar文件alias untar='tar -zxvf ' 下载出问题, 恢复下载alias wget='wget -c ' 下载文件并测试校验和alias sha='shasum -a 256 ' ping命令限制在5个pingalias ping='ping -c 5' 获取你的外部 IP 地址alias ipe='curl ipinfo.io/ip' 关于ls命令的别名：# 带颜色的ls别名 alias ls='ls --color=auto' alias ll='ls -la' # 显示隐藏文件或目录的命令别名 alias l.='ls -d .* --color=auto' 关于cd命令的别名 # 进入父目录 alias cd..='cd ..' # 快速返回到父目录 alias ..='cd ..' alias ...='cd ../../' alias ....='cd ../../../' alias .....='cd ../../../../' alias .4='cd ../../../../' alias .5='cd ../../../../../' 关于grep命令的别名# 加入颜色输出，在搜索log文件时很有用 alias grep='grep --color=auto' alias egrep='egrep --color=auto' alias fgrep='fgrep --color=auto' 回收站功能mkdir -p ~/.trash alias rm=trash alias r=trash alias rl='ls ~/.trash/' alias ur=undelfile undelfile() { mv -i ~/.trash/$@ ./ } trash() { mv -i $@ ~/.trash/ } cleartrash() { read -p \"clear sure?[n]\" confirm [ $confirm == 'y' ] || [ $confirm == 'Y' ] && /bin/rm -rf ~/.trash/* } 在这里，我们是在家目录下建立一个 .trash 的隐藏文件夹，作为回收站。然后，我们对 rm 命令进行重定义。当我们执行 rm 或者 r 的时候，将执行 trash 函数。而在 trash 函数里，只做一件事： mv -i $@ ~/.trash/ 就是将 rm 之后所有的文件移动到 .trash 目录下（即模拟丢进回收站）。-i 选项表示如果 .trash 目录有同名文件的话，将提示是否覆盖。 我们将 rl 定义为 ls ~/.trash/ ，也就是说，我们可以通过 rl 来查看 .trash 目录下的文件，即被「删除」的文件。 如果要还原文件，可以执行 ur ，而 ur 将执行 undelfile 函数。在 undelfile 里，又将 ur 之后的文件从 .trash 目录移回到原目录，从而实现文件删除还原。 当过了一段时间后，回收站里文件太多了，我们可以使用 cleartrash 命令清空回收站。它将执行同名函数，调用 /bin/rm 命令将 .trash 目录清空。 删除文件~/workspace/test » touch file1 file2 file3 ~/workspace/test » ls file1 file2 file3 ~/workspace/test » rm file1 file2 ~/workspace/test » r file3 查看回收站文件~/workspace/test » rl file1 file2 file3 还原被删除的文件~/workspace/test » ur file1 ~/workspace/test » ur file2 ~/workspace/test » ur file3 ~/workspace/test » ls file1 file2 file3 清空回收站~/workspace/test » rm file1 file2 file3 ~/workspace/test » cleartrash clear sure?[n]y ~/workspace/test » rl ~/workspace/test » 注意 : 将以上命令编辑到到 ~/.bash_profile后, 需要执行source ~/.bash_profile命令使其生效;","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.cayzlh.com/tags/Linux/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"}]},{"title":"MySql数据库优化细节","date":"2018-10-29T12:47:34.000Z","path":"2018/10/29/a7c2d6f3.html","text":"MySQL 数据库性能的优化是 MySQL 数据库发展的必经之路， MySQL 数据库性能的优化也是 MySQL 数据库前进的见证。记录一些MySQL优化的一些细节 选取最适用的字段属性（出处）MySQL 可以很好的支持大数据量的存取，但是一般说来，数据库中的表越小，在它上面执行的查询也就会越快。因此，在创建表的时候，为了获得更好的性能，我们可以将表中字段的宽度设得尽可能小。例如，在定义邮政编码这个字段时，如果将其设置为CHAR(255)，显然给数据库增加了不必要的空间，甚至使用VARCHAR这种类型也是多余的，因为CHAR(6)就可以很好的完成任务了。同样的，如果可以的话，我们应该使用MEDIUMINT而不是BIGIN来定义整型字段。 另外一个提高效率的方法是在可能的情况下，应该尽量把字段设置为NOT NULL，这样在将来执行查询的时候，数据库不用去比较NULL值。 对于某些文本字段，例如“省份”或者“性别”，我们可以将它们定义为ENUM类型。因为在 MySQL 中，ENUM类型被当作数值型数据来处理，而数值型数据被处理起来的速度要比文本类型快得多。这样，我们又可以提高数据库的性能。 使用连接（JOIN）来代替子查询(Sub-Queries)（出处）MySQL 从4.1开始支持 SQL 的子查询。这个技术可以使用SELECT语句来创建一个单列的查询结果，然后把这个结果作为过滤条件用在另一个查询中。例如，我们要将客户基本信息表中没有任何订单的客户删除掉，就可以利用子查询先从销售信息表中将所有发出订单的客户ID取出来，然后将结果传递给主查询，如下所示： DELETE FROM customerinfo WHERE CustomerID NOT in (SELECT CustomerID FROM salesinfo ); 使用子查询可以一次性的完成很多逻辑上需要多个步骤才能完成的 SQL 操作，同时也可以避免事务或者表锁死，并且写起来也很容易。但是，有些情况下，子查询可以被更有效率的连接（JOIN）.. 替代。例如，假设我们要将所有没有订单记录的用户取出来，可以用下面这个查询完成： SELECT * FROM customerinfoWHERE CustomerID NOT in (SELECT CustomerID FROM salesinfo ) 如果使用连接（JOIN）.. 来完成这个查询工作，速度将会快很多。尤其是当salesinfo表中对CustomerID建有索引的话，性能将会更好，查询如下： SELECT * FROM customerinfoLEFT JOIN salesinfo ON customerinfo.CustomerID=salesinfo.CustomerID WHERE salesinfo.CustomerID IS NULL 连接（JOIN）.. 之所以更有效率一些，是因为 MySQL 不需要在内存中创建临时表来完成这个逻辑上的需要两个步骤的查询工作。 使用联合(UNION)来代替手动创建的临时表（出处）MySQL 从 4.0 的版本开始支持 UNION查询，它可以把需要使用临时表的两条或更多的 SELECT查询合并的一个查询中。在客户端的查询会话结束的时候，临时表会被自动删除，从而保证数据库整齐、高效。使用 UNION来创建查询的时候，我们只需要用 UNION作为关键字把多个 SELECT语句连接起来就可以了，要注意的是所有 SELECT语句中的字段数目要想同。下面的例子就演示了一个使用 UNION的查询。 SELECT Name, Phone FROM client UNION SELECT Name, BirthDate FROM author UNION SELECT Name, Supplier FROM product 事务（出处）尽管我们可以使用子查询（Sub-Queries）、连接（JOIN）和联合（UNION）来创建各种各样的查询，但不是所有的数据库操作都可以只用一条或少数几条 SQL 语句就可以完成的。更多的时候是需要用到一系列的语句来完成某种工作。但是在这种情况下，当这个语句块中的某一条语句运行出错的时候，整个语句块的操作就会变得不确定起来。设想一下，要把某个数据同时插入两个相关联的表中，可能会出现这样的情况：第一个表中成功更新后，数据库突然出现意外状况，造成第二个表中的操作没有完成，这样，就会造成数据的不完整，甚至会破坏数据库中的数据。要避免这种情况，就应该使用事务，它的作用是：要么语句块中每条语句都操作成功，要么都失败。换句话说，就是可以保持数据库中数据的一致性和完整性。事物以BEGIN关键字开始，COMMIT关键字结束。在这之间的一条 SQL 操作失败，那么，ROLLBACK命令就可以把数据库恢复到BEGIN开始之前的状态。 BEGIN; INSERT INTO salesinfo SET CustomerID=14; UPDATE inventory SET Quantity=11 WHERE item='book'; COMMIT; 事务的另一个重要作用是当多个用户同时使用相同的数据源时，它可以利用锁定数据库的方法来为用户提供一种安全的访问方式，这样可以保证用户的操作不被其它的用户所干扰。 不用以下操作 显示或隐式的类型转换 比如 SELECT id FROM table WHERE id=&#39;1&#39;再如在WHERE子句中numeric 型和int型的列相比较就属于隐式转换 使用非同类型的列进行等值查询 在WHERE子句中的&quot;=&quot;左边表达式进行函数、算术运算或其他表达式运算 使用前缀为%的LIKE 使用负向查询，如NOT, !=, &lt;&gt;, !&gt;, 1&lt;, NOT EXISTS, NOT IN以及NOT LIKE 比如 NOT IN会把空和NULL给查出来 在数据库中跑大查询 单条SQL语句同时更新多个表 使用跨库查询 建议拆分成单表简单查询，通过程序进行关联 避免使用以下操作 避免大事务 事务要简单，整个事务的时间长度不要太长。拆分复杂SQL为多个小SQL，避免大事务 避免使用：触发器、函数、存储过程、视图 避免在数据库中进数学运算 MySQL不擅长数学运算和逻辑判断 避免取出大字段且无用的内容 SELECT只获取必要的字段，尽量少使用SELECT * 避免使用大表的JOIN 避免一次更新太多数据 比如，对数据的更新要打散后批量更新 尽量避免使用子查询，建议将子查询转换成关联查询 但由于子查询不使用索引，在关联查询也不使用索引的情况下，子查询是要优于关联查询的。因此至于是使用关联查询还是子查询则需要使用EXPLAIN对SQL进行分析才是万全之策 替换使用 用IN代替OR OR的效率没有IN的效率高 IN条件里面的数据的个数建议控制在500个以内 要学会使用EXISTS代替IN，EXISTS在一些场景查询会比IN快 用UNION ALL代替UNION 使用EXISTS来判断记录是否存在，而不使用SELECT COUNT(1)来判断记录是否存在","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cayzlh.com/tags/MySQL/"}],"categories":[{"name":"笔记本","slug":"笔记本","permalink":"https://www.cayzlh.com/categories/%E7%AC%94%E8%AE%B0%E6%9C%AC/"}]},{"title":"Stream表达式语法","date":"2018-10-09T15:02:36.000Z","path":"2018/10/09/9f722777.html","text":"本文转自：ifeve.com Stream初体验 A sequence of elements supporting sequential and parallel aggregate operations. 以上是Java里面是对Stream的定义，解读一下这句话： Stream是元素的集合，这点让Stream看起来用些类似Iterator； 可以支持顺序和并行的对原Stream进行汇聚的操作； 可以把Stream当成一个高级版本的Iterator。 原始版本的Iterator，用户只能一个一个的遍历元素并对其执行某些操作； 高级版本的Stream，用户只要给出需要对其包含的元素执行什么操作，比如“过滤掉长度大于10的字符串”、“获取每个字符串的首字母”等，具体这些操作如何应用到每个元素上，就给Stream就好了！ 下面一段代码直观的认识一下Stream： //Lists是Guava中的一个工具类 List&lt;Integer> nums = Lists.newArrayList(1,null,3,4,null,6); nums.stream().filter(num -> num != null).count(); 上面这段代码是获取一个List中，元素不为null的个数。我们现在开始深入解刨这个例子，完成以后你可能可以基本掌握Stream的用法！ 剖析Stream通用语法 图片就是对于Stream例子的一个解析，可以很清楚的看见：原本一条语句被三种颜色的框分割成了三个部分。 红色框中的语句是一个Stream的生命开始的地方，负责创建一个Stream实例； 绿色框中的语句是赋予Stream灵魂的地方，把一个Stream转换成另外一个Stream，红框的语句生成的是一个包含所有nums变量的Stream，进过绿框的filter方法以后，重新生成了一个过滤掉原nums列表所有null以后的Stream； 蓝色框中的语句是丰收的地方，把Stream的里面包含的内容按照某种算法来汇聚成一个值，例子中是获取Stream中包含的元素个数。 在此我们总结一下使用Stream的基本步骤： 创建Stream； 转换Stream，每次转换原有Stream对象不改变，返回一个新的Stream对象（可以有多次转换）； 对Stream进行聚合（Reduce）操作，获取想要的结果； 创建Stream最常用的创建Stream有两种途径： 通过Stream接口的静态工厂方法（注意：Java8里接口可以带静态方法）； 通过Collection接口的默认方法（默认方法：Default method，也是Java8中的一个新特性，就是接口中的一个带有实现的方法）–stream()，把一个Collection对象转换成Stream 使用Stream静态方法来创建Stream of方法：有两个overload方法，一个接受变长参数，一个接口单一值 Stream&lt;Integer> integerStream = Stream.of(1, 2, 3, 5); Stream&lt;String> stringStream = Stream.of(\"taobao\"); generator方法：生成一个无限长度的Stream，其元素的生成是通过给定的Supplier（这个接口可以看成一个对象的工厂，每次调用返回一个给定类型的对象） Stream.generate(new Supplier&lt;Double>() { @Override public Double get() { return Math.random(); } }); Stream.generate(() -> Math.random()); Stream.generate(Math::random); 三条语句的作用都是一样的，只是使用了lambda表达式和方法引用的语法来简化代码。每条语句其实都是生成一个无限长度的Stream，其中值是随机的。这个无限长度Stream是懒加载，一般这种无限长度的Stream都会配合Stream的limit()方法来用。 iterate方法：也是生成无限长度的Stream，和generator不同的是，其元素的生成是重复对给定的种子值(seed)调用用户指定函数来生成的。其中包含的元素可以认为是：seed，f(seed),f(f(seed))无限循环 Stream.iterate(1, item -> item + 1).limit(10).forEach(System.out::println); 这段代码就是先获取一个无限长度的正整数集合的Stream，然后取出前10个打印。千万记住使用limit方法，不然会无限打印下去。 通过Collection子类获取Stream查看Java doc就可以发现Collection接口有一个stream方法，所以其所有子类都都可以获取对应的Stream对象。 public interface Collection&lt;E> extends Iterable&lt;E> { //其他方法省略 default Stream&lt;E> stream() { return StreamSupport.stream(spliterator(), false); } } 转换Stream转换Stream其实就是把一个Stream通过某些行为转换成一个新的Stream。Stream接口中定义了几个常用的转换方法，下面挑选几个常用的转换方法来解释。 distinct: 对于Stream中包含的元素进行去重操作（去重逻辑依赖元素的equals方法），新生成的Stream中没有重复的元素； distinct方法示意图： filter: 对于Stream中包含的元素使用给定的过滤函数进行过滤操作，新生成的Stream只包含符合条件的元素； filter方法示意图： map: 对于Stream中包含的元素使用给定的转换函数进行转换操作，新生成的Stream只包含转换生成的元素 这个方法有三个对于原始类型的变种方法，分别是：mapToInt，mapToLong和mapToDouble。这三个方法也比较好理解，比如mapToInt就是把原始Stream转换成一个新的Stream，这个新生成的Stream中的元素都是int类型。之所以会有这样三个变种方法，可以免除自动装箱/拆箱的额外消耗； map方法示意图： flatMap：和map类似，不同的是其每个元素转换得到的是Stream对象，会把子Stream中的元素压缩到父集合中； flatMap方法示意图： peek: 生成一个包含原Stream的所有元素的新Stream，同时会提供一个消费函数（Consumer实例），新Stream每个元素被消费的时候都会执行给定的消费函数； peek方法示意图： limit: 对一个Stream进行截断操作，获取其前N个元素，如果原Stream中包含的元素个数小于N，那就获取其所有的元素； limit方法示意图： skip: 返回一个丢弃原Stream的前N个元素后剩下元素组成的新Stream，如果原Stream中包含的元素个数小于N，那么返回空Stream； skip方法示意图： 综合使用： List&lt;Integer> nums = Lists.newArrayList(1,1,null,2,3,4,null,5,6,7,8,9,10); System.out.println(“sum is:”+nums.stream().filter(num -> num != null). distinct().mapToInt(num -> num * 2). peek(System.out::println).skip(2).limit(4).sum()); 这段代码演示了上面介绍的所有转换方法（除了flatMap）。 简单解释一下这段代码的含义：给定一个Integer类型的List，获取其对应的Stream对象，然后进行过滤掉null，再去重，再每个元素乘以2，再每个元素被消费的时候打印自身，在跳过前两个元素，最后去前四个元素进行加和运算(解释一大堆，很像废话，因为基本看了方法名就知道要做什么了。这个就是声明式编程的一大好处！)。 性能问题 可能会有这样的疑问：在对于一个Stream进行多次转换操作，每次都对Stream的每个元素进行转换，而且是执行多次，这样时间复杂度就是一个for循环里把所有操作都做掉的N（转换的次数）倍啊。其实不是这样的，转换操作都是lazy的，多个转换操作只会在汇聚操作的时候融合起来，一次循环完成。可以这样简单的理解，Stream里有个操作函数的集合，每次转换操作就是把转换函数放入这个集合中，在汇聚操作的时候循环Stream对应的集合，然后对每个元素执行所有的函数。 汇聚（Reduce）StreamJava doc中对于其定义： A reduction operation (also called a fold) takes a sequence of input elements and combines them into a single summary result by repeated application of a combining operation, such as finding the sum or maximum of a set of numbers, or accumulating elements into a list. The streams classes have multiple forms of general reduction operations, called reduce() and collect(), as well as multiple specialized reduction forms such as sum(), max(), or count(). 汇聚操作（也称为折叠）接受一个元素序列为输入，反复使用某个合并操作，把序列中的元素合并成一个汇总的结果。比如查找一个数字列表的总和或者最大值，或者把这些数字累积成一个List对象。Stream接口有一些通用的汇聚操作，比如reduce()和collect()；也有一些特定用途的汇聚操作，比如sum(),max()和count()。注意：sum方法不是所有的Stream对象都有的，只有IntStream、LongStream和DoubleStream是实例才有。 分两部分来介绍汇聚操作： 可变汇聚：把输入的元素们累积到一个可变的容器中，比如Collection或者StringBuilder； 其他汇聚：除去可变汇聚剩下的，一般都不是通过反复修改某个可变对象，而是通过把前一次的汇聚结果当成下一次的入参，反复如此。比如reduce，count，allMatch； 可变汇聚可变汇聚对应的只有一个方法：collect，正如其名字显示的，它可以把Stream中的要有元素收集到一个结果容器中（比如Collection）。先看一下最通用的collect方法的定义（还有其他override方法）： &lt;R> R collect(Supplier&lt;R> supplier, BiConsumer&lt;R, ? super T> accumulator, BiConsumer&lt;R, R> combiner); 先来看看这三个参数的含义： Supplier supplier是一个工厂函数，用来生成一个新的容器； BiConsumer accumulator也是一个函数，用来把Stream中的元素添加到结果容器中； BiConsumer combiner还是一个函数，用来把中间状态的多个结果容器合并成为一个（并发的时候会用到）； 来段代码： List&lt;Integer> nums = Lists.newArrayList(1,1,null,2,3,4,null,5,6,7,8,9,10); List&lt;Integer> numsWithoutNull = nums.stream().filter(num -> num != null). collect(() -> new ArrayList&lt;Integer>(), (list, item) -> list.add(item), (list1, list2) -> list1.addAll(list2)); 上面这段代码就是对一个元素是Integer类型的List，先过滤掉全部的null，然后把剩下的元素收集到一个新的List中。进一步看一下collect方法的三个参数，都是lambda形式的函数。 第一个函数生成一个新的ArrayList实例； 第二个函数接受两个参数，第一个是前面生成的ArrayList对象，二个是stream中包含的元素，函数体就是把stream中的元素加入ArrayList对象中。第二个函数被反复调用直到原stream的元素被消费完毕； 第三个函数也是接受两个参数，这两个都是ArrayList类型的，函数体就是把第二个ArrayList全部加入到第一个中； 但是上面的collect方法调用也有点太复杂了，来看一下collect方法另外一个override的版本： &lt;R, A> R collect(Collector&lt;? super T, A, R> collector); Java8还给我们提供了Collector的工具类，其中已经定义了一些静态工厂方法，比如：Collectors.toCollection()收集到Collection中, Collectors.toList()收集到List中和Collectors.toSet()收集到Set中。 使用Collectors对于代码的简化： List&lt;Integer> numsWithoutNull = nums.stream().filter(num -> num != null). collect(Collectors.toList()); 其他汇聚 reduce方法：reduce方法非常的通用，后面介绍的count，sum等都可以使用其实现。 reduce方法的第一种形式，其方法定义如下： Optional&lt;T> reduce(BinaryOperator&lt;T> accumulator); 接受一个BinaryOperator类型的参数，在使用的时候可以用lambda表达式来。 List&lt;Integer> ints = Lists.newArrayList(1,2,3,4,5,6,7,8,9,10); System.out.println(\"ints sum is:\" + ints.stream().reduce((sum, item) -&amp;gt; sum + item).get()); 可以看到reduce方法接受一个函数，这个函数有两个参数，第一个参数是上次函数执行的返回值（也称为中间结果），第二个参数是stream中的元素，这个函数把这两个值相加，得到的和会被赋值给下次执行这个函数的第一个参数。要注意的是：第一次执行的时候第一个参数的值是Stream的第一个元素，第二个参数是Stream的第二个元素。这个方法返回值类型是Optional，这是Java8防止出现NPE的一种可行方法，后面的文章会详细介绍，这里就简单的认为是一个容器，其中可能会包含0个或者1个对象。 reduce方法还有一个很常用的变种： T reduce(T identity, BinaryOperator&lt;T> accumulator); 这个定义上上面已经介绍过的基本一致，不同的是：它允许用户提供一个循环计算的初始值，如果Stream为空，就直接返回该值。而且这个方法不会返回Optional，因为其不会出现null值。 List&lt;Integer> ints = Lists.newArrayList(1,2,3,4,5,6,7,8,9,10); System.out.println(\"ints sum is:\" + ints.stream().reduce(0, (sum, item) -> sum + item)); count方法：获取Stream中元素的个数 List&lt;Integer> ints = Lists.newArrayList(1,2,3,4,5,6,7,8,9,10); System.out.println(\"ints sum is:\" + ints.stream().count()); 其他方法： allMatch：是不是Stream中的所有元素都满足给定的匹配条件 anyMatch：Stream中是否存在任何一个元素满足匹配条件 findFirst： 返回Stream中的第一个元素，如果Stream为空，返回空Optional noneMatch：是不是Stream中的所有元素都不满足给定的匹配条件 max和min：使用给定的比较器（Operator），返回Stream中的最大|最小值 参考 ifeve.com 《Java SE 8 for the Really Impatient》 Java 8 Tutorial Java 8 API doc","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"}]},{"title":"lambda表达式语法","date":"2018-10-09T14:17:19.000Z","path":"2018/10/09/26787cb3.html","text":"本文转自：ifeve.com Lambda初体验 a function (or a subroutine) defined, and possibly called, without being bound to an identifier。 以上是维基百科上对于“Lambda expression”的解释，简单来说就是：一个不用被绑定到一个标识符上，并且可能被调用的函数。 这个解释还不够通俗，lambda表达式可以这样定义（不精确）：一段带有输入参数的可执行语句块。 先提供一个没用stream的lambda表达式的例子： //这里省略list的构造 List&lt;String> names = ...; Collections.sort(names, (o1, o2) -> o1.compareTo(o2)); - //这里省略list的构造 List&lt;String> names = ...; Collections.sort(names, new Comparator&lt;String>() { @Override public int compare(String o1, String o2) { return o1.compareTo(o2); } }); 上面两段代码分别是：使用lambda表达式来排序和使用匿名内部类来排序。 这个例子可以很明显的看出lambda表达式简化代码的效果。接下来展示lambda表达式和其好基友Stream的配合： List&lt;String> names = new ArrayList&lt;>(); names.add(\"TaoBao\"); names.add(\"ZhiFuBao\"); List&lt;String> lowercaseNames = names.stream().map((String name) -> {return name.toLowerCase();}).collect(Collectors.toList()); 这段代码就是对一个字符串的列表，把其中包含的每个字符串都转换成全小写的字符串。注意代码第四行的map方法调用，这里map方法就是接受了一个lambda表达式（其实是一个java.util.function.Function的实例）。 看看在Java8之前，如果我们想做上面代码的操作应该怎么办。 普通青年的代码： List&lt;String> names = new ArrayList&lt;>(); names.add(\"TaoBao\"); names.add(\"ZhiFuBao\"); List&lt;String> lowercaseNames = new ArrayList&lt;>(); for (String name : names) { lowercaseNames.add(name.toLowerCase()); } 文艺青年的代码（借助Guava）: List&lt;String> names = new ArrayList&lt;>(); names.add(\"TaoBao\"); names.add(\"ZhiFuBao\"); List&lt;String> lowercaseNames = FluentIterable.from(names).transform(new Function&lt;String, String>() { @Override public String apply(String name) { return name.toLowerCase(); } }).toList(); 在此，不再讨论普通青年和文艺青年的代码风格孰优孰劣（有兴趣的可以去google搜索“命令式编程vs声明式编程”）。 文艺青年代码初看起来看起来干扰信息有点多，Function匿名类的构造语法稍稍有点冗长。所以Java8的lambda表达式给我们提供了创建SAM（Single Abstract Method）接口更加简单的语法糖。 Lambda语法详解抽象一下lambda表达式的一般语法： (Type1 param1, Type2 param2, ..., TypeN paramN) -> { statment1; statment2; //............. return statmentM; } 从lambda表达式的一般语法可以看出来，还是挺符合上面给出的非精确版本的定义–“一段带有输入参数的可执行语句块”。 上面的lambda表达式语法可以认为是最全的版本，写起来还是稍稍有些繁琐。别着急，下面陆续介绍一下lambda表达式的各种简化版： 参数类型省略–绝大多数情况，编译器都可以从上下文环境中推断出lambda表达式的参数类型。这样lambda表达式就变成了： (param1,param2, ..., paramN) -> { statment1; statment2; //............. return statmentM; } 当lambda表达式的参数个数只有一个，可以省略小括号。lambda表达式简写为： param1 -> { statment1; statment2; //............. return statmentM; } 所以最开始的例子再次简化为： List&lt;String> lowercaseNames = names.stream().map(name -> {return name.toLowerCase();}).collect(Collectors.toList()); 当lambda表达式只包含一条语句时，可以省略大括号、return和语句结尾的分号。lambda表达式简化为： param1 -> statment 所以最开始的例子再次简化为： List&lt;String> lowercaseNames = names.stream().map(name -> name.toLowerCase()).collect(Collectors.toList()); 使用Method Reference（方法引用）: List&lt;String> lowercaseNames = names.stream().map(String::toLowerCase).collect(Collectors.toList()); Lambda表达式眼中的外部世界 lambda表达式其实是快速创建SAM接口的语法糖，原先的SAM接口都可以访问接口外部变量，lambda表达式肯定也是可以（不但可以，在java8中还做了一个小小的升级）。 String[] array = {\"a\", \"b\", \"c\"}; for(Integer i : Lists.newArrayList(1,2,3)){ Stream.of(array).map(item -> Strings.padEnd(item, i, '@')).forEach(System.out::println); } 上面的这个例子中，map中的lambda表达式访问外部变量Integer i。并且可以访问外部变量是lambda表达式的一个重要特性，这样我们可以看出来lambda表达式的三个重要组成部分： 输入参数 可执行语句 存放外部变量的空间 不过lambda表达式访问外部变量有一个非常重要的限制：变量不可变（只是引用不可变，而不是真正的不可变）。 String[] array = {\"a\", \"b\", \"c\"}; for(int i = 1; i&lt;4; i++){ Stream.of(array).map(item -> Strings.padEnd(item, i, '@')).forEach(System.out::println); } 上面的代码，会报编译错误。因为变量i被lambda表达式引用，所以编译器会隐式的把其当成final来处理。 以前java的匿名内部类在访问外部变量的时候，外部变量必须用final修饰。在java8对这个限制做了优化（前面说的小小优化），可以不用显示使用final修饰，但是编译器隐式当成final来处理。 Lambda眼中的this在lambda中，this不是指向lambda表达式产生的那个SAM对象，而是声明它的外部对象。 方法引用（Method reference）和构造器引用（construct reference）方法引用方法引用可以在某些条件成立的情况下，更加简化lambda表达式的声明。 方法引用语法格式有以下三种： objectName::instanceMethod ClassName::staticMethod ClassName::instanceMethod 前两种方式类似，等同于把lambda表达式的参数直接当成instanceMethod|staticMethod的参数来调用。比如System.out::println等同于x-&gt;System.out.println(x)；Math::max等同于(x, y)-&gt;Math.max(x,y)。 最后一种方式，等同于把lambda表达式的第一个参数当成instanceMethod的目标对象，其他剩余参数当成该方法的参数。比如String::toLowerCase等同于x-&gt;x.toLowerCase()。 构造器引用构造器引用语法如下：ClassName::new，把lambda表达式的参数当成ClassName构造器的参数 。例如BigDecimal::new等同于x-&gt;new BigDecimal(x)。 参考 ifeve.com 《Java SE 8 for the Really Impatient》 Java 8 Tutorial Java 8 API doc","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"}]},{"title":"Redis高逼格指令","date":"2018-09-24T14:22:45.000Z","path":"2018/09/24/f6707a82.html","text":"keys过度使用keys这个命令，将会导致出现性能毛刺。这个命令的时间复杂度是O(N)，而且redis又是单线程执行，在执行keys时即使是时间复杂度只有O(1)例如SET或者GET这种简单命令也会堵塞，从而导致这个时间点性能抖动，甚至可能出现timeout。 强烈建议生产环境屏蔽keys命令 scan既然keys命令不推荐使用，那就就用scan命令。如果把keys命令比作类似select * from users where username like &#39;%afei%&#39;这种SQL，那么scan应该是select * from users where id&gt;? limit 10这种命令。 官方文档用法如下： SCAN cursor [MATCH pattern] [COUNT count] 初始执行scan命令例如scan 0。SCAN命令是一个基于游标的迭代器。这意味着命令每次被调用都需要使用上一次这个调用返回的游标作为该次调用的游标参数，以此来延续之前的迭代过程。当SCAN命令的游标参数被设置为0时，服务器将开始一次新的迭代，而当redis服务器向用户返回值为0的游标时，表示迭代已结束，这是唯一迭代结束的判定方式，而不能通过返回结果集是否为空判断迭代结束。 使用方式： 127.0.0.1:6380> scan 0 1) \"22\" 2) 1) \"23\" 2) \"20\" 3) \"14\" 4) \"2\" 5) \"19\" 6) \"9\" 7) \"3\" 8) \"21\" 9) \"12\" 10) \"25\" 11) \"7\" 返回结果分为两个部分：第一部分即1)就是下一次迭代游标，第二部分即2)就是本次迭代结果集。 slowlog上面提到不能使用keys命令，如果就有开发这么做了呢，我们如何得知？与其他任意存储系统例如mysql，mongodb可以查看慢日志一样，redis也可以，即通过命令slowlog。用法如下： SLOWLOG subcommand [argument] subcommand主要有： get，用法：slowlog get [argument]，获取argument参数指定数量的慢日志。 len，用法：slowlog len，总慢日志数量。 reset，用法：slowlog reset，清空慢日志。 执行结果如下： 127.0.0.1:6380> slowlog get 5 1) 1) (integer) 2 2) (integer) 1532656201 3) (integer) 2033 4) 1) \"flushddbb\" 2) 1) (integer) 1 ---- 慢日志编码，一般不用care 2) (integer) 1532646897 ---- 导致慢日志的命令执行的时间点，如果api有timeout，可以通过对比这个时间，判断可能是慢日志命令执行导致的 3) (integer) 26424 ---- 导致慢日志执行的redis命令，通过4)可知，执行config rewrite导致慢日志，总耗时26ms+ 4) 1) \"config\" 2) \"rewrite\" 命令耗时超过多少才会保存到slowlog中，可以通过命令config set slowlog-log-slower-than 2000配置并且不需要重启redis。注意：单位是微秒，2000微秒即2毫秒。 rename-command为了防止把问题带到生产环境，我们可以通过配置文件重命名一些危险命令，例如keys等一些高危命令。操作非常简单，只需要在conf配置文件增加如下所示配置即可： rename-command flushdb flushddbb rename-command flushall flushallall rename-command keys keysys bigkeys随着项目越做越大，缓存使用越来越不规范。我们如何检查生产环境上一些有问题的数据。bigkeys就派上用场了，用法如下： redis-cli -p 6380 --bigkeys 执行结果如下： ... ... -------- summary ------- Sampled 526 keys in the keyspace! Total key length in bytes is 1524 (avg len 2.90) Biggest string found 'test' has 10005 bytes Biggest list found 'commentlist' has 13 items 524 strings with 15181 bytes (99.62% of keys, avg size 28.97) 2 lists with 19 items (00.38% of keys, avg size 9.50) 0 sets with 0 members (00.00% of keys, avg size 0.00) 0 hashs with 0 fields (00.00% of keys, avg size 0.00) 0 zsets with 0 members (00.00% of keys, avg size 0.00) 最后5行可知，没有set,hash,zset几种数据结构的数据。string类型有524个，list类型有两个；通过Biggest ... ...可知，最大string结构的key是test，最大list结构的key是commentlist。 需要注意的是，这个bigkeys得到的最大，不一定是最大。说明原因前，首先说明bigkeys的原理，非常简单，通过scan命令遍历，各种不同数据结构的key，分别通过不同的命令得到最大的key： 如果是string结构，通过strlen判断； 如果是list结构，通过llen判断； 如果是hash结构，通过hlen判断； 如果是set结构，通过scard判断； 如果是sorted set结构，通过zcard判断。 正因为这样的判断方式，虽然string结构肯定可以正确的筛选出最占用缓存，也可以说最大的key。但是list不一定，例如，现在有两个list类型的key，分别是：numberlist--[0,1,2]，stringlist--[&quot;123456789123456789&quot;]，由于通过llen判断，所以numberlist要大于stringlist。而事实上stringlist更占用内存。其他三种数据结构hash，set，sorted set都会存在这个问题。使用bigkeys一定要注意这一点。 monitor假设生产环境没有屏蔽keys等一些高危命令，并且slowlog中还不断有新的keys导致慢日志。那如何揪出这些命令是由谁执行的呢？这就是monitor的用处，用法如下： redis-cli -p 6380 monitor 如果当前redis环境OPS比较高，那么建议结合linux管道命令优化，只输出keys命令的执行情况： [afei@redis ~]# redis-cli -p 6380 monitor | grep keys 1532645266.656525 [0 10.0.0.1:43544] \"keyss\" \"*\" 1532645287.257657 [0 10.0.0.1:43544] \"keyss\" \"44*\" 执行结果中很清楚的看到keys命名执行来源。通过输出的IP和端口信息，就能在目标服务器上找到执行这条命令的进程，揪出元凶，勒令整改。 info如果说哪个命令能最全面反映当前redis运行情况，那么非info莫属。用法如下： INFO [section] section可选值有： Server：运行的redis实例一些信息，包括：redis版本，操作系统信息，端口，GCC版本，配置文件路径等； Clients：redis客户端信息，包括：已连接客户端数量，阻塞客户端数量等； Memory：使用内存，峰值内存，内存碎片率，内存分配方式。这几个参数都非常重要； Persistence：AOF和RDB持久化信息； Stats：一些统计信息，最重要三个参数：OPS(instantaneous_ops_per_sec)，keyspace_hits和keyspace_misses两个参数反应缓存命中率； Replication：redis集群信息； CPU：CPU相关信息； Keyspace：redis中各个DB里key的信息； configconfig是一个非常有价值的命令，主要体现在对redis的运维。因为生产环境一般是不允许随意重启的，不能因为需要调优一些参数就修改conf配置文件并重启。redis作者早就想到了这一点，通过config命令能热修改一些配置，不需要重启redis实例，可以通过如下命令查看哪些参数可以热修改： config get * 热修改就比较容易了，执行如下命令即可： config set 例如：config set slowlog-max-len 100，config set maxclients 1024 这样修改的话，如果以后由于某些原因redis实例故障需要重启，那通过config热修改的参数就会被配置文件中的参数覆盖，所以我们需要通过一个命令将config热修改的参数刷到redis配置文件中持久化，通过执行如下命令即可： config rewrite 执行该命令后，我们能在config文件中看到类似这种信息： # 如果conf中本来就有这个参数，通过执行config set，那么redis直接原地修改配置文件 maxclients 1024 # 如果conf中没有这个参数，通过执行config set，那么redis会追加在Generated by CONFIG REWRITE字样后面 # Generated by CONFIG REWRITE save 600 60 slowlog-max-len 100 set官方文档介绍的用法如下： SET key value [EX seconds] [PX milliseconds] [NX|XX] 你可能用的比较多的就是set key value，或者SETEX key seconds value，所以很多同学用redis实现分布式锁分为两步：首先执行SETNX key value，然后执行EXPIRE key seconds。很明显，这种实现有很严重的问题，因为两步执行不具备原子性，如果执行第一个命令后出现某些未知异常导致无法执行EXPIRE key seconds，那么分布式锁就会一直无法得到释放。 通过SET命令实现分布式锁的正式姿势应该是SET key value EX seconds NX（EX和PX任选，取决于对过期时间精度要求）。另外，value也有要求，最好是一个类似UUID这种具备唯一性的字符串。当然如果问你redis是否还有其他实现分布式锁的方案。你能说出redlock，那对方一定眼前一亮，心里对你竖起大拇指，但嘴上不会说。 参考 阿飞的博客，公众号","tags":[{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"Redis","slug":"Redis","permalink":"https://www.cayzlh.com/tags/Redis/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"},{"name":"Redis","slug":"运维/Redis","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/Redis/"}]},{"title":"线程安全与锁优化","date":"2018-09-21T08:28:32.000Z","path":"2018/09/21/7876bd5d.html","text":"并发处理的广泛应用是使得Amdahl定律代替摩尔定律成为计算机性能发展源动力的根本原因，也是人类压榨计算机运算能力最有力的武器。 概述在软件业发展的初期，程序编写都是以算法为核心的，程序员会把数据和过程分别作为独立的部分来考虑，数据代表问题空间中的客体，程序代码则用于处理这些数据，这种思维方式是直接站在计算机的角度去抽象问题和解决问题，称为面向过程的编程思想。与此相对，面向对象的编程思想则站在现实世界的角度去抽象和解决问题，它把数据和行为都看作是对象的一部分，这样可以让程序员能以符合现实世界的思维方式来编写和组织程序。 人们很难想象现实中的对象在一项工作进行器件，会被不停地中断和切换，对象地属性可能会在中断期间被修改和变脏，而这些事件在计算机世界中是很正常地事情。良好地设计原则不得不向现实做出一些让步，我们必须让程序在计算机中正确无误地运行，然后再考虑如何将代码组织得更好，让程序运行得更快。 线程安全 “当多个线程访问一个对象时，如果不用考虑这些线程在运行时环境下得调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协同操作，调用这个对象的行为都可以获得正确的结果，那这个对象就是线程安全的。” —— 《Java Concurrency In Practice》的作者Brian Goetz对“线程安全”的定义 这个定义很严谨，它要求了线程安全的代码必须都具备一个特征：代码本身封装了所有必要的正确性保障手段（如互斥同步等），令调用者无须关系多线程的问题，更无须自己实现任何措施来保证多线程的正确调用。这点并不容易做到。 Java语言中的线程安全我们讨论线程安全，就限定于多个线程之间存在共享数据访问这个前提，因为如果一段代码根本不会与其他线程共享数据，那么从线程安全的角度上看，程序时串行执行还是多线程执行对它来说是完全没有区别的。 按照线程安全的“安全程度”由强至弱来排序，可以将Java语言中各种操作共享的数据分为五类：不可变、绝对线程安全、相对线程安全、县城兼容和线程对立。 不可变在Java语言里面，不可变的对象一定是线程安全的，无论是对象的方法实现还是方法的调用者，都不需要再进行任何的线程安全保障措施，只要一个不可变的对象被正确的构建出来（没有发生this逃逸的情况），那其外部的可见状态永远不会改变，永远也不会看到它再多个线程之中处于不一致的狂态。“不可变”带来的安全性是最简单最纯粹的。 如果共享数据是一个一本数据类型，那么只要再定义时使用final关键字修饰它就可以保证它是不可变的。如果共享数据是一个对象，那就需要保证对象的行为不会对其状态产生任何影响才行。java.lang.String类的对象，是一个典型的不可变对象，我们调用它的substring()、replace()和concat()这些方法都不会影响它原来的值，只会返回一个新构造的字符串对象。 保证对象行为不影响自己状态的途径由很多种，其中最简单的就是把对象中带有状态的变量都声明为final，这样在构造函数结束之后， 它就是不可变的。 java.lang.Integer构造函数，它通过将内部状态变量value定义为final来保障状态不变： /** * The value of the {@code Integer}. * * @serial */ private final int value; /** * Constructs a newly allocated {@code Integer} object that * represents the specified {@code int} value. * * @param value the value to be represented by the * {@code Integer} object. */ public Integer(int value) { this.value = value; } 在Java API中符合不可变要求的类型，除了String之外，常用的还有枚举类型，以及java.lang.Number的部分子类。 绝对线程安全绝对线程安全完全满足Brian Goetz给出的线程安全的定义，这个定义其实是很严格的，一个类要达到“不管运行时环境如何，调用者都不需要任何额外的同步措施”通常需要付出很大的，甚至是不切实际的代价。在Java API中标注自己是线程安全的类，大多数都不是绝对的线程安全。 java.util.Vector是一个线程安全的容器，因为它的add()、get()和size()这类方法都是被synchronized修饰的，尽管这样效率很低，但确实是安全的。但是，即使它所有的方法都被修饰成同步，也不意味着调用它的时候永远都不再需要同步手段了。 代码清单，对Vector线程安全的测试： package com.cayzlh.jvmdemo; import java.util.Vector; /** * @author Ant丶 */ public class VectorSaveTest { private static Vector&lt;Integer> vector = new Vector&lt;>(); public static void main(String[] args) { while (true) { for (int i = 0; i &lt; 10; i++) { vector.add(i); } Thread removeThread = new Thread(new Runnable() { @Override public void run() { for (int i = 0; i &lt; vector.size(); i++) { vector.remove(i); } } }); Thread printThread = new Thread(new Runnable() { @Override public void run() { for (int i = 0; i &lt; vector.size(); i++) { System.out.println(vector.get(i)); } } }); removeThread.start(); printThread.start(); // 不要同时产生过多的线程，否则会导致操作系统假死 while (Thread.activeCount() > 20) { } } } } 运行结果： 尽管这里使用到的Vector的get()、remove()和size()方法都是同步的，但是在多线程的环境中，如果不在方法调用端做额外的不同措施，使用这段代码仍然是不安全的，因为如果另一个线程切好在错误的时间里删除了一个元素，导致序号i已经不再可用的话，get()方法就会抛出一个ArrayIndexOutOfBoundsException。 要保证这段代码能正确地执行下去，要对removeThread和printThread做一些修改： Thread removeThread = new Thread(new Runnable() { @Override public void run() { synchronized (vector) { for (int i = 0; i &lt; vector.size(); i++) { vector.remove(i); } } } }); Thread printThread = new Thread(new Runnable() { @Override public void run() { synchronized (vector) { for (int i = 0; i &lt; vector.size(); i++) { System.out.println(vector.get(i)); } } } }); 相对线程安全相对线程安全就是我们通常意义上所讲的线程安全， 它需要保证对这个对象单独的操作是线程安全的，我们在调用的时候不需要做额外的保障措施，但是对于一些特定顺序的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性。 在Java语言中，大部分的线程安全类都属于这种类型，例如Vector、HashTable、Collections的synchronizedCollection()方法包装的集合等。 线程兼容线程兼容是指对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中安全地使用，我们平常说一个类不是线程安全的，绝大多数指的都是这种情况。Java API中大部分的类都是线程兼容的，如Vector和Hashtable相对应的集合类ArrayList和HashMap等。 线程对立线程对立是指不管调用端是否采取了同步措施，都无法在多线程环境中并发使用的代码。由于Java语言天生就具备多线程特性，线程对立这种排斥多线程的代码很少出现，而且通常是有害的，应尽量避免。 一个线程对立的例子是Thread类的suspend()和resume()方法，如果有两个线程同时持有一个线程对象，一个尝试去中断线程，一个尝试去恢复线程，如果并发进行的话， 无论调用时是否进行了同步，目标线程都是存在死锁风险的，如果suspend()中断的线程就是即将要执行resume()的那个线程，那就肯定产生死锁了。 线程安全的实现方法如何实现线程安全与代码的编写有很大的关系，但虚拟机提供的同步和锁机制也起到了非常重要的作用。 互斥同步互斥同步是最常见的一种并发正确性保障手段，同步是指在多个线程并发访问共享数据时，保证共享数据在同一时刻只被一条线程使用。而互斥是实现同步的一种手段，临界区、互斥量和信号量都是主要的互斥实现方式。互斥是因，同步是果，互斥是方法，同步是目的。 在Java里面，最基本的互斥同步手段就是synchronized关键字，synchronized关键字经过编译之后，会在同步块的前后分别形成monitorenter和monitorexit这两个字节码指令，这两个字节码都需要一个reference类型的参数来指明要锁定和解锁的对象。如果Java程序中的synchronized明确指定了对象参数，那就是对这个参数的reference；如果没有明确指定，那就根据synchronized修饰的实例方法还是类方法，去取对应的对象实例或Class对象来作为锁对象。 在执行monitorenter指令时，首先要尝试获取对象的锁。如果这个对象没有被锁定，或者当前线程已经拥有了那个对象的锁，把锁的计数器加1，相应地，在执行monitorexit指令时会讲锁计数器减1，当计数器为0时，锁就释放了。如果获取对象锁失败了，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。 首先synchronized同步块对同一条线程来说是可重入的，不会出现自己把自己锁死的问题。其次，同步块在已进入的线程执行完之前，会阻塞后面其他线程的进入。Java的线程是映射到操作系统的原声线程上的，如果要阻塞或唤醒一条线程，都需要操作系统来帮忙完成，这就需要从用户态转换到核心态中，因此状态转换需要耗费很多的处理器时间。对于代码简单的同步块，状态转换消耗的时间可能比用户代码执行的时间还要常。所以synchronized是Java语言中的一个重量级的操作，在必要的情况下才使用这种操作。虚拟机本身也会进行一些优化，譬如在通知操作系统阻塞线程之前加入一段自旋等待过程，避免频繁地切入到核心态之中。 非阻塞同步互斥同步最要的问题是进行线程阻塞和唤醒所带来的性能问题，因此这种同步也被称为阻塞同步。另外，它属于一种悲观的并发策略，总是认为只要不去做正确的同步措施，那就肯定会出问题，无论共享数据是否真的会出现竞争，它都要进行加锁、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要被唤醒等操作。 随着硬件指令集的发展，有了另外一个选择：基于冲突检测的乐观并发策略，通俗地说就是先进行操作，如果没有其他线程争用共享数据，那操作就成功了；如果共享数据有争用，产生了冲突，那就再进行其他的补偿措施（不断地重试，直到成功为止），这种乐观的并发策略的许多首先都不需要把线程挂起，因此这种同步操作被称为非阻塞同步。 无同步方案要保证线程安全，并不是以顶要进行同步，两者没有因果关系。同步只是保障共享数据竞争用时的正确性的手段，如果一个方法本来就不涉及共享数据，那它自然就无需任何同步措施去保证正确性，因此会有一些代码天生就是线程安全的： 可重入代码这种代码也叫纯代码，可以在代码执行的任何时刻中断它，转而去执行另外一段代码，而在控制权返回后，原来的程序出现任何错误。相对线程安全来说， 可重入性是更基本的特性，它可以是线程安全，即所有的可重入的代码都是线程安全的，但是并非所有的线程安全的代码都是可重入的。 可重入代码有一些共同的特征：例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。判断代码是否具备可重入：如果一个方法，它返回的结果是可以预测的，只要输入了相同的数据，就能返回相同的结果，那它满足可重入性的要求，当然也就是线程安全的。 线程本地存储一段代码中所需要的数据必须与其他代码共享，那就看看能否否正这些共享数据在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。最常见的应用就是消费队列的架构模式（生产者-消费者模式），都会讲产品的消费过程尽量在一个线程中消费完，其中最重要的一个应用实例就是Web交互模型中的“一个请求对应一个服务器线程的处理方式，这种处理方式的广泛应用使得Web服务端的很多应用都可以使用线程本地存储来解决线程安全问题。” Java语言中，如果一个变量要被多线程访问，可以使用volatile关键字声明它为“易变的”；如果一个变量要被某个线程独享，可以通过java.lang.ThreadLocal类来实现线程本地存储的功能。每一个线程的Thread对象中都有一个ThreadLocalMap对象，这个对象存储了一组以ThreadLocal.threadLocalHashCode为键，以本地线程变量为值的K-V值对，ThreadLocal对象就是当前线程的ThreadLocalMap的访问入口，每个ThreadLocal对象都包含了一个独一无二的threadLocalHashCode值，使用这个值就可以在线程K-V值对中找回对应的本地线程变量。 锁优化虚拟机开发团队实现各种锁优化技术，如适应性自旋、锁消除、锁粗化、轻量级锁、偏向锁等，这些技术都是为了线程之间更高效地共享数据，以及解决竞争问题，从而提高程序的执行效率。 自旋锁与自适应自旋互斥同步对性能最大的影响是阻塞的实现，挂起线程和恢复线程的操作都需要转内核态中完成，这些操作给系统的并发性能带来了很大的压力。同时，共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和恢复线程并不值得。如果物理机器有一个以上的处理器，能让两个或以上的线程同时执行，就可以让后面请求锁的那个线程“稍等一会儿”，但不放弃处理器的执行时间，看啊可能持有锁是否很快就会释放锁。为了让线程等待，只须让线程执行一个忙循环（自旋），这项技术就是所谓自旋锁。 自旋等待不能代替阻塞，先不说对处理器数量的要求，自旋等待本身虽然避免了线程切换的开销，但它是要占用处理器时间的，所以如果锁被占用的时间很短，自旋等待的效果就会非常好，反之如果锁被占用的时间很长，那么自旋的线程只会拜拜消耗处理器资源，而不会做任何游泳的工作，反而会带来性能的浪费。因此自旋等待的时间必须要有一定的限度，如果自旋超过了限定的次数仍然没有成功获得锁，就应当使用传统的方式去挂起线程了。 自适应自旋锁，意味着自旋的时间不再是固定的，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。另外一方面，如果对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能省略掉自旋过程，一面浪费处理器资源。 有了自适应自旋，随着程序运行和性能监控信息的不断完善，虚拟机对程序锁的状况预测就会越来越准确，虚拟机就会变得越来越“聪明”。 锁消除锁消除是指虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。锁消除的主要判断依据来源于逃逸分析的数据支持，如果判断到一段代码中，在堆上的所有数据都不会逃逸出去被其他线程访问到，那就可以把它们做栈上数据对待，认为它们是线程私有的，同步加锁自然就无须进行。 锁粗化原则上，在编写代码的时候，推荐将同步块的作用范围限制得尽量小——只在共享数据的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁竞争，那等待锁的线程也能尽快拿到锁。 如果一系列连续操作都对同一个对象反复加锁和解锁，甚至加锁操作是出现在循环体中的，那即使没有线程的竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗。 如果虚拟机探测到有这样的一串零碎的操作都对同一个对象加锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部，在第一个操作之前直至最后一个操作之后，这样只需要加锁一次就可以了。 轻量级锁 轻量级是相对于操作系统互斥量来实现的传统锁而言的，因此传统的锁机制就被称为重量级锁。 轻量级锁并不是用来代替重量级锁的，它本意是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。 在代码进入同步块的时候，如果此同步对象没有被锁定，虚拟机首先将在当前线程的栈帧中建立一个名为锁记录的空间，用于存储锁对象目前的Mark Word的拷贝。然后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针。如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位将转变为“00”，即表示此对象出于轻量级锁的状态。 如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，可以直接进入同步块继续执行，否则说明这个锁对象已经被其他线程抢占了。如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁。 轻量级锁能替身程序同步性能的依据是“对于绝大部分的锁，在整个同步周期内都是不存在竞争的”，这是一个经验数据。如果没有竞争，轻量级锁使用CAS避免了使用互斥量的开销，但如果存在锁竞争，出了互斥量的开销外，还额外发生了CAS操作，因此在有竞争的情况下，轻量级锁回避传统的重量级锁更慢。 偏向锁偏向锁的目的是消除数据在无竞争情况下的同步原语，进一步提高程序的运行性能。如果说轻量级锁是在无竞争的情况下使用CAS操作去消除同步使用的互斥量，那偏向锁就是在无竞争的情况下把整个同步都消除，连CAS操作都不做了。 偏向锁的“偏”，意思是这个锁会偏向于第一个获得它的线程，如果在接下来的执行过程中，该锁没有被其他线程的获取，则持有偏向锁的线程将永远不需要再进行同步。 当有另外一个线程去尝试获取这个锁时，偏向模式就宣告结束。根据锁对象目前是否被锁定的状态，撤销偏向后恢复到未锁定或轻量级锁定的状态，后续的同步操作就如轻量级锁那样执行。 偏向锁可以提高带有不同但无竞争的程序性能。它同样是一个带有利益权衡性质的优化，也就是说它不一定总是对程序运行有利，如果程序中大多数锁都总是被多个不同的线程访问，那偏向模式就是多余的。 小结介绍了线程安全涉及的概念和分类、同步实现的方式及虚拟机的底层运作原理，并且介绍了虚拟机实现高效并发所作的一系列锁优化措施。 参考 周志明，深入理解Java虚拟机：JVM高级特性与最佳实践，机械工业出版社","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://www.cayzlh.com/tags/JVM/"},{"name":"《深入理解Java虚拟机》","slug":"《深入理解Java虚拟机》","permalink":"https://www.cayzlh.com/tags/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B/"}],"categories":[{"name":"书籍","slug":"书籍","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/"},{"name":"《深入理解Java虚拟机》","slug":"书籍/《深入理解Java虚拟机》","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B/"}]},{"title":"Java内存模型与线程","date":"2018-09-18T08:28:32.000Z","path":"2018/09/18/badf9669.html","text":"并发处理的广泛应用是使得Amdahl定律代替摩尔定律成为计算机性能发展源动力的根本原因，也是人类压榨计算机运算能力最有力的武器。 概述除了充分利用计算机处理器的能力外，一个服务端同时对多个客户端提供服务是一个具体的并发应用的场景。衡量一个服务器性能的高低好坏，每秒事务处理数（Transactions Per Second，TPS）是最重要的指标之一，它代表着一秒内服务端平均能响应的请求总数，二TPS值与程序的并发能力又有非常密切的关系。对于计算量相同的任务，程序线程并发协调得越有条不紊，效率自然就会越高；反之，线程之间频繁阻塞甚至死锁，将会大大降低程序的并发能力。 服务端是Java语言最擅长的领域之一，这个领取的应用占了Java应用中最大的一块份额，不过如何写好并发应用程序确实程序开发的难点之一，处理好并发方面的问题通常需要更多的经验。无论语言、中间件和框架如何先进，我们都不能期望它们能独立完成并发处理的所有事情，了解并发的内幕也是不可缺少的课程。 硬件的效率与一致性由于计算机的存储设备与处理器的运算速度之间有着几个数量级的差距，所以现代计算机系统都不得不加入一层读写尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲：将运算需要使用的数据赋值到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中，这样处理器就无须等待缓慢的内存读写了。 基于高速缓存的存储交互很好地解决了处理器与内存地速度矛盾，但是也引入了新的问题：缓存一致性（Cache Coherence）。每个处理器都有自己地高速缓存，而它们又共享同一主内存（Main Memory）。当多个处理器地运算任务都涉及同一块主内存区域时，将可能导致各自地缓存数据不一致地情况。为了解决一致性地问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作。Java虚拟机内存模型中定义地内存访问操作与硬件地缓存访问操作时具有可比性地。 为了使得处理器内部地运算单元能尽量被充分利用，处理器可能会对输入代码进行乱序执行（Out-Of-Order Execution）优化，处理器会在计算之后将乱序执行地结果重组，保证该结果与顺序执行地结果是一致的，但并不保证程序中各个语句计算的先后顺序与输入代码的顺序一致，因此如果存在一个计算任务依赖另一个计算任务的中间结果，那么其顺序性并不能靠代码的先后顺序来保证。与处理器的乱序执行优化类似，Java虚拟机的即时编译器中也有类似的指令重排序（Instruction Reorder）优化。 Java内存模型Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model，JMM）来屏蔽掉各种硬件和操作系统的内存访问差异，以实现Java程序在各种平台下都能达到一致的并发效果。 主内存与工作内存Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出来变量这样的底层细节。此处的变量与Java编程中所说的变量有区别，它包括了实例字段、静态字段和构成数组对象的元素，但是不包括局部变量与方法参数，因为后者是线程私有的，不会被共享，自然就不存在竞争问题。 为了获得较好的执行效能，Java内存模型并没有限制执行引擎使用处理器的特定寄存器或缓存来和主内存进行交互，也没有限制即时编译器调整代码执行顺序这类权利。 Java内存模型规定了所有变量都存储在主内存（Main Memory）中。每条线程还有自己的工作内存（Working Menory，类比高速缓存），线程的工作内存中保存了该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存中的变量。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的值传递均需要通过主内存来完成。 这里所讲的主内存、工作内存与Java内存区域中的Java堆、栈、方法区等并不是同一个层次的内存划分。从变量、主内存、工作内存的定义来看，主内存主要对应Java堆中对象的实例数据部分，而工作内存则对应于虚拟机栈中的部分区域。从更低的层次来说，主内存就是硬件的内存，而为了获得更好的运行速度，虚拟机及硬件系统可能会让工作内存优先存储与寄存器和高速缓存中。 内存间交互操作关于主内存与工作内存之间具体的交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存之类的实现细节，Java内存模型顶了八种操作来完成： lock（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。 unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。 read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。 load（载入）：作用于工作内存的变量，它把read操作从内主内存得到的变量值放入工作内存的变量副本中。 use（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。 assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传递到主内存中，以便随后的write操作使用。 write（写入）：作用于主内存的变量，它把store操作从工作内存中得到的变量值放入主内存的变量中。 如果要把一个变量从主内存复制到工作内存，那就要按顺序执行read和load操作，如果要把变量从工作内存同步回主内存，就要按顺序地执行store和write操作。 Java内存模型只要求上述两个操作必须按顺序执行，而没有保证必须连续执行。 Java内存模型还规定了在执行上述八种基本操作时必须满足： 不允许read和load、store和write操作之一单独出现，即不允许一个变量从主内存读取了但工作内存不接受，或者从工作内存发起回写了但主内存不接受地情况出现。 不允许一个线程丢弃它最忌你地assign操作，即变量在工作内存中改变了之后必须把该变化同步回主内存。 不允许一个线程无原因地把数据从线程地工作内存同步回主内存中。 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量，换句话说就是对一个变量实施use和store操作之前，必须先执行过了assign和load操作。 一个变量在同一个时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。 如果对一个变量执行lock操作，将会晴空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或assign操作初始化变量的值。 如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许unlock一个被其他线程锁定住的变量。 对一个变量执行unlock操作之前，必须先把此变量同步回住内存中（执行store和write操作）。 对于volatile型变量的特殊规则 关键字volatile可以说是Java虚拟机提供的最轻量级的同步机制，但是它并不容易被正确地、完整地理解，以至于很多时候都不去使用它，遇到需要处理多线程数据竞争的时候一律使用synchronize来进行同步。 当一个变量被定义成volatile之后，它将具备两种特性： 第一保证此变量对所有线程的可见性，这里的“可见性”是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。而普通变量不能做到这一点，变量值在线程间传递均需要通过主内存来完成。 volatile变量在各个线程的工作内存中不存在一执行问题（在各个线程的工作内存中volatile变量也可以存在不一致的情况，但是由于每次使用之前都要先刷新，执行引擎看不到不一致的情况，因此可以认为不存在一执行问题），但是Java里面的运算并非原子操作，导致volatile变量的运算在并发下一样不是安全的。 一条字节码指令在解释执行时，解释器将要运行许多行代码才能实现它的语义，如果是编译执行，一条字节码指令也可能转化成若干条本地机器码指令。 由于volatile变量只能保证可见性，在不符合以下两种规则的运算场景中，仍然要通过枷锁（使用synchronized或java.util.concurrent中的原子类）来保证原子性。 运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值。 变量不需要与其他的状态变量共同参与不变约束。 使用使用volatile来控制并发的代码： volatile boolean shutdownRequested; public void shutdown() { shutdownRequested = false; } public void doWork() { while (!shutdownRequested) { // do stuff } } 第二禁止指令重排序优化，普通的变量仅仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序与程序代码中的执行顺序一致。因为在一个线程的方法执行过程中无法感知到这点，这就是Java内存模型中描述的所谓的“线程内存表现为串行的语义”（Within-Thread As-If-Serial Semantics）。 指令重排序会干扰程序的并罚执行的例子： Map configOptions; char[] configText; // 此变量必须定义为volatile volatile boolean initialized = false; // 假设以下代码在线程A中执行 // 模拟读取配置信息，当读取完成后，将initialized设置为true来通知其他线程配置可用 configOptions = new HashMap(); configText = readConfigFile(fileName); processConfigOptions(configText, configOptions); initialized = true; // 假设以下代码在线程B中执行 // 等待initialized为true，代表线程A已经把配置信息初始化完成 while (!initialized) { sleep(); } // 使用线程A中初始化好的配置信息 doSomethingWithConfig(); 这段伪代码描述的场景十分常见，只是我们在处理配置文件时一般不会出现并发而已。如果initialized没有使用volatile修饰，就可能会由于指令重排序的优化，导致线程A中最后一句中的“initialized = true;”被提前执行，这样线程B中使用配置信息的代码就可能出现错误，而volatile可以避免这类情况的发生。 Java内存模型中对volatile变量定义的特殊规则。假定T表示一个线程，V和W分别表示两个volatile型变量，那么在进行read、load、use、asign、store和write操作时需要满足如下的规则： 只有当线程T对变量V执行的前一个动作时load的时候，线程T才能对变量V执行use动作；并且，只有线程T对变量V执行的后一个动作时use的时候，线程T才能对V执行load动作。程序T对变量V的use动作可以认为是与线程T对变量V的load和read动作相关联的，必须一起连续出现。（这条规则要求在工作内存中，每次使用V前都必须从主内存刷新最先的值，用于保证能看见其他线程对变量V所做的修改后的值）。 只有当线程T对变量V执行的前一个动作时assign的时候， 线程T才能对变量V执行store动作；并且，只有当线程T对变量执行的后一个动作时store的时候，线程T才能对变量V执行assign动作。线程T对变量V的assign动作可以认为是与线程T对变量V的store和writy动作相关联的，必须一起连续出现（这条规则要求在工作内存中，每次修改V后都必须立刻同步回主内存中，用于保证其他线程可以看到自己对变量V所做的的修改）。 假定动作A是线程T对变量V实施的use或assign动作，假定动作F是与动作A相关联的load和store动作，假定动作P是与动作F相应的对变量V的read或write动作；类似的，假定动作B是线程T对变量W实施的use或assign动作，假定动作G是与动作B相关的load或store动作，假定动作Q是与动作G相应的对变量W的read或write动作。如果A先于B，那么P先于Q（这条规则要求volatile修饰的变量不回呗指令重排序优化，保证代码的执行顺序与程序的顺序相同）。 对于long和double型变量的特殊规则Java内存模型要求lock、unlock、read、load、assign、use、store和write这八个操作都具有原子性，但是对于64位的数据类型（long和double），在模型中特别定义了一条宽松的规定：允许虚拟机将没有被volatile修饰的64位数据的读写操作划分为两次32位的操作来进行，即允许虚拟机实现选择可以不保证64位数据类型的load、store、read和write这四个操作的原子性，这点就是所谓的long和double的非原子性协定。在编写代码时一般不需要将用到的long和double变量专门声明为volatile。 原子性、可见性与有序性Java内存模型时围绕着在并发过程中如何处理原子性、可见性和有序性这三个特征来建立的。 原子性由Java内存模型来直接保证的原子性变量操作包括read、load、assign、use、store和write这六个，大致可以认为基本数据类型的访问和读写时具备原子性的。 如果需要一个更大范围的原子性保证，Java内存模型提供了lock和unlock操作来满足这种需求，尽管虚拟机未把lock和unlock操作直接开放给用户使用，但是却提供了更高层次的字节码指令monitorenter和monitorexit来隐式地使用这两个操作，这两个字节码反映到Java代码中就是痛不快——synchronized关键字，因此在synchronized块之间的操作也具备原子性。 可见性可见性是指当一个线程修改了共享变量的值，其他线程能够立即得知这个修改。Java内存模型时通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式来实现可见性的，无论是普通的变量还是volatile变量都是如此，普通变量与volatile变量的区别是volatile的特殊规则保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新。 除了volatile外，Java的synchronized和final关键字也能实现可见性。 有序性如果在本线程内观察，所有的操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。前半句是指“线程内表现为串行的语义”，后半句是指“指令重排序现象”和“工作内存与主内存同步延迟”现象。 Java语言提供了volatile和synchronized两个关键字来保证线程之间的操作的有序性，volatile关键字本身就包含了禁止指令重排序的语义，而synchronized则是由“一个变量在同一个时刻只允许一条线程对其进行lock操作”这条规则获得的，这个规则决定了持有同一个锁的两个同步块只能串行地进入。 先行发生原则先行发生时Java内存模型中定义的两项操作之间的偏序关系，如果说操作A先行发生与操作B，其实就是说在发生操作B之前，操作A产生的影响能呗操作B观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等。 Java内存模型下一些天然的先行发生关系： 程序次序规则：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生与书写在后面的操作。准确的说应该是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。 管程锁规则：一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是同一个锁，而后面是指时间上的先后顺序。 volatile变量规则：对一个volatile变量的写操作先行发生于后面对这个变量的毒操作，这里的后面同样是指时间上的先后顺序。 线程启动规则：Thread对象的start()方法先行发生于此线程的每一个动作。 线程终止规则：线程的所有操作都先行发生于此线程的终止检测。 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生。 对象终结规则：一个对象的初始化完成先行发生于它的finalize()方法的开始。 传递性：如果操作A先行发生于操作B，操作B先行发生于C，那就可以得出A操作先行发生于操作C的结论。 事件上先后顺序与先行发生原则之间基本没有太大的关系，所以我们衡量并发安全问题时不要收到事件顺序的干扰，一切必须以先行发生原则为准。 Java与线程并发不一定要依赖多线程，但是在Java里面谈论并发，大多数都与线程脱不开关系。 线程的实现主流的操作系统都提供了线程实现，Java语言则提供了在不同硬件和操作系统平台下对线程操作的统一处理，每个java.lang.Thread类的实例就代表了一个线程。不过Thread类与大部分的Java API有着显著的区别，它的所有关键方法都被声明为Native。在Java API中一个Native方法可能就以为着这个方法没有使用或无法使用平台无关的手段来实现。 实现线程主要有三种方式：使用内核实现，使用用户线程实现，使用用户线程加轻量级进程混合实现。 使用内核线程实现直接由操作系统内核支持的线程，这种线程由内核线程来完成切换，内核通过操纵调度器对线程进行调度，并负责将线程的任务映射到各个处理器上。程序一般不会直接去使用内核线程，而是使用内核线程的一种高级接口——轻量级进程，轻量级进程就是我们通常意义上所将的线程，由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程。 由于内核线程的支持，每个轻量级进程都成为一个独立的调度单元，即使有一个轻量级进程在系统调用中阻塞了，也不会影响整个进程继续工作，但是轻量级进程具有它的局限性：首先，由于是基于内核线程实现的，所以各种进程操作，如创建、析构及同步，都需要进行系统调用。而系统调用的代价相对较高，需要在用户态和内核态中来回切换。其次，每个轻量级进程都需要有一个内核线程的支持，因此轻量级进程要消耗一定的内核资源，因此一个系统支持轻量级进程的数量是有限的。 使用用户线程实现广义上来讲，一个线程只要不是内核线程，那就可以认为是用户线程，因此从这个定义上来讲轻量级进程也属于用户线程，但轻量级进程的实现始终是建立在内核之上的，许多操作都要进行系统嗲用，因此效率会收到限制。 狭义上来讲，用户的线程指的是完全建立在用户空间的线程库上，系统内核不能感知到线程存在的实现。用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要内核的帮助。如果程序实现得当，这种线程不需要切换到内核态，因此操作可以是非常快且低消耗的，也可以支持规模更大的线程数量，部分高性能数据库中的多线程就是由用户线程实现的。 使用用户线程的优势在于不需要系统内核支援，劣势在于没有系统内核的支援，所有的线程操作都需要用户程序自己处理。线程的创建、切换和调度都是需要考虑问题。 混合实现线程除了依赖内核线程实现和完全由用户程序自己实现之外，还有一种将内核线程与用户线程一起使用的实现方式。在这种混合实现下，既有用户线程，也存在轻量级进程。用户县城还是完全建立在用户空间中，因此用户线程的创建、切换、析构等操作依然廉价，并且可以支持大规模的用户线程并发。而操作系统提供支持的轻量级进程则作为用户线程和内核线程之间的桥梁，这样可以使用内核提供的线程调度功能及处理器映射，并且用户线程的系统调用要通过轻量级线程来完成，大大降低了进程被阻塞的风险。 Java线程的实现操作系统支持怎样的线程模型，在很大成都上就决定了Java虚拟机的线程是怎么样映射的，这点在不同的平台上没有办法达成一致，虚拟机规范中也并未限定Java线程需要使用哪种线程模型来实现。 Java线程调度线程调度是指系统为线程分配处理器使用权的过程，主要调度方式有两种，分别是协同式线程调度和抢占式线程调度。 协同式调度线程的执行时间由线程本身来控制，线程把自己的工作执行完了之后，要主动通知系统切换到另外一个线程上去。协同式多线程的最大好处是实现简单，而且由于线程要把自己的事情干完后才会进行线程切换，切换操作对线程自己是可知的，所以没有什么线程同步的问题。 抢占式调度每个线程由系统来分配执行时间，线程的切换不由线程本身来决定。在这种实现线程调度的方式下，线程的执行时间是系统可控的，也不会有一个线程导致整个进程阻塞的问题，Java使用的线程调度方式就是抢占式调度。 状态转换Java定义了5种进程状态，在任意一个时间点中，一个进程只能由且只有一种状态： 新建：创建后尚未启动的线程处于这种状态 运行：Runable包括了操作系统线程状态中的Running和Ready，也就是处于此状态的线程有可能正在执行，也有可能正在等待着CPU为它分配执行时间。 无限期等待：处于这种状态的进程不会被分配CPU执行时间，它们要等待被其他线程显式地唤醒。以下方法会让线程陷入无限期等待状态： 没有设置Timeout参数地Object.wait()方法。 没有设置Timeout参数地Thread.join()方法。 LockSupport.park()方法。 限期等待：处于这种状态的进程也不会分配CPU执行时间，不过无须等待被其他线程显式唤醒，在一定时间之后他们会由系统自动唤醒。以下方法会让线程进入限期等待状态： Thread.sleep()方法。 设置了Timeout参数的Object.wait()方法。 设置了Timeout参数的Thread.join()方法。 LockSupport.parkNanos()方法。 LockSupport.parkUntil()方法。 阻塞：进程被阻塞了，阻塞状态在等待着获取到一个排他锁，这个事件将在另外一个线程放弃这个锁的时候发生；等待状态则是在等待一段时间，或者唤醒动作的发生。在程序等待进入同步区域的时候， 线程将进入这种状态。 结束：已终止线程的线程状态，线程已经结束执行。 线程状态转换关系： 小结了解了虚拟机Java内存模型的结构及操作，讲解了原子性、可见性、有序性在Java内存模型中的体现，先行发生原则的规则及使用。还有线程在Java语言之中时如何实现的。 参考 周志明，深入理解Java虚拟机：JVM高级特性与最佳实践，机械工业出版社 图片来源","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://www.cayzlh.com/tags/JVM/"},{"name":"《深入理解Java虚拟机》","slug":"《深入理解Java虚拟机》","permalink":"https://www.cayzlh.com/tags/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B/"}],"categories":[{"name":"书籍","slug":"书籍","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/"},{"name":"《深入理解Java虚拟机》","slug":"书籍/《深入理解Java虚拟机》","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B/"}]},{"title":"虚拟机字节码执行引擎","date":"2018-09-16T06:37:26.000Z","path":"2018/09/16/4cd43d51.html","text":"代码编译的结果从本地机器码变为字节码，是存储格式发展的一小步，确实编程语言发展的一大步 概述执行引擎是Java虚拟机最核心的组成部分之一。“虚拟机”是一个相对于“物理机”的概念，这两种机器都有代码执行能力，其区别是物理机的执行引擎是直接建立在处理器、硬件、指令集和操作系统层面上的，而虚拟机的执行引擎则是由自己实现的，因此可以自行制定指令集与执行引擎的结构体系，并且能够执行哪些不被硬件直接支持的指令集够格式。 Java虚拟机规范中制定了虚拟机字节码执行引擎的概念模型，这个概念模型成为各种虚拟机执行引擎的统一外观（Facade）。在不同的虚拟机实现里面，执行引擎在执行Java代码的时候可能有解释执行（通过解释器执行）和编译执行（通过即时编译器产生本地代码执行）两种选择，也可能两者兼备，甚至还可能包含几个不同级别的编译器执行引擎。但从外观上看起来，所有Java虚拟机的执行引擎都是一致的：输入的是字节码文件，处理过程是字节码解析的等效过程，输出的是执行结果。 运行时栈帧结构栈帧（Stack Frame）是用于支持虚拟机进行方法调用和方法执行的数据结构，它是虚拟机运行时数据区中的虚拟机栈的栈元素。栈帧存储的方法的的局部变量表、操作数栈、动态连接和方法返回地址等信息。 每一个方法从调用开始到执行完成的过程，就对应着一个栈帧在虚拟机栈里面从入栈道出栈的过程。 每一个栈帧都包括了局部变量表、操作数栈、动态连接、方法返回地址和一些额外的附加信息。在编译程序代码的时候，栈帧中需要多大的局部变量表、多深的操作数栈都已经完全确定了，并且写入到方法表的Code属性之中，因此一个栈帧需要分配多少内存，不会收到程序运行期变量数据的影响，而仅仅取决于具体的虚拟机实现。 一个线程中的方法调用链可能回很长，很多方法都同事处于执行状态。对于执行引擎来讲，活动线程中，只有栈顶是有效的，称为当前栈帧，这个栈帧所关联的方法称为当前方法。执行引擎所运行的所有字节码指令都只针对当前栈帧进行操作。 局部变量表局部变量表是一组变量值存储空间，用于存放方法参数和方法内部定义的局部变量。Java程序被编译为Class文件时，就在方法的Code属性的mac_locals数据项中确定了该方法所需要分配的最大局部变量表的容量。 局部变量表的容量以变量槽（Variable Slot）为最小单位，虚拟机规范中没有明确指明一个Slot应占内存空间大小，只是说明每个Slot都应该能存放一个boolean、btye、char、short、int、float、reference或returnAddress类型的数据，它允许Slot的长度随着处理器、操作系统或虚拟机的不同而发生变化。不过无论如何，即使在64位虚拟机中使用了64位长度的内存空间里爱实现一个Slot，虚拟机仍要使用对齐和补白的手段让Slot在外观上看起来与32位虚拟机的一致。 对于64位的数据类型，虚拟机会以高位在前的方式为其分配两个连续的Slot空间。Java语言中明确规定的64位的数据类型只有long和double两种。 这里把long和double数据类型分割存储的做法与“long和double的非原子性协定”中把long和double数据类型读写分割为两次32位读写的做法类似。不过，由于局部变量表建立在线程的对战上，是线程私有的数据，无论读写两个连续的Slot是否是原子操作，都不会引起数据安全问题。 虚拟机通过索引定位的方式使用局部变量表，索引值的范围是从0开始到局部变量表最大的Slot变量。如果是32位数据类型的变量，索引n就代表了使用第n个Slot，如果是64位数据类型的变量，则说明要使用第n和第n+1两个Slot。 操作数栈操作数栈也常被称为操作栈，是一个后入先出（Last In First Out，LIFO）栈。同局部变量表一样，操作栈的最大深度也在编译的时候被写入到Code属性的max_stacks数据项中。操作栈的每一个元素可以是任意Java数据类型，包括long和double。32位的数据类型所栈的栈容量为1，64位的数据类型所占的栈容量为2。在方法执行的任何时候，操作数栈的深度都不会超过在max_stacks数据项中设定的最大值。 当一个方法刚刚开始执行的时候，这个方法的操作数栈是空的，在方法的执行过程中，会有各种字节码指令向操作数栈中写入和提取内容，也就是入栈出栈操作。 例如，在做算术运算的时候是通过操作数栈来进行的，又或者在调用其他方法的时候是通过操作数栈来进行参数传递的。 举个例子，整数加法的字节码指令iadd在运行的时候要求操作数栈中最接近栈顶的两个元素已经存入了两个int型的数值，当执行这个指令时，会将这两个int值出栈并相加，然后将相加的结果入栈。 在概念模型中，两个栈帧作为虚拟机栈的元素，相互之间时完全独立的。但是大多数虚拟机的实现里都会做一些优化处理，令两个栈帧出现一部分重叠。让下面栈帧的部分操作数栈与上面栈帧的部分局部变量表重叠在一起，这样在进行方法调用时就可以共用一部分数据，而无须进行额外的参数复制传递了。 Java虚拟机的解释执行引擎称为“基于栈的执行引擎”，其中所指的“栈”就是操作数栈。 动态连接每个栈帧都包含一个指向运行时常量池中该栈所属的方法的引用，持有这个引用时为了支持方法调用过程中的动态连接。字节码中的方法调用指令就以常量池中指向方法的符号引用为参数。这些符号引用一部分会在类加载阶段或第一次使用的时候转化为直接引用，这种转化称为静态解析。另外一部分将在每一次的运行期间转化为直接引用，这部分称为动态连接。 方法返回地址当一个方法被执行后，有两种方式退出这个方法。 执行引擎遇到任意一个方法返回的字节码指令，这个时候可能会有返回值传递给上层的方法调用者，是否有返回值和返回值的类型将根据遇到何种方法返回指令来决定，这种退出方法的方式称为正常完成出口。 在方法执行过程中遇到了异常，并且这个异常没有在方法体内得到处理，无论是Java虚拟机内部产生的异常，还是代码中使用athrow字节码指令产生的异常，只要在本方法的异常表中没有搜索到匹配的异常处理器，就会导致方法退出，这种退出方法的方式称为异常完成出口。一个方法使用异常完成出口的方式退出，是不会给它的上层调用者产生返回值的。 无论采用何种退出方式，在方法退出之后，都需要返回到方法被调用的位置，程序藏能继续执行，方法返回时可能需要在栈帧中保存一些信息，用来帮助恢复它的上层方法执行状态。一般来说，方法正常退出时，调用者的PC计数器的值就可以作为返回地址，栈帧中很可能会保存这个计数器值。而方法异常退出时，返回地址时要通过异常处理器表来确定的，栈帧中一般不会保存这部分信息。 方法退出的过程实际上等同于把当前栈帧出栈，因此退出时可能执行的操作有： 恢复上层方法的局部变量表和操作数栈 把返回值压入调用者栈帧的操作数栈中 调整PC计数器的值以指向方法调用指令后面的一条指令 附加信息虚拟机规范允许具体的虚拟机实现增加一些规范里没有描述的信息到栈帧之中，例如与调试相关的信息，这部分信息完全取决于具体的虚拟机实现。在实际开发中，一般会把动态连接、方法返回地址与其他附加信息全部归位一类，称为栈帧信息。 方法调用方法调用并不等同于方法执行，方法调用阶段唯一的任务就是确定被调用方法的版本（即调用哪一个方法），暂时还不涉及方法内部的具体运行过程。 在程序运行时，进行方法调用时最普遍、最频繁的操作，但前面已经讲过，Class文件进行编译过程中不包含传统编译中的连续步骤，一切方法调用在Class文件里存储的都只是符号引用，而不是方法在实际运行时内存布局中的入口地址。这个特性给Java带来了更强大的动态扩展能力，但也使得Java方法的调用过程变得相对复杂起来，需要在类加载期间甚至到运行期间才能确定目标方法的直接引用。 解析所有方法调用中的目标方法在Class文件里面都是一个常量池的符号引用，在类加载的解析阶段，会将其中的一部分符号引用转化为直接引用，这种解析能成立的前提是：方法在程序真正执行之前就有一个确定的调用版本，这种解析能成立的前提是：方法在程序真正运行之前就有一个可确定的调用版本，并且这个方法的调用版本在运行期是不可改变的。换句话说，调用目标在程序代码写好、编译器进行编译时就必须确定下来。这类方法的调用称为解析。 在Java语言中，符合“编译器可知，运行期不可变”这个要求的方法主要有静态方法和私有方法两大类，前者与类型直接关联，后者在外部不可被访问，这两种方法都不可能通过继承或别的方式充血出其他版本，因此它们都适合在类加载阶段进行解析。 解析调用一定是个静态的过程，在编译期间就完全确定，在类装载的解析阶段就会把涉及的符号引用全部转变为可确定的直接引用，不会延迟到运行期再去完成。而分派调用则可能时静态的也可能时动态的，根据分派一句的宗量数可分为单分派和多分派。这两类分派方式两两组合就构成了静态单分派、静态多分派、动态单分派、动态多分派四种分派情况。 分派Java是一门面向对象的程序设计语言，因为Java具备面向对象的三个特征：继承、封装和多态。分派调用过程将会揭示多态特性的一些最基本的体现（如“重载”和“重写”）。 静态分派代码清单（方法静态分派演示）： package com.cayzlh.demo; /** * 方法静态分派演示 */ public class StaticDispatch { static abstract class Human{} static class Man extends Human {} static class Woman extends Human {} public void sayHello(Human guy) { System.out.println(\"Hello, guy!\"); } public void sayHello(Man guy) { System.out.println(\"Hello, gentleman!\"); } public void sayHello(Woman guy) { System.out.println(\"Hello, lady!\"); } public static void main(String[] args) { Human man = new Man(); Human women = new Woman(); StaticDispatch sd = new StaticDispatch(); sd.sayHello(man); sd.sayHello(women); } } 运行结果： Hello, guy! Hello, guy! 相信对Java稍微有经验的程序员看完程序后都能得出正确的运行结果，但为什么会选择执行参数类型为human的重载呢？在解决这个问题之前，先按如下代码定义两个重要的概念： Human man = new Man(); 把上面代码中的“Human”称为变量的静态类型（Static Type）或者外观类型（Apparent Type），后面的“Man”则称为变量的实际类型（Actual Type），静态类型和实际类型在程序中都可以发生一些变化，区别是静态类型的变化仅仅在使用时发生，变量本身的静态变量类型不会改变，并且最终的静态类型是在编译期可知的；而实际类型变化的结果在运行期才可确定，编译器在编译程序的时候并不知道一个对象的实际类型是什么。 // 实际类型变化 Human man = new Man(); man = new Women(); // 静态类型变化 sd.sayHello((Man) man); sd.sayHello((Women) women); 会到代码中，main()里面两次sayHello()方法调用，在方法接收者已经确定是对象sd的前提下，使用哪个重载版本，就完全取决于传入参数的数量和数据类型。代码中定义了两个静态类型相同、实际类型不同的变量，单虚拟机在重载时是通过参数的静态类型而不是实际类型作为判定依据的。并且静态类型是编译期可知的，所以在编译阶段，Javac编译器就根据参数的静态类型决定使用哪个重载版本。 所有依赖静态类型来定位方法执行版本的分派动作，都称为静态分派。静态分派的最典型应用就是方法重载。静态分派发生在编译阶段，因此静态分派的动作实际上不是由虚拟机来执行的。另外，编译器虽然能确定出方法的重载版本，但在很多情况下这个重载版本并不是“唯一的”，往往只能确定一个“更加适合的”版本。 动态分派动态分派和多态性的另外一个重要体现——重写（Override）有着很密切的关联。 代码清单： package com.cayzlh.demo; /** * 方法动态分派演示 */ public class DynamicDispatch { static abstract class Human { protected abstract void sayHello(); } static class Man extends Human { @Override protected void sayHello() { System.out.println(\"man say hello\"); } } static class Women extends Human { @Override protected void sayHello() { System.out.println(\"women say hello\"); } } public static void main(String[] args) { Human man = new Man(); Human women = new Women(); man.sayHello(); women.sayHello(); man = new Women(); man.sayHello(); } } 运行结果： man say hello women say hello women say hello 显然这里是不可能根据静态类型来决定的，因为静态类型都是Human的两个变量man和women在调用sayHello()方法时执行了不同的行为，并且变量man在两次调用中执行了不同的方法。导致这个现象的原因很明显，是这两个变量的实际类型不同。 单分派与多分派方法的接收者与方法的参数统称为方法的宗量。根据分派基于多少种宗量，可以将分派划分为单分派和多分派两种。单分派是根据一个宗量对目标进行选择，多分派则是根据多余一个的宗量对目标进行选择。 代码清单（列举一个Father和Son一起来做出“一个艰难的决定”的例子）： package com.cayzlh.demo; /** * 单分派与多分派 */ public class Dispatch { static class QQ { } static class _360 { } public static class Father { public void hardChoice(QQ arg) { System.out.println(\"father choose qq\"); } public void hardChoice(_360 arg) { System.out.println(\"father choose 360\"); } } public static class Son extends Father { public void hardChoice(QQ arg) { System.out.println(\"son choose qq\"); } public void hardChoice(_360 arg) { System.out.println(\"son choose 360\"); } } public static void main(String[] args) { Father father = new Father(); Father son = new Son(); father.hardChoice(new _360()); son.hardChoice(new QQ()); } } 运行结果： father choose 360 son choose qq 编译节点编译期的选择过程，即静态分派的过程。这时候选择目标方法的依据有两点：一是静态类型是Father还是Son，二是方法参数是QQ还是360。这次选择结果的最终产物是产生了两条invokevirtual指令，这两条指令的参数分别为常量池中指向Father.hardChoince(360)及Father.hardChoice(QQ)方法的符号引用。因为是根据两个宗量进行选择，所以Java语言的静态分派属于多分派类型。 运行阶段虚拟机的选择，即动态分派的过程。在执行”son.hardChoice(new QQ())”这句代码时，更准确的说，在执行这句代码所对应的invokevirtual指令时，由于编译期已经决定目标方法的签名必须为hardChoice(QQ)，虚拟机此时不会关心传递过来的参数是“QQ”到底是“腾讯QQ”还是“奇瑞QQ”，因为这时参数的静态类型、实际类型都不会对方法的选择构成任何影响，唯一可以影响虚拟机选择的因素只有此方法的接收者的实际类型是Father还是Son。因为只有一个宗量作为选择依据，所以Java语言的动态分派属于单分派类型。 虚拟机动态分派的实现由于动态分派是非常频繁的动作，而且动态分派的方法版本选择过程需要运行时在类的方法元数据中搜索合适的目标方法，因此在虚拟机的实际实现中基于性能的考虑，大部分实现都不会真的进行如此频繁的搜索。 面对这种情况，最常用的“稳定优化”手段就是**在类的方法区中建立一个徐方法表，使用虚拟方法表索引来代替原数据查找以提高性能。 虚方法表中存放着各个方法的实际入口地址。如果某个方法在子类中没有被重写，那么子类的虚方法表里面的地址入口和父类相同方法的入口时一致的，都指向父类的实现入口。如果子类中重写了这个方法，子类方法表中的地址将会被替换为指向子嘞实现版本的入口地址。 为了程序实现上的方便，具有相同签名的方法，在父类、子类的虚方法表中都应当具有一样的索引序号，这样当类型变换时，仅需要变更查找的方法表，就可以从不同的虚方法表中按索引转换出所需的入口地址。 方法表一般在类加载的连接阶段进行初始化，准备了类的变量初始值后，虚拟机会把该类的方法表也初始化完毕。 基于栈的字节码解释执行引擎解释执行不论是解释还是编译，也不论是物理机还是虚拟机，对于应用程序，机器都不可能如人那样阅读和理解，然后几获得了理解能力。大部分的程序代码到物理机的目标代码或虚拟机能执行的指令集之前，都需要经过编译过程。如下图，中下面的那条分支，就是传统编译原理中程序代码到目标机器代码的生成过程，而中间的那条分支自然就是解释执行的过程。 如今，基于物理机、Java虚拟机或者是非Java的其他高级语言虚拟机的语言，大多都遵循着中基于现代经典编译原理的思路，在执行前先对程序源码进行词法分析和语法分析处理，把源码转化为抽象语法术。对于一门具体语言的实现来说，词法和语法分析乃至后面的优化器和目标代码生成器都可以选择独立于执行引擎，形成一个完整意义的编译器去实现，这类代表是C/C++语言，也可以选择把其中的一部分步骤实现为一个半独立的编译器，这类代表是Java语言。又或者把这些步骤和执行引擎全部集中封装在一个封闭的黑夹子之中，如大多数的JavaScript执行器， Java语言中，Javac编译器完成了程序代码经过词法分析、语法分析到抽象语法书，再便遍历语法术生成线性的字节码指令的过程。因为这一部分动作是在Java虚拟机之外进行的，而解释器在虚拟机的内部，所以Java的编译就是半独立的实现。 基于栈的指令集与基于寄存器的指令集Java编译器输出的指令流，基本上是一种基于栈的指令集架构，指令流里面的指令大部分都是零地址指令，它们依赖操作数栈进行工作。与之相对的另外一套常用的指令集架构师基于寄存器的指令集，最典型的就是x86的二地址指令集。 基于栈的指令集最主要的优点就是可移植性，寄存器由硬件直接提供，程序直接以来这些硬件寄存器则不可避免地要受到约束。 栈架构指令集的主要缺点是执行速度相对来说稍慢一些。所有主流物理机的指令集都是寄存器架构也从侧面印证了这一点。 栈架构指令集的代码虽然紧凑，但是完成相同功能所需的指令数量一般会比寄存器架构多，因为出栈、入栈操作本身就产生了相当多的指令。更重要的是栈实现在内存之中，频繁的栈访问也就意味着频繁的内存访问，相对于处理器来说，内存始终是执行速度的瓶颈。尽管虚拟机可以采取栈顶缓存的手段，把最长用的操作映射到寄存器中以避免直接内存访问，但这也只能是优化措施而不是解决本质问题的方法。因此，**由于指令数量和内存访问的原因，导致了栈架构指令集的执行速度相对较慢。 小结分析了虚拟机在执行代码时如何找到正确的方法，如何执行方法内的字节码，以及执行代码时涉及的内存结构。针对Java程序时如何存储的、如何载入（创建）的以及如何执行的问题相关知识讲解了一下。 参考 周志明，深入理解Java虚拟机：JVM高级特性与最佳实践，机械工业出版社","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://www.cayzlh.com/tags/JVM/"},{"name":"《深入理解Java虚拟机》","slug":"《深入理解Java虚拟机》","permalink":"https://www.cayzlh.com/tags/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B/"}],"categories":[{"name":"书籍","slug":"书籍","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/"},{"name":"《深入理解Java虚拟机》","slug":"书籍/《深入理解Java虚拟机》","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B/"}]},{"title":"虚拟机类加载机制","date":"2018-09-14T02:44:37.000Z","path":"2018/09/14/cdffca23.html","text":"代码编译的结果从本地机器码变为字节码，是存储格式发展的一小步，确实编程语言发展的一大步 概述虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。 与哪些编译时需要进行连接工作的语言不同，在Java语言里面，类型的加载和连接过程都是在程序运行期间完成的，这样会在类加载时稍微增加一些性能开销，但时却能为Java应用程序提供高度的灵活性，Java中天生可以动态扩展的语言特性就是依赖运行期动态加载和动态连接这个特点实现的。例如，如果编写一个使用接口的应用程序，可以等到运行时再指定其实际的实现。这种组装应用程序的方式广泛应用于Java程序之中。 类加载的时机类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括了：加载（Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化（Initialization）、使用（Using）和卸载（Unloading）七个阶段。其中验证、准备和解析三个部分统称为连接（Linking）。 加载、验证、准备、初始化和卸载这五个阶段的顺序是确定的，类的加载过程必须按照这种顺序按部就班地开始，而解析阶段则不一定：它在某些情况下可以在初始化阶段之后再开始，这是为了支持Java语言的运行时绑定（也称为动态绑定或晚期绑定）。注意这里是按部就班地“开始”，而不是按部就班地“进行”或“完成”，因为这些阶段通常都是互相交叉地混合式进行地，通常会再下一个阶段执行地过程中调用或激活另外一个阶段。 Java虚拟机规范严格规定了有且只有四种情况必须立即对类进行“初始化”（而加载、验证、准备自然需要在此之前开始）： 遇到new、getstatic、putstatic或invokestatic这4条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。生成这4条指令地最常见地Java代码场景是：使用new关键字实例化对象地时候、读取或设置一个类字段（被final修饰、已在编译器把结果放入常量池地静态字段除外）地时候，以及调用一个类地静态方法地时候。 使用java.lang.reflect包地方法对类进行发射调用地时候，如果类没有进行过初始化，则需要先触发其初始化。 当初始化一个类地时候，如果发现其父类还没有进行过初始化，则需要先触发其父类地初始化。 当虚拟机启动时，用户需要指定一个要执行地主类（包括main()方法地那个类），虚拟机会先初始化这个主类。 被动引用地例子之一父类： package com.cayzlh.reference1; /** * 被动使用类字段演示一 * 通过子类引用父类的静态字段，不会导致子类初始化 */ public class SuperClass { static { System.out.println(\"SuperClass init..\"); } public static int value = 123; } 子类： package com.cayzlh.reference1; public class SubClass extends SuperClass { static { System.out.println(\"SubClass init..\"); } } 执行： package com.cayzlh.reference1; /** * 非主动使用类字段演示 */ public class NotInitialization { public static void main(String[] args) { System.out.println(SuperClass.value); } } 运行结果： 上述代码运行之后， 只会输出“SuperClass init..”，而不会输出“SubClass init..”。对于静态字段，只有直接定义这个字段的类才会被初始化，因此通过子类来引用父类中定义的静态字段，只会触发父类的初始化而不会触发子类的初始化。至于是否要触发子类的加载和验证，再虚拟机规范中没有明确规定，这点取决于虚拟机的具体实现。 被动引用的例子之二代码： package com.cayzlh.reference2; import com.cayzlh.reference1.SuperClass; /** * 通过数组定义来引用，不会触发此类的初始化 */ public class NotInitialization { public static void main(String[] args) { SuperClass[] sca = new SuperClass[10]; } } 运行结果： 运行之后发现没有输出“SuperClass init..”，说明并没有触发SuperClass类的初始化阶段。 被动引用的例子之三代码1： package com.cayzlh.reference3; /** * 常量在编译阶段会存入调用类的常量池中， * 本质上没有直接引用到定义定义常量的类， * 因此不能触发定义常量的类的初始化 */ public class ConstClass { static { System.out.println(\"ConstClass init..\"); } public static final String HELLOWORLD = \"Hello World.\"; } 代码2： package com.cayzlh.reference3; /** * 非主动使用类字段演示 */ public class NotInitialization { public static void main(String[] args) { System.out.println(ConstClass.HELLOWORLD); } } 运行结果： 上述代码运行之后，没有输出“ConstClass init..”，这是因为虽然在Java源码中引用了ConstClass类中的常量HELLOWORLD，但是在编译阶段将此常量的值”Hello World.”存储到了NotInitialization类的常量池中，对常量ConstClass.HELLOWORLD的引用都被转化为NotInitialization类对自身常量池的引用了。也就是说实际上NotInitialization的Class文件之中并没有ConstClass类的符号引用入口，这两个类在编译成Class之后就不再存在任何联系了。 类加载的过程类加载的的全过程，也就是加载、验证、准备、解析和初始化这五个阶段的过程。 加载“加载”（Loading）阶段是“类加载”（Class Loading）过程的一个阶段。在加载阶段，虚拟机需要完成以下三件事情： 1）通过一个类的全限定名来获取定义此类的二进制字节流 2）将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 3）在Java堆中生成一个代表这个类的java.lang.Class对象，作为方法区将这些数据的访问入口 虚拟机规范的这三点要求实际上并不具体，因此虚拟机实现与具体应用的灵活度相当大。相对于类加载过程的其他阶段，加载阶段（加载阶段中获取类的二进制字节流的动作）是开发期可控性最强的阶段，因为加载阶段是既可以使用系统提供的类加载器来完成，也可以由用户自定义的类加载器去完成，开发人员可以通过自己定义的类加载器去控制字节流的获取方式。 验证 验证时连接阶段的第一步，这一阶段的目的时为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 Class文件并不一定要求用Java源码编译而来，可以使用任何途径，包括用十六进制编辑器直接编写来产生Class文件。如果虚拟机不检查输入的字节流，对其完全信任的话，很可能会因为载入了有害的字节流而导致系统崩溃，所以验证时虚拟机自身保护的一项重要工作。 虚拟机大致上会完成下面四个阶段的检查过程：文件格式验证、元数据验证、字节码验证和符号引用验证。 文件格式验证第一阶段要验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理： 是否以魔数0xCAFEBABE开头 主、次版本号是否在当前虚拟机处理范围之内 常量池的常量中是否有不被支持的常量类型 指向常量的各种索引值是否有只想不存在常量或不符合类型的常量 CONSTANT_Utf8_info型的常量中是否有不符合UTF8编码的数据 Class文件中各个部分及文件本身是否有被删除的额或附加的其他信息 ······ 实际上第一阶段的验证还远远不止这些，该验证阶段的主要目的时保证输入的字节流能正确地解析并存储与方法区之内，格式上符合描述一个Java类型信息地要求。这阶段的验证时基于字节流进行的，经过这个阶段的验证之后，字节流才会流入内存的方法区中进行存储，所以以后的三个验证阶段都是基于方法区存储结构进行的。 元数据验证第二阶段是堆字节码描述的信息进行语义分析，以保证其描述的信息符合Java语言的规范的要求，这个阶段包括： 这个类是否有父类（除了java.lang.Object，所有的类都应当有父类） 这个类的父类是否继承了不允许被继承的类（被final修饰的类） 如果这个类不是抽象类，是否实现了其父类或接口之中要求实现的所有方法 类中的字段、方法是否与父类产生了矛盾（例如覆盖了父类的final字段，或者出现不符合规则的方法重载，例如方法参数都一致，但返回值类型却不同等） ······ 第二阶段的主要目的是对类的元数据信息进行语义校验，保证不存在不符合Java语言规范的元数据信息。 字节码验证第三阶段是整个验证过程中最复杂的一个阶段，主要工作是进行数据流和控制流分析。在第二阶段对元数据信息中的数据类型做完校验后，这阶段对类的方法体进行校验分析。这阶段的任务是保证被校验类的方法在运行时不会做出危害虚拟机安全的行为： 保证任意时刻操作数据栈与指令代码序列都能配合工作，例如不会出现类似的情况：在操作栈中放置了一个int类型的数据，使用时却按long类型来加载如本地变量表中。 保证跳转指令不会跳转到方法体意外的字节码指令上。 保证方法体中的类型转换是有效的，例如可以把一个子类对象赋值给父类数据类型，这是安全的，但是把父类对象赋值给子类数据类型，甚至把对象赋值给与它毫无关系、完全不相干的数据类型，则是危险和不合法的。 ······ 如果一个类的方法体的字节码没有通过字节码验证，那肯定是有问题的；但如果一个方法体通过了字节码验证，也不能说明其一定就是安全的。即使字节码验证之中进行了大量的检查，也不能保证这一点。通俗一点讲就是，通过程序去校验程序逻辑是无法做到绝对准确的——不能通过程序准确的检查出程序是否能在有限的时间之内结束运行。 符号引用验证最后一个阶段的校验发生在虚拟机将符号引用转化直接引用的时候，这个自动转化将在连接的第三个阶段——解析阶段中发生。符号引用验证可以看作是对类自身以外（常量池中的各种符号引用）的信息进行匹配性的校验： 符号引用中通过符号串描述的全限定名是否能找到对象的类。 在指定类中是否存在符合方法的字段描述符及简单名称所描述的方法和字段。 符号引用中的类、字段和方法的访问行（private、protected、public、default）是否可被当前类访问。 ······ 符号引用验证的目的是确保解析动作能正常执行。 验证阶段对于虚拟机的类加载机制来说，是一个非常重要的、但不一定时必要的阶段。如果所运行的全部代码（包括自己写的、第三方包中的代码）都已经被反复使用和验证过，在实施阶段就口可以考虑使用-Xverify:none参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中进行分配。这个阶段中有两个容易产生混淆的概念需要强调一下，首先是这时候进行内存分配的仅包括类变量（被static修饰的变量），而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在Java堆中。其次时这里所说的初始值“通常情况”下时数据类型的零值，假设一个类变量定义为： public static int value = 123; 那么变量value在准备阶段过后的初始值是0而不是123，因为这时候尚未开始执行任何Java方法，而把value赋值为123的putstatic指令是程序被编译后，存放于类结构器()方法之中，所以value赋值为123的动作将在初始化阶段才会被执行。 “通常情况”下时数据类型的零值，那相对的会有一些“特殊情况”：如果类字段的字段属性表中存在ConstantValue属性，那在准备阶段变量value就会被初始化为ConstantValue属性所指的值，如： public static final int value = 123; 编译时将会为value生成ConstantValues属性，在准备阶段虚拟机就会根据ConstantValue的设置将value赋值为123。 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。解析阶段中所说的直接引用与符号引用有什么关联呢？ 符号引用（Symbolic Reference）：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。富豪引用与虚拟机实现地内存布局无关，引用地目标并不一定已经加载到内存中。 直接引用（Direct Reference）：直接引用可以时直接指向目标地指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用是与虚拟机实现的内存布局相关的，同一个符号引用在不同虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用，那引用的目标必定已经在内存中存在。 解析动作主要针对类或接口、字段、类方法、接口方法四类符号引用进行，分别对应于常量池中的CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info及CONSTANT_InterfaceMethodref_info四种常量类型。 类或接口的解析要把一个类或者接口的符号引用解析为直接引用，需要以下三个步骤： 如果该符号引用不是一个数组类型，那么虚拟机将会把该符号代表的全限定名称传递给类加载器去加载这个类。这个过程由于涉及验证过程所以可能会触发其他相关类的加载 如果该符号引用是一个数组类型，并且该数组的元素类型是对象。我们知道符号引用是存在方法区的常量池中的，该符号引用的描述符会类似”[java/lang/Integer”的形式，将会按照上面的规则进行加载数组元素类型，如果描述符如前面假设的形式，需要加载的元素类型就是java.lang.Integer ,接着由虚拟机将会生成一个代表此数组对象的直接引用 如果上面的步骤都没有出现异常，那么该符号引用已经在虚拟机中产生了一个直接引用，但是在解析完成之前需要对符号引用进行验证，主要是确认当前调用这个符号引用的类是否具有访问权限，如果没有访问权限将抛出java.lang.IllegalAccess异常 字段解析对字段的解析需要首先对其所属的类进行解析，因为字段是属于类的，只有在正确解析得到其类的正确的直接引用才能继续对字段的解析。对字段的解析主要包括以下几个步骤： 如果该字段符号引用就包含了简单名称和字段描述符都与目标相匹配的字段，则返回这个字段的直接引用，解析结束 否则，如果在该符号的类实现了接口，将会按照继承关系从下往上递归搜索各个接口和它的父接口，如果在接口中包含了简单名称和字段描述符都与目标相匹配的字段，那么久直接返回这个字段的直接引用，解析结束 否则，如果该符号所在的类不是Object类的话，将会按照继承关系从下往上递归搜索其父类，如果在父类中包含了简单名称和字段描述符都相匹配的字段，那么直接返回这个字段的直接引用，解析结束 否则，解析失败，抛出java.lang.NoSuchFieldError异常 如果最终返回了这个字段的直接引用，就进行权限验证，如果发现不具备对字段的访问权限，将抛出java.lang.IllegalAccessError异常 类方法解析进行类方法的解析仍然需要先解析此类方法的类，在正确解析之后需要进行如下的步骤： 类方法和接口方法的符号引用是分开的，所以如果在类方法表中发现class_index（类中方法的符号引用）的索引是一个接口，那么会抛出java.lang.IncompatibleClassChangeError的异常 如果class_index的索引确实是一个类，那么在该类中查找是否有简单名称和描述符都与目标字段相匹配的方法，如果有的话就返回这个方法的直接引用，查找结束 否则，在该类的父类中递归查找是否具有简单名称和描述符都与目标字段相匹配的字段，如果有，则直接返回这个字段的直接引用，查找结束 否则，在这个类的接口以及它的父接口中递归查找，如果找到的话就说明这个方法是一个抽象类，查找结束，返回java.lang.AbstractMethodError异常 否则，查找失败，抛出java.lang.NoSuchMethodError异常 如果最终返回了直接引用，还需要对该符号引用进行权限验证，如果没有访问权限，就抛出java.lang.IllegalAccessError异常。 接口方法解析同类方法解析一样，也需要先解析出该方法的类或者接口的符号引用，如果解析成功，就进行下面的解析工作： 如果在接口方法表中发现class_index的索引是一个类而不是一个接口，那么也会抛出java.lang.IncompatibleClassChangeError的异常 否则，在该接口方法的所属的接口中查找是否具有简单名称和描述符都与目标字段相匹配的方法，如果有的话就直接返回这个方法的直接引用。 否则，在该接口以及其父接口中查找，直到Object类，如果找到则直接返回这个方法的直接引用 否则，查找失败 接口的所有方法都是public，所以不存在访问权限问题 初始化初始化阶段才真正开始执行类中定义的java程序代码。 初始化阶段是执行类构造器()方法的过程。在以下四种情况下初始化过程会被触发执行： 遇到new、getstatic、putstatic或invokestatic这4条字节码指令时，如果类没有进行过初始化，则需先触发其初始化。生成这4条指令的最常见的java代码场景是：使用new关键字实例化对象、读取或设置一个类的静态字段(被final修饰、已在编译器把结果放入常量池的静态字段除外)的时候，以及调用类的静态方法的时候。 使用java.lang.reflect包的方法对类进行反射调用的时候 当初始化一个类的时候，如果发现其父类还没有进行过初始化、则需要先出发其父类的初始化 jvm启动时，用户指定一个执行的主类(包含main方法的那个类)，虚拟机会先初始化这个类 在准备阶段，变量已经赋过一次系统要求的初始值，二在初始阶段，则是根据程序员通过程序制定的主观计划去初始化类变量和其他资源。 类加载器 虚拟机设计团队把类加载阶段中的“通过一个类的全限定名来获取描述此类的二进制字节流”这个动作放到Java虚拟机外部去实现，以便让应用程序自己决定如何去获取所需要的类。实现这个动作的代码模块被称为“类加载器”。 类加载器可以说是Java语言的一项创新，也是Java语言流行的重要原因之一。 类与类加载器类加载器虽然只用于实现类的加载动作，但它在Java程序中起到的作用却远远不限于类加载阶段。对于任意一个类，都需要由加载它的类加载器和这个类本身一同确定其在Java虚拟机中的唯一性。通俗一点：比较两个类是否“相等”，只有在这两个类是由同一个类加载器加载的前提之下才有意义，否则，即使这两个类来源同一个Class文件，只要记载他们的类加载器不同，那这两个类就必定不相等。 双亲委派模型站在Java虚拟机的角度看，只存在两种不同的类加载器：一种是启动类加载器（Bootstrap ClassLoader），这个类加载器使用C++语言实现，是虚拟机自身的一部分；另外一种就是所有其他的类加载器，这些类加载器都由Java语言实现，独立于虚拟机外部，并且全部都继承自抽象类java.lang.ClassLoader。 绝大部分Java程序都会使用到以下三种系统提供的类加载器： 启动类加载器（Bootstrap ClassLoader）：负责将存放在bin目录中的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机识别的类库加载到虚拟机内存中。启动类加载器无法被Java程序直接引用。 扩展类加载器（Extension ClassLoader）：负责加载lib\\ext目录中，或者被java.ext.dirs系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。 应用程序加载器（Application ClassLoader）：由于这个类加载器是ClassLoader中的getSystemClassLoader()方法的返回值，所以一般也称为系统类加载器。负责加载用户类路径上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 我们的应用程序都是由这三种类加载器互相配合进行加载的，如果有必要，还可以加入自己定义的类加载器。这些类加载器之间的关系一般如图所示： 双亲委派模型除了要求顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器。这里类加载器之间的父子关系一般不会以继承的关系实现，而是都使用组合关系来复用父类加载器的代码。 双亲委派模型的工作过是：如果一个类加载器收到了类加的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当附加在七反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。 使用双亲委派模型来组织类加载器之间的关系，好处就是Java类随着它的类加载器一起具备了一种带有优先级的层次关系。双亲委派模型对于保证Java程序的稳定运行很重要，但它的实现却非常简单，实现双亲委派的代码都集中在java.lang.ClassLoader的loadClass()方法之中。先检查是否已经被加载过，若没有加载则调用父类加载器的loadClass()方法，若父类加载器为空则默认使用启动类加载器作为父类加载器。如果父类加载失败，则在抛出ClassNotFoundException异常后，再调用自己的findClass()方法进行加载。 破坏双亲委派模型第一次破坏由于双亲委派模型是在JDK1.2之后才被引入的，而类加载器和抽象类java.lang.ClassLoader则在JDK1.0时代就已经存在，面对已经存在的用户自定义类加载器的实现代码，Java设计者引入双亲委派模型时不得不做出一些妥协。在此之前，用户去继承java.lang.ClassLoader的唯一目的就是为了重写loadClass()方法，因为虚拟机在进行类加载的时候会调用加载器的私有方法loadClassInternal()，而这个方法唯一逻辑就是去调用自己的loadClass()。 第二次破坏双亲委派模型的第二次“被破坏”是由这个模型自身的缺陷所导致的，双亲委派很好地解决了各个类加载器的基础类的同一问题（越基础的类由越上层的加载器进行加载），基础类之所以称为“基础”，是因为它们总是作为被用户代码调用的API，但世事往往没有绝对的完美。 如果基础类又要调用回用户的代码，那该么办？一个典型的例子就是JNDI服务，JNDI现在已经是Java的标准服务， 它的代码由启动类加载器去加载（在JDK1.3时放进去的rt.jar），但JNDI的目的就是对资源进行集中管理和查找，它需要调用由独立厂商实现并部署在应用程序的ClassPath下的JNDI接口提供者的代码，但启动类加载器不可能“认识”这些代码。 为了解决这个问题，Java设计团队只好引入了一个不太优雅的设计：线程上下文类加载器(Thread Context ClassLoader)。这个类加载器可以通过java.lang.Thread类的setContextClassLoader()方法进行设置，如果创建线程时还未设置，他将会从父线程中继承一个，如果在应用程序的全局范围内都没有设置过的话，那这个类加载器默认就是应用程序类加载器。 有了线程上下文加载器，JNDI服务就可以使用它去加载所需要的SPI代码，也就是父类加载器请求子类加载器去完成类加载的动作，这种行为实际上就是打通了双亲委派模型层次结构来逆向使用类加载器，实际上已经违背了双亲委派模型的一般性原则，但这也是无可奈何的事情。Java中所有涉及SPI的加载动作基本上都采用这种方式，例如JNDI、JDBC、JCE、JAXB和JBI等。 第三次破坏双亲委派模型的第三次“被破坏”是由于用户对程序动态性的追求导致的，这里所说的“动态性”指的是当前一些非常“热门”的名词：代码热替换、模块热部署等，简答的说就是机器不用重启，只要部署上就能用。 OSGi实现模块化热部署的关键则是它自定义的类加载器机制的实现。每一个程序模块(Bundle)都有一个自己的类加载器，当需要更换一个Bundle时，就把Bundle连同类加载器一起换掉以实现代码的热替换。在OSGi幻境下，类加载器不再是双亲委派模型中的树状结构，而是进一步发展为更加复杂的网状结构，当受到类加载请求时，OSGi将按照下面的顺序进行类搜索： 1）将java.＊开头的类委派给父类加载器加载。 2）否则，将委派列表名单内的类委派给父类加载器加载。 3）否则，将Import列表中的类委派给Export这个类的Bundle的类加载器加载。 4）否则，查找当前Bundle的ClassPath，使用自己的类加载器加载。 5）否则，查找类是否在自己的Fragment Bundle中，如果在，则委派给Fragment Bundle的类加载器加载。 6）否则，查找Dynamic Import列表的Bundle，委派给对应Bundle的类加载器加载。 7）否则，类加载器失败。 小结介绍了类加载过程的加载、验证、准备、解析和初始化五个阶段中虚拟机进行了哪些动作，还介绍了类加载器的工作原理及其堆虚拟机的意义 参考 周志明，深入理解Java虚拟机：JVM高级特性与最佳实践，机械工业出版社 破坏双亲委派模型","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://www.cayzlh.com/tags/JVM/"},{"name":"《深入理解Java虚拟机》","slug":"《深入理解Java虚拟机》","permalink":"https://www.cayzlh.com/tags/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B/"}],"categories":[{"name":"书籍","slug":"书籍","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/"},{"name":"《深入理解Java虚拟机》","slug":"书籍/《深入理解Java虚拟机》","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B/"}]},{"title":"Redis配置认证密码","date":"2018-09-13T13:10:12.000Z","path":"2018/09/13/d11f1e94.html","text":"方法一，修改配置文件修改redis.confvi redis.conf 找到： requirepass myRedis 将注释去掉，把myRedis换成你的密码。 重启redissudo service redis restart # 或者 sudo service redis stop sudo redis-server /etc/redis.conf 这个时候尝试登录redis，发现可以登上，但是执行具体命令是提示操作不允许sudo redis-cli 尝试用密码登录并执行具体的命令看到可以成功执行sudo redis-cli -a yourpasswd 方法二，通过命令行进行配置redis 127.0.0.1:6379[1]> config set requirepass my_redis OK redis 127.0.0.1:6379[1]> config get requirepass 1) \"requirepass\" 2) \"my_redis\" 无需重启redis , 使用修改后的密码登录redis，可以执行相应操作 用这种方法修改密码，重启redis后，用新配置的密码登录redis执行操作，发现新的密码失效，redis重新使用了配置文件中的密码。 除了在登录时通过 -a 参数制定密码外，还可以登录时不指定密码，而在执行操作前进行认证。 master配置了密码，slave如何配置若master配置了密码则slave也要配置相应的密码参数否则无法进行正常复制的。 slave中配置文件内找到如下行，移除注释，修改密码即可。 #masterauth mstpassword","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"Redis","slug":"Redis","permalink":"https://www.cayzlh.com/tags/Redis/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"},{"name":"Redis","slug":"运维/Redis","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/Redis/"}]},{"title":"虚拟机性能监控与故障处理工具","date":"2018-09-13T08:14:28.000Z","path":"2018/09/13/fea7515.html","text":"Java与C++之间有一堵由内存动态分配和垃圾收集围城的高墙，墙外面的人想进来，墙里面的人却想出去. 概述经常使用适当的虚拟机监控和分析的工具可以加快我们分析数据和定位问题的速度，但我们在学习工具前，也应当意识到工具永远都是知识技能的一层包装，没有什么工具是“秘密武器”，学会了就能包治百病。 JDK的命令行工具Java开发人员肯定都知道JDK的bin目录下有“java.exe”和“javac.exe”这两个命令行工具，但并非所有程序员都了解过JDK的bin目录之中其他命令行程序的作用。 这些工具中包含了用于监视虚拟机和公章处理的工具。这些工具都非常稳定而且功能强大，能在处理应用程序应能问题、定位故障时发挥很大的作用。 JDK开发团队选择采用Java代码来实现这些监控工具时有特别用意的：当用用程序部署到生产环境后，无论是直接解除物理服务器还是远程Telnet到服务器上都可能会收到限制。借助tools.jar类库里面的接口，我们可以直接在应用程序中实现强大的监控分析功能。 jps：虚拟机进程状况工具JDK的很多小工具的名字都参考了Unix命令的命名方式，jps（JVM Process Status Tool）是其中的典型。可以列出真该运行的虚拟机进程，并显示虚拟机执行主类（Main Class，main() 函数所在的类）的名称，以及这些进程的本地虚拟机的唯一ID（LVMID，Local Virtual Machine Identifier）。对于本地虚拟机进程来说，LVMID与操作系统的进程ID（PID，Process Identifier）是一致的，使用Windows的任务管理器或Unix的ps命令也可以查询到虚拟机进程的LVMID，但如果同时启动了多个虚拟机进程，无法根据进程名称定为时，那就只能以来jps命令显示主类的功能才能区分了。 jps命令格式： jps [ options ] [ hostid ] 样例： jps -l jps可以通过RMI协议查询开启了RMI服务器的远程虚拟机进程状态，hostid为RMI注册表中注册的主机名。 jps工具主要选项 选项 作用 -q 只输出LVMID，省略主类的名称 -m 输出虚拟机进程启动时传递给主类main()函数的参数 -l 输出主类的全名，如果进程执行的是Jar包，输出Jar路径 -v 输出虚拟机进程启动时JVM参数 – jstat：虚拟机统计信息监视工具jstat（JVM Statistics Monitoring Tool）是用于监视虚拟机各种运行状态信息的命令行工具。它可以显示本地或远程虚拟机进程中的类加载、内存、垃圾收集、JIT编译等运行数据，在没有GUI图形界面，只提供了纯文本控制台环境的服务器上，它将是运行期定位虚拟机性能问题的首选工具。 jstat命令格式： jstat [ option vmid [ interval[s|ms] [ count ] ] ] 参数interval和count代表查询间隔和次数，如果省略这两个参数，说明只查询一次。假设需要每250毫秒查询一次进程2764垃圾收集的状况，一共查询20此，那命令应当是： jstat -gc 2764 250 20 选项option代表着用户希望查询的虚拟机信息，主要分3类：类装载、垃圾收集和运行期编译状况，具体选项及作用参考下表： 选项 作用 -class 监视类装载、卸载数量、总空间及类装载所耗费的时间 -gc 监视Java堆状况，包括Eden区、2个Survivor区、老年代、永久代等的容量、已用空间、GC时间合计等信息 -gccapacity 监视内容与-gc基本相同，但输出主要关注Java堆各个区域使用到的最大和最小空间 -gcutil 监视内容与-gc基本相同，但输出主要关注已使用空间占总空间的百分比 -gccause 与-gcutil的功能一样，但是会额外输出导致上一次GC产生的原因 -gcnew 监视新生代GC的状况 -gcnewcapacity 监视内容与-gcnew基本相同，输出主要关注使用到的最大和最小空间 -gcold 监视老年代GC的状况 -gcoldcapacity 监视内容与-gcold基本相同，输出主要关注使用到的最大和最小空间 -gcpermcapacity 输出永久代使用的最大和最小空间 -compiler 输出JIT编译器编译过的方法、耗时等信息 -printcompilation 输出已经被JIT编译的方法 – jinfo：Java配置信息工具jinfo（Configuration Info for Java）的作用是实时地查看和调整虚拟机的各项参数。 格式： jinfo [ option ] pid 样例：查询CMSInitiatingOccupancyFraction参数值。 jinfo -flag CMSInitiatingOccupancyFraction 1444 jmap：Java内存映像工具jmap（Memory Map for Java）命令用于生成堆转储快照（一般称为heapdump或dump文件）。jmap的作用并不仅仅是为了获取dump文件，它还可以查询finalize执行队列，Java堆和永久代的详细信息，如空间使用率、当前用的是哪种收集器等。 格式： jmap [ option ] vmid 参数表： 选项 作用 -dump 生成Java堆转储快照，格式：-dump:[live,]format=b,file=filename,其中live子参数说明是否只dump出存活的对象 -finalizerinfo 显示在F-Queue中等待Finalizer线程执行finalize方法的对象。只在Liux/Solaris平台有效 -heap 显示Java堆详细信息， 如使用那种回收器、参数配置分代状况等。只在Liux/Solaris平台有效 -histo 显示堆中对象统计信息，包括类、实例数量和合计容量 -permstat 以ClassLoader为统计口径显示永久代的内存状态。只在Liux/Solaris平台有效 -F 当虚拟机进程堆-dump选项没有响应时，可使用这个选项强制生成dump快照。只在Liux/Solaris平台有效 – jhat：虚拟机堆转储快照分析工具与jmap搭配使用，来分析jmap生成的堆转储快照。 jstack：Java堆栈跟踪工具jstack（Stack Trace for Java）命令用于生成虚拟机当前时刻快照。线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待都是导致线程长时间停顿的常见原因。 格式： jstack [ option ] vmid 参数表： 选项 作用 -F 当正常输出请求不被响应时，强制输出线程堆栈 -l 除堆栈外，显示关于锁的附加信息 -m 如果调用到本地方法的话，可以显示C/C++的堆栈 – JDK的可视化工具JDK中除了提供大量的命令行工具外，还有两个功能强大的可视化工具：JConsole和VisualVM，这两个工具时JDK的正式成员。 JConsole：Java监视与管理控制台JConsole是一款基于JMX的可视化监视管理的工具。它管理部分的功能时针对JMX MBean进行管理，MBean可以使用代码、中间件服务器的管理控制台或者所有符合JMX规范的软件进行访问。 参考文献： 官方文档 如何利用 JConsole观察分析Java程序的运行，进行排错调优 JVM检测分析JConsole VisualVM：多合一故障处理工具VisualVM是到目前为止，随JDK发布的功能最强大的运行监视和故障处理程序，并且可以预见在未来一段时间内都是官方主力发展的虚拟机故障处理工具。 参考文献： https://visualvm.github.io/ 使用 VisualVM 进行性能分析及调优 学习Java VisualVM的使用 小结介绍了随JDK发布的6个命令行工具和2个可视化的故障处理工具，灵活使用这些工具，可以给处理问题带来很大的便利。 参考 周志明，深入理解Java虚拟机：JVM高级特性与最佳实践，机械工业出版社","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://www.cayzlh.com/tags/JVM/"},{"name":"《深入理解Java虚拟机》","slug":"《深入理解Java虚拟机》","permalink":"https://www.cayzlh.com/tags/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B/"}],"categories":[{"name":"书籍","slug":"书籍","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/"},{"name":"《深入理解Java虚拟机》","slug":"书籍/《深入理解Java虚拟机》","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B/"}]},{"title":"垃圾收集器与内存分配策略","date":"2018-09-11T08:34:53.000Z","path":"2018/09/11/ddb92a08.html","text":"Java与C++之间有一堵由内存动态分配和垃圾收集围城的高墙，墙外面的人想进来，墙里面的人却想出去. 一、概述垃圾收集需要完成的三件事情： 哪些内存需要回收？ 什么时候回收？ 如何回收？ 内存的动态分配和内存回收技术已经相当成熟，为什么还需要去了解GC和内存分配呢？ 答案很简单：当需要排查各种内存溢出、内存泄漏问题时，当垃圾收集成为系统达到更高并发量的瓶颈时，我们对这些“自动化”的技术实施必要的监控和调节。 Java运行时区域的各个部分中，程序计数器、虚拟机栈、本地方法栈三个区域随线程而生，随线程而灭；栈中的栈帧随着方法的进入和退出而有条不紊的执行着出栈和入栈操作。每个栈帧中分配多少内存基本上是在类结构确定下来时就是已经知道的，因此这几个区域的内存分配和回收都具备确定性，在这几个区域内不需要过多考虑回收问题，因为在方法结束或线程结束的时候，内存自然就跟着回收了。 Java堆和方法区则不一样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也可能不一样，我们只有在程序处于运行期间时才能知道会创建哪些对象，这部分的分配和回收都是动态的，垃圾收集器所关注的是这部分内存。 二、对象已死？ 堆中几乎存放这Java世界中所有的对象实例，垃圾收集器在对堆进行回收前，第一件事就是要确定这些对象有哪些还“活着”，哪些已经“死去”。 1、引用计数算法给对象添加一个引用计数器，每当有一个地方引用它时，计数器就加1；当引用消失时，计数器值就减1；任何时刻计数器都为0的对象就是不可能再被使用的。 Java语言中没有选用引用计数算法来管理内存，其中最主要的原因是它很难解决对象之间相互循环引发的问题。 例：当两个对象互相引用对方，除此之外两个对象再无任何引用，实际上这两个对象已经不可能再被访问，但是他们因为互相引用着对方，导致他们的引用计数都不为0，于是引用计数算法无法通知GC收集器回收它们。 2、根搜索算法在主流的商用程序语言中（Java和C#）都使用根搜索算法（GC Roots Tracing）判断对象是否存活的。这个算法的基本思路就是通过一系列名为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所有走过的路径成为引用链（Reference Chain），当一个对象到GC Roots没有任何引用链相连（用图论的话来说就是从GC Roots到这个对象不可达）时，则证明此对象是不可用的。 在Java语言里，可作为GC Roots的对象包括下面几种： 虚拟机栈（栈帧中的本地变量表）中的引用的对象 方法区中的类静态属性引用的对象 方法区中的常量引用的对象 本地方法栈中JNI（即一般说的Native方法）的引用的对象 3、引用无论是通过引用计数算法判断对象的引用数量，还是 通过根搜索算法判断对象的引用链是否可达，判定对象是否存活都与“引用”有关。 在JDK1.2之前，Java中的引用的定义很传统：如果reference类型的数据中存储的数值代表的是另外一块内存的起始地址，就称这块内存代表着一个引用。 这种定义很存粹，但是太过狭隘，一个对象在这种定义下只有被引用或者没有被引用两种状态。希望能描述这样一类对象：当内存空间还足够时，则能保留在内存之中；如果内存在进行垃圾收集后还是非常进场，则可以抛弃这些对象。 Java堆引用的概念进行了扩充，将引用分为：强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）、虚引用（Phantom Reference）四种，这四种引用的强度一次组建减弱。 强引用：在程序代码之间普遍存在的，类似“Object obj = new Object()”这类的引用，只要强引用还存在，垃圾收集器永远不会回收调被引用的对象。 软引用：用来描述一些还用，但并非必须的对象。对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中并进行第二次回收。如果这次回收还是没有足够的内存，才会抛出内存溢出异常。 弱引用：用来描述非必须的对象的，它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。 xu虚引用：又称为幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是希望能在这个对象被收集器回收时受到一个系统通知。 4、生存还是死亡在跟搜索算法中不可达的对象，也并非时“非死不可”的，这个时候他们处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历两次标记过程： 如果对象在进行跟搜索后发现没有与GC Roots相连接的引用链，那它将会被第一次标记并且进行一次筛选，筛选的条件时此对象是否有必要执行finalize()方法。 当对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机用过，虚拟机将这两种情况都视为“没有必要执行”。 如果这个对象被判定为有必要执行finalize()方法，那么这个对象将会被放置在一个名为F-Queue的队列之中，并在稍后由一条由虚拟机自动建立的、低优先级的Finalizer线程去执行。 任何一个对象的finalize()方法都只会被系统自动调用一次，如果对象面临下一次回收，它的finalize()方法不会再次执行 finalize()能做的所有工作，使用try-finally或者其他方式都可以做得更好、更及时。完全可以忘掉Java语言中还有这个方法存在。 5、回收方法区（永久代） Java虚拟机规范中说过可以不要求虚拟机再方法区实现垃圾收集，而且再方法区进行垃圾收集的“性价比”一般比较低：再堆中，尤其是再新生代中，常规应用进行一次垃圾收集一般可以回收70%~95%的空间，而永久代的垃圾收集效率远低于此。 永久代的垃圾收集主要回收两部分内容：废弃常量和无用的类。 判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要满足3个条件才能算是“无用的类：” 该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例 加载该类的ClassLoader已经被回收 该类对应的java.lang.Class对象没在任何地方被引用，无法在任何地方通过反射访问该类的方法。 虚拟机可以堆满足上述3个条件的无用类进行回收，这里说的仅仅是“可以”，而不是和对象一样，不使用了就必然会被回收。 在大量使用反射、动态代理、CGLib等bytecode框架的场景，以及动态生成JSP和OSGi这类频繁自定义ClassLoader的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。 三、垃圾收集算法介绍几种算法的思想及其发展过程。 1、标记-清除算法最基础的收集算法是“标记-清除（Mark-Sweep）”算法：首先标记出所有需要回收的对象，在标记完成后统一回收调所有被标记的对象。它主要缺点有两个：一个是效率问题，标记和清除过程的效率都不高；另外一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致，当程序在以后的运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 2、复制算法为了解决效率问题，于是就有了“复制（Copying）”算法。它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是堆其中的一块进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动栈顶指针，按顺序分配内存即可，实现简单，运行高效。但是这种算法的代价时将内存缩小为原来的一般。 现在的商业虚拟机都采用这种收集算法来回收新生代，IBM的专门研究表明，新生代中的对象98%是朝生夕死的，所以并不需要按照1:1的比例来划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中的一块Survivor。当回收时，将Eden和Survivor中还活着的对象一次性拷贝到另外一块Survivor空间上，最后清理调Eden和刚才用过的Survivor的空间。 Hotspot虚拟机默认Eden和Survivor的大小比例时8:1，也就是每次新生代中可用内存空间为整个新生代容量的90%(80%+10%)，只有10%的内存是会被“浪费”的。 3、标记-整理算法复制收集算法在对象存活率较高时就要执行较多的复制操作，效率将会变低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。 根据老年代的特点，提出了”标记-整理（Mark-Compact）“算法，标记过程仍然与”标记-清除“算法一样，但后续步骤不是直接堆可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理调端边界意外的内存。 4、分代收集算法当前商业虚拟机的垃圾收集都采用”分代收集“（Generational Collection）算法，这种算法并没有什么新的思想，只是根据对象存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适合的收集算法。 在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存货对象的复制成本就可以完成收集。 在老年代中因为对象存活率高、没有额外空间堆它进行分配担保，就必须使用”标记-清理“或”标记-整理“算法来进行回收。 四、内存分配与回收策略 Java计数习题中所提倡的自动内存管理最终可以归结为自动化地解决两个问题：给对象分配内存以及回收分配给对象的内存。 对象的那内存分配，往大方向上讲，就是在堆上分配，对象主要分配在新生代的Eden区上，如果启动了本地线程分配缓冲，将按线程优先在TLAB上分配。少数情况下也可能会直接分配在老年代中，分配的规则并不是百分之百固定的，其细节取决于当前使用的时哪一种垃圾收集器组合，还有虚拟机中与内存相关的参数的设置。 1、对象优先在Eden分配大多数情况下， 对象字新生代Eden区中分配。当Eden区没有足够的空间进行分配时，虚拟机将发起一次Minor GC。 Minor GC和Full GC的区别？ 新生代GC（Minor GC）：指发生在新生代的垃圾收集动作，因为Java对象大多都具备朝生夕灭的特性，所以Minor GC非常频繁，一般回收速度也比较快。 老年代GC（Major GC / Full GC）：指发生在老年代的GC，出现了Major GC，经常会伴随至少一次的Minor GC（但非绝对的）。Major GC的速度一般会比Minor GC慢10杯以上。 2、大对象直接进入老年代所谓大对象是指，需要大量连续内存空间的Java对象，最经典的大对象就是那种很长的字符串及数组。 大对象堆虚拟机的内存分配来说就是一个坏消息，经常出现大对象容易导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来“安置”它们。 3、长期存活的对象将进入老年代虚拟机既然采用了分代收集的思想来管理内存，那内存回收时就必须能识别哪些对象应当放在新生代，哪些对象应放在老年代中。为了做到这点，虚拟机给每个对象定义了一个对象年龄（Age）计数器。如果对象在Eden出生并经过第一次Minor GC后仍然存活，并且能被Survivor容纳的话， 将被移动到Survivor空间中，并将对象年龄设为1。对象在Survivor区中每熬过一次Minor GC，年龄就增加1岁，当它的年龄增加到一定程度（15）时，就会被晋升到老年代中。 4、动态对象年龄判定为了能更好的地适应不同程序的内存状况，虚拟机并不能总是要求对象的年龄必须达到MaxTenuringThreshold才能晋升老年代，如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代。 5、空间分配担保在发生Minor GC时，虚拟机会检测之前每次晋升到老年代的平均大小是否大于老年代的生于空间大小，如果大于，则改为直接进行一次Full GC。如果小于，则查看HandlePromotionFailure设置是否允许担保时报；如果允许，那指挥进行Minor GC；如果不允许，则也要改为进行一次Full GC。 小结内存回收与垃圾收集器在很多时候都时影响系统性能、并发能力的主要因素之一，虚拟机之所以提供多种不同的垃圾收集器及大量的调节参数，是因为只有根据实际应用需要、实现方式选择最优的收集方式才能获取最好的性能。 没有固定收集器、参数组合，也没有最优的调优方法，虚拟机也没有什么必然的内存回收行为。 因此学习虚拟机内存只是，如果要到实践调优阶段，必须了解每个具体收集器的行为，优势和劣势、调节参数。 参考 图片来源，jvm垃圾收集（标记-清除,复制，标记-整理，分代）算法 周志明，深入理解Java虚拟机：JVM高级特性与最佳实践，机械工业出版社","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://www.cayzlh.com/tags/JVM/"},{"name":"《深入理解Java虚拟机》","slug":"《深入理解Java虚拟机》","permalink":"https://www.cayzlh.com/tags/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B/"}],"categories":[{"name":"书籍","slug":"书籍","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/"},{"name":"《深入理解Java虚拟机》","slug":"书籍/《深入理解Java虚拟机》","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B/"}]},{"title":"Java内存区域内存溢出异常","date":"2018-09-08T14:19:36.000Z","path":"2018/09/08/bc3decee.html","text":"Java与C++之间有一堵由内存动态分配和垃圾收集围城的高墙，墙外面的人想进来，墙里面的人却想出去. 概述对于从事C和C++程序开发的开发人员来说，在内存管理领域，他们既是拥有最高权力的皇帝，又是从事最基础工作的劳动人民——既拥有每一个对象的“所有权”，又担负着每一个对象的生命开始到中积极而的维护责任。 但对于Java程序员来说，在虚拟机的自动内存管理机制的帮助下，不再需要为每一个new操作去写配对的delete/free代码，而且不容易出现内存溢出和内存泄漏的问题，看起来由虚拟机管理内存一切都很美好。 不过，也正是因为Java程序员把内存控制的权力交给了Java虚拟机，一旦出现内存泄漏和溢出方面的问题，如果不了解虚拟机是怎么样使用内存的，那排查错误将会成为一项异常艰难的工作。 运行时数据区域 Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干不同的数据区域。这些区域都有各自的用途，以及创建和销毁的时间，有的区域随着虚拟机进程的启动而存在，有些区域则依赖用户线程的启动和结束而建立和销毁。 程序计数器程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看成是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里，字节码解释器工作时通过改变这个计数器的值来选取吓一跳需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的命令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。 如果线程正在执行的是一个Java方法， 这个计数器记录的是正在执行的虚拟机字节码指令地址；如果正在执行的是Natvie方法， 这个计数器值则为空（Undefined）。此内存区域是唯一一个在Java虚拟机规范中没有规定任何OOM情况的区域。 Java虚拟机栈Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。 虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同事创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。 每个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机中从入栈道出栈的过程。 经常所说的堆内存（Heap）和栈内存（Stack）是种比较粗糙的分发，Java内存区域的划分实际上会复杂很多。这里所指的“栈”就是虚拟机栈，或者说虚拟机栈中的局部变量表部分。 局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不等同于对象本身，根据不同的虚拟机实现，可能是指向一个对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与对象相关的位置）和returnAddress类型（指向一条字节码指令的地址）。 64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据只占用一个。 局部变量表所需要的内存空间在编译期间完成分配。当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 这个区域规定了两种异常状况： 如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常； 如果虚拟机栈可以动态扩展，当扩展到无法申请到足够的内存时会抛出OutOfMemoryError异常； 当前大部分的Java虚拟机都可以动态扩展，只不过Java虚拟机规范中也允许固定长度的虚拟机栈。 本地方法栈本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用时非常相似的。 区别 虚拟机栈为虚拟机执行Java方法（也就是字节码）服务 本地方法栈则是为虚拟机使用到的Native服务。 虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。有些虚拟机（Sun Hotspot）直接把本地方法栈与虚拟机栈合二为一。 与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。 Java堆 对于大多数应用来说，Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块。 Java虚拟机规范中描述：所有对象实例以及数组都要在堆上分配。 Java堆事被所有线程共享的一块内存区域，在虚拟机启动时创建。 此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都是在这里分配内存。 Java堆事垃圾收集器管理的主要区域，因此很多时候也称作“GC堆”（Garbage Collected Heap）。 Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。 从内存回收角度看，由于现在收集齐基本都是采用分代手机算法，所以Java堆中还可以细分为：新生代和老年代；再细分有Eden空间、From Survivor空间、To Survivor空间等。 从内存分配的角度看，线程共享的Java堆中可能划分出多个线程私有的分配缓冲区。 无论如何划分，都与存放内容无关，无论哪个区域，存储的都仍然是对象实例，进一步划分是为了更好的回收内存，或者更快的分配内存。主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制）。如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。 方法区方法区（Method Area）和Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机家在的类信息、常量、静态变量、即时编译后的代码等数据。 虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它有一个别名叫NonHeap（非堆），目的应该是与Java堆区分开来。 Java虚拟机规范堆这个区域的限制非常宽松，除了和Java堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集。 相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入了方法区就如永久代的名字一样“永久”存在了。 这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载，这个区域的回收“成绩”比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收的确是有必要的。 根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将会抛出OutOfMemoryError异常。 运行时常量池运行时常量池（Runtime Constant Pool）是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息时常量池（Constant Pool Table），用于存放编译期生成的各种字面亮和符号饮用，这部分内容将在类加载后存放到方法区运行时常量池中。 Java虚拟机对Class的每一部分的格式都有严格的规定，每一个字节用于存储哪种数据都必须符合规范上的要求，这样才会被虚拟机认可、装载和执行。但是对于常量池，Java虚拟机规范没有做任何细节的要求。一般来说，除了保存Class文件中描述的符号引用外，还会把翻译出来的直接饮用也存储在运行时常量池中。 运行时常量池对于Class文件常量池的另外一个重要特征是具有动态性，Java语言并不要求常量一定只能在编译期产生，也就是并非预置入Class文件中常量池的内容才能进入方法区运行时的常量池，运行期间也可能将新的常量放入池中，这种特性被开发人员利用的比较多的便是String类的intern()方法。 public String intern(); 返回字符串对象的规范化表示形式。 一个初始时为空的字符串池，它由类 String 私有地维护。 当调用 intern 方法时，如果池已经包含一个等于此 String 对象的字符串（该对象由 equals(Object) 方法确定），则返回池中的字符串。否则，将此 String 对象添加到池中，并且返回此 String 对象的引用。 它遵循对于任何两个字符串 s 和 t，当且仅当 s.equals(t) 为 true 时，s.intern() == t.intern() 才为 true。 所有字面值字符串和字符串赋值常量表达式都是内部的。 返回： 一个字符串，内容与此字符串相同，但它保证来自字符串池中。 运行时常量池是方法区的一部分，自然会收到方法区内的限制，当常量池无法再申请到内存时会抛出OutOfMemoryError异常。 直接内存直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用，而且也可能导致OutOfMemoryError异常出现。 本机内存的分配不会收到Java堆大小的限制，但是，既然是内存，则肯定还是会收到本机总内存（RAM及SWAP区或者分页文件）的大小及处理器寻址空间的限制。分配虚拟机参数时，容易忽略掉直接内存，使得各个内存区域的总和大于物理内存限制，从而导致动态扩展时出现OutOfMemoryError异常。 对象访问对象的访问在Java语言中无处不在，时最普通的程序行为，但即使时最简单的访问，也会去涉及Java栈、Java堆、方法区这三个最重要的内存区域之间的关联关系，如： Object obj = new Object(); 假设这句代码出现在方法体中： “Object obj”这部分的语义将会反映到Java栈的本地变量表中，作为一个reference类型数据出现。 “new Object( )”这部分语义将会反映到Java堆中 形成一块存储了Object类型所有实例数据值（Instance Data，对象中各个实例字段的数据）的结构化内存，根据具体类型以及虚拟机实现的对象内存布局的不同，这块内存的长度时不固定的。Java堆中还必须包含能查找到此对象类型数据（如对象类型、父类、实现的接口、方法等）的地址信息，这些类型数据则存储在方法区中。 不同虚拟机实现的对象访问方式会有所不同。主流的访问方式有两种： 使用句柄 Java堆中会划分出一块内存作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据和类型数据各自的具体地址信息。 )/2.png) 句柄访问方式最大的好处就是reference中存储的事稳定的句柄地址，在对象被移动（垃圾收集时移动对象时非常普遍的行为）只会改变句柄中的实例数据指针，而reference本身不需要被修改。 直接指针 Java堆对象的布局中必须考虑如何放置访问类型数据的相关信息，reference中直接存储的就是对象地址。 指针访问方式在最大好处就是速度更快，它节省了一次指针定位的时间开销，由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本。 重现OOM异常在Java虚拟机规范的描述中，除了程序计数器外，虚拟机内存的其他几个运行时区域都有发生OOM异常的可能。 Java堆溢出Java堆用于存储对象实例，我们只要不断的创建对象，并保证GC Roots到对象之间有可达路径来避免垃圾回收机制清除这些对象，就会在对象数量达到最大堆容量限制后产生内存溢出异常。 在IDE（如IDEA）里设置JVM参数： -Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError public class HeapOOM { static class OOMObject { } public static void main(Stringp[] args) { List&lt;OOMObject> list = new ArrayList&lt;OOMObject>; while(true) { list.add(new OOMObject()); } } } 运行代码将会抛出：java.lang.OutOfMemoryError: Java heap space. 要解决这些问题，重点是确认内存中的对象是否时必要的，也就是要先分清楚到底时出现了内存泄漏还是内存溢出。 如果时内存泄漏，可进一步通过工具查看泄漏对象到GC Roots的引用链。于是就能找到泄漏对象是通过怎样的路径与GC Roots相关联并导致垃圾收集器无法自动回收它们的。 如果不存在内存泄漏，那就应该检查虚拟机堆参数（-Xmx 和 -Xms）与机器无力内存对比是否还可以调大，从代码上检查是否存在某些对象的生命周期过长、持有状态时间过长的情况。尝试减少程序运行期的内存消耗。 虚拟机栈和本地方法栈溢出 对于HotSpot来说，-Xoss参数（设置本地方法栈大小）虽然存在，但实际上是无效的，栈容量只由-Xss参数设定。 如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出StackOverflowError异常。 如果虚拟机在拓展栈时无法申请到足够的内存空间，则抛出OutOfMemoryError异常。 在IDE（如IDEA）里设置JVM参数： -Xss128k public class JavaVMStackSOF { private int stackLength = 1; public void stackLeak() { stackLength++; stackLeak(); } public static void main(String[] args) throws Throwable { JavaVMStackSOF oom = new JavaVMStackSOF(); try { oom.stackLeak(); } catch (Throwable e) { System.out.println(\"stack length:\" + ooo.stackLength); throw e; } } } 运行结果： Stack length:2402 Exception in thread “main” java.lang.StackOverflowError ··········后续异常栈信息省略。 结果证明：在单个线程下，无论是由于栈帧太大，还是虚拟机栈容量太小，当内存无法分配的时候， 虚拟机抛出的都是StackOverflowError异常。\u0010 在IDE（如IDEA）里设置JVM参数： -Xss2M public class JavaVMStackOOM { private void dontStop() { while (true) { } } public void stackLeakThread() { while (true) { Thread thread = new Thread(new Runnable() { @Override public void run () { dontStop(); } }); thread.start(); } } public static void main(String[] args) throws Throwable { JavaVMStackOOM oom = new JavaVMStackOOM(); oom.stackLeakThread(); } } 注：如果要运行这顿啊代码，记得要先保存当前的工作，由于在Windows平台的虚拟机中，Java的线程是映射到操作系统的内核线程上的，所以上述代码执行时有较大的风险，可能会导致操作系统假死。 运行结果： Exception in thread “main” java.lang.OutOfMemoryError: unable to create new native thread 实验证明： 通过不断的建立线程的方式可以产生内存溢出异常，但是，这样产生的内存溢出异常与栈空间是否足够大并不存在任何联系，或者准确的说，在这种情况下，给每个线程的栈分配的内存越大，反而越容易产生内存溢出异常。 如果是建立过多线程导致的内存溢出，在不能减少线程数或者更换64位虚拟机的情况下，就只能通过减少最大堆和减少栈容量来换取更多的线程。如果没有这方面的经验，这种通过“减少内存”的手段来解决内存溢出的方式会比较难以想到。 运行时常量池溢出如果要向运行时常量池中添加内容， 嘴贱的做法就是使用String.intern()这个Native方法。该方法的作用是：如果池中已经包含一个等于此String对象的字符串，则返代表池中这个字符串的String对象；否则，将此String对象包含的字符串的添加到常量池中，并且返回此String对象的引用。 在IDE（如IDEA）里设置JVM参数： -XXPermSize=10M -XX:MaxPermSize=10M public class RuntimeConstantPoolOOM { public static void main(String[] args) { // 使用List保存着常量池引用，避免Full GC回收常量池行为 List&lt;String> list = new ArrayList&lt;String>(); int i = 0; while (true) { list.add(String.valueOf(i++).intern()); } } } 运行结果： Exception in thread “main” java.lang.OutOfMemoryError: PermGen space 实验结果： 运行时常量池溢出，在OOM后面跟随着的提示信息是PermGen space，说明运行时常量池属于方法区（HotSpot虚拟机中的永久代）的一部分。 方法区溢出方法区用于存放Class的相关信息，如类名、访问修饰符、常量池、字段描述、方法描述等。这个实验需要通过生成大量的动态类来实现，使用CGLib这类字节码技术，增强的类越多，就需要越大的方法区来保证动态生成的Class可以加载如内存。 在IDE（如IDEA）里设置JVM参数： -XX:PermSize=10M -XX:MaxPermSize=10M public class JavaMethodAreaOOM { public static void main(String[] args) { while (true) { Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(OOMObject.class); enhancer.setUseCache(false); enhancer.setCallback(new MethodInterceptor() { public Object intercept(Object object, Method method, Object[] args, MethodProxy mhodProxy) throws Throwable { return proxy.invokeSuper(obj, args); } }); enhancer.create(); } } static class OOMObject(); } 运行结果： Caused by: java.lang.OutOfMemoryError: PermGen space 实验结果： 方法区溢出也是一种常见的内存溢出异常，一个类如果被垃圾收集器回收掉，判断条件是非常苛刻的。在经常动态生成大量Class的应用中，需要特别注意类的回收状态。 本机直接内存溢出通过反射获取Unsafe实例进行内存分配（Unsafe类的getUnSafe()方法限制了只有引导类加载器才会返回实例，也就是设计者希望只有rt.jar中的类可以使用Unsafe的功能）。因为，虽然使用DirectByteBuffer分配内存也会抛出内存溢出异常，但它抛出异常时并没有真正向操作系统申请分配内存，而是通过计算得知内存无法分配，于是手动抛出异常，真正申请分配内存的方法是unsafe.allocateMemory()。 在IDE（如IDEA）里设置JVM参数： -Xmx20M -XX:MaxDirectMemorySize=10M public class DirectMemoryOOM { private static final int _1MB = 1024 * 1024; public static void main(String[] args) throws Exception { Field unsafeField = Unsafe.class.getDeclaredFields()[0]; unsafeField.setAccessible(true); Unsafe unsafe = (Unsafe) unsafeField.get(null); while (true) { unsafe.allocateMemory(_1MB); } } } 运行结果： Exception in thread “main” java.lang.OutOfMemoryError 小结 内存是如何划分的 哪部分区域、什么样的代码和操作可能导致内存溢出异常 虽然Java有垃圾收集机制，但内存溢出异常离我们并不遥远，本章讲解了解了各个区域出现内存溢出异常的原因。 参考 周志明，深入理解Java虚拟机：JVM高级特性与最佳实践，机械工业出版社","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://www.cayzlh.com/tags/JVM/"},{"name":"《深入理解Java虚拟机》","slug":"《深入理解Java虚拟机》","permalink":"https://www.cayzlh.com/tags/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B/"}],"categories":[{"name":"书籍","slug":"书籍","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/"},{"name":"《深入理解Java虚拟机》","slug":"书籍/《深入理解Java虚拟机》","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B/"}]},{"title":"Java集合框架","date":"2018-09-05T14:20:51.000Z","path":"2018/09/05/9753a2e.html","text":"集合框架底层数据结构总结CollectionList Arraylist： Object数组 Vector： Object数组 LinkedList： 双向循环链表 Set HashSet（无序，唯一）: 基于 HashMap 实现的，底层采用 HashMap 来保存元素 LinkedHashSet： LinkedHashSet 继承与 HashSet，并且其内部是通过 LinkedHashMap 来实现的。有点类似于我们之前说的LinkedHashMap 其内部是基于 Hashmap 实现一样，不过还是有一点点区别的。 TreeSet（有序，唯一）： 红黑树(自平衡的排序二叉树。) Map HashMap： JDK1.8之前HashMap由数组+链表组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）.JDK1.8以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间 LinkedHashMap: LinkedHashMap 继承自 HashMap，所以它的底层仍然是基于拉链式散列结构即由数组和链表或红黑树组成。另外，LinkedHashMap 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。 HashTable: 数组+链表组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的 TreeMap: 红黑树（自平衡的排序二叉树） 集合框架体系如图 集合接口 集合框架定义了一些接口。本节提供了每个接口的概述： 序号 接口描述 1 Collection 接口 Collection 是最基本的集合接口，一个 Collection 代表一组 Object，即 Collection 的元素, Java不提供直接继承自Collection的类，只提供继承于的子接口(如List和set)。Collection 接口存储一组不唯一，无序的对象。 2 List 接口 List接口是一个有序的 Collection使用此接口能够精确的控制每个元素插入的位置，能够通过索引(元素在List中位置，类似于数组的下标)来访问List中的元素，第一个元素的索引为 0，而且允许有相同的元素。List 接口存储一组不唯一，有序（插入顺序）的对象。 3 Set Set 具有与 Collection 完全一样的接口，只是行为上不同，Set 不保存重复的元素。Set 接口存储一组唯一，无序的对象。 4 SortedSet 继承于Set保存有序的集合。 5 Map Map 接口存储一组键值对象，提供key（键）到value（值）的映射。 6 Map.Entry 描述在一个Map中的一个元素（键/值对）。是一个Map的内部类。 7 SortedMap 继承于 Map，使 Key 保持在升序排列。 8 Enumeration 这是一个传统的接口和定义的方法，通过它可以枚举（一次获得一个）对象集合中的元素。这个传统接口已被迭代器取代。 Set和List的区别 Set 接口实例存储的是无序的，不重复的数据。List 接口实例存储的是有序的，可以重复的元素。 Set检索效率低下，删除和插入效率高，插入和删除不会引起元素位置改变 &lt;实现类有HashSet,TreeSet&gt;。 List和数组类似，可以动态增长，根据实际存储的数据的长度自动增长List的长度。查找元素效率高，插入删除效率低，因为会引起其他元素位置改变 &lt;实现类有ArrayList,LinkedList,Vector&gt; 。 集合实现类（集合类） Java提供了一套实现了Collection接口的标准集合类。其中一些是具体类，这些类可以直接拿来使用，而另外一些是抽象类，提供了接口的部分实现。 标准集合类汇总于下表： 序号 类描述 1 AbstractCollection 实现了大部分的集合接口。 2 AbstractList 继承于AbstractCollection 并且实现了大部分List接口。 3 AbstractSequentialList 继承于 AbstractList ，提供了对数据元素的链式访问而不是随机访问。 4 LinkedList 该类实现了List接口，允许有null（空）元素。主要用于创建链表数据结构，该类没有同步方法，如果多个线程同时访问一个List，则必须自己实现访问同步，解决方法就是在创建List时候构造一个同步的List。例如：Listlist=Collections.synchronizedList(newLinkedList(...));LinkedList 查找效率低。 5 ArrayList 该类也是实现了List的接口.实现了可变大小的数组，随机访问和遍历元素时，提供更好的性能。该类也是非同步的,在多线程的情况下不要使用。ArrayList 增长当前长度的50%，插入删除效率低。 6 AbstractSet 继承于AbstractCollection 并且实现了大部分Set接口。 7 HashSet 该类实现了Set接口，不允许出现重复元素，不保证集合中元素的顺序，允许包含值为null的元素，但最多只能一个。 8 LinkedHashSet 具有可预知迭代顺序的 Set 接口的哈希表和链接列表实现。 9 TreeSet 该类实现了Set接口，可以实现排序等功能。 10 AbstractMap 实现了大部分的Map接口。 11 HashMap HashMap 是一个散列表，它存储的内容是键值对(key-value)映射。 该类实现了Map接口，根据键的HashCode值存储数据，具有很快的访问速度，最多允许一条记录的键为null，不支持线程同步。 12 TreeMap 继承了AbstractMap，并且使用一颗树。 13 WeakHashMap 继承AbstractMap类，使用弱密钥的哈希表。 14 LinkedHashMap 继承于HashMap，使用元素的自然顺序对元素进行排序. 15 IdentityHashMap 继承AbstractMap类，比较文档时使用引用相等。 通过java.util包中定义的类，如下所示： 序号 类描述 1 Vector 该类和ArrayList非常相似，但是该类是同步的，可以用在多线程的情况，该类允许设置默认的增长长度，默认扩容方式为原来的2倍。 2 Stack 栈是Vector的一个子类，它实现了一个标准的后进先出的栈。 3 Dictionary Dictionary 类是一个抽象类，用来存储键/值对，作用和Map类相似。 4 Hashtable Hashtable 是 Dictionary(字典) 类的子类，位于 java.util 包中。 5 Properties Properties 继承于 Hashtable，表示一个持久的属性集，属性列表中每个键及其对应值都是一个字符串。 6 BitSet 一个Bitset类创建一种特殊类型的数组来保存位值。BitSet中数组大小会随需要增加。 集合算法集合框架定义了几种算法，可用于集合和映射。这些算法被定义为集合类的静态方法。 在尝试比较不兼容的类型时，一些方法能够抛出 ClassCastException异常。当试图修改一个不可修改的集合时，抛出UnsupportedOperationException异常。 集合定义三个静态的变量：EMPTY_SET，EMPTY_LIST，EMPTY_MAP的。这些变量都不可改变。 序号 算法描述 1 Collection Algorithms 这里是一个列表中的所有算法实现。 小结 Java集合框架为程序员提供了预先包装的数据结构和算法来操纵他们。 集合是一个对象，可容纳其他对象的引用。集合接口声明对每一种类型的集合可以执行的操作。 集合框架的类和接口均在java.util包中。 任何对象加入集合类后，自动转变为Object类型，所以在取出的时候，需要进行强制类型转换。 Arraylist 与 LinkedList 异同 1. 是否保证线程安全： ArrayList 和 LinkedList 都是不同步的，也就是不保证线程安全； 2. 底层数据结构： Arraylist 底层使用的是Object数组；LinkedList 底层使用的是双向循环链表数据结构； 3. 插入和删除是否受元素位置的影响： ① ArrayList 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行add(E e)方法的时候， ArrayList 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是O(1)。但是如果要在指定位置 i 插入和删除元素的话（add(int index, E element)）时间复杂度就为 O(n-i)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。 ② LinkedList 采用链表存储，所以插入，删除元素时间复杂度不受元素位置的影响，都是近似 O（1）而数组为近似 O（n）。 4. 是否支持快速随机访问： LinkedList 不支持高效的随机元素访问，而ArrayList 实现了RandmoAccess 接口，所以有随机访问功能。快速随机访问就是通过元素的序号快速获取元素对象(对应于get(int index)方法)。 5. 内存空间占用： ArrayList的空 间浪费主要体现在在list列表的结尾会预留一定的容量空间，而LinkedList的空间花费则体现在它的每一个元素都需要消耗比ArrayList更多的空间（因为要存放直接后继和直接前驱以及数据）。 数据结构基础之双向链表: 双向链表也叫双链表，是链表的一种，它的每个数据结点中都有两个指针，分别指向直接后继和直接前驱。所以，从双向链表中的任意一个结点开始，都可以很方便地访问它的前驱结点和后继结点。一般我们都构造双向循环链表，如下图所示，同时下图也是LinkedList 底层使用的是双向循环链表数据结构。 ArrayList 与 Vector 区别Vector类的所有方法都是同步的。可以由两个线程安全地访问一个Vector对象、但是一个线程访问Vector的话代码要在同步操作上耗费大量的时间。 Arraylist不是同步的，所以在不需要保证线程安全时时建议使用Arraylist。 HashMap 和 Hashtable 的区别 线程是否安全： HashMap 是非线程安全的，HashTable 是线程安全的；HashTable 内部的方法基本都经过 synchronized 修饰。（如果你要保证线程安全的话就使用 ConcurrentHashMap 吧！）； 效率： 因为线程安全的问题，HashMap 要比 HashTable 效率高一点。另外，HashTable 基本被淘汰，不要在代码中使用它； 对Null key 和Null value的支持： HashMap 中，null 可以作为键，这样的键只有一个，可以有一个或多个键所对应的值为 null。。但是在 HashTable 中 put 进的键值只要有一个 null，直接抛出 NullPointerException。 初始容量大小和每次扩充容量大小的不同 ： ①创建时如果不指定容量初始值，Hashtable 默认的初始大小为11，之后每次扩充，容量变为原来的2n+1。HashMap 默认的初始化大小为16。之后每次扩充，容量变为原来的2倍。②创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充为2的幂次方大小。也就是说 HashMap 总是使用2的幂作为哈希表的大小,后面会介绍到为什么是2的幂次方。 底层数据结构： JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间。Hashtable 没有这样的机制。 HashSet 和 HashMap 区别 ConcurrentHashMap 和 Hashtable 的区别ConcurrentHashMap 和 Hashtable 的区别主要体现在实现线程安全的方式上不同。 底层数据结构： JDK1.7的 ConcurrentHashMap 底层采用 分段的数组+链表 实现，JDK1.8 采用的数据结构跟HashMap1.8的结构一样，数组+链表/红黑二叉树。Hashtable 和 JDK1.8 之前的 HashMap 的底层数据结构类似都是采用 数组+链表 的形式，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的； 实现线程安全的方式（重要）： ① 在JDK1.7的时候，ConcurrentHashMap（分段锁） 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。（默认分配16个Segment，比Hashtable效率提高16倍。） 到了 JDK1.8 的时候已经摒弃了Segment的概念，而是直接用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。（JDK1.6以后 对 synchronized锁做了很多优化） 整个看起来就像是优化过且线程安全的 HashMap，虽然在JDK1.8中还能看到 Segment 的数据结构，但是已经简化了属性，只是为了兼容旧版本；② Hashtable(同一把锁) :使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。 参考文献 https://juejin.im/post/5b7e955be51d4538de11550c 菜鸟教程","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"}]},{"title":"Redis基础知识总结","date":"2018-09-04T07:21:32.000Z","path":"2018/09/04/cd7b78e0.html","text":"什么是redis?Redis 是一个基于内存的高性能key-value数据库。 Reids的特点Redis本质上是一个Key-Value类型的内存数据库，很像memcached，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据flush到硬盘上进行保存。 因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。 Redis的出色之处不仅仅是性能，Redis最大的魅力是支持保存多种数据结构，此外单个value的最大限制是1GB，不像 memcached只能保存1MB的数据，因此Redis可以用来实现很多有用的功能。 比方说用他的List来做FIFO双向链表，实现一个轻量级的高性 能消息队列服务，用他的Set可以做高性能的tag系统等等。另外Redis也可以对存入的Key-Value设置expire时间，因此也可以被当作一 个功能加强版的memcached来用。 Redis的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。 使用redis有哪些好处 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1) 支持丰富数据类型，支持string，list，set，sorted set，hash 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除 redis 支持哪些数据结构支持多种类型的数据结构，如字符串（String），散列（Hash），列表（List），集合（Set），有序集合（Sorted Set或者是ZSet）与范围查询，Bitmaps，Hyperloglogs 和地理空间（Geospatial）索引半径查询。其中常见的数据结构类型有：String、List、Set、Hash、ZSet这5种。 Java中对Redis数据类型的操作Stringpublic class StringTest { public Jedis jedis = JedisPoolUtil.getJedis(); @Test //添加和获取 public void fun(){ jedis.set(\"num\",\"1\"); System.out.println(jedis.get(\"num\")); } @Test //删除值 public void fun1(){ jedis.del(\"num\"); System.out.println(jedis.get(\"num\")); } @Test //自减和自减 public void fun2(){ jedis.set(\"num\",\"1\"); System.out.println(jedis.get(\"num\")); jedis.decr(\"num\"); System.out.println(jedis.get(\"num\")); jedis.incr(\"num\"); jedis.incr(\"num\"); System.out.println(jedis.get(\"num\")); } @Test //加上/减去 一个数 //incrBy 返回的是修改之后的值如果原值是字符串不是数字，则会抛出异常 public void fun3(){ Long num = jedis.incrBy(\"num\", 3); System.out.println(num); jedis.decrBy(\"num\",10); System.out.println(jedis.get(\"num\")); jedis.set(\"name\",\"caopengfei\"); //jedis.decrBy(\"name\",1); } @Test //字符串拼接 public void fun4(){ Long len = jedis.append(\"name\", \"123\"); System.out.println(len); System.out.println(jedis.get(\"name\")); } } Hashpublic class HashTest { public Jedis jedis = JedisPoolUtil.getJedis(); // hash 操作的是map对象 // 适合存储键值对象的信息 @Test //存值 参数第一个变量的名称， map键名(key)， map键值(value) // 调用hset public void fun() { Long num = jedis.hset(\"hash1\", \"username\", \"caopengfei\"); System.out.println(num); String hget = jedis.hget(\"hash1\", \"username\"); System.out.println(hget); } @Test //也可以存多个key // 调用hmset public void fun1() { Map&lt;String, String> map = new HashMap&lt;String, String>(); map.put(\"username\", \"caopengfei\"); map.put(\"age\", \"25\"); map.put(\"sex\", \"男\"); String res = jedis.hmset(\"hash2\", map); System.out.println(res);//ok } @Test //获取hash中所有的值 public void fun2() { Map&lt;String, String> map2 = new HashMap&lt;String, String>(); map2 = jedis.hgetAll(\"hash2\"); System.out.println(map2); } @Test // 删除hash中的键 可以删除一个也可以删除多个，返回的是删除的个数 public void fun3() { Long num = jedis.hdel(\"hash2\", \"username\", \"age\"); System.out.println(num); Map&lt;String, String> map2 = new HashMap&lt;String, String>(); map2 = jedis.hgetAll(\"hash2\"); System.out.println(map2); } @Test //增加hash中的键值对 public void fun4() { Map&lt;String, String> map2 = new HashMap&lt;String, String>(); map2 = jedis.hgetAll(\"hash2\"); System.out.println(map2); jedis.hincrBy(\"hash2\", \"age\", 10); map2 = jedis.hgetAll(\"hash2\"); System.out.println(map2); } @Test //判断hash是否存在某个值 public void fun5() { System.out.println(jedis.hexists(\"hash2\", \"username\")); System.out.println(jedis.hexists(\"hash2\", \"age\")); } @Test //获取hash中键值对的个数 public void fun6() { System.out.println(jedis.hlen(\"hash2\")); } // 获取一个hash中所有的key值 @Test public void fun7() { Set&lt;String> hash2 = jedis.hkeys(\"hash2\"); System.out.println(hash2); } // 获取所有的value值 @Test public void fun8() { List&lt;String> hash2 = jedis.hvals(\"hash2\"); System.out.println(hash2); } } List操作public void testList() { jedis.flushDB(); System.out.println(\"===========添加一个list===========\"); jedis.lpush(\"collections\", \"ArrayList\", \"Vector\", \"Stack\", \"HashMap\", \"WeakHashMap\", \"LinkedHashMap\"); jedis.lpush(\"collections\", \"HashSet\"); jedis.lpush(\"collections\", \"TreeSet\"); jedis.lpush(\"collections\", \"TreeMap\"); System.out.println(\"collections的内容：\"+jedis.lrange(\"collections\", 0, -1));//-1代表倒数第一个元素，-2代表倒数第二个元素 System.out.println(\"collections区间0-3的元素：\"+jedis.lrange(\"collections\",0,3)); System.out.println(\"===============================\"); // 删除列表指定的值 ，第二个参数为删除的个数（有重复时），后add进去的值先被删，类似于出栈 System.out.println(\"删除指定元素个数：\"+jedis.lrem(\"collections\", 2, \"HashMap\")); System.out.println(\"collections的内容：\"+jedis.lrange(\"collections\", 0, -1)); System.out.println(\"删除下表0-3区间之外的元素：\"+jedis.ltrim(\"collections\", 0, 3)); System.out.println(\"collections的内容：\"+jedis.lrange(\"collections\", 0, -1)); System.out.println(\"collections列表出栈（左端）：\"+jedis.lpop(\"collections\")); System.out.println(\"collections的内容：\"+jedis.lrange(\"collections\", 0, -1)); System.out.println(\"collections添加元素，从列表右端，与lpush相对应：\"+jedis.rpush(\"collections\", \"EnumMap\")); System.out.println(\"collections的内容：\"+jedis.lrange(\"collections\", 0, -1)); System.out.println(\"collections列表出栈（右端）：\"+jedis.rpop(\"collections\")); System.out.println(\"collections的内容：\"+jedis.lrange(\"collections\", 0, -1)); System.out.println(\"修改collections指定下标1的内容：\"+jedis.lset(\"collections\", 1, \"LinkedArrayList\")); System.out.println(\"collections的内容：\"+jedis.lrange(\"collections\", 0, -1)); System.out.println(\"===============================\"); System.out.println(\"collections的长度：\"+jedis.llen(\"collections\")); System.out.println(\"获取collections下标为2的元素：\"+jedis.lindex(\"collections\", 2)); System.out.println(\"===============================\"); jedis.lpush(\"sortedList\", \"3\",\"6\",\"2\",\"0\",\"7\",\"4\"); System.out.println(\"sortedList排序前：\"+jedis.lrange(\"sortedList\", 0, -1)); System.out.println(jedis.sort(\"sortedList\")); System.out.println(\"sortedList排序后：\"+jedis.lrange(\"sortedList\", 0, -1)); } Set操作/* * Set集合，和List类的区别就是 * set中不会出现重复的数据 * 他可以进行聚合操作效率比较高 * 其余的操作基本上和list相同 * * */ public class SetTest { public Jedis jedis = JedisPoolUtil.getJedis(); @Test /*添加元素删除元素*/ public void fun(){ Long num = jedis.sadd(\"myset\", \"a\", \"a\", \"b\",\"abc\"); System.out.println(num); } @Test /*获得元素*/ public void fun1(){ Set&lt;String> myset = jedis.smembers(\"myset\"); System.out.println(myset); } @Test /*移除元素*/ public void fun2(){ jedis.srem(\"myset\",\"a\",\"b\"); Set&lt;String> myset = jedis.smembers(\"myset\"); System.out.println(myset); } @Test //判断是否这个set中存在某个值 public void fun3(){ Boolean sismember = jedis.sismember(\"myset\", \"a\"); System.out.println(sismember); } @Test //获得A-B 获得差集合 public void fun4(){ jedis.sadd(\"myset1\",\"123\",\"32\",\"abc\",\"def\",\"123456\",\"sdfasd\"); jedis.sadd(\"myset2\",\"abc\",\"345\",\"123\",\"fda\"); Set&lt;String> sdiff = jedis.sdiff(\"myset1\", \"myset2\"); System.out.println(sdiff); } @Test //获得交集 public void fun5(){ Set&lt;String> sinter = jedis.sinter(\"myset1\", \"myset2\"); System.out.println(sinter); } @Test // 获得并集合 public void fun6(){ Set&lt;String> sunion = jedis.sunion(\"myset1\", \"myset2\"); System.out.println(sunion); } @Test // 成员数量 public void fun7(){ System.out.println(jedis.scard(\"myset1\")); } @Test // 获得随机的一个成员 public void fun8(){ System.out.println(jedis.srandmember(\"myset1\")); } @Test // 将相差的成员放到一个新的set中同理交集和并集都可以后面均 // 加上一个store即可 // 并返回新的长度 public void fun9(){ System.out.println(jedis.sdiffstore(\"myset3\",\"myset1\",\"myset2\")); System.out.println(jedis.smembers(\"myset3\")); } } SortedSet 操作/* 和set极为的类似，他们是字符串的集合，没有重复的数据 差别是sortedset每个成员中都会有一个分数（score）与之关联 ，redis正是通过分数来为集合中的成员进行从小到大的排序 sortedset中数据必须单一但是他的score可以是重复的 */ public class SortedsetTest { public Jedis jedis = JedisPoolUtil.getJedis(); // 添加元素 @Test public void fun(){ jedis.zadd(\"mysort\",100.0, \"zhangsan\"); jedis.zadd(\"mysort\",200.0,\"lisi\"); jedis.zadd(\"mysort\",50.0,\"wangwu\"); Map&lt;String ,Double>map = new HashMap&lt;String ,Double>(); map.put(\"mutouliu\",70.0); jedis.zadd(\"mysort\",map); Set&lt;String> mysort = jedis.zrange(\"mysort\", 0, -1); System.out.println(mysort); Set&lt;String> mysort1 = jedis.zrange(\"mysort\", 1, 2); System.out.println(mysort1); } } redis相比memcached有哪些优势 memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型 redis的速度比memcached快很多 redis可以持久化其数据 Memcache与Redis的区别都有哪些 存储方式 Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。 Redis有部份存在硬盘上，这样能保证数据的持久性。 数据支持类型 Memcache对数据类型支持相对简单。 Redis有复杂的数据类型。 使用底层模型不同 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。 Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。 redis常见性能问题和解决方案: Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。 Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。 Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。 Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内 mySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据 redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略（回收策略）。 redis 提供 6种数据淘汰策略： volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据 为什么redis需要把所有数据放到内存中Redis为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以redis具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘I/O速度为严重影响redis的性能。在内存越来越便宜的今天，redis将会越来越受欢迎。 如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。 Redis是单进程单线程的redis利用队列技术将并发访问变为串行访问，消除了传统数据库串行控制的开销 redis的并发竞争问题如何解决Redis为单进程单线程模式，采用队列模式将并发访问变为串行访问。Redis本身没有锁的概念，Redis对于多个客户端连接并不存在竞争，但是在Jedis客户端对Redis进行并发访问时会发生连接超时、数据转换错误、阻塞、客户端关闭连接等问题，这些问题均是由于客户端连接混乱造成。 对此有2种解决方法： 1.客户端角度，为保证每个客户端间正常有序与Redis进行通信，对连接进行池化，同时对客户端读写Redis操作采用内部锁synchronized。 2.服务器角度，利用setnx实现锁。 注：对于第一种，需要应用程序自己处理资源的同步，可以使用的方法比较通俗，可以使用synchronized也可以使用lock；第二种需要用到Redis的setnx命令，但是需要注意一些问题。 redis持久化的几种方式快照（snapshots）缺省情况情况下，Redis把数据快照存放在磁盘上的二进制文件中，文件名为dump.rdb。你可以配置Redis的持久化策略，例如数据集中每N秒钟有超过M次更新，就将数据写入磁盘；或者你可以手工调用命令SAVE或BGSAVE。 工作原理 Redis forks. 子进程开始将数据写到临时RDB文件中。 当子进程完成写RDB文件，用新文件替换老文件。 这种方式可以使Redis使用copy-on-write技术。 AOF快照模式并不十分健壮，当系统停止，或者无意中Redis被kill掉，最后写入Redis的数据就会丢失。 这对某些应用也许不是大问题，但对于要求高可靠性的应用来说，Redis就不是一个合适的选择。Append-only文件模式是另一种选择。你可以在配置文件中打开AOF模式 虚拟内存方式当你的key很小而value很大时,使用VM的效果会比较好.因为这样节约的内存比较大. 当你的key不小时,可以考虑使用一些非常方法将很大的key变成很大的value,比如你可以考虑将key,value组合成一个新的value. vm-max-threads这个参数,可以设置访问swap文件的线程数,设置最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的.可能会造成比较长时间的延迟,但是对数据完整性有很好的保证. 自己测试的时候发现用虚拟内存性能也不错。如果数据量很大，可以考虑分布式或者其他数据库。 redis的缓存失效策略和主键失效机制作为缓存系统都要定期清理无效数据，就需要一个主键失效和淘汰策略. 在Redis当中，有生存期的key被称为volatile。在创建缓存时，要为给定的key设置生存期，当key过期的时候（生存期为0），它可能会被删除。 1、影响生存时间的一些操作生存时间可以通过使用 DEL 命令来删除整个 key 来移除，或者被 SET 和 GETSET 命令覆盖原来的数据，也就是说，修改key对应的value和使用另外相同的key和value来覆盖以后，当前数据的生存时间不同。 比如说，对一个 key 执行INCR命令，对一个列表进行LPUSH命令，或者对一个哈希表执行HSET命令，这类操作都不会修改 key 本身的生存时间。另一方面，如果使用RENAME对一个 key 进行改名，那么改名后的 key的生存时间和改名前一样。 RENAME命令的另一种可能是，尝试将一个带生存时间的 key 改名成另一个带生存时间的 another_key ，这时旧的 another_key (以及它的生存时间)会被删除，然后旧的 key 会改名为 another_key ，因此，新的 another_key 的生存时间也和原本的 key 一样。使用PERSIST命令可以在不删除 key 的情况下，移除 key 的生存时间，让 key 重新成为一个persistent key 。 如何更新生存时间可以对一个已经带有生存时间的 key 执行EXPIRE命令，新指定的生存时间会取代旧的生存时间。过期时间的精度已经被控制在1ms之内，主键失效的时间复杂度是O（1），EXPIRE和TTL命令搭配使用，TTL可以查看key的当前生存时间。设置成功返回 1；当 key 不存在或者不能为 key 设置生存时间时，返回 0 。 最大缓存配置：在 redis 中，允许用户设置最大使用内存大小，server.maxmemory默认为0，没有指定最大缓存，如果有新的数据添加，超过最大内存，则会使redis崩溃，所以一定要设置。redis 内存数据集大小上升到一定大小的时候，就会实行数据淘汰策略。 redis 提供 6种数据淘汰策略： volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据 注意这里的6种机制，volatile和allkeys规定了是对已设置过期时间的数据集淘汰数据还是从全部数据集淘汰数据，后面的lru、ttl以及random是三种不同的淘汰策略，再加上一种no-enviction永不回收的策略。 使用策略规则： 如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用allkeys-lru 如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用allkeys-random 三种数据淘汰策略：ttl和random比较容易理解，实现也会比较简单。主要是Lru最近最少使用淘汰策略，设计上会对key 按失效时间排序，然后取最先失效的key进行淘汰 redis 适合的场景Redis最适合所有数据in-momory的场景，虽然Redis也提供持久化功能，但实际更多的是一个disk-backed的功能，跟传统意义上的持久化有比较大的差别，那么可能大家就会有疑问，似乎Redis更像一个加强版的Memcached，那么何时使用Memcached，何时使用Redis呢? 如果简单地比较Redis与Memcached的区别，大多数都会得到以下观点： Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 会话缓存（Session Cache）最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。当维护一个不是严格要求一致性的缓存时，如果用户的购物车信息全部丢失，大部分人都会不高兴的，现在，他们还会这样吗？ 幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使用Redis来缓存会话的文档。甚至广为人知的商业平台Magento也提供Redis的插件。 全页缓存（FPC）除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC。 再次以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。 此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。 队列Reids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。 如果你快速的在Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用Redis创建非常好的后端工具，以满足各种队列需求。例如，Celery有一个后台就是使用Redis作为broker，你可以从这里去查看。 排行榜/计数器Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构。 所以，我们要从排序集合中获取到排名最靠前的10个用户–我们称之为“user_scores”，我们只需要像下面一样执行即可： 当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行： ZRANGE user_scores 0 10 WITHSCORES Agora Games就是一个很好的例子，用Ruby实现的，它的排行榜就是使用Redis来存储数据的，你可以在这里看到。 发布/订阅最后（但肯定不是最不重要的）是Redis的发布/订阅功能。发布/订阅的使用场景确实非常多。我已看见人们在社交网络连接中使用，还可作为基于发布/订阅的脚本触发器，甚至用Redis的发布/订阅功能来建立聊天系统！ Redis提供的所有特性中，我感觉这个是喜欢的人最少的一个，虽然它为用户提供如果此多功能。 参考文献 https://juejin.im/entry/5b7cfe976fb9a01a13366d95?utm_source=gold_browser_extension Redis的那些最常见面试问题 java中Redis5大基本类型的用法","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"Redis","slug":"Redis","permalink":"https://www.cayzlh.com/tags/Redis/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"},{"name":"Redis","slug":"运维/Redis","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/Redis/"}]},{"title":"Spring事务管理","date":"2018-09-03T12:54:11.000Z","path":"2018/09/03/762945f0.html","text":"事务是逻辑上的一组操作，要么都执行，要么都不执行. 事务的特性(ACID) 原子性： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性： 执行事务前后，数据保持一致； 隔离性： 并发访问数据库时，一个用户的事物不被其他事物所干扰，各并发事务之间数据库是独立的； 持久性: 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 Spring事务管理接口PlatformTransactionManager： （平台）事务管理器Spring并不直接管理事务，而是提供了多种事务管理器 ，他们将事务管理的职责委托给Hibernate或者JTA等持久化机制所提供的相关平台框架的事务来实现。 Spring事务管理器的接口是： org.springframework.transaction.PlatformTransactionManager ，通过这个接口，Spring为各个平台如JDBC、Hibernate等都提供了对应的事务管理器，但是具体的实现就是各个平台自己的事情了。 PlatformTransactionManager接口中定义了三个方法： Public interface PlatformTransactionManager()...{ // Return a currently active transaction or create a new one, according to the specified propagation behavior（根据指定的传播行为，返回当前活动的事务或创建一个新事务。） TransactionStatus getTransaction(TransactionDefinition definition) throws TransactionException; // Commit the given transaction, with regard to its status（使用事务目前的状态提交事务） Void commit(TransactionStatus status) throws TransactionException; // Perform a rollback of the given transaction（对执行的事务进行回滚） Void rollback(TransactionStatus status) throws TransactionException; } Spring中PlatformTransactionManager根据不同持久层框架所对应的接口实现类 TransactionDefinition： 事务定义信息(事务隔离级别、传播行为、超时、只读、回滚规则)事务管理器接口 PlatformTransactionManager 通过 getTransaction(TransactionDefinition definition) 方法来得到一个事务，这个方法里面的参数是 TransactionDefinition类 ，这个类就定义了一些基本的事务属性。 那么什么是事务属性呢？ 事务属性可以理解成事务的一些基本配置，描述了事务策略如何应用到方法上。事务属性包含了5个方面。 TransactionDefinition接口中的方法如下： TransactionDefinition接口中定义了5个方法以及一些表示事务属性的常量比如隔离级别、传播行为等等的常量。 我下面只是列出了TransactionDefinition接口中的方法而没有给出接口中定义的常量 public interface TransactionDefinition { // 返回事务的传播行为 int getPropagationBehavior(); // 返回事务的隔离级别，事务管理器根据它来控制另外一个事务可以看到本事务内的哪些数据 int getIsolationLevel(); // 返回事务必须在多少秒内完成 //返回事务的名字 String getName()； int getTimeout(); // 返回是否优化为只读事务。 boolean isReadOnly(); } TransactionStatus： 事务运行状态TransactionStatus接口用来记录事务的状态 该接口定义了一组方法,用来获取或判断事务的相应状态信息. PlatformTransactionManager.getTransaction(…) 方法返回一个 TransactionStatus 对象。返回的TransactionStatus 对象可能代表一个新的或已经存在的事务（如果在当前调用堆栈有一个符合条件的事务）。 TransactionStatus接口接口内容如下： public interface TransactionStatus{ boolean isNewTransaction(); // 是否是新的事物 boolean hasSavepoint(); // 是否有恢复点 void setRollbackOnly(); // 设置为只回滚 boolean isRollbackOnly(); // 是否为只回滚 boolean isCompleted; // 是否已完成 } 所谓事务管理，其实就是“按照给定的事务规则来执行提交或者回滚操作”。 参考链接 https://juejin.im/post/5b00c52ef265da0b95276091","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"}]},{"title":"volatile","date":"2018-08-30T14:28:56.000Z","path":"2018/08/30/fe4c9cb6.html","text":"volatile的用法volatile通常被比喻成”轻量级的synchronized“，也是Java并发编程中比较重要的一个关键字。和synchronized不同，volatile是一个变量修饰符，只能用来修饰变量。无法修饰方法及代码块等。 volatile的用法比较简单，只需要在声明一个可能被多线程同时访问的变量时，使用volatile修饰就可以了。 public class Singleton { private volatile static Singleton singleton; private Singleton (){} public static Singleton getSingleton() { if (singleton == null) { synchronized (Singleton.class) { if (singleton == null) { singleton = new Singleton(); } } } return singleton; } } 如以上代码，是一个比较典型的使用双重锁校验的形式实现单例的，其中使用volatile关键字修饰可能被多个线程同时访问到的singleton。 volatile的原理 为了提高处理器的执行速度，在处理器和内存之间增加了多级缓存来提升。但是由于引入了多级缓存，就存在缓存数据不一致问题。 但是，对于volatile变量，当对volatile变量进行写操作的时候，JVM会向处理器发送一条lock前缀的指令，将这个缓存中的变量回写到系统主存中。 但是就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题，所以在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议 缓存一致性协议每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器要对这个数据进行修改操作的时候，会强制重新从系统内存里把数据读到处理器缓存里。 所以，如果一个变量被volatile所修饰的话，在每次数据变化之后，其值都会被强制刷入主存。而其他处理器的缓存由于遵守了缓存一致性协议，也会把这个变量的值从主存加载到自己的缓存中。这就保证了一个volatile在并发编程中，其值在多个缓存中是可见的。 volatile与可见性可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 Java内存模型规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程的工作内存中保存了该线程中是用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。所以，就可能出现线程1改了某个变量的值，但是线程2不可见的情况。 Java中的volatile关键字提供了一个功能，那就是被其修饰的变量在被修改后可以立即同步到主内存，被其修饰的变量在每次是用之前都从主内存刷新。因此，可以使用volatile来保证多线程操作时变量的可见性。 volatile对于可见性的实现，内存屏障也起着至关重要的作用。因为内存屏障相当于一个数据同步点，他要保证在这个同步点之后的读写操作必须在这个点之前的读写操作都执行完之后才可以执行。并且在遇到内存屏障的时候，缓存数据会和主存进行同步，或者把缓存数据写入主存、或者从主存把数据读取到缓存。 内存一致性模型的实现可以通过缓存一致性协议来实现。同时，留了一个问题：已经有了缓存一致性协议，为什么还需要volatile？ 1、并不是所有的硬件架构都提供了相同的一致性保证，Java作为一门跨平台语言，JVM需要提供一个统一的语义。 2、操作系统中的缓存和JVM中线程的本地内存并不是一回事，通常我们可以认为：MESI可以解决缓存层面的可见性问题。使用volatile关键字，可以解决JVM层面的可见性问题。 3、缓存可见性问题的延伸：由于传统的MESI协议的执行成本比较大。所以CPU通过Store Buffer和Invalidate Queue组件来解决，但是由于这两个组件的引入，也导致缓存和主存之间的通信并不是实时的。也就是说，缓存一致性模型只能保证缓存变更可以保证其他缓存也跟着改变，但是不能保证立刻、马上执行。 写内存屏障（Store Memory Barrier）可以促使处理器将当前store buffer（存储缓存）的值写回主存。 读内存屏障（Load Memory Barrier）可以促使处理器处理invalidate queue（失效队列）。 所以，内存屏障也是保证可见性的重要手段，操作系统通过内存屏障保证缓存间的可见性，JVM通过给volatile变量加入内存屏障保证线程之间的可见性。进而避免由于Store Buffer和Invalidate Queue的非实时性带来的问题。 内存屏障Java中的内存屏障：用于控制特定条件下的重排序和内存可见性问题。Java编译器也会根据内存屏障的规则禁止重排序。 volatile与有序性 有序性即程序执行的顺序按照代码的先后顺序执行。 除了引入了时间片以外，由于处理器优化和指令重排等，CPU还可能对输入代码进行乱序执行，比如load-&gt;add-&gt;save 有可能被优化成load-&gt;save-&gt;add 。这就是可能存在有序性问题。 而volatile除了可以保证数据的可见性之外，还有一个强大的功能，那就是他可以禁止指令重排优化等。 普通的变量仅仅会保证在该方法的执行过程中所依赖的赋值结果的地方都能获得正确的结果，而不能保证变量的赋值操作的顺序与程序代码中的执行顺序一致。 volatile可以禁止指令重排，这就保证了代码的程序会严格按照代码的先后顺序执行。这就保证了有序性。被volatile修饰的变量的操作，会严格按照代码顺序执行，load-&gt;add-&gt;save 的执行顺序就是：load、add、save。 volatile是通过内存屏障来来禁止指令重排的。 内存屏障（Memory Barrier）是一类同步屏障指令，是CPU或编译器在对内存随机访问的操作中的一个同步点，使得此点之前的所有读写操作都执行后才可以开始执行此点之后的操作。下表描述了和volatile有关的指令重排禁止行为： 可以看出： 当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。 当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。 当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。 具体实现方式是在编译期生成字节码时，会在指令序列中增加内存屏障来保证，下面是基于保守策略的JMM内存屏障插入策略： 在每个volatile写操作的前面插入一个StoreStore屏障。 对于这样的语句Store1; StoreLoad; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。 在每个volatile写操作的后面插入一个StoreLoad屏障。 对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。 在每个volatile读操作的后面插入一个LoadLoad屏障。 对于这样的语句Load1;LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。 在每个volatile读操作的后面插入一个LoadStore屏障。 对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。 所以，volatile通过在volatile变量的操作前后插入内存屏障的方式，来禁止指令重排，进而保证多线程情况下对共享变量的有序性。 volatile与原子性 原子性是指一个操作是不可中断的，要全部执行完成，要不就都不执行。 线程是CPU调度的基本单位。CPU有时间片的概念，会根据不同的调度算法进行线程调度。当一个线程获得时间片之后开始执行，在时间片耗尽之后，就会失去CPU使用权。所以在多线程场景下，由于时间片在线程间轮换，就会发生原子性问题。 synchronized提到过，为了保证原子性，需要通过字节码指令monitorenter和monitorexit，但是volatile和这两个指令之间是没有任何关系的。 所以，volatile是不能保证原子性的。 在以下两个场景中可以使用volatile来代替synchronized： 1、运算结果并不依赖变量的当前值，或者能够确保只有单一的线程会修改变量的值。 2、变量不需要与其他状态变量共同参与不变约束。 除以上场景外，都需要使用其他方式来保证原子性，如synchronized或者concurrent包。 看如下代码： public class Test { public volatile int i = 0; public void increase() { i++; } public static void main(String[] args) { final Test test = new Test(); for(int i=0;i&lt;10;i++){ new Thread(){ public void run() { for(int j=0;j&lt;1000;j++) test.increase(); }; }.start(); } while(Thread.activeCount()>1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.i); } } 以上代码比较简单，就是创建10个线程，然后分别执行1000次i++操作。正常情况下，程序的输出结果应该是10000，但是，多次执行的结果都小于10000。这其实就是volatile无法满足原子性的原因。 为什么会出现这种情况呢，那就是因为虽然volatile可以保证i在多个线程之间的可见性。但是无法保证i++的原子性。 i++操作，一共有三个步骤：load i ，add i ,save i。在多线程场景中，如果这三个步骤无法按照顺序执行的话，那么就会出现问题。 其他由于CPU按照时间片来进行线程调度的，只要是包含多个步骤的操作的执行，天然就是无法保证原子性的。因为这种线程执行，又不像数据库一样可以回滚。如果一个线程要执行的步骤有5步，执行完3步就失去了CPU了，失去后就可能再也不会被调度，这怎么可能保证原子性呢。 为什么synchronized可以保证原子性 ，因为被synchronized修饰的代码片段，在进入之前加了锁，只要他没执行完，其他线程是无法获得锁执行这段代码片段的，就可以保证他内部的代码可以全部被执行。进而保证原子性。 但是synchronized对原子性保证也不绝对，一旦代码运行异常，也没办法回滚。所以呢，在并发编程中，原子性的定义不应该和事务中的原子性一样。他应该定义为：一段代码，或者一个变量的操作，在没有执行完之前，不能被其他线程执行。 那么，为什么volatile不能保证原子性呢？因为他不是锁，他没做任何可以保证原子性的处理。当然就不能保证原子性了。","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://www.cayzlh.com/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"https://www.cayzlh.com/categories/Java/JVM/"}]},{"title":"synchronized","date":"2018-08-28T14:28:56.000Z","path":"2018/08/28/edea11bc.html","text":"Java语言为了解决并发编程中存在的原子性、可见性和有序性问题，提供了一系列和并发处理相关的关键字，比如synchronized、volatile、final、concurren包等。 在《深入理解Java虚拟机》中，有这样一段话： synchronized关键字在需要原子性、可见性和有序性这三种特性的时候都可以作为其中一种解决方案，看起来是“万能”的。的确，大部分并发控制操作都能使用synchronized来完成。 synchronized只是个关键字而已，用起来很简单。之所以我们可以在处理多线程问题时可以不用考虑太多，就是因为这个关键字帮我们屏蔽了很多细节。 本文主要介绍synchronized的用法、原理，以及如何提供原子性、可见性和有序性保障的等。 synchronized的用法synchronized是Java提供的一个并发控制的关键字。主要有两种用法，分别是同步方法和同步代码块。 也就是说，synchronized既可以修饰方法也可以修饰代码块。代码如下： public class SynchronizedDemo { //同步方法 public synchronized void doSomeThing(){ System.out.println(\"Hello World\"); } //同步代码块 public void doOtherThing(){ synchronized (SynchronizedDemo.class){ System.out.println(\"Hello World\"); } } } 被synchronized修饰的代码块及方法，在同一时间，只能被单个线程访问。 synchronized的实现原理 synchronized，是Java中用于解决并发情况下数据同步访问的一个很重要的关键字。当我们想要保证一个共享资源在同一时间只会被一个线程访问到时，我们可以在代码中使用synchronized关键字对类或者对象加锁。 我们对上面的代码进行反编译，可以得到如下代码： public class com.cayzlh.SynchronizedDemo { public com.cayzlh.SynchronizedDemo(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init>\":()V 4: return public synchronized void doSomeThing(); Code: 0: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #3 // String Hello World 5: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return public void doOtherThing(); Code: 0: ldc #5 // class com/cayzlh/SynchronizedDemo 2: dup 3: astore_1 4: monitorenter 5: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 8: ldc #3 // String Hello World 10: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 13: aload_1 14: monitorexit 15: goto 23 18: astore_2 19: aload_1 20: monitorexit 21: aload_2 22: athrow 23: return Exception table: from to target type 5 15 18 any 18 21 18 any } 可以看出： 对于同步方法，JVM采用ACC_SYNCHRONIZED标记符来实现同步。 对于同步代码块。JVM采用monitorenter、monitorexit两个指令来实现同步。 在The Java® Virtual Machine Specification中有关于同步方法和同步代码块的实现原理的介绍: Method-level synchronization is performed implicitly, as part of method invocation and return. A synchronized method is distinguished in the run-time constant pool’s methodinfo structure by the ACCSYNCHRONIZED flag, which is checked by the method invocation instructions. When invoking a method for which ACC_SYNCHRONIZED is set, the executing thread enters a monitor, invokes the method itself, and exits the monitor whether the method invocation completes normally or abruptly. During the time the executing thread owns the monitor, no other thread may enter it. If an exception is thrown during invocation of the synchronized method and the synchronized method does not handle the exception, the monitor for the method is automatically exited before the exception is rethrown out of the synchronized method. 方法级的同步是隐式的。同步方法的常量池中会有一个ACC_SYNCHRONIZED标志。当某个线程要访问某个方法的时候，会检查是否有ACC_SYNCHRONIZED，如果有设置，则需要先获得监视器锁，然后开始执行方法，方法执行之后再释放监视器锁。这时如果其他线程来请求执行方法，会因为无法获得监视器锁而被阻断住。值得注意的是，如果在方法执行过程中，发生了异常，并且方法内部并没有处理该异常，那么在异常被抛到方法外面之前监视器锁会被自动释放。 同步代码块使用monitorenter和monitorexit两个指令实现。可以把执行monitorenter指令理解为加锁，执行monitorexit理解为释放锁。 每个对象维护着一个记录着被锁次数的计数器。未被锁定的对象的该计数器为0，当一个线程获得锁（执行monitorenter）后，该计数器自增变为 1 ，当同一个线程再次获得该对象的锁的时候，计数器再次自增。当同一个线程释放锁（执行monitorexit指令）的时候，计数器再自减。当计数器为0的时候。锁将被释放，其他线程便可以获得锁。 无论是ACC_SYNCHRONIZED还是monitorenter、monitorexit都是基于Monitor实现的，在Java虚拟机(HotSpot)中，Monitor是基于C++实现的，由ObjectMonitor实现。 ObjectMonitor类中提供了几个方法，如enter、exit、wait、notify、notifyAll等。sychronized加锁的时候，会调用objectMonitor的enter方法，解锁的时候会调用exit方法。 synchronized与有序性有序性即程序执行的顺序按照代码的先后顺序执行。 由于处理器优化和指令重排等，CPU还可能对输入代码进行乱序执行，比如load-&gt;add-&gt;save 有可能被优化成load-&gt;save-&gt;add 。这就是可能存在有序性问题。 这里需要注意的是，synchronized是无法禁止指令重排和处理器优化的。也就是说，synchronized无法避免上述提到的问题。 那么，为什么还说synchronized也提供了有序性保证呢？ Java程序中天然的有序性可以总结为一句话：如果在本线程内观察，所有操作都是天然有序的。如果在一个线程中观察另一个线程，所有操作都是无序的。 以上这句话也是《深入理解Java虚拟机》中的原句，这和as-if-serial语义有关。 as-if-serial语义的意思指：不管怎么重排序（编译器和处理器为了提高并行度），单线程程序的执行结果都不能被改变。编译器和处理器无论如何优化，都必须遵守as-if-serial语义。 简单说就是，as-if-serial语义保证了单线程中，指令重排是有一定的限制的，而只要编译器和处理器都遵守了这个语义，那么就可以认为单线程程序是按照顺序执行的。当然，实际上还是有重排的，只不过我们无须关心这种重排的干扰。 所以呢，由于synchronized修饰的代码，同一时间只能被同一线程访问。那么也就是单线程执行的。所以，可以保证其有序性。 synchronized与锁优化synchronized其实是借助Monitor实现的，在加锁时会调用objectMonitor的enter方法，解锁的时候会调用exit方法。事实上，只有在JDK1.6之前，synchronized的实现才会直接调用ObjectMonitor的enter和exit，这种锁被称之为重量级锁。 所以，在JDK1.6中出现对锁进行了很多的优化，进而出现轻量级锁，偏向锁，锁消除，适应性自旋锁，锁粗化(自旋锁在1.4就有，只不过默认的是关闭的，jdk1.6是默认开启的)，这些操作都是为了在线程之间更高效的共享数据 ，解决竞争问题。","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://www.cayzlh.com/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"https://www.cayzlh.com/categories/Java/JVM/"}]},{"title":"Java内存模型的实现","date":"2018-08-28T14:15:18.000Z","path":"2018/08/28/2e82a2db.html","text":"在Java中提供了一系列和并发处理相关的关键字，比如volatile、synchronized、final、concurren包等。其实这些就是Java内存模型封装了底层的实现后提供给程序员使用的一些关键字。 什么是内存模型 ？缓存一致性问题、处理器器优化的指令重排问题是硬件的不断升级导致的。那么，有没有什么机制可以很好的解决上面的这些问题呢？ 最简单直接的做法就是废除处理器和处理器的优化技术、废除CPU缓存，让CPU直接和主存交互。但是，这么做虽然可以保证多线程下的并发问题。但是，这就有点因噎废食了。 所以，为了保证并发编程中可以满足原子性、可见性及有序性。有一个重要的概念，那就是——内存模型。 为了保证共享内存的正确性（可见性、有序性、原子性），内存模型定义了共享内存系统中多线程程序读写操作行为的规范。通过这些规则来规范对内存的读写操作，从而保证指令执行的正确性。它与处理器有关、与缓存有关、与并发有关、与编译器也有关。他解决了CPU多级缓存、处理器优化、指令重排等导致的内存访问问题，保证了并发场景下的一致性、原子性和有序性。 在开发多线程的代码的时候，可以直接使用synchronized等关键字来控制并发，从来就不需要关心底层的编译器优化、缓存一致性等问题。所以，Java内存模型，除了定义了一套规范，还提供了一系列原语，封装了底层实现后，供开发者直接使用。 原子性 在一个操作中就是cpu不可以在中途暂停然后再调度，既不被中断操作，要不执行完成，要不就不执行 在Java中，为了保证原子性，提供了两个高级的字节码指令monitorenter和monitorexit。这两个字节码，在Java中对应的关键字就是synchronized。 因此，在Java中可以使用synchronized来保证方法和代码块内的操作是原子性的。 可见性 当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值 Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值的这种依赖主内存作为传递媒介的方式来实现的。 Java中的volatile关键字提供了一个功能，那就是被其修饰的变量在被修改后可以立即同步到主内存，被其修饰的变量在每次是用之前都从主内存刷新。因此，可以使用volatile来保证多线程操作时变量的可见性。 除了volatile，Java中的synchronized和final两个关键字也可以实现可见性。只不过实现方式不同，这里不再展开了。 有序性 程序执行的顺序按照代码的先后顺序执行 在Java中，可以使用synchronized和volatile来保证多线程之间操作的有序性。实现方式有所区别： volatile关键字会禁止指令重排。synchronized关键字保证同一时刻只允许一条线程操作。 ENDsynchronized的一些记录。","tags":[{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"JVM","slug":"JVM","permalink":"https://www.cayzlh.com/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"}]},{"title":"Redis为什么这么快","date":"2018-08-25T09:16:34.000Z","path":"2018/08/25/8b544b71.html","text":"Redis简介Redis是一个开源的内存中的数据结构存储系统，它可以用作：数据库、缓存和消息中间件。 它支持多种类型的数据结构，如字符串（String），散列（Hash），列表（List），集合（Set），有序集合（Sorted Set或者是ZSet）与范围查询，Bitmaps，Hyperloglogs 和地理空间（Geospatial）索引半径查询。其中常见的数据结构类型有：String、List、Set、Hash、ZSet这5种。 Redis 内置了复制（Replication），LUA脚本（Lua scripting）， LRU驱动事件（LRU eviction），事务（Transactions） 和不同级别的磁盘持久化（Persistence），并通过 Redis哨兵（Sentinel）和自动分区（Cluster）提供高可用性（High Availability）。 Redis也提供了持久化的选项，这些选项可以让用户将自己的数据保存到磁盘上面进行存储。根据实际情况，可以每隔一定时间将数据集导出到磁盘（快照），或者追加到命令日志中（AOF只追加文件），他会在执行写命令时，将被执行的写命令复制到硬盘里面。您也可以关闭持久化功能，将Redis作为一个高效的网络的缓存数据功能使用。 Redis不使用表，他的数据库不会预定义或者强制去要求用户对Redis存储的不同数据进行关联。 数据库的工作模式按存储方式可分为：硬盘数据库和内存数据库。Redis 将数据储存在内存里面，读写数据的时候都不会受到硬盘 I/O 速度的限制，所以速度极快。 Redis为什么这么快 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)； 数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的； 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗； 使用多路I/O复用模型，非阻塞IO； 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求； 多路 I/O 复用模型多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。 这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。 采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），且 Redis 在内存中操作数据的速度非常快，也就是说内存内的操作不会成为影响Redis性能的瓶颈，主要由以上几点造就了 Redis 具有很高的吞吐量。 Redis为什么是单线程的 官方FAQ表示，因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦！）。 注1：这里我们一直在强调的单线程，只是在处理我们的网络请求的时候只有一个线程来处理，一个正式的Redis Server运行的时候肯定是不止一个线程的，这里需要大家明确的注意一下！例如Redis进行持久化的时候会以子进程或者子线程的方式执行（具体是子线程还是子进程待读者深入研究） 注2：从Redis 4.0版本开始会支持多线程的方式，但是，只是在某一些操作上进行多线程的操作！以后的版本中是否还是单线程的方式需要考证！","tags":[{"name":"Redis","slug":"Redis","permalink":"https://www.cayzlh.com/tags/Redis/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"},{"name":"Redis","slug":"运维/Redis","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/Redis/"}]},{"title":"JVM (内存区域控制参数及对应溢出异常)","date":"2018-08-19T09:16:34.000Z","path":"2018/08/19/95c0309a.html","text":"开发过程中，或程序运行过程中每次遇到OutOfMemory异常或GC异常或StackOverflowError异常我们都是一堆参数乱配，都把值调大，只是大体知道是跟jvm内存分配有关, 具体应该怎么调，对应的异常应该调整那些参数，或者换句话说，jvm内存分配区域中都分别对应那些参数大多数情况下都是不知道的，只是把相关的参数跳上去，预期结果都是应该起作用，到底能不能起作用，自己心里也没底。下面就来说一下jvm堆、栈、方法区等内存区域对应的参数，及每个区域可能抛出的异常类型，发生异常的场景分析。 参数类型 堆空间参数 栈空间参数 方法区空间参数 本机直接内存参数 异常类型 1.OutOfMemory异常 2.StackOverflowError异常 辅助参数说明 -XX:+HeapDumpOnOutOfMemoryError 打印堆内存异常时打印出快照信息 -XX:+HeapDumpPath 快照输出路径 -Xmn指定eden区的大小 -XX:SurvirorRation来调整幸存区的大小 -XX:PretenureSizeThreshold设置进入老年代的阀值 参数说明、对应场景的异常堆内存参数-Xms：堆最小值（新生代和老年代之和） -Xmx：堆最大值（新生代和老年代之和） 当最小值=最大值时，这时堆内存是不可扩展的。 例：-Xms80M -Xmx80M 通常将-Xmx和-Xms设置为一样的大小来减少gc的次数，堆内存不足时抛出OutOfMemoryError异常。 栈内存参数-Xss 例：-Xss128k 单线程下无论栈帧太大还是栈容量太小，及引用深度超过虚拟机允许深度都会抛出StackOverflowError每个方法压入栈的帧大小是不一致的。多线程下当每个线程分配栈帧太大内存不能够扩展时抛出OutOfMemoryError异常线程栈帧越大，可创建的线程越少。 方法区参数-XX:PermSize方法区内存最小值 -XX:MaxPermSize 方法区内存最大值 各个线程共享的内存区域，主要用来存储类的元数据、常量、静态变量、即时编译器编译后的代码等数据 例：-XX:PermSize=20M -XX:MaxPermSize=20M 异常类型 OutOfMemoryError : 原因：常量过多，或代理反射等使用频繁 本机直接内存参数-XX:MaxDirectMemorySize 例：-XX:MaxDirectMemorySize=10M 不足时抛出OutOfMemory异常","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://www.cayzlh.com/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"https://www.cayzlh.com/categories/Java/JVM/"}]},{"title":"JVM (垃圾收集)","date":"2018-08-19T09:16:34.000Z","path":"2018/08/19/99ebe472.html","text":"垃圾收集算法经典的垃圾回收算法以下几种： 标记–清除算法(Mark-Sweep)回收前状态： 回收后状态： 优缺点：优点：算法执行分为两个阶段标记与清除，所有的回收算法，基本都基于标记回收算法做了深度优化 缺点：效率问题，内存空间碎片（不连续的空间） 复制算法(Copying)回收前状态： Eden内存空间 8 Survivor1空间（From空间）1 Survivor2空间(To空间) 1 Eden内存空间与Survivor空间 8:1 回收后状态： Survivor1空间（From空间）1 Eden内存空间与Survivor空间 8:1 优缺点：优点比较标记清除算法，避免了回收造成的内存碎片问题 缺点：以局部的内存空间牺牲为代价，不过空间的浪费比较小，默认8:1的比例1是浪费的。复制也有一定的效率与空间成本 标记整理算法(Mark-Compact)回收前状态： 回收后状态： 优缺点：优点：避免了，空间的浪费，与内存碎片问题。 缺点：整理时复制有效率成本。​ 垃圾收集器七种垃圾收集器 1、 Serial（串行GC）-XX:+UseSerialGC 2、 ParNew（并行GC）-XX:+UseParNewGC 3、 Parallel Scavenge（并行回收GC） 4、 Serial Old（MSC）（串行GC）-XX:+UseSerialGC 5、 CMS（并发GC）-XX:+UseConcMarkSweepGC 6、 Parallel Old（并行GC）-XX:+UseParallelOldGC 7、 G1（JDK1.7update14才可以正式商用） 调优方法新对象预留新生代由于fullGC(老年代)的成本远比minorGC（新生代和老年代）的成本大，所以给应用分配一个合理的新生代空间，尽量将对象分配到新生代减小fullGC的频率 大对象进入老年代将大对象直接分配到老年代，保持新生代对象的结构的完整性，以提高GC效率， 以通过-XX:PretenureSizeThreshold设置进入老年代的阀值 稳定与震荡的堆大小稳定的对大小是对垃圾回收有利的，方法将-Xms和-Xmx的大小一致 吞吐量优先尽可能减少系统执行垃圾回收的总时间，故采用并行垃圾回收器 -XX:+UseParallelGC或使用-XX:+UseParallelOldGC 降低停顿使用CMS回收器,同时减少fullGC的次数 获取gc信息的方法 -verbose:gc或者-XX:+PrintGC 获取gc信息 -XX:+PrintGCDetails 获取更加详细的gc信息 -XX:+PrintGCTimeStamps 获取GC的频率和间隔 -XX:+PrintHeapAtGC 获取堆的使用情况 -Xloggc:D:\\gc.log 指定日志情况的保存路径 jvm调优实战-tomcat启动加速在tomcat的bin/catalina.bat文件的开头添加相关的配置","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://www.cayzlh.com/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"https://www.cayzlh.com/categories/Java/JVM/"}]},{"title":"JVM (对象访问内部实现过程)","date":"2018-08-19T09:16:34.000Z","path":"2018/08/19/e43d0ef1.html","text":"对象访问 涉及到对象的地址变更状态变更，内存地址移动，变量、接口、实现类、方法、父类型等。 句柄方式 (访问) 指针方式 (访问) 优缺点句柄访问方式：reference中存储的是稳定的地址，对象变更时只会改变句柄实例数据指针，引用本身不需要修改。 指针访问方式：优点速度快，节省了指针定位时间开销。","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://www.cayzlh.com/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"https://www.cayzlh.com/categories/Java/JVM/"}]},{"title":"JVM (虚拟机内存)","date":"2018-08-19T09:16:34.000Z","path":"2018/08/19/b8276f2d.html","text":"JAVA程序运行与虚拟机之上，运行时需要内存空间。虚拟机执行JAVA程序的过程中会把它管理的内存划分为不同的数据区域方便管理。 虚拟机管理内存数据区域划分如下图： 数据区域分类: 方法区：(Method Area) 虚拟机栈：(VM Stack) 本地方法栈 ：(Native Method Stack) 堆：(Heap) 程序计数器 ：(Program Counter Register) 直接内存：(Direct Memory) 说明： 程序计数器行号指示器，字节码指令的分支、循环、跳转、异常处理、线程恢复(CPU切换)，每条线程都需要一个独立的计数器，线程私有内存互不影响,该区域不会发生内存溢出异常。 虚拟机栈是线程私有的，声明周期与线程相同，虚拟机栈是Java方法执行的内存模型，每个方法被执行时都会创建一个栈帧，即方法运行期间的基础数据结构。栈帧用于存储：局部变量表、操作数栈、动态链接、方法出口等，每个方法执行中都对应虚拟机栈帧从入栈到处栈的过程。 是一种数据结构，是虚拟机中的局部变量表，对应物理层之上的程序数据模型。 局部变量表，是一种程序运行数据模型，存放了编译期可知的各种数据类型例如： Boolean、byte、char、short、int、float、long、double、对象引用类型(对象内存地址变量，指针或句柄)。程序运行时，根据局部变量表分配栈帧空间大小，在运行中，大小是不变的异常类型：stackOverFlowError 线程请求栈深度大于虚拟机允许深度 OutOfMemory 内存空间耗尽无法进行扩展。 本地方法栈与虚拟机栈类似，虚拟机栈为Java程序服务，本地方法栈支持虚拟机的运行服务，具体实现由虚拟机厂商决定，也会抛出 stackOverFlowError、OutOfMemory异常。 堆是虚拟机管理内存中最大的一部分，被所有线程共享，用于存放对象实例(对象、数组)，物理上不连续的内存空间，由于GC收集器，分代收集。所以划分为：新生代 Eden、From SurVivor空间、To SurVivor空间，allot buffer(分配空间)，可能会划分出多个线程私有的缓冲区，老年代。 方法区与堆一样属于线程共享的内存区域，用于存储虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码（动态加载OSGI）等数据。理论上属于java虚拟机的一部分，为了区分开来叫做 Non-Heap非堆。 这个区域可以选择不进行垃圾回收，该区域回收目的主要是常量池的回收，及类型的卸载class,内存区不足时会抛出OutOfMemory异常 运行时常量池： 方法区的一部分，Class的版本、字段、接口、方法等，及编译期生成的各种字面量、符号引用，编译类加载后存放在该区域。会抛出OutOfMemory异常。 直接内存直接内存不属于虚拟内存区域，是一种基于通道与缓冲区的IO方式，可以使用本地函数直接分配堆外内存，在堆中存储引用的外部内存地址，通过引用完成对直接引用内存的操作。1.4之后提供的NIO显著提高效率，避免了堆内存与Native内存的来回复制操作，不受虚拟机内存控制，会抛出OUtOfMemory异常。","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://www.cayzlh.com/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"https://www.cayzlh.com/categories/Java/JVM/"}]},{"title":"Tomcat的三种接收请求处理方式","date":"2018-07-06T05:56:21.000Z","path":"2018/07/06/a7d421ca.html","text":"Tomcat的三种接收请求方式处理: BIO、NIO、APR BIO模式阻塞式I/O操作，表示Tomcat使用的是传统Java I/O操作(即java.io包及其子包)。Tomcat7以下版本默认情况下是以bio模式运行的，由于每个请求都要创建一个线程来处理，线程开销较大，不能处理高并发的场景，在三种模式中性能也最低.启动tomcat看到如下日志，表示使用的是BIO模式： 06-Jul-2018 06:04:38.909 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [\"http-bio-8080\"] 06-Jul-2018 06:04:38.939 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [\"ajp-bio-8009\"] NIO是Java SE 1.4及后续版本提供的一种新的I/O操作方式(即java.nio包及其子包)。是一个基于缓冲区、并能提供非阻塞I/O操作的Java API，它拥有比传统I/O操作(bio)更好的并发运行性能。要让Tomcat以nio模式来运行比较简单，只需要在Tomcat安装目录/conf/server.xml文件中将如下配置： &lt;Connector port=\"8080\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" /> 修改成: &lt;Connector port=\"8080\" protocol=\"org.apache.coyote.http11.Http11NioProtocol\" connectionTimeout=\"20000\" redirectPort=\"8443\" /> 注意：Tomcat8以上版本，默认使用的就是NIO模式，不需要额外修改 APR模式简单理解，就是从操作系统级别解决异步IO问题，大幅度的提高服务器的处理和响应性能， 也是Tomcat运行高并发应用的首选模式。 启用这种模式稍微麻烦一些，需要安装一些依赖库: APR 1.2+ development headers (libapr1-dev package) OpenSSL 0.9.7+ development headers (libssl-dev package) JNI headers from Java compatible JDK 1.4+ GNU development environment (gcc, make) 启用APR模式步骤因为apr模式本质是使用JNI技术调用操作系统IO接口，需要用到相关API的头文件CentOS: yum install apr-devel yum install openssl-devel yum install gcc yum install make Ubuntu: sudo apt-get install libapr1 libapr1-dev sudo apt-get install openssl sudo apt-get install libssl-dev sudo apt-get install gcc sudo apt-get install make 安装apr动态库进入tomcat的bin目录，解压tomcat-native.tar.gz文件，并进入tomcat-native-1.2.7-src/native目录，执行./configure &amp;&amp; make &amp;&amp; make install 命令，动态库默认安装在/usr/local/apr/lib目录下 配置apr动态库到系统共享库搜索路径中 方式1: 设置LD_LIBRARY_PATH和LD_RUN_PATH环境变量，指向/usr/local/apr/lib目录，可配置到$HOME/.profile文件中 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/apr/lib export LD_RUN_PATH=$LD_RUN_PATH:/usr/local/apr/lib 方式2: 拷贝/usr/local/apr/lib目录下所有动态库到/usr/lib或/lib系统共享库搜索目录下即可。 cp /usr/local/apr/lib/libtcnative* /usr/lib/ 方式3(推荐): 编辑$TOMCAT_HOME/bin/catalina.sh文件，在虚拟机启动参数JAVA_OPTS中添加java.library.path参数，指定apr库的路径: JAVA_OPTS=\"$JAVA_OPTS -Djava.library.path=/usr/local/apr/lib\" Tomcat8以下版本，需要指定运行模式，将protocol从HTTP/1.1改成org.apache.coyote.http11.Http11AprProtocol 注意: 如果没有配置SSL相关参数，并且开启了SSL，启动时会发生org.apache.tomcat.jni.Error: 70023: This function has not been implemented on this platform异常。 这时: 如果不想启用SSL，将server.xml中apr模式下ssl关闭即可： 将SSLEngine的值从on改成off即可： 其他Tomcat 6.x版本从6.0.32开始就默认支持apr。Tomcat 7.x版本从7.0.30开始就默认支持apr。","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"Tomcat","slug":"Tomcat","permalink":"https://www.cayzlh.com/tags/Tomcat/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"},{"name":"Tomcat","slug":"运维/Tomcat","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/Tomcat/"}]},{"title":"Docker使用MySQL","date":"2018-06-24T13:08:37.000Z","path":"2018/06/24/38104de.html","text":"MySQL是一个广泛使用的开源关系数据库管理系统（RDBMS）。记录Docker里面使用MySQL的方法 镜像docker pull mysql 启用一个MySQL服务器实例启动一个MySQL实例很简单: docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag some-mysql您想要分配给您的容器的名称在哪里，my-secret-pw是为MySQL根用户设置的密码，是tag指定您想要的MySQL版本的标记。 这里可以加上-p参数把端口映射到主机端口: docker run --name some-mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag 这样, 就把容器的3306端口映射到宿主机器的3306端口上了, 并且可以使用Navicat等工具来连接MySQL数据库(127.0.0.1:3306). 从另一个Docker容器中的应用程序连接到MySQL该映像公开了标准的MySQL端口（3306），因此容器链接使MySQL实例可用于其他应用程序容器。像这样启动您的应用程序容器，以便将其链接到MySQL容器： docker run --name some-app --link some-mysql:mysql -d application-that-uses-mysql 从MySQL命令行客户端连接到MySQL以下命令将启动另一个MySQL容器实例，并MySQL针对原始MySQL容器运行命令行客户端，从而允许您针对数据库实例执行SQL语句： docker run -it --link some-mysql:mysql --rm mysql sh \\ -c 'exec mysql -h\"$MYSQL_PORT_3306_TCP_ADDR\" -P\"$MYSQL_PORT_3306_TCP_PORT\" \\ -uroot -p\"$MYSQL_ENV_MYSQL_ROOT_PASSWORD\"' some-mysql是你指定的MySQL容器名. 该映像也可以用作非Docker或远程MySQL实例的客户端： docker run -it --rm mysql mysql -hsome.mysql.host -usome-mysql-user -p 有关MySQL命令行客户端的更多信息可以在MySQL文档中找到 查看日志docker logs some-mysql 进入容器docker exec -it app_mysql bash ENDhttps://hub.docker.com/_/mysql/","tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cayzlh.com/tags/Docker/"},{"name":"MySQL","slug":"MySQL","permalink":"https://www.cayzlh.com/tags/MySQL/"}],"categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Docker","slug":"微服务/Docker","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/Docker/"}]},{"title":"Docker使用zookeeper","date":"2018-06-24T13:08:37.000Z","path":"2018/06/24/53a89266.html","text":"Apache ZooKeeper是一个开源的服务器，可以实现高度可靠的分布式协调。记录Docker里面使用zookeeper的方法 镜像docker pull zookeeper 启动一个Zookeeper服务器实例启动一个zookeeper实例很简单: docker run --name some-zookeeper --restart always -d zookeeper 由于Zookeeper “fails fast”，最好始终重新启动它。 这里可以加上-p参数把端口映射到主机端口: docker run --name some-zookeeper -p 2181:2181 --restart always -d zookeeper 这样, 就把容器的2181端口映射到宿主机器的2181端口上了, java程序等可以直接连接(127.0.0.1:2181) 从另一个Docker容器中的应用程序连接到Zookeeperdocker run --name some-app --link some-zookeeper:zookeeper \\ -d application-that-uses-zookeeper 从Zookeeper命令行客户端连接到Zookeeperdocker run -it --rm --link some-zookeeper:zookeeper zookeeper zkCli.sh -server zookeeper 查看日志docker logs -f e36790ea5c5e 其中e36790ea5c5e是容器的ID, 可以通过docker container ls 来查看. ENDhttps://hub.docker.com/_/zookeeper/","tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cayzlh.com/tags/Docker/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://www.cayzlh.com/tags/zookeeper/"}],"categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Docker","slug":"微服务/Docker","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/Docker/"}]},{"title":"Docker知识扫盲","date":"2018-06-23T06:50:06.000Z","path":"2018/06/23/e0ec2a44.html","text":"Docker与传统虚拟机区别容器和 VM（虚拟机）的主要区别是: 容器提供了基于进程的隔离，而虚拟机提供了资源的完全隔离。 虚拟机可能需要一分钟来启动，而容器只需要一秒钟或更短。 容器使用宿主操作系统的内核，而虚拟机使用独立的内核。 Dokcer平台的基本构成 客户端：用户使用 Docker 提供的工具（CLI 以及 API 等）来构建，上传镜像并发布命令来创建和启动容器 Docker 主机：从 Docker registry 上下载镜像并启动容器 Docker registry：Docker 镜像仓库，用于保存镜像，并提供镜像上传和下载 Docker容器的状态机一个容器在某个时刻可能处于以下几种状态之一： created：已经被创建 （使用 docker ps -a 命令可以列出）但是还没有被启动 （使用 docker ps 命令还无法列出） running：运行中 paused：容器的进程被暂停了 restarting：容器的进程正在重启过程中 exited：上图中的 stopped 状态，表示容器之前运行过但是现在处于停止状态（要区别于 created 状态，它是指一个新创出的尚未运行过的容器）。可以通过 start 命令使其重新进入 running 状态 destroyed：容器被删除了，再也不存在了 Dokcer命令把Docker的命令大概分类。 镜像操作build Build an image from a Dockerfile commit Create a new image from a container's changes images List images load Load an image from a tar archive or STDIN pull Pull an image or a repository from a registry push Push an image or a repository to a registry rmi Remove one or more images search Search the Docker Hub for images tag Tag an image into a repository save Save one or more images to a tar archive history 显示某镜像的历史 inspect 获取镜像的详细信息 容器及其中应用的生命周期操作create 创建一个容器 kill Kill one or more running containers inspect Return low-level information on a container, image or task pause Pause all processes within one or more containers ps List containers rm 删除一个或者多个容器 rename Rename a container restart Restart a container run 创建并启动一个容器 start 启动一个处于停止状态的容器 stats 显示容器实时的资源消耗信息 stop 停止一个处于运行状态的容器 top Display the running processes of a container unpause Unpause all processes within one or more containers update Update configuration of one or more containers wait Block until a container stops, then print its exit code attach Attach to a running container exec Run a command in a running container port List port mappings or a specific mapping for the container logs 获取容器的日志 容器文件系统操作cp Copy files/folders between a container and the local filesystem diff Inspect changes on a container's filesystem export Export a container's filesystem as a tar archive import Import the contents from a tarball to create a filesystem image Docker registry操作login Log in to a Docker registry. logout Log out from a Docker registry. Volume操作volume Manage Docker volumes 网络操作network Manage Docker networks Swarm相关操作swarm Manage Docker Swarm service Manage Docker services node Manage Docker Swarm nodes 系统操作version Show the Docker version information events 持续返回docker 事件 info 显示Docker 主机系统范围内的信息 容器相关# 查看运行中的容器 docker ps # 查看所有容器 docker ps -a # 退出容器 按Ctrl+D 即可退出当前容器【但退出后会停止容器】 # 退出不停止容器： 组合键：Ctrl+P+Q # 启动容器 docker start 容器名或ID # 进入容器 docker attach 容器名或ID # 停止容器 docker stop 容器名或ID # 暂停容器 docker pause 容器名或ID #继续容器 docker unpause 容器名或ID # 删除容器 docker rm 容器名或ID # 删除全部容器--慎用 docker stop $(docker ps -q) & docker rm $(docker ps -aq) #保存容器，生成镜像 docker commit 容器ID 镜像名称 #从 host 拷贝文件到 container 里面 docker cp /home/soft centos:/webapp docker run 和start的区别docker run 只在第一次运行时使用，将镜像放到容器中，以后再次启动这个容器时，只需要使用命令docker start 即可。 docker run相当于执行了两步操作：将镜像放入容器中（docker create）,然后将容器启动，使之变成运行时容器（docker start）。 docker start的作用是，重新启动已存在的镜像。也就是说，如果使用这个命令，我们必须事先知道这个容器的ID，或者这个容器的名字，我们可以使用docker ps找到这个容器的信息。 docker配置更改存储目录： #复制docker存储目录 rsync -aXS /var/lib/docker/. /home/docker #更改 docker 存储文件目录 ln -s /home/docker /var/lib/docker 获取ip： docker inspect 要获取所有容器名称及其IP地址只需一个命令： docker inspect -f '{{.Name}} - {{.NetworkSettings.IPAddress }}' $(docker ps -aq) docker inspect --format='{{.Name}} - {{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' $(docker ps -aq)","tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.cayzlh.com/tags/Docker/"}],"categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Docker","slug":"微服务/Docker","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/Docker/"}]},{"title":"Linux配置ssh使用公钥登录远程服务器","date":"2018-06-04T12:46:53.000Z","path":"2018/06/04/5d82d1e9.html","text":"起因Windows更新了Ubuntu18.04子系统, 于是就下载下来体验一波, 结果发现, 稍微设置一下, 很合我的胃口… 对我来说, 用虚拟机来做开发服务器的, 什么Vmware、VirtureBox之类的, 统统可以卸载了啊… 用了一段时间之后, 就想着, 这个界面挺不错的, 那直接拿这个来当ssh客户端好了, 什么XShell之类的也可以卸载了啊… 但是为题来, 每次使用ssh连接远程服务器, 都有输入密码, 有些密码及其复杂, 根本不可能记得住, 这咋搞, 于是乎…. 来折腾一波ssh直接连接远程服务器的配置过程… 过程安装openssh-serversudo apt-get update sudo apt-get install openssh-server 依次执行以上命令, 安装ssh服务, 通常情况下, 子系统下已经安装好了这个服务了, 那就可以忽略这一步. 生成公钥和密钥使用当前用户执行 ssh-keygen 一直安回车,生成的公钥和密钥在用户文件夹下的 ~/.ssh. cat ~/.ssh/id_rsa.pub 执行上面的命令, 将公钥的内容复制到粘贴板 在远程服务器上操作(远程服务器ssh服务装好的情况)登录远程服务器执行:vi ~/.ssh/authorized_keys 将粘贴板的内容复制到文件中,或者利用sftp工具, 将本地的id_rsa.pub上传到远程服务器,执行 cat id_rsa.pub >> ~/.ssh/authorized_keys 用vi打开/etc/ssh/sshd_config这个文件将下面几行前面“#”注释取掉 RSAAuthentication yes PubkeyAuthentication yes AuthorizedKeysFile .ssh/authorized_keys 重启ssh服务service sshd restart 本地操作在~/.ssh/中创建config文件vi ~/.ssh/config 填入如下内容: Host AAAAAA HostName youipaddress User root Port 22 IdentityFile /home/yourusername/.ssh/id_rsa 其中 Host 是别名 HostName ip地址 User 远程服务器的登录用户名 Port 远程登录的ssh端口与 IdentityFile 本地服务器的私钥地址 修改config文件的权限chmod 700 ~/.ssh/config 使用输入以下命令, 就可以直接连接远程服务器了, 其中AAAAAA是config文件中指定的Host的值… ssh AAAAAA END emmmmmmmmmmmm, Enjoy it !!","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.cayzlh.com/tags/Linux/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"}]},{"title":"SpringBoot实现Jwt单点登录","date":"2018-06-02T03:21:50.000Z","path":"2018/06/02/5d83f396.html","text":"安全管理是应用系统不可缺少的功能. 本文主要分享借助JWT的token技术实现分布式系统的安全管理. 基本概念JSON Web Tokens(JWT)是一种开放的、行业标准(RFC 7519)，用于网络应用环境间安全传递声明。JWT的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源，也可以增加一些额外的业务逻辑所须的声明信息。 JWT特点：▷ 跨语言:支持Python、Node.js、Java、Go、c、JavaScript等主流语言 ▷ 自包含：包含了必要的所有信息，如用户信息和签名等 ▷ 易传递：很方便通过HTTP头部传递 官网位置：https://jwt.io JWT原理JWT的token组成 JWT的token是三段由小数点分隔组成的字符串,如 aaaa.bbbb.ccccc，这三部分含义分别是header、payload、signature。 header头部包含了两部分：类型和使用的哈希算法（如HMAC SHA256）： { \"typ\": \"JWT\", \"alg\": \"HS256\" } payload也称为JWT claims，放置需要传输的信息，有三类：保留claims、公共claims、私有claims。 ▷ 保留claims，主要包括iss发行者、exp过期时间、sub主题、aud用户等 ▷ 公共claims，定义新创的信息，比如用户信息和其他重要信息 ▷ 私有claims，用于发布者和消费者都同意以私有的方式使用的信息 JWT示例： { \"iss\": \"jwt.io\", \"exp\": 1496199995458, \"name\": \"sinwaj\", \"role\": \"admin\" } signature 需要采用编码的header、编码的payload、secret，使用header中指定的算法进行签名。 JWT提供下述功能：▷ 某种程度的用户身份验证▷ 使用密钥签名▷ 客户端每个请求都带有JWT▷ 服务器使用密钥分析和检查claims 以上摘自公众号: 中兴开发者社区 代码实现项目地址https://github.com/cayzlh/springboot-jwt-demo 自定义Jwt登录拦截器package com.cayzlh.jwt.security.filter; import com.cayzlh.jwt.exception.BaseException; import com.cayzlh.jwt.security.dto.AuthenticationRequest; import com.cayzlh.jwt.security.jwt.JwtTokenUtil; import com.cayzlh.jwt.security.service.UserDetailsServiceImpl; import com.fasterxml.jackson.databind.ObjectMapper; import com.google.common.base.Preconditions; import com.google.common.collect.Lists; import org.apache.log4j.Logger; import org.springframework.security.authentication.AuthenticationManager; import org.springframework.security.authentication.UsernamePasswordAuthenticationToken; import org.springframework.security.core.Authentication; import org.springframework.security.core.AuthenticationException; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter; import javax.servlet.FilterChain; import javax.servlet.ServletException; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.io.IOException; /** * Description: * * &lt;p> * 验证用户名密码是否正确, 生成一个token, 并将token返回给客户端 * 该类继承自UsernamePasswordAuthenticationFilter，重写了其中的2个方法 * * attemptAuthentication ：接收并解析用户凭证。 * successfulAuthentication ：用户成功登录后，这个方法会被调用，我们在这个方法里生成token。 * &lt;/p> * * @author Ant丶 * @date 2018-05-11. */ public class LoginFilter extends UsernamePasswordAuthenticationFilter { private static final Logger logger = Logger.getLogger(LoginFilter.class); private AuthenticationManager authenticationManager; private JwtTokenUtil jwtTokenUtil; private UserDetailsServiceImpl jwtUserDetailsService; private String tokenHeader; public LoginFilter(AuthenticationManager authenticationManager, JwtTokenUtil jwtTokenUtil, UserDetailsServiceImpl jwtUserDetailsService, String tokenHeader) { this.authenticationManager = authenticationManager; this.jwtTokenUtil = jwtTokenUtil; this.jwtUserDetailsService = jwtUserDetailsService; this.tokenHeader = tokenHeader; } /** * 接收并解析用户凭证 * * @param request request * @param response response * @return * @throws AuthenticationException */ @Override public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException { try { AuthenticationRequest user = new ObjectMapper().readValue(request.getInputStream(), AuthenticationRequest.class); return authenticationManager.authenticate( new UsernamePasswordAuthenticationToken(user.getUsername(), user.getPassword(), Lists.newArrayList()) ); } catch (IOException e) { logger.error(\"[LoginFilter][attemptAuthentication()]\", e); throw new BaseException(e); } } /** * 用户成功登录后 * 这个方法会被调用, 在这里生成token * 设置到header里面返回 * * @param request request * @param response response * @param chain chain * @param authResult authResult * @throws IOException * @throws ServletException */ @Override protected void successfulAuthentication(HttpServletRequest request, HttpServletResponse response, FilterChain chain, Authentication authResult) throws IOException, ServletException { UserDetails userDetails = jwtUserDetailsService.loadUserByUsername(authResult.getName()); Preconditions.checkNotNull(userDetails); String token = jwtTokenUtil.generateToken(userDetails); response.addHeader(tokenHeader, \"Bearer \" + token); } } 自定义Jwt认证拦截器package com.cayzlh.jwt.security.filter; import com.cayzlh.jwt.security.jwt.JwtTokenUtil; import io.jsonwebtoken.ExpiredJwtException; import org.apache.commons.lang3.StringUtils; import org.apache.log4j.Logger; import org.springframework.security.authentication.AuthenticationManager; import org.springframework.security.authentication.UsernamePasswordAuthenticationToken; import org.springframework.security.core.context.SecurityContextHolder; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.web.AuthenticationEntryPoint; import org.springframework.security.web.authentication.WebAuthenticationDetailsSource; import org.springframework.security.web.authentication.www.BasicAuthenticationFilter; import javax.servlet.FilterChain; import javax.servlet.ServletException; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.io.IOException; /** * Description: * * &lt;p> * Jwt token认证拦截器 * 如果校验通过, 就认为这是一个合法的请求 * &lt;/p> * * @author Ant丶 * @date 2018-05-10. */ public class AuthorizationTokenFilter extends BasicAuthenticationFilter { private static final Logger logger = Logger.getLogger(AuthorizationTokenFilter.class); private UserDetailsService userDetailsService; private JwtTokenUtil jwtTokenUtil; private String tokenHeader; public AuthorizationTokenFilter(AuthenticationManager authenticationManager, AuthenticationEntryPoint authenticationEntryPoint, UserDetailsService userDetailsService, JwtTokenUtil jwtTokenUtil, String tokenHeader) { super(authenticationManager, authenticationEntryPoint); this.userDetailsService = userDetailsService; this.jwtTokenUtil = jwtTokenUtil; this.tokenHeader = tokenHeader; } @Override protected void doFilterInternal(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, FilterChain filterChain) throws ServletException, IOException { logger.debug(\"processing authentication for '\"+httpServletRequest.getRequestURL()+\"'\"); final String requestHeader = httpServletRequest.getHeader(this.tokenHeader); String username = null; String authToken = null; if (StringUtils.isNotBlank(requestHeader) &amp;&amp; requestHeader.startsWith(\"Bearer \")) { authToken = requestHeader.substring(7); try { username = jwtTokenUtil.getUsernameFromToken(authToken); } catch (IllegalArgumentException e) { logger.error(\"从令牌[\"+authToken+\"]获取用户名期间发生错误\", e); } catch (ExpiredJwtException e) { logger.error(\"令牌[\"+authToken+\"]已过期并且不再有效\", e); } } else { logger.debug(\"找不到Bearer字符串, 忽略Header继续.\"); } logger.debug(\"检查用户[\"+username+\"]的身份验证\"); if (StringUtils.isNotBlank(username) &amp;&amp; null == SecurityContextHolder.getContext().getAuthentication()) { logger.debug(\"security context为空, 授权用户\"); // 从数据库加载使用使用细节并不是必需的, 也可以存储信息在令牌中读取它并从中读取它. UserDetails userDetails = this.userDetailsService.loadUserByUsername(username); //对于简单的验证，仅检查令牌完整性就足够了, 不需要引人注目地调用数据库. if (jwtTokenUtil.validateToken(authToken, userDetails)) { UsernamePasswordAuthenticationToken authentication = new UsernamePasswordAuthenticationToken(userDetails, null, userDetails.getAuthorities()); authentication.setDetails(new WebAuthenticationDetailsSource().buildDetails(httpServletRequest)); logger.info(\"认证用户 [\"+username+\"], 设置 security到context上下文\"); SecurityContextHolder.getContext().setAuthentication(authentication); } } filterChain.doFilter(httpServletRequest, httpServletResponse); } } 自定义身份验证组件package com.cayzlh.jwt.security.provider; import com.cayzlh.jwt.security.dto.GrantedAuthorityImpl; import com.google.common.base.Preconditions; import org.springframework.security.authentication.AuthenticationProvider; import org.springframework.security.authentication.BadCredentialsException; import org.springframework.security.authentication.UsernamePasswordAuthenticationToken; import org.springframework.security.core.Authentication; import org.springframework.security.core.AuthenticationException; import org.springframework.security.core.GrantedAuthority; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.core.userdetails.UsernameNotFoundException; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.util.DigestUtils; import java.util.ArrayList; /** * Description: * * &lt;p> * 自定义身份验证组件 * &lt;/p> * * @author Ant丶 * @date 2018-05-11. */ public class CustomAuthenticationProvider implements AuthenticationProvider { private UserDetailsService userDetailsService; private BCryptPasswordEncoder bCryptPasswordEncoder; public CustomAuthenticationProvider(UserDetailsService userDetailsService, BCryptPasswordEncoder bCryptPasswordEncoder) { this.userDetailsService = userDetailsService; this.bCryptPasswordEncoder = bCryptPasswordEncoder; } @Override public Authentication authenticate(Authentication authentication) throws AuthenticationException { String name = authentication.getName(); String password = authentication.getCredentials().toString(); Preconditions.checkNotNull(name); Preconditions.checkNotNull(password); // TODO 重新整理逻辑 UserDetails userDetails = userDetailsService.loadUserByUsername(name); if (null != userDetails) { String encodePassword = DigestUtils.md5DigestAsHex((password).getBytes()); if (userDetails.getPassword().equalsIgnoreCase(encodePassword)) { // TODO 设置权限 ArrayList&lt;GrantedAuthority> authorities = new ArrayList&lt;>(); authorities.add( new GrantedAuthorityImpl(\"ROLE_ADMIN\") ); authorities.add( new GrantedAuthorityImpl(\"AUTH_WRITE\") ); // 生成令牌 这里令牌里面存入了:name,password,authorities, 当然你也可以放其他内容 todo 不要放密码 Authentication auth = new UsernamePasswordAuthenticationToken(name, password, authorities); return auth; } else { throw new BadCredentialsException(\"Password verification failed.\"); } } else { throw new UsernameNotFoundException(\"Username does not exist.\"); } } /** * 是否可以提供输入类型的认证服务 * * @param authentication auth * @return 是否可以提供输入类型的认证服务 */ @Override public boolean supports(Class&lt;?> authentication) { return authentication.equals(UsernamePasswordAuthenticationToken.class); } public static void main(String[] args) { String encodePassword = DigestUtils.md5DigestAsHex((\"Aa262535636@@\").getBytes()); System.out.println(encodePassword); } } 配置Security@Override protected void configure(HttpSecurity httpSecurity) throws Exception { // jwt登录拦截器 LoginFilter jwtLoginFilter = new LoginFilter(authenticationManager(), jwtTokenUtil, jwtUserDetailsService, tokenHeader); // 自定义Jwt认证拦截器 AuthorizationTokenFilter authenticationTokenFilter = new AuthorizationTokenFilter(authenticationManager(), unauthorizedHandler, userDetailsService(), jwtTokenUtil, tokenHeader); httpSecurity // 不使用CSRF .cors().and().csrf().disable() // 不创建session .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS).and() // 异常处理 .exceptionHandling().authenticationEntryPoint(unauthorizedHandler).and() .authorizeRequests() .antMatchers(HttpMethod.POST, \"/auth/**\").permitAll() .anyRequest().authenticated() .and() .addFilter(jwtLoginFilter) .addFilter(authenticationTokenFilter) .logout().logoutUrl(\"/auth/logout\") .logoutSuccessUrl(\"/auth/login\") .permitAll() ; // disable page caching httpSecurity .headers() .frameOptions().sameOrigin() // required to set for H2 else H2 Console will be blank. .cacheControl(); } 主要代码如上 测试编写一个测试的controller@RestController @RequestMapping(value = \"/jwt\") public class TestController { @RequestMapping(value = \"/test\") public String restTest() { return \"hello .\"; } } 使用Posman访问 可以看到, 直接抛出Unauthorized错误 登录获取token访问 http://localhost:8080/login, 这是security自带的登录接口, 不需要自己定义: 可以看到, 在返回的Header中多了 Authorization →Bearer eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJjaGVuYW55dSIsImV4cCI6MTU0NjA1MzExNywiaWF0IjoxNTI3OTA5MTE3fQ.N37plSdzjBMkw5BoZQWXxVA8bobdI5vPfYs5N9CZq1Y_k-LVL3WhzySJBBwjwyVeySGB8CQR0l8yJr8fbxgiFw 这样的内容, 这个就是jwt生成的token. 带上token访问test接口将token放到head的Authorization节点里面, 重新访问test接口 可以看到, 这个时候是可以正常返回结果的. 结束 JWT中的token是明文, 但是明文被签名过，签名可以使用对称或者非对称秘钥，无论使用什么秘钥，都没人知道，所以别人无法伪造。也无法修改。 不需要退出的接口, token已经授权给客户端了，有过期时间，退出的话, 只需客户端把token删掉即可. end.","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cayzlh.com/tags/SpringBoot/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"https://www.cayzlh.com/categories/Spring/SpringBoot/"}]},{"title":"SpringBoot实现Redis分布式锁","date":"2018-05-30T14:14:43.000Z","path":"2018/05/30/61b3f288.html","text":"最近项目中有用到redis实现的分布式锁, 但是胆码写起来比较繁琐, 就想着整一套注解的方式实现的分布式锁 前言分布式锁一般有三种实现方式：1. 数据库乐观锁；2. 基于Redis的分布式锁；3. 基于ZooKeeper的分布式锁。本文介绍基于Redis实现分布式锁。 为什么需要分布式锁在单机时代，虽然不需要分布式锁，但也面临过类似的问题，只不过在单机的情况下，如果有多个线程要同时访问某个共享资源的时候，我们可以采用线程间加锁的机制，即当某个线程获取到这个资源后，就立即对这个资源进行加锁，当使用完资源之后，再解锁，其它线程就可以接着使用了。例如，在JAVA中，甚至专门提供了一些处理锁机制的一些API（synchronize/Lock等）。 但是到了分布式系统的时代，这种线程之间的锁机制，就没作用了，系统可能会有多份并且部署在不同的机器上，这些资源已经不是在线程之间共享了，而是属于进程之间共享的资源。 因此，为了解决这个问题，我们就必须引入「分布式锁」。 分布式锁，是指在分布式的部署环境下，通过锁机制来让多客户端互斥的对共享资源进行访问。 分布式锁要满足哪些要求呢？ 排他性：在同一时间只会有一个客户端能获取到锁，其它客户端无法同时获取 避免死锁：这把锁在一段有限的时间之后，一定会被释放（正常释放或异常释放） 高可用：获取或释放锁的机制必须高可用且性能佳 可靠性(From)首先，为了确保分布式锁可用，我们至少要确保锁的实现同时满足以下四个条件： 互斥性。在任意时刻，只有一个客户端能持有锁。 不会发生死锁。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。 具有容错性。只要大部分的Redis节点正常运行，客户端就可以加锁和解锁。 解铃还须系铃人。加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了 原理基于Redis实现的锁机制，主要是依赖Redis自身的原子操作，例如： SET user_key user_value NX PX 100 redis从2.6.12版本开始，SET命令才支持这些参数：NX：只在在键不存在时，才对键进行设置操作，SET key value NX 效果等同于 SETNX key valuePX millisecond：设置键的过期时间为millisecond毫秒，当超过这个时间后，设置的键会自动失效 上述代码示例是指，当redis中不存在user_key这个键的时候，才会去设置一个user_key键，并且给这个键的值设置为 user_value，且这个键的存活时间为100ms 为什么这个命令可以帮我们实现锁机制呢？因为这个命令是只有在某个key不存在的时候，才会执行成功。那么当多个进程同时并发的去设置同一个key的时候，就永远只会有一个进程成功。当某个进程设置成功之后，就可以去执行业务逻辑了，等业务逻辑执行完毕之后，再去进行解锁。 解锁很简单，只需要删除这个key就可以了，不过删除之前需要判断，这个key对应的value是当初自己设置的那个。 另外，针对redis集群模式的分布式锁，可以采用redis的Redlock机制。 实现创建一个SpringBoot工程修改pom.xml文件, 添加如下依赖包: &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter&lt;/artifactId> &lt;exclusions> &lt;exclusion> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-logging&lt;/artifactId> &lt;/exclusion> &lt;/exclusions> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-log4j&lt;/artifactId> &lt;version>1.3.8.RELEASE&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-cache&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-redis&lt;/artifactId> &lt;version>1.4.7.RELEASE&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-aop&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;/dependency> &lt;/dependencies> 定义一个注解类@Target({ElementType.METHOD}) @Retention(RetentionPolicy.RUNTIME) @Inherited public @interface DistributeLock { /** * 锁的资源，key。 * 支持spring El表达式 */ @AliasFor(\"name\") String name() default \"'default'\"; /** * 锁的资源，value。 * 支持spring El表达式 */ @AliasFor(\"value\") String value() default \"'default'\"; /** * 持锁时间,单位毫秒 */ long keepMills() default 5000; /** * 当获取失败时候动作 */ LockFailAction action() default LockFailAction.CONTINUE; public enum LockFailAction{ /** 放弃 */ GIVEUP, /** 继续 */ CONTINUE; } /** * 重试的间隔时间,设置GIVEUP忽略此项 */ long sleepMills() default 200; /** * 重试次数 */ int retryTimes() default 5; } 定义接口public interface IDistributedLock { public static final long TIMEOUT_MILLIS = 5000; public static final int RETRY_TIMES = Integer.MAX_VALUE; public static final long SLEEP_MILLIS = 500; public boolean lock(String key); public boolean lock(String key, int retryTimes); public boolean lock(String key, int retryTimes, long sleepMillis); public boolean lock(String key, long expire); public boolean lock(String key, long expire, int retryTimes); public boolean lock(String key, long expire, int retryTimes, long sleepMillis); public boolean releaseLock(String key); } 定义抽象类public abstract class AbstractDistributedLockImpl implements IDistributedLock { @Override public boolean lock(String key) { return lock(key, TIMEOUT_MILLIS, RETRY_TIMES, SLEEP_MILLIS); } @Override public boolean lock(String key, int retryTimes) { return lock(key, TIMEOUT_MILLIS, retryTimes, SLEEP_MILLIS); } @Override public boolean lock(String key, int retryTimes, long sleepMillis) { return lock(key, TIMEOUT_MILLIS, retryTimes, sleepMillis); } @Override public boolean lock(String key, long expire) { return lock(key, expire, RETRY_TIMES, SLEEP_MILLIS); } @Override public boolean lock(String key, long expire, int retryTimes) { return lock(key, expire, retryTimes, SLEEP_MILLIS); } } 定义Redis分布式锁实现类public class RedisDistributedLock extends AbstractDistributedLockImpl { private static final Logger logger = getLogger(RedisDistributedLock.class); private RedisTemplate&lt;Object, Object> redisTemplate; private ThreadLocal&lt;String> lockFlag = new ThreadLocal&lt;>(); private static final String UNLOCK_LUA; private static final String SET_IF_NOT_EXIST = \"NX\"; private static final String SET_WITH_EXPIRE_TIME = \"PX\"; static { UNLOCK_LUA = \"if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\"; } public RedisDistributedLock(RedisTemplate&lt;Object, Object> redisTemplate) { super(); this.redisTemplate = redisTemplate; } @Override public boolean lock(String key, long expire, int retryTimes, long sleepMillis) { boolean result = setRedis(key, expire); // 如果获取锁失败，按照传入的重试次数进行重试 while((!result) &amp;&amp; retryTimes-- > 0){ try { logger.debug(\"lock failed, retrying...\" + retryTimes); Thread.sleep(sleepMillis); } catch (InterruptedException e) { return false; } result = setRedis(key, expire); } return result; } @Override public boolean releaseLock(String key) { // 释放锁的时候，有可能因为持锁之后方法执行时间大于锁的有效期，此时有可能已经被另外一个线程持有锁，所以不能直接删除 try { List&lt;String> keys = new ArrayList&lt;>(); keys.add(key); List&lt;String> args = new ArrayList&lt;>(); args.add(lockFlag.get()); // 使用lua脚本删除redis中匹配value的key，可以避免由于方法执行时间过长而redis锁自动过期失效的时候误删其他线程的锁 // spring自带的执行脚本方法中，集群模式直接抛出不支持执行脚本的异常，所以只能拿到原redis的connection来执行脚本 Long result = redisTemplate.execute((RedisCallback&lt;Long>) redisConnection -> { Object nativeConnection = redisConnection.getNativeConnection(); // 集群模式和单机模式虽然执行脚本的方法一样，但是没有共同的接口，所以只能分开执行 // 集群模式 if (nativeConnection instanceof JedisCluster) { return (Long) ((JedisCluster) nativeConnection).eval(UNLOCK_LUA, keys, args); } // 单机模式 else if (nativeConnection instanceof Jedis) { return (Long) ((Jedis) nativeConnection).eval(UNLOCK_LUA, keys, args); } return 0L; }); return result != null &amp;&amp; result > 0; } catch (Exception e) { logger.error(\"release lock occured an exception\", e); } finally { // 清除掉ThreadLocal中的数据，避免内存溢出 lockFlag.remove(); } return false; } private boolean setRedis(String key, long expire) { try { String result = redisTemplate.execute((RedisCallback&lt;String>) redisConnection -> { JedisCommands commands = (JedisCommands) redisConnection.getNativeConnection(); String uuid = UUID.randomUUID().toString(); lockFlag.set(uuid); return commands.set(key, uuid, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expire); }); return !StringUtils.isEmpty(result); } catch (Exception e) { logger.error(\"set redis occured an exception\", e); } return false; } } 装配DistributeLock@Configuration @AutoConfigureAfter(RedisAutoConfiguration.class) public class DistributedLockAutoConfiguration { @Bean @ConditionalOnBean(RedisTemplate.class) public IDistributedLock redisDistributedLock(RedisTemplate&lt;Object, Object> redisTemplate){ return new RedisDistributedLock(redisTemplate); } } 定义切面@Aspect @Configuration @ConditionalOnClass(IDistributedLock.class) @AutoConfigureAfter(DistributedLockAutoConfiguration.class) public class DistributedLockAspectConfiguration { private static final Logger logger = getLogger(DistributedLockAspectConfiguration.class); @Autowired private IDistributedLock distributedLock; private ExpressionParser parser = new SpelExpressionParser(); private LocalVariableTableParameterNameDiscoverer discoverer = new LocalVariableTableParameterNameDiscoverer(); /** * 定义切入点 */ @Pointcut(\"@annotation(com.cayzlh.distributedlock.annotations.DistributeLock)\") private void lockPoint() { } /** * 环绕通知 * * @param pjp pjp * @return 方法返回结果 * @throws Throwable throwable */ @Around(\"lockPoint()\") public Object around(ProceedingJoinPoint pjp) throws Throwable { Method method = ((MethodSignature) pjp.getSignature()).getMethod(); DistributeLock lockAction = method.getAnnotation(DistributeLock.class); String logKey = getLogKey(lockAction, pjp, method); int retryTimes = lockAction.action().equals(DistributeLock.LockFailAction.CONTINUE) ? lockAction.retryTimes() : 0; boolean lock = distributedLock.lock(logKey, lockAction.keepMills(), retryTimes, lockAction.sleepMills()); if (!lock) { logger.debug(\"get lock failed : \" + logKey); return null; } //得到锁,执行方法，释放锁 logger.debug(\"get lock success : \" + logKey); try { return pjp.proceed(); } catch (Exception e) { logger.error(\"execute locked method occured an exception\", e); } finally { boolean releaseResult = distributedLock.releaseLock(logKey); logger.debug(\"release lock : \" + logKey + (releaseResult ? \" success\" : \" failed\")); } return null; } /** * 获得分布式缓存的key * * @param lockAction 注解对象 * @param pjp pjp * @param method method * @return String */ private String getLogKey(DistributeLock lockAction, ProceedingJoinPoint pjp, Method method) { String name = lockAction.name(); String value = lockAction.value(); Object[] args = pjp.getArgs(); return parse(name, method, args) + \"_\" + parse(value, method, args); } /** * 解析spring EL表达式 * * @param key key * @param method method * @param args args * @return parse result */ private String parse(String key, Method method, Object[] args) { String[] params = discoverer.getParameterNames(method); if (null == params || params.length == 0 || !key.contains(\"#\")) { return key; } EvaluationContext context = new StandardEvaluationContext(); for (int i = 0; i &lt; params.length; i++) { context.setVariable(params[i], args[i]); } return parser.parseExpression(key).getValue(context, String.class); } } 配置文件server.port=8080 spring.redis.host=127.0.0.1 spring.redis.port=6379 spring.redis.jedis.pool.max-idle=8 spring.redis.jedis.pool.min-idle=0 spring.redis.jedis.pool.max-active=8 spring.redis.jedis.pool.max-wait=-1ms spring.redis.timeout=20ms spring.redis.password= 配置log4j配置文件# server默认为空 server= # 日志输出目录 logFilePath=logs log4j.rootCategory=DEBUG,stdout,debugLog,infoLog,errorLog # 控制台日志输出 log4j.logger.consoleLogger=stdout log4j.appender.stdout=org.apache.log4j.ConsoleAppender log4j.appender.stdout.Threshold=DEBUG log4j.appender.stdout.layout=org.apache.log4j.PatternLayout log4j.appender.stdout.layout.ConversionPattern=[%p] %d %c - %m%n log4j.appender.stdout.ImmediateFlush=true # debug日志输出 log4j.logger.debugLog=DEBUG, debugLog log4j.appender.debugLog=org.apache.log4j.DailyRollingFileAppender log4j.appender.debugLog.File=${logFilePath}/debug.log log4j.appender.debugLog.layout=org.apache.log4j.PatternLayout log4j.appender.debugLog.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss,SSS} %5p %c{1}:%L - %m%n log4j.appender.debugLog.DatePattern='.'yyyy-MM-dd log4j.appender.debugLog.ImmediateFlush=true log4j.appender.debugLog.Threshold=DEBUG log4j.appender.debugLog.encoding=UTF-8 log4j.appender.debugLog.filter.debugFilter=org.apache.log4j.varia.LevelRangeFilter log4j.appender.debugLog.filter.debugFilter.LevelMin=DEBUG log4j.appender.debugLog.filter.debugFilter.LevelMax=DEBUG 完源码在这.","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"Redis","slug":"Redis","permalink":"https://www.cayzlh.com/tags/Redis/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cayzlh.com/tags/SpringBoot/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"https://www.cayzlh.com/categories/Spring/SpringBoot/"}]},{"title":"SpringBoot封装JedisUtils工具类","date":"2018-05-28T14:38:23.000Z","path":"2018/05/28/dd9b08f1.html","text":"SpringBoot已经实现了很多实用的缓存组件;但是由于工作中习惯了试用JedisUtils工具类来进行缓存操作, 这里记录一下SpringBoot中对于JedisUtils的封装 操作新建一个SpringBoot项目修改pom.xml增加: &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-cache&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-redis&lt;/artifactId> &lt;version>1.4.7.RELEASE&lt;/version> &lt;/dependency> 新建JedisConfiguration.java用于配置JedisPool Beanimport org.springframework.beans.factory.annotation.Value; import org.springframework.cache.annotation.EnableCaching; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import redis.clients.jedis.JedisPool; import redis.clients.jedis.JedisPoolConfig; @Configuration @EnableCaching public class JedisConfiguration { @Value(\"${spring.redis.host}\") private String host; @Value(\"${spring.redis.port}\") private int port; @Value(\"${spring.redis.timeout}\") private String timeouts; @Value(\"${spring.redis.jedis.pool.min-idle}\") private int maxIdle; @Value(\"${spring.redis.jedis.pool.max-wait}\") private String maxWaitMilliss; @Value(\"${spring.redis.password}\") private String password; @Bean(name = \"jedisPool\") public JedisPool redisPoolFactory() { JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); jedisPoolConfig.setMaxIdle(maxIdle); long maxWaitMillis = Long.parseLong(maxWaitMilliss.replace(\"ms\", \"\")); jedisPoolConfig.setMaxWaitMillis(maxWaitMillis); int timeout = Integer.parseInt(timeouts.replace(\"ms\", \"\")); return new JedisPool(jedisPoolConfig, host, port, timeout); } } 创建JedisUtils.javaimport org.apache.log4j.Logger; import org.springframework.beans.BeansException; import org.springframework.context.ApplicationContext; import org.springframework.context.ApplicationContextAware; import redis.clients.jedis.Jedis; import redis.clients.jedis.JedisPool; import java.util.List; import java.util.Set; public class JedisUtils implements ApplicationContextAware { private static ApplicationContext applicationContext = null; private static JedisPool jedisPool = null; private static volatile Jedis jedis = null; private static Logger logger = Logger.getLogger(\"JedisUtils\"); public JedisUtils() { } @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { if (JedisUtils.applicationContext == null) { //初始化 spring applicationContext JedisUtils.applicationContext = applicationContext; } } public static Jedis getJedis() { if (jedis == null) { synchronized (Jedis.class) { if (jedis == null) { jedis = getJedisPool().getResource(); } } } return jedis; } public static JedisPool getJedisPool() { if (jedisPool == null) { synchronized (JedisPool.class) { if (jedisPool == null) { jedisPool = applicationContext.getBean(\"jedisPool\", JedisPool.class); } } } return jedisPool; } /** * 根据key查看是否存在 * * @param key * @return */ public static boolean hasKey(String key) { return getJedis().exists(key); } /** * 设置key -value 形式数据 * * @param key * @param value * @return */ public static boolean set(String key, String value) { boolean result = false; Jedis jedis = null; try { jedis = getJedis(); result = \"OK\".equals(jedis.set(key, value)); } catch (Exception e) { closeBrokenJedis(jedis); logger.error(\"JedisCache.set falid\", e); } return result; } /** * 设置 一个过期时间 * * @param key key * @param value value * @param timeOut 单位秒 * @return */ public static boolean set(String key, String value, int timeOut) { boolean result = false; Jedis jedis = null; try { jedis = getJedis(); result = \"OK\".equals(jedis.setex(key, timeOut, value)); } catch (Exception e) { closeBrokenJedis(jedis); logger.error(\"JedisCache.set falid\", e); } return result; } /** * 根据key获取value * * @param key * @return */ public static String get(String key) { String result = null; Jedis jedis = null; try { jedis = getJedis(); result = jedis.get(key); closeJedis(jedis); } catch (Exception e) { closeBrokenJedis(jedis); logger.error(\"JedisCache.get falid\", e); } return result; } /** * 根据key删除 * * @param key */ public static void del(String key) { getJedis().del(key); } } 其中的getJedisPool()可以从bean获取JedisPool对象, 用于后续的操作, 上面给出了部分代码, 完整版在这. 在springboot的主类上添加注解@SpringBootApplication @EnableCaching @Import({JedisUtils.class, JedisPool.class}) public class DemoApplication { public static void main(String[] args) { SpringApplication.run(DemoApplication.class, args); } } 结束至此, 就可以愉快的使用JedisUtils直接操作Redis缓存了.","tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cayzlh.com/tags/SpringBoot/"}],"categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"https://www.cayzlh.com/categories/Spring/SpringBoot/"}]},{"title":"记录Linux安装Nginx全过程","date":"2018-05-27T14:01:12.000Z","path":"2018/05/27/4ba42594.html","text":"本文记录在Linux下安装Nginx的全过程. 操作因为yum安装只是一条命令的事情, 这里只记录源码安装的方法 : 首先安装缺少的依赖包 yum -y install gcc gcc-c++ make libtool zlib zlib-devel openssl openssl-devel pcre pcre-devel 下载 wget http://nginx.org/download/nginx-1.10.1.tar.gz 解压缩： tar -zxvf nginx-1.10.1.tar.gz 配置安装 ./configure --prefix=/usr/local/nginx --with-http_ssl_module --prefix=/usr/local/nginx：指定安装目录 --with-http_ssl_module：开启SSL模块 进入解压后的目录执行 make && make install 进入到sbin目录启动nginx /usr/local/path/nginx/sbin/nginx 相关配置 用vi命令打开usr/local/path/nginx/conf/nginx.conf, 在底部添加include /usr/local/path/nginx/conf.d/*.conf;. 往后所有的配置都放到/usr/local/path/nginx/conf.d/下, 方便管理 参考xxx.websitename.conf : server { listen 80; server_name xxx.websitename.com; rewrite ^(.*)$ https://$host$1 permanent; # 强制转发http到https, 没有证书则不需要配置 } server { listen 443 ssl; # https监听, 没有证书则改成80 server_name argo.cayzlh.cn; ssl_certificate /usr/local/path/nginx/cert/111.pem; # https证书配置, 没有则注释掉 ssl_certificate_key /usr/local/path/nginx/cert/111.key; # https证书配置, 没有则注释掉 ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location ~ / { proxy_set_header Host argo.cayzlh.cn; proxy_set_header X-Real-IP $http_x_forwarded_for; proxy_set_header X-Forwarded-For $http_x_forwarded_for; proxy_pass http://websitename.service; } } upstream.conf : upstream websitename.service { server 127.0.0.1:11200 weight=10; } 以上配置表示, 将xxx.websitename.com映射到服务器的https端口上, 并且做了强制http转https的配置； 其他请求头header支持下划线配置underscores_in_headers on underscores_in_headers 默认值是off，会把header里面的下划线拦截，设置为on解决。","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.cayzlh.com/tags/Linux/"},{"name":"nginx","slug":"nginx","permalink":"https://www.cayzlh.com/tags/nginx/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"}]},{"title":"记录Linux安装Redis全过程","date":"2018-05-27T13:58:22.000Z","path":"2018/05/27/28cbd204.html","text":"本文记录在Linux下安装Redis的全过程. 使用linux wget命令下载源码 wget http://download.redis.io/releases/redis-3.0.0.tar.gz 解压源码 tar -zxvf redis-3.0.0.tar.gz 进入解压后的目录进行编译 cd ./redis-3.0.0 安装到指定目录 如 /usr/local/redis make PREFIX=/usr/local/redis install redis.conf是redis的配置文件，redis.conf在redis源码目录, 将其拷贝到安装目录下 cd /usr/local/redis mkdir conf cp /usr/local/redis-3.0.0/redis.conf /usr/local/redis/conf 前端启动Redis直接运行bin/redis-server将以前端模式启动，前端模式启动的缺点是ssh命令窗口关闭则redis-server程序结束，不推荐使用此方法 ./redis-server 后端启动Redis修改redis.conf配置文件， daemonize yes 以后端模式启动 执行如下命令启动redis cd /usr/local/redis ./bin/redis-server ./redis.conf","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"Redis","slug":"Redis","permalink":"https://www.cayzlh.com/tags/Redis/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"},{"name":"Redis","slug":"运维/Redis","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/Redis/"}]},{"title":"记录Linux安装Mysql全过程","date":"2018-05-27T13:41:45.000Z","path":"2018/05/27/8c40be27.html","text":"Linux上安装Mysql其实并没有什么好说的, 只需要照着Mysql官网的步骤一步步来就可以了;这里记录一下操作步骤 操作流程下载在官网下载对应的rpm包 mysql57-community-release-el6-n.noarch.rpm, 并放到Linux的任意目录里; 执行以下语句sudo rpm -Uvh mysql57-community-release-el6-n.noarch.rpm 启用MySQL5.7修改/etc/yum.repos.d/mysql-community.repo 文件来选择一个系列, 这里选择的是 MySQL 5.7 Community Server, 将enabled的值设为1; 验证是否已启用和禁用正确的子库yum repolist enabled | grep mysql 通过以下命令安装Mysql :sudo yum install mysql-community-server 这将安装MySQL服务器的软件包以及其他必需的软件包 通过以下命令启动Mysql :sudo service mysqld start 显示root用户的密码超级用户帐户‘root’@’localhost’ 已创建。超级用户的密码被设置并存储在错误日志文件中。要显示它，请使用以下命令： sudo grep 'temporary password' /var/log/mysqld.log 自定义root用户密码通过使用生成的临时密码登录并尽快更改root密码并为超级用户帐户设置自定义密码: mysql -uroot -pxxxxx ALTER USER 'root'@'localhost' IDENTIFIED BY 'MyNewPass4!' 其中xxxxx为查看到的密码 允许root用户远程登录 :grant all privileges on *.* to root@'%' identified by \"MyNewPass4\"; 如果是mysql8.0的话, 则执行 : grant all privileges on *.* to root@'%' 其他鬼操作MySQL命令行创建 用户与授权. MySQL8.0的一些坑在SpringBoot中使用pom包的配置在SpringBoot中使用mysql8.0的话， 需要引入以下配置： &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;version>8.0.13&lt;/version> &lt;/dependency> application配置文件配置数据库驱动配置： spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver 数据库连接配置需要加上： ?useSSL=false&amp;serverTimezone=UTC","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cayzlh.com/tags/MySQL/"},{"name":"Linux","slug":"Linux","permalink":"https://www.cayzlh.com/tags/Linux/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"}]},{"title":"Tomcat单机多实例部署","date":"2018-05-27T00:50:02.000Z","path":"2018/05/27/50538a7f.html","text":"前言 单机多实例部署tomcat, 可以充分利用系统资源, 周期性地更新Tomcat，使用最新版的Tomcat, 统一管理，让Tomcat版本统一, 实例的配置统一. 本文介绍Linux下Tomcat单机多实例的部署步骤. 实现四路1、Tomcat运行时，系统会从conf及webapps目录中读取配置文件，并且写入logs、temp和work目录中2、一些jar文件和class文件需要从公共目录例如lib/中加载，只需要加载一次就可以。3、为了多个实例能同时运行，每一个Tomcat实例必须有自己的目录集 传统实现方式：简单的复制出一个新的Tomcat目录后改一下端口缺点：1、资源浪费，公用资源被多次加载，造成在内存中不必要的重用2、针对不同web服务做配置能做但是异常麻烦3、对Tomcat进行版本升级时能做但是异常麻烦，每个目录都需要替换，不必要的大量工作 实现步骤下载并解压安装包到目录cd /usr/local/path/tomcat 编辑 /etc/profile 文件sudo vi /etc/profile 添加Tomcatexport CATALINA_HOME=/usr/local/path/tomcat/apache-tomcat-7.0.85 以上代码添加到profile中 将在 /data/service/中创建两个实例文件夹cd /data/service mkdir tomcat1 mkdir tomcat2 tomcat的配置文件复制到实例文件夹内cd tomcat1/ cp -a /usr/local/path/tomcat/* ./ rm -rf lib/ bin/ cd .. cp -a tomcat1/* tomcat2/ cd /usr/local/path/tomcat rm -rf work/ webapps/ logs/ conf/ 此时/usr/local/path/tomcat 内剩下文件为: bin/, lib/;两个实例文件夹中剩下的文件为; work/ webapps/ logs/ conf/ 创建运行脚本cd /data/service/tomcat1 mkdir bin cd bin/ touch startup.sh touch shutdown.sh 编辑startup.sh和shutdown.shstartup.sh : #!/bin/bash export CATALINA_BASE=/data/service/tomcat1 echo $CATALINA_BASE TOMCAT_ID=`ps aux |grep \"java\"|grep \"Dcatalina.base=$CATALINA_BASE \"|grep -v \"grep\"|awk '{ print $2}'` if [ -n \"$TOMCAT_ID\" ] ; then echo \"tomcat(${TOMCAT_ITOMCAT_ID}) still running now , please shutdown it firest\"; exit 2; fi TOMCAT_START_LOG=`$CATALINA_HOME/bin/startup.sh` if [ \"$?\" = \"0\" ]; then echo \"$0 ${1%/} start succeed\" else echo \"$0 ${1%/} start failed\" echo $TOMCAT_START_LOG fi shutdown.sh : rt CATALINA_BASE=/data/service/tomcat-1 echo $CATALINA_BASE TOMCAT_ID=`ps aux |grep \"java\"|grep \"[D]catalina.base=$CATALINA_BASE \"|awk '{ print $2}'` if [ -n \"$TOMCAT_ID\" ] ; then TOMCAT_STOP_LOG=`$CATALINA_HOME/bin/shutdown.sh` else echo \"Tomcat instance not found : ${1%/}\" exit fi if [ \"$?\" = \"0\" ]; then echo \"$0 ${1%/} stop succeed\" else echo \"$0 ${1%/} stop failed\" echo $TOMCAT_STOP_LOG fi 至此, 单机多实例的tomcat已经基本上配置好了. 运行: /data/service/tomcat1/bin/startup.sh 即可. 当然, 要运行两个以上实例的话, 还得配置 server.xml, 这里就不讨论了. 两个tomcat实例运行起来之后, 可以看到2个tomcat实例的PID是不同的，也就是说对某个实例进行操作是不会影响到另外一个实例的.","tags":[{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"Tomcat","slug":"Tomcat","permalink":"https://www.cayzlh.com/tags/Tomcat/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"},{"name":"Tomcat","slug":"运维/Tomcat","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/Tomcat/"}]},{"title":"Mybatis Generator自定义插件","date":"2018-05-26T01:29:36.000Z","path":"2018/05/26/8ab70c16.html","text":"使用Mybatis就一定离不开MyBatis Generator这款代码生成插件，而这款插件自身还提供了插件拓展功能用于强化插件本身，官方已经提供了一些拓展插件，本文介绍通过该插件机制来强化Mybatis Generator本身，方便和减少我们平时的代码开发量。项目地址: https://github.com/cayzlh/mybatis-mbg-plugins 直接引入, 在pom.xml的相应节点中添加:&lt;dependencies> &lt;dependency> &lt;groupId>com.cayzlh&lt;/groupId> &lt;artifactId>plugins&lt;/artifactId> &lt;version>1.0&lt;/version> &lt;/dependency> &lt;/dependencies> &lt;repositories> &lt;repository> &lt;id>cayzlh-mvn-repo&lt;/id> &lt;name>cayzlh-mvn-repo&lt;/name> &lt;url>https://raw.github.com/cayzlh/mavenRepository/master/repository&lt;/url> &lt;/repository> &lt;/repositories> 或者, 下载代码, 编译后install到本地仓库 MBG的具体用法及配置文件等, 这里不做阐述, 查看 MBG官方文档 即可.提供一个参考配置模板: generatorConfig.xml 在项目中使用在pom.xml 中添加:&lt;build> &lt;defaultGoal>install&lt;/defaultGoal> &lt;plugins> &lt;plugin> &lt;groupId>org.mybatis.generator&lt;/groupId> &lt;artifactId>mybatis-generator-maven-plugin&lt;/artifactId> &lt;version>1.3.6&lt;/version> &lt;configuration> &lt;configurationFile>src/main/resources/mybatis-generator/generatorConfig.xml&lt;/configurationFile> &lt;verbose>true&lt;/verbose> &lt;overwrite>true&lt;/overwrite> &lt;/configuration> &lt;executions> &lt;execution> &lt;id>Generate MyBatis Artifacts&lt;/id> &lt;goals> &lt;goal>generate&lt;/goal> &lt;/goals> &lt;/execution> &lt;/executions> &lt;dependencies> &lt;dependency> &lt;groupId>org.mybatis.generator&lt;/groupId> &lt;artifactId>mybatis-generator-core&lt;/artifactId> &lt;version>1.3.6&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;version>5.1.31&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>com.cayzlh&lt;/groupId> &lt;artifactId>plugins&lt;/artifactId> &lt;version>1.0&lt;/version> &lt;/dependency> &lt;/dependencies> &lt;/plugin> &lt;/plugins> &lt;/build> 生成代码在idea的maven管理界面找到插件, 右键 - run. 然后, 生成的代码就到了你指定的目录了. 使用效果Model/** * Description: * 用来测试mbg * * Table: * t_demo * * @author Ant丶 * @mbg.generated */ public class Demo implements Serializable { /** * Description: * ID * * Column: * t_demo.id * * @mbg.generated */ private Long id; /** * Description: * 邮箱 * * Column: * t_demo.email * * @mbg.generated */ private String email; /** * * Column: * t_demo.phone * * @mbg.generated */ private String phone; /** * * Column: * t_demo.createTime * * @mbg.generated */ private Date createtime; /** * * Column: * t_demo.updateTime * * @mbg.generated */ private Date updatetime; .... } mapper.javapublic interface DemoMapper { /** * Description: 使用Example统计总数 * * @param example example * @return countByExample 的结果. * @mbg.generated */ long countByExample(DemoExample example); /** * Description: 根据Example删除 * * @param example example * @return deleteByExample 的结果. * @mbg.generated */ int deleteByExample(DemoExample example); /** * Description: 根据主键删除 * * @param id id * @return deleteByPrimaryKey 的结果. * @mbg.generated */ int deleteByPrimaryKey(Long id); /** * Description: 插入一条记录 * * @param record record * @return insert 的结果. * @mbg.generated */ int insert(Demo record); /** * Description: 插入一条记录, 实现选择入库 * * @param record record * @return insertSelective 的结果. * @mbg.generated */ int insertSelective(Demo record); /** * Description: 根据Example查询返回数据 * * @param example example * @return selectByExample 的结果. * @mbg.generated */ List&lt;Demo> selectByExample(DemoExample example); /** * Description: 查询结果选择性返回 * * @param example example * @param selective selective * @return selectByExampleSelective 的结果. * @mbg.generated */ List&lt;Demo> selectByExampleSelective(@Param(\"example\") DemoExample example, @Param(\"selective\") Demo.Column ... selective); /** * Description: 根据主键查询返回数据 * * @param id id * @return selectByPrimaryKey 的结果. * @mbg.generated */ Demo selectByPrimaryKey(Long id); /** * Description: 通过主键查询的结果选择性返回 * * @param id id * @param selective selective * @return selectByPrimaryKeySelective 的结果. * @mbg.generated */ Demo selectByPrimaryKeySelective(@Param(\"id\") Long id, @Param(\"selective\") Demo.Column ... selective); /** * Description: Selective选择插入更新增强功能 * * @param record record * @param example example * @return updateByExampleSelective 的结果. * @mbg.generated */ int updateByExampleSelective(@Param(\"record\") Demo record, @Param(\"example\") DemoExample example); /** * Description: 根据Example更新数据 * * @param record record * @param example example * @return updateByExample 的结果. * @mbg.generated */ int updateByExample(@Param(\"record\") Demo record, @Param(\"example\") DemoExample example); /** * Description: 根据主键更新数据, 可选择 * * @param record record * @return updateByPrimaryKeySelective 的结果. * @mbg.generated */ int updateByPrimaryKeySelective(Demo record); /** * Description: 根据主键更新数据 * * @param record record * @return updateByPrimaryKey 的结果. * @mbg.generated */ int updateByPrimaryKey(Demo record); /** * Description: 查询单条数据 * * @param example example * @return selectOneByExample 的结果. * @mbg.generated */ Demo selectOneByExample(DemoExample example); /** * Description: 查询单条数据字段选择性返回 * * @param example example * @param selective selective * @return selectOneByExampleSelective 的结果. * @mbg.generated */ Demo selectOneByExampleSelective(@Param(\"example\") DemoExample example, @Param(\"selective\") Demo.Column ... selective); /** * Description: 批量插入 * * @param list list * @return batchInsert 的结果. * @mbg.generated */ int batchInsert(@Param(\"list\") List&lt;Demo> list); /** * Description: 可选择字段批量插入 * * @param list list * @param selective selective * @return batchInsertSelective 的结果. * @mbg.generated */ int batchInsertSelective(@Param(\"list\") List&lt;Demo> list, @Param(\"selective\") Demo.Column ... selective); /** * Description: 存在即更新(saveOrUpdate) * * @param record record * @return upsert 的结果. * @mbg.generated */ int upsert(Demo record); /** * Description: 存在即更新, 可选字段(saveOrUpdate) * * @param record record * @return upsertSelective 的结果. * @mbg.generated */ int upsertSelective(Demo record); } 使用Demo链式调用Demo demo = new Demo.Builder() .email(\"243689185@qq.com\") .phone(\"13800138000\") .build(); Example使用DemoExample example = new DemoExample() .createCriteria() .andIdEqualTo(1l) .example(); 以上","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cayzlh.com/tags/MySQL/"}],"categories":[{"name":"框架","slug":"框架","permalink":"https://www.cayzlh.com/categories/%E6%A1%86%E6%9E%B6/"},{"name":"MyBatis","slug":"框架/MyBatis","permalink":"https://www.cayzlh.com/categories/%E6%A1%86%E6%9E%B6/MyBatis/"}]},{"title":"Linux开发环境搭建","date":"2018-03-29T15:14:26.000Z","path":"2018/03/29/375f8f1e.html","text":"最近阿里云推出优惠活动, 99元一年的服务器, 一口气整了三年, 这里记录一下Linux下的各种环境搭建. 服务器安全 由于root用户的权限过于大, 所以要做一些处理, 让服务器更安全一些. 修改SSH远程登录端口SSH 端口默认是22. 但从安全方面考虑，建议修改这个端口。 端口的取值范围是 0-65535(即2的16次方)，0到1024是系统使用的端口，如 http服务的端口80。我们可以使用的端口范围：1024到65535。这个是socket规定的. 修改端口配置文件vim /etc/ssh/ssh_config vim /etc/ssh/sshd_config 将两个配置文件中的Prot端口改为65535, 当然也可以修改为自己喜欢的端口. 重启sshd服务service sshd restart 此时在用SSH连接，就需要修改ssh 的端口为6535才能连接了。 添加一个用户添加一个用户, 用于远程登录: 创建普通权限的用户 useradd username 修改密码 passwd username 需要注意的是, 用户的密码需要满足密码规则. 禁用root用户远程登录vim /etc/ssh/sshd_config 把 PermitRootLogin yes 改为 PermitRootLogin no, 然后重启Service: service sshd restart Java去官网下载对应系统版本的jdk, 解压到 /usr/local/path/java; 配置环境变量 : vim /etc/profile 在最底下添加 : JAVA_HOME=/usr/local/path/java/jdk1.7.0_80 CLASSPATH=.:$JAVA_HOME/lib/tools.jar PATH=$JAVA_HOME/bin:$PATH export JAVA_HOME CLASSPATH PATH 让环境变量生效 : source /etc/profile 验证Java是否配置成功 : java -version MysqlLinux上安装Mysql其实并没有什么难度, 只需要照着Mysql官网的步骤一步步来就可以了; 在官网下载对应的rpm包 mysql57-community-release-el6-n.noarch.rpm, 并放到Linux的任意目录里; 执行以下语句 :sudo rpm -Uvh mysql57-community-release-el6-n.noarch.rpm 修改/etc/yum.repos.d/mysql-community.repo 文件来选择一个系列, 这里选择的是 MySQL 5.7 Community Server, 将enabled的值设为1; 验证是否已启用和禁用正确的子库 :yum repolist enabled | grep mysql 通过以下命令安装Mysql :sudo yum install mysql-community-server 这将安装MySQL服务器的软件包以及其他必需的软件包 通过以下命令启动Mysql :sudo service mysqld start 超级用户帐户‘root’@’localhost’ 已创建。超级用户的密码被设置并存储在错误日志文件中。要显示它，请使用以下命令：sudo grep 'temporary password' /var/log/mysqld.log 通过使用生成的临时密码登录并尽快更改root密码并为超级用户帐户设置自定义密码: mysql -uroot -pxxxxx ALTER USER 'root'@'localhost' IDENTIFIED BY 'MyNewPass4!' 其中xxxxx为查看到的密码 Redis 使用linux wget命令下载源码wget http://download.redis.io/releases/redis-3.0.0.tar.gz 解压源码tar -zxvf redis-3.0.0.tar.gz 进入解压后的目录进行编译cd ./redis-3.0.0 安装到指定目录 如 /usr/local/redismake PREFIX=/usr/local/redis install redis.conf是redis的配置文件，redis.conf在redis源码目录, 将其拷贝到安装目录下cd /usr/local/redis mkdir conf cp /usr/local/redis-3.0.0/redis.conf /usr/local/redis/conf 前端启动Redis直接运行bin/redis-server将以前端模式启动，前端模式启动的缺点是ssh命令窗口关闭则redis-server程序结束，不推荐使用此方法./redis-server 后端启动Redis修改redis.conf配置文件， daemonize yes 以后端模式启动 执行如下命令启动rediscd /usr/local/redis ./bin/redis-server ./redis.conf Nginx因为yum安装只是一条命令的事情, 这里只记录源码安装的方法 : 首先安装缺少的依赖包yum -y install gcc gcc-c++ make libtool zlib zlib-devel openssl openssl-devel pcre pcre-devel 下载wget http://nginx.org/download/nginx-1.10.1.tar.gz 解压缩：tar -zxvf nginx-1.10.1.tar.gz 配置安装 ./configure --prefix=/usr/local/nginx --with-http_ssl_module --prefix=/usr/local/nginx：指定安装目录 --with-http_ssl_module：开启SSL模块 进入解压后的目录执行 make && make install 进入到sbin目录启动nginx /usr/local/path/nginx/sbin/nginx","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.cayzlh.com/tags/Linux/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"}]},{"title":"Linux搭建Git服务器","date":"2017-05-13T01:04:03.000Z","path":"2017/05/13/43f0b02.html","text":"Ubuntu环境搭建Git服务器 第一步，安装gitsudo apt-get install git第二步，创建一个git用户sudo adduser git第三步，创建证书登录客户端在命令行中输入以下指令生成ssh key： ssh-keygen -t rsa -C &quot;your_email@example.com&quot;收集所有需要登录的用户的公钥，就是他们自己的id_rsa.pub文件，把所有公钥导入到/home/git/.ssh/authorized_keys文件里，一行一个。 第四步，初始化Git仓库先选定一个目录作为Git仓库，假定是/srv/sample.git，在/srv目录下输入命令： $ sudo git init --bare sample.git第五步，禁用shell登录出于安全考虑，第二步创建的git用户不允许登录shell，这可以通过编辑/etc/passwd文件完成。找到类似下面的一行： git:x:1001:1001:,,,:/home/git:/bin/bash改为： git:x:1001:1001:,,,:/home/git:/usr/bin/git-shell这样，git用户可以正常通过ssh使用git，但无法登录shell，因为我们为git用户指定的git-shell每次一登录就自动退出。 第六步，克隆远程仓库：现在，可以通过git clone命令克隆远程仓库了，在各自的电脑上运行： $ git clone git@server:/srv/sample.git Cloning into &#39;sample&#39;... warning: You appear to have cloned an empty repository.剩下的推送就简单了。 其他如果没有装ssh服务，则需要安装ssh服务，不然无法正常使用git glone 指令 安装sshd： sudo apt-get install openssh-server启动sshd： sudo net start sshd检查防火墙设置，关闭防火墙 sudo ufw disable运行以下代码查看是否有sshd进程 ps -e|grep ssh 管理公钥如果团队很小，把每个人的公钥收集起来放到服务器的/home/git/.ssh/authorized_keys文件里就是可行的。如果团队有几百号人，就没法这么玩了，这时，可以用Gitosis来管理公钥。 这里我们不介绍怎么玩Gitosis了，几百号人的团队基本都在500强了，相信找个高水平的Linux管理员问题不大。 管理权限有很多不但视源代码如生命，而且视员工为窃贼的公司，会在版本控制系统里设置一套完善的权限控制，每个人是否有读写权限会精确到每个分支甚至每个目录下。因为Git是为Linux源代码托管而开发的，所以Git也继承了开源社区的精神，不支持权限控制。不过，因为Git支持钩子（hook），所以，可以在服务器端编写一系列脚本来控制提交等操作，达到权限控制的目的。Gitolite就是这个工具。 这里我们也不介绍Gitolite了，不要把有限的生命浪费到权限斗争中。 小结 搭建Git服务器非常简单，通常10分钟即可完成； 要方便管理公钥，用Gitosis； 要像SVN那样变态地控制权限，用Gitolite。","tags":[{"name":"Git","slug":"Git","permalink":"https://www.cayzlh.com/tags/Git/"},{"name":"Linux","slug":"Linux","permalink":"https://www.cayzlh.com/tags/Linux/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"},{"name":"Git","slug":"运维/Git","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/Git/"}]},{"title":"Linux常用命令整理","date":"2017-04-12T14:39:48.000Z","path":"2017/04/12/f42d2759.html","text":"防火墙问题重启后永久性生效 开启：chkconfig iptables on 关闭：chkconfig iptables off 即时生效 开启：service iptables start 关闭：service iptables stop 解压tar –xvf file.tar //解压 tar包tar -xzvf file.tar.gz //解压tar.gztar -xjvf file.tar.bz2 //解压 tar.bz2tar –xZvf file.tar.Z //解压tar.Zunrar e file.rar //解压rarunzip file.zip //解压zip 查询并删除find /data/xxx/ -name spring-2.5.6.SEC03.jar | xargs rm -rf 清除10天以上的日志find /data/program/nginx/logs/ -type f -atime +10 | xargs rm -rf 第3000行开始，显示1000行。即显示3000~3999行cat filename | tail -n +3000 | head -n 1000 显示1000行到3000行cat filename| head -n 3000 | tail -n +1000 用sed命令sed -n &#39;5,10p&#39; filename 这样你就可以只查看文件的第5行到第10行。 查看某一进程产生的线程数ps hH p 3531 |wc -l 把文件夹权限授权给别的用户chown -R username:groupname /data/* 未完待续","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.cayzlh.com/tags/Linux/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"}]},{"title":"MySQL命令行创建用户与授权","date":"2017-03-25T15:30:18.000Z","path":"2017/03/25/3cd82c29.html","text":"创建用户命令：create user username identified by password; 说明：username–你创建的用户名， password–该用户的登录密码，登录密码可以为空，如果是空则表示该用户可以不需要密码登录服务器。 示例：[sql]view plain copy CREATE USER user1 IDENTIFIED BY a1234; 授权命令:GRANT privileges ON databasename.tablename TO username; 说明:privileges——用户的操作权限,如SELECT , INSERT , UPDATE 等，如果要授予所有的权限则使用ALL.;databasename——数据库名；tablename——表名,如果要授予该用户对所有数据库和表的相应操作权限则可用表示, 如.*. 示例: [sql] view plain copyGRANT SELECT, INSERT,UPDATE ON test.user TO wgv;GRANT ALL ON *.* TO ; 注意:用以上命令授权的用户不能给其它用户授权,如果想让该用户可以授权,用以下命令: GRANT privileges ONdatabasename.tablename TO WITH GRANT OPTION; 授权后还要刷新系统权限表：[sql] view plain copyflush privileges;","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cayzlh.com/tags/MySQL/"}],"categories":[{"name":"笔记本","slug":"笔记本","permalink":"https://www.cayzlh.com/categories/%E7%AC%94%E8%AE%B0%E6%9C%AC/"}]},{"title":"关于tomcat的一些笔记","date":"2017-03-25T13:25:21.000Z","path":"2017/03/25/147f8f4e.html","text":"关于tomcat 在web开发中经常要用到tomcat来部署运行项目等等，以下是关于使用tomcat的一些记录。 一台电脑装多个Tomcat时需要修改的端口&lt;Serverport=\"8005\" shutdown=\"SHUTDOWN\" > &lt;Connectorport=\"8080\" protocol=\"HTTP/1.1 connectionTimeout=\"20000\" redirectPort=\"8443\"/> &lt;Connectorport=\"8009\" protocol=\"AJP/1.3\"redirectPort=\"8443\" /> ​ tomcat部署项目的方法第一种方法在tomcat中的conf目录中，在server.xml中的&lt;host&gt;&lt;/host&gt;节点中添加: &lt;Context path=\"/helloword\" docBase=\"….\\WebRoot\" debug=\"0\" privileged=\"true\">&lt;/Context> 第二种方法将web项目文件拷贝到webapps目录中 第三种方法在conf目录中，在Catalina\\localhost目录，新建一个xml文件，名字任意取，只要和当前文件中的文件名不重复就行，xml文件的内容 &lt;?xml version=\"1.0\" encoding=\"utf-8\"?> &lt;Context docBase=\"E:\\project\\iportal\\ips\\WebRoot\" debug=\"1\" reloadable=\"false\">&lt;/Context> XML的名字为项目的访问路径名，如 xml的名字为 test.xml 则访问路径为 http://localhost:8080/test 将解压版的tomcat配置成服务一、注册为Windows系统服务： 运行cmd打开控制台，进入Tomat目录/bin文件夹，会看到service.bat输入如下命令运行。 service install 服务名称 这一句是将当前Tomcat服务器注册为系统服务，服务名称为service.bat中PR_DISPLAYNAME加上指定的服务名称， 如果服务名不写则服务名为service.bat文件中的 PR_DISPLAYNAME加上SERVICE_NAME 二、让注册的服务随系统启动： 开始- 运行 输入services.msc 或者图形界面进入Windows服务，找到刚刚注册的服务项 右键-属性-启动类型设置为自动,然后启动该服务，点击应用。 三、卸载服务 运行cmd打开控制台，进入Tomat目录/bin文件夹 service uninstall 服务名 四、控制台控制服务的命令 1.启动服务 net Start 服务名 2.关闭服务 net stop 服务名 内存溢出的处理（不是所有场景有效）D:\\apache-tomcat-7.0.41\\bin 修改文件catalina.bat 在第一行增加如下代码： set JAVA_OPTS= -Xms1024m -Xmx1024m -XX:PermSize=512M -XX:PermSize=512M 其他1 多个Tomcat要分配不同的端口，可以再%TOMCAT_HOME%\\conf中的service.xml中修改 2 可以修改 service.bat 文件来更改一些默认配置。 3 如果服务名中包含空格或者中文，请将服务名用半角双引号包含起来。 4 批处理中设置服务为自动 sc config %SERVICE_NAME% start= auto 设置环境变量 set JAVA_HOME=d:/Program Files/Java/jdk1.6.0_02 setCATALINA_HOME=D:/tomcat6","tags":[{"name":"Tomcat","slug":"Tomcat","permalink":"https://www.cayzlh.com/tags/Tomcat/"}],"categories":[{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"},{"name":"Tomcat","slug":"运维/Tomcat","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/Tomcat/"}]}],"categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cayzlh.com/categories/SpringBoot/"},{"name":"书籍","slug":"书籍","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/"},{"name":"《Elasticsearch权威指南》","slug":"书籍/《Elasticsearch权威指南》","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/%E3%80%8AElasticsearch%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97%E3%80%8B/"},{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Docker","slug":"微服务/Docker","permalink":"https://www.cayzlh.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/Docker/"},{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/categories/Java/"},{"name":"《MyBatis技术内幕》","slug":"书籍/《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"},{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/categories/Spring/"},{"name":"Maven","slug":"Java/Maven","permalink":"https://www.cayzlh.com/categories/Java/Maven/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"https://www.cayzlh.com/categories/Spring/SpringBoot/"},{"name":"框架","slug":"框架","permalink":"https://www.cayzlh.com/categories/%E6%A1%86%E6%9E%B6/"},{"name":"MyBatis","slug":"框架/MyBatis","permalink":"https://www.cayzlh.com/categories/%E6%A1%86%E6%9E%B6/MyBatis/"},{"name":"《Spring源码分析》","slug":"Spring/《Spring源码分析》","permalink":"https://www.cayzlh.com/categories/Spring/%E3%80%8ASpring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%8B/"},{"name":"运维","slug":"运维","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/"},{"name":"Redis","slug":"运维/Redis","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/Redis/"},{"name":"笔记本","slug":"笔记本","permalink":"https://www.cayzlh.com/categories/%E7%AC%94%E8%AE%B0%E6%9C%AC/"},{"name":"Java设计模式","slug":"Java/Java设计模式","permalink":"https://www.cayzlh.com/categories/Java/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"雕虫小技","slug":"雕虫小技","permalink":"https://www.cayzlh.com/categories/%E9%9B%95%E8%99%AB%E5%B0%8F%E6%8A%80/"},{"name":"SpringCloud","slug":"Spring/SpringCloud","permalink":"https://www.cayzlh.com/categories/Spring/SpringCloud/"},{"name":"Git","slug":"运维/Git","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/Git/"},{"name":"《深入理解Java虚拟机》","slug":"书籍/《深入理解Java虚拟机》","permalink":"https://www.cayzlh.com/categories/%E4%B9%A6%E7%B1%8D/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B/"},{"name":"JVM","slug":"Java/JVM","permalink":"https://www.cayzlh.com/categories/Java/JVM/"},{"name":"Tomcat","slug":"运维/Tomcat","permalink":"https://www.cayzlh.com/categories/%E8%BF%90%E7%BB%B4/Tomcat/"}],"tags":[{"name":"转载","slug":"转载","permalink":"https://www.cayzlh.com/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cayzlh.com/tags/SpringBoot/"},{"name":"Docker","slug":"Docker","permalink":"https://www.cayzlh.com/tags/Docker/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://www.cayzlh.com/tags/elasticsearch/"},{"name":"Consul","slug":"Consul","permalink":"https://www.cayzlh.com/tags/Consul/"},{"name":"Java","slug":"Java","permalink":"https://www.cayzlh.com/tags/Java/"},{"name":"MyBatis","slug":"MyBatis","permalink":"https://www.cayzlh.com/tags/MyBatis/"},{"name":"《MyBatis技术内幕》","slug":"《MyBatis技术内幕》","permalink":"https://www.cayzlh.com/tags/%E3%80%8AMyBatis%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B/"},{"name":"核心处理层","slug":"核心处理层","permalink":"https://www.cayzlh.com/tags/%E6%A0%B8%E5%BF%83%E5%A4%84%E7%90%86%E5%B1%82/"},{"name":"Spring, SpringBoot","slug":"Spring-SpringBoot","permalink":"https://www.cayzlh.com/tags/Spring-SpringBoot/"},{"name":"Maven","slug":"Maven","permalink":"https://www.cayzlh.com/tags/Maven/"},{"name":"Spring","slug":"Spring","permalink":"https://www.cayzlh.com/tags/Spring/"},{"name":"设计模式","slug":"设计模式","permalink":"https://www.cayzlh.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"源码学习","slug":"源码学习","permalink":"https://www.cayzlh.com/tags/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"name":"死磕Spring","slug":"死磕Spring","permalink":"https://www.cayzlh.com/tags/%E6%AD%BB%E7%A3%95Spring/"},{"name":"基础支持层","slug":"基础支持层","permalink":"https://www.cayzlh.com/tags/%E5%9F%BA%E7%A1%80%E6%94%AF%E6%8C%81%E5%B1%82/"},{"name":"Redis","slug":"Redis","permalink":"https://www.cayzlh.com/tags/Redis/"},{"name":"消息队列","slug":"消息队列","permalink":"https://www.cayzlh.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Gson","slug":"Gson","permalink":"https://www.cayzlh.com/tags/Gson/"},{"name":"SonarQube","slug":"SonarQube","permalink":"https://www.cayzlh.com/tags/SonarQube/"},{"name":"concurrent","slug":"concurrent","permalink":"https://www.cayzlh.com/tags/concurrent/"},{"name":"markdown","slug":"markdown","permalink":"https://www.cayzlh.com/tags/markdown/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://www.cayzlh.com/tags/SpringCloud/"},{"name":"微服务","slug":"微服务","permalink":"https://www.cayzlh.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://www.cayzlh.com/tags/rabbitmq/"},{"name":"easyexcel","slug":"easyexcel","permalink":"https://www.cayzlh.com/tags/easyexcel/"},{"name":"Linux","slug":"Linux","permalink":"https://www.cayzlh.com/tags/Linux/"},{"name":"Git","slug":"Git","permalink":"https://www.cayzlh.com/tags/Git/"},{"name":"MySQL","slug":"MySQL","permalink":"https://www.cayzlh.com/tags/MySQL/"},{"name":"JVM","slug":"JVM","permalink":"https://www.cayzlh.com/tags/JVM/"},{"name":"《深入理解Java虚拟机》","slug":"《深入理解Java虚拟机》","permalink":"https://www.cayzlh.com/tags/%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B/"},{"name":"Tomcat","slug":"Tomcat","permalink":"https://www.cayzlh.com/tags/Tomcat/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://www.cayzlh.com/tags/zookeeper/"},{"name":"nginx","slug":"nginx","permalink":"https://www.cayzlh.com/tags/nginx/"}]}